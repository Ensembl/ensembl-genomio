{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ensembl GenomIO","text":"<p>A repository dedicated to pipelines used to turn basic genomic data into formatted  Ensembl core databases. Also allow users to dump core databases into various formats.</p> <p>File formats handled : FastA, GFF3, JSON (following BRC4 specifications).</p>"},{"location":"#contents","title":"Contents","text":"<p>Check out installation section for further information on how  to install the project.</p> <ol> <li>Install</li> <li>Usage</li> <li>Code of Conduct</li> <li>Code reference</li> </ol>"},{"location":"#ehive-pipelines","title":"Ehive pipelines","text":"<p>Check out the usage section for further information of requirements to run ensembl-genomio pipelines.</p> <ol> <li>Genome loader: Creates an Ensembl core database from a set of flat files.</li> <li>Genome dumper: Dumps flat files from an Ensembl core database.</li> </ol>"},{"location":"#nextflow-pipelines","title":"Nextflow pipelines","text":"<ol> <li>Additional seq prepare: BRC/Ensembl metazoa pipeline. Preparation of genome data loading files for new sequence(s) to existing species databases.  </li> <li>Genome Prepare: BRC/Ensembl metazoa pipeline. Retrieve data for genome(s), obtained from INSDC and RefSeq, validate and prepare GFF3, FASTA, JSON files for each genome accession.</li> </ol>"},{"location":"#license","title":"License","text":"<p>Software as part of Ensembl GenomIO is distributed under the Apache-2.0 License.</p>"},{"location":"BRC4_genome_compare_conf/","title":"Compare genomes pipeline","text":"<p>MODULE: Bio::EnsEMBL::Pipeline::PipeConfig::BRC4_genome_compare_conf</p>"},{"location":"BRC4_genome_compare_conf/#overview","title":"Overview","text":"<p>This pipeline is used for a sequence-level comparison of an assembly with INSDC and provides a detailed report on the discrepancies. The following steps are performed:</p> <ol> <li>Download the files for the corresponding assembly from INSDC</li> <li>Retrieve metadata seq.json and fasta files from the database</li> <li>Compare the fasta files<ul> <li>compare the sequence ids</li> <li>compare the sequence </li> <li>MD5 check of the files</li> <li>identify organellar sequences in both assemblies</li> </ul> </li> <li>Report the results</li> </ol>"},{"location":"BRC4_genome_compare_conf/#prerequisites","title":"Prerequisites","text":"<p>A registry file to connect to the database.</p>"},{"location":"BRC4_genome_compare_conf/#example-of-how-to-create-the-pipeline","title":"Example of how to create the pipeline","text":"<pre><code>init_pipeline.pl Bio::EnsEMBL::Pipeline::PipeConfig::BRC4_genome_compare_conf \\\n  --host $HOST --port $PORT --user $USER --pass $PASS \\\n  --registry $REGISTRY \\\n  --hive_force_init 1 \\\n  --output_dir $OUTPUT_DIR \\\n  --tmp_dir temp/compare \\\n  --species acanthamoeba_astronyxis_gca000826245\n</code></pre>"},{"location":"BRC4_genome_compare_conf/#parameters","title":"PARAMETERS","text":"Options Type Default value Mandatory Description <code>--registry</code> file yes service that connects to the database <code>--pipeline_name</code> str brc4_genome_compare optional name of the hive pipeline <code>--hive_force_init</code> int yes drop and create the hive pipeline from scratch <code>--output_dir</code> dir ./output optional directory to store the result <code>--tmp_dir</code> dir ./tmp optional temp directory for downloaded files <code>--species</code> str yes species (one or multiple) to process (production name) <code>--run_all</code> int 0 yes process all the species in the registry <code>--email</code> str $USER.ebi.ac.uk optional a summary is emailed when the pipeline is complete <p>Note: Either use <code>--species</code> to run one or multiple species separately or <code>--run_all 1</code> for all the species in the database. Currently this pipeline is only used to compare with Genbank assembly. </p>"},{"location":"BRC4_genome_compare_conf/#result","title":"RESULT","text":"<p>Generates 3 files:   - report.log: A tab-delimited file containing a summary of the compared sequences between the INSDC assembly/assemblies and the database(s)     - The report contains 13 columns:        - species: name of the species        - accession: GCA accession       - seq_count_1: total number of sequences in INSDC       - seq_count_2: total number of sequences in the database       - num_diff_seq: the total number of sequences that differ between INSDC and the database       - common: the total number of common sequences between INSDC and the database       - only1: count of sequences found only in INSDC       - only2: count of sequences found only in the database       - max_only1: a total of the sequence length in only1       - max_only2: a total of the sequence length in only2       - other_locations: the total count of organellar genomes        - summary (mismatch or identical)       - organellar_summary</p> <ul> <li>species_fasta_dna.map: A JSON schema file containing metadata of the common sequences</li> <li>species_fasta_dna.log: Detailed report of mismatched sequences</li> </ul>"},{"location":"BRC4_genome_loader/","title":"BRC4 genome loader","text":""},{"location":"BRC4_genome_loader/#brc4_genome_loader","title":"BRC4_genome_loader","text":""},{"location":"BRC4_genome_loader/#module-bioensemblpipelinepipeconfigbrc4_genome_loader_conf","title":"Module: Bio::EnsEMBL::Pipeline::PipeConfig::BRC4_genome_loader_conf","text":"<p>Creates an Ensembl core database from a set of flat files or adds ad-hoc (i.e. organellas) sequences to the existing core.</p>"},{"location":"BRC4_genome_loader/#prerequisites","title":"Prerequisites","text":"<p>A registry file with the locations of the core database server(s) and the production database (or <code>-production_db $PROD_DB_URL</code> specified).</p>"},{"location":"BRC4_genome_loader/#how-to-run","title":"How to run","text":"<pre><code># REP_LIB_OPT= # or whatever\n\ninit_pipeline.pl Bio::EnsEMBL::EGPipeline::PipeConfig::NOTDNAFeatures_conf \\\n  $($CMD details script) \\\n  -registry $REG_FILE \\\n  -production_db \"$($PROD_SERVER details url)\"\"$PROD_DBNAME\" \\\n  -hive_force_init 1\\\n  -pipeline_tag \"_${SPECIES_TAG}\" \\\n  -pipeline_dir $OUT_DIR \\\n  -species $SPECIES \\\n  -redatrepeatmasker 0 \\\n  -always_use_repbase 1 \\\n  -repeatmasker_timer '10H' \\\n  $REP_LIB_OPT \\\n  -repeatmasker_repbase_species \"$REPBASE_SPECIES_NAME\" \\\n  -max_seq_length 300000 \\\n  2&gt; $OUT_DIR/init.stderr \\\n  1&gt; $OUT_DIR/init.stdout\n\nSYNC_CMD=$(cat $OUT_DIR/init.stdout | grep -- -sync'$' | perl -pe 's/^\\s*//; s/\"//g')\n# should get something like\n#   beekeeper.pl -url $url -sync\n\nLOOP_CMD=$(cat $OUT_DIR/init.stdout | grep -- -loop | perl -pe 's/^\\s*//; s/\\s*#.*$//; s/\"//g')\n# should get something like\n#   beekeeper.pl -url $url -reg_file $REG_FILE -loop\n\n$SYNC_CMD 2&gt; $OUT_DIR/sync.stderr 1&gt; $OUT_DIR/sync.stdout\n$LOOP_CMD 2&gt; $OUT_DIR/loop.stderr 1&gt; $OUT_DIR/loop.stdout\n</code></pre>"},{"location":"BRC4_genome_loader/#parameters-options","title":"Parameters / Options","text":"option default value meaning <code>-division</code> division (intersection with registry) to be processed <code>-species</code> species to process, several <code>-species</code> options are possible <code>-pipeline_dir</code> directory to store results to"},{"location":"BRC4_genome_loader/#notes","title":"Notes","text":"<p>2nd mode for adding</p>"},{"location":"BRC4_genome_loader/#input-data","title":"Input data","text":""},{"location":"BRC4_genome_loader/#parts","title":"Parts","text":""},{"location":"BRC4_genome_loader/#runnables","title":"Runnables","text":""},{"location":"BRC4_genome_loader/#configuration-files","title":"Configuration files","text":"<p>xref map</p>"},{"location":"cicd_gitlab/","title":"Cicd gitlab","text":""},{"location":"cicd_gitlab/#gitlab-cicd-pipelines","title":"Gitlab CI/CD pipelines","text":""},{"location":"cicd_gitlab/#location-cicdgitlab","title":"Location cicd/gitlab","text":"<p>Some Gitlab based CI/CD helper pipelines</p>"},{"location":"cicd_gitlab/#description","title":"Description","text":""},{"location":"cicd_gitlab/#setup","title":"Setup","text":"<p>0) Import your GitHub project from GitLab. See this Gitlab documentation.</p> <p>1) Enable \"Require status checks to pass before merging\"? in \"Settings\"/\"Branch protection rules\" section for the \"main\" branch.</p> <p>2) Get repo</p> <p>3) Create (if you need)  cicd/gitlab folders, add configs. We use cicd/gitlab/dot.gitlab-ci.yml for this repo instead the default one (see below).</p> <p>4) Edit settings for CI/CD [General pipelines] expand Set \"CI/CD configuration file\" to cicd/gitlab/dot.gitlab-ci.yml Click [Save changes] at the end of this small section</p> <p>5) Enable runners [General pipelines] expand [Runners] expand Pick \"Shared runners\"</p> <p>6) Customize email settings Like it's stated on the official documentation:</p> <ul> <li>Go to Settings &gt; Integrations &gt; Pipeline status emails.</li> <li>Edit Recipients (a comma-separated list of email addresses)</li> <li>Select Notify only broken pipelines</li> <li>Select the branches</li> <li>Save</li> </ul>"},{"location":"cicd_gitlab/#a-few-notes-on-style","title":"A few notes on style","text":"<ul> <li> <p>We suggest separating logic for running various parts into separate pipelines and using different <code>trigger</code> jobs to invoke these pipelines. As for now we have cicd/gitlab/parts/ folder for these needs.</p> </li> <li> <p>Feel free to use external pipelines (as <code>trigger</code> jobs) or other parts from GitLab templates. Though for pipelines, please, add </p> </li> </ul> <pre><code>  trigger:\n    ...\n    forward:\n      pipeline_variables: false\n      yaml_variables: false\n...\n</code></pre> <p>to your trigger jobs whenever possible.</p> <ul> <li> <p>We're trying to use <code>:</code> decided \"namespace\" qualifiers for stage and job names.</p> </li> <li> <p>Feel free to use template/generic jobs with names starting from <code>.</code> and <code>extends</code> keyword (see <code>extends</code> description</p> </li> </ul>"},{"location":"code_of_conduct/","title":"Code of Conduct","text":"<p>The Ensembl project is built on a foundation of collaboration, mutual respect and equality with a diverse and global community. We do not condone discrimination or abusive behaviour of any form. We encourage participation and engagement for everyone, in a professional manner, and wish all members of our community to adhere to the same principles.</p>"},{"location":"genome_prepare/","title":"Genome prepare","text":""},{"location":"genome_prepare/#genomio-prepare-pipeline","title":"Genomio prepare pipeline","text":""},{"location":"genome_prepare/#module-bioensemblpipelinepipeconfigbrc4_genome_prepare_conf","title":"Module [Bio::EnsEMBL::Pipeline::PipeConfig::BRC4_genome_prepare_conf]","text":"<p>Genome prepare pipeline for BRC/Metazoa.</p>"},{"location":"genome_prepare/#description","title":"Description","text":"<p>Retrieve data for a genome from INSDC and prepare the following files in a separate folder for each genome:</p> <ul> <li>FASTA for DNA sequences</li> <li>FASTA for protein sequences</li> <li>GFF gene models</li> <li>JSON functional annotation</li> <li>JSON seq_region</li> <li>JSON genome</li> <li>JSON manifest</li> </ul> <p>The JSON files follow the schemas defined in the <code>src/python/ensembl/io/genomio/data/schemas</code> folder.</p> <p>These files can then be fed to the Genome loader pipeline.</p>"},{"location":"genome_prepare/#how-to-run","title":"How to run","text":"<pre><code>init_pipeline.pl Bio::EnsEMBL::Pipeline::PipeConfig::BRC4_genome_prepare_conf \\\n    --host $HOST --port $PORT --user $USER --pass $PASS \\\n    --hive_force_init 1 \\\n    --pipeline_dir temp/prepare \\\n    --data_dir $INPUT \\\n    --output_dir $OUTPUT \\\n    ${OTHER_OPTIONS}\n</code></pre>"},{"location":"genome_prepare/#parameters","title":"Parameters","text":"option default value meaning <code>--pipeline_name</code> brc4_genome_prepare name of the hive pipeline <code>--pipeline_dir</code> temp directory for this pipeline run <code>--data_dir</code> directory with json files for each genome to prepare, following the format set by <code>src/python/ensembl/io/genomio/data/schemas/genome.json</code> <code>--output_dir</code> directory where the prepared files are to be stored <code>--merge_split_genes</code> 0 Sometimes the gene features are split in a gff file. Ensembl expects genes to be contiguous, so this option merge the parts into 1. <code>--exclude_seq_regions</code> Do not include those seq_regions (apply to all genomes, this should be seldom used) <code>--validate_gene_id</code> 0 Enforce a strong gene ID pattern (replace by GeneID if available) <code>--ensembl_mode</code> 0 By default, set additional metadata for BRC genomes. With this parameter, use vanilla Ensembl metadata."},{"location":"install/","title":"Installation","text":"<p>GenomIO is now publicly available in PyPI, so you can easily install it with your preferred Python package manager, e.g.</p> <pre><code>pip install ensembl-genomio\n</code></pre>"},{"location":"install/#api-setup-and-installation","title":"API setup and installation","text":"<p>To run also the pipelines present in the repository, you will need to have Perl 5.26 and Bioperl 1.6.9+ installed in your system, and then clone the GitHub repository together with some other repositories:</p> <pre><code>git clone https://github.com/Ensembl/ensembl-genomio\ngit clone https://github.com/Ensembl/ensembl-analysis -b dev/hive_master\ngit clone https://github.com/Ensembl/ensembl-production\ngit clone https://github.com/Ensembl/ensembl-hive\ngit clone https://github.com/Ensembl/ensembl-taxonomy\ngit clone https://github.com/Ensembl/ensembl-orm\n</code></pre>"},{"location":"install/#documentation","title":"Documentation","text":"<p>Documentation for Ensembl-genomio generated using mkdocs. For full information visit mkdocs.org.</p> <p>Useful commands: * <code>mkdocs new [dir-name]</code> - Create a new project * <code>mkdocs serve</code> - Start the live-reloading docs server * <code>mkdocs build</code> - Build the documentation site * <code>mkdocs -h</code> - Print help message and exit</p>"},{"location":"nextflow/","title":"Nextflow related documentation","text":""},{"location":"nextflow/#installation","title":"Installation","text":"<p>If you do not have an installed environment or you don't have nextflow itself, here is one of the ways to install it.</p> <p>Define <code>NXF_HOME</code> env variable to use a nextflow home location instead of the default one (<code>$HOME/.nextflow</code>). Everything else is unchanged from the default Nextflow installation instructions on https://www.nextflow.io/index.html#GetStarted.</p> <pre><code># add NXF_HOME env\nexport NXF_HOME=$(pwd)/dot.nextflow # or whatever\n\n# get nextflow and install almost like here: https://www.nextflow.io/index.html#GetStarted\nwget -O - https://get.nextflow.io  &gt; nextflow.install.bash\n\n# review and run\ncat nextflow.install.bash | bash -i 2&gt;&amp;1 | tee nextflow.install.log\n\n# run test, see https://www.nextflow.io/index.html#GetStarted\n./nextflow run hello\n</code></pre> <p>Configure the environment you are using if you have not done so yet. Don't forget to add <code>NXF_HOME</code>, patch <code>PATH</code> and export them.</p> <pre><code># fix env variables, i.e.:\nexport NXF_HOME=$(pwd)/dot.nextflow\nexport PATH=$(pwd):$PATH\n</code></pre> <p>If you wish, you can set <code>NXF_WORK</code> env to be used by <code>nextflow</code>.</p> <pre><code>export NXF_WORK=...\n</code></pre> <p>Or use <code>nextflow -e.NXF_WORK=...</code> approach. Ideally, should be overridable by the <code>-work-dir</code> (<code>-w</code>) option of <code>nextflow run</code></p>"},{"location":"nextflow/#running-a-pipeline","title":"Running a pipeline","text":"<p>Once you have production (and nextflow) env ready, you can run pipelines. I.e.</p> <pre><code>CMD=&lt;dba_alias&gt;\n\nmkdir -p data\npushd data\n  data_dir=$(pwd)\n  nextflow run \\\n    -w ${data_dir}/nextflow_work \\\n    ${ENSEMBL_ROOT_DIR}/ensembl-genomio/pipelines/nextflow/workflows/dumper_pipeline/main.nf \\\n    -profile lsf \\\n    $(${CMD} details script) \\\n    --dbname_re '^drosophila_melanogaster_\\w+_57_.*$' \\\n    --output_dir ${data_dir}/dumper_output\npopd\n</code></pre> <p>Try to invoke pipelines with <code>--help</code> option to get insight on how to run them.</p>"},{"location":"nextflow/#strange-things-we-met","title":"Strange things we met","text":""},{"location":"nextflow/#channel-is-not-forked-only-one-operation-on-stream-is-allowed","title":"Channel is not forked, only one operation on stream is allowed","text":""},{"location":"nextflow/#symptoms","title":"Symptoms:","text":"<p>When running a stage or a subworkflow on a channel with a single element we expect stream to be forked, allowing us to seed several task at a time.</p> <pre><code>// create that channel with a single element\n//   calls read_json(...) in turn, see below\ndbs = from_read_json(...)\n\nDUMP_SQL(..., dbs, ...)\nDUMP_METADATA(..., dbs, ...)\n</code></pre> <p>Instead pipeline dies with</p> <pre><code>Caused by: Cannot load from object array because \"this.keys\" is null\n</code></pre> <p>and when printing this object (<code>dbs</code> in this case, with <code>println \"db: ${db}\"</code>), we see it dict surrounded by the curly brackets like this</p> <pre><code>{..., \"db_name\":\"some_db_name\", ...}\n</code></pre> <p>instead of this (with square brackets)</p> <pre><code>[..., \"db_name\":\"some_db_name\", ...]\n</code></pre>"},{"location":"nextflow/#reason-solution","title":"Reason / solution","text":"<p>In our case we used the <code>read_json</code> function similar to this one:</p> <pre><code>def read_json(json_path) {\n    slurp = new JsonSlurper()\n    json_file = file(json_path)\n    text = json_file.text\n    return slurp.parseText(text) // &lt;-- problem here\n}\n</code></pre> <p>that returned some kind of a lazy evaluator/iterator/whatever(not sure).</p> <p>Replacing <code>return slurp.parseText(text)</code> with</p> <pre><code>    not_a_lazy_val = slurp.parseText(text)\n    return not_a_lazy_val\n</code></pre> <p>did help.</p>"},{"location":"pipelines/","title":"Ensembl Genomio Pipelines:","text":""},{"location":"pipelines/#genomio-prepare-pipeline","title":"Genomio prepare pipeline","text":"<p>Module [Bio::EnsEMBL::Pipeline::PipeConfig::BRC4_genome_prepare_conf]</p> <p>Genome prepare pipeline for BRC/Metazoa</p>"},{"location":"pipelines/#description","title":"Description","text":"<p>Retrieve data for a genome from INSDC and prepare the following files in a separate folder for each genome:</p> <ul> <li>FASTA for DNA sequences</li> <li>FASTA for protein sequences</li> <li>GFF gene models</li> <li>JSON functional annotation</li> <li>JSON seq_region</li> <li>JSON genome</li> <li>JSON manifest</li> </ul> <p>The JSON files follow the schemas defined in the <code>src/python/ensembl/io/genomio/data/schemas</code> folder.</p> <p>These files can then be fed to the Genome loader pipeline.</p>"},{"location":"pipelines/#how-to-run","title":"How to run","text":"<pre><code>init_pipeline.pl Bio::EnsEMBL::Pipeline::PipeConfig::BRC4_genome_prepare_conf \\\n    --host $HOST --port $PORT --user $USER --pass $PASS \\\n    --hive_force_init 1 \\\n    --pipeline_dir temp/prepare \\\n    --data_dir $INPUT \\\n    --output_dir $OUTPUT \\\n    ${OTHER_OPTIONS}\n</code></pre>"},{"location":"pipelines/#parameters","title":"Parameters","text":"option default value meaning <code>--pipeline_name</code> brc4_genome_prepare name of the hive pipeline <code>--pipeline_dir</code> temp directory for this pipeline run <code>--data_dir</code> directory with json files for each genome to prepare, following the format set by <code>src/python/ensembl/io/genomio/data/schemas/genome.json</code> <code>--output_dir</code> directory where the prepared files are to be stored <code>--merge_split_genes</code> 0 Sometimes the gene features are split in a gff file. Ensembl expects genes to be contiguous, so this option merge the parts into 1. <code>--exclude_seq_regions</code> Do not include those seq_regions (apply to all genomes, this should be seldom used) <code>--validate_gene_id</code> 0 Enforce a strong gene ID pattern (replace by GeneID if available) <code>--ensembl_mode</code> 0 By default, set additional metadata for BRC genomes. With this parameter, use vanilla Ensembl metadata."},{"location":"trf_split_run/","title":"trf_split_run.bash","text":"<p>A trf wrapper with chunking support to be used with ensembl-production-imported DNAFeatures pipeline Compatible compatible with input/output format of trf invocation from Bio::EnsEMBL::Analysis::Runnable::TRF. And can be used as a hack to allow TRF stage to be accomplished at the cost of splitting  long repeat into several adjacent ones  (with possible losses).</p>"},{"location":"trf_split_run/#prerequisites","title":"Prerequisites","text":"<p>You should have Biopython installed and available in your environment. You may check this with</p> <pre><code>python -c 'from Bio import SeqIO' || echo \"no biopython\" &gt;&gt; /dev/stderr\n</code></pre>"},{"location":"trf_split_run/#options","title":"Options","text":"<p>Use environment variable to control script run * <code>DNA_FEATURES_TRF_SPLIT_NO_SPLITTING</code> -- set to <code>YES</code> to skip splitting stage * <code>DNA_FEATURES_TRF_SPLIT_NO_TRF</code> -- set to <code>YES</code> to skip trf stage * <code>DNA_FEATURES_TRF_SPLIT_SPLITTER_CHUNK_SIZE</code> -- chunk size [<code>1_000_000</code>] * <code>DNA_FEATURES_TRF_SPLIT_SPLITTER_OPTIONS</code> -- for a finer control [<code>--n_seq 1 --chunk_tolerance 10 --chunk_size ${DNA_FEATURES_TRF_SPLIT_SPLITTER_CHUNK_SIZE}</code>]  * <code>DNA_FEATURES_TRF_SPLIT_TRF_EXE</code> -- trf executable (or abs path to be used) [<code>trf</code>] * <code>DNA_FEATURES_TRF_SPLIT_TRF_OPTIONS</code> -- additional options for TRF (like <code>-l 10</code>) []</p>"},{"location":"trf_split_run/#usage-examples","title":"Usage examples","text":""},{"location":"trf_split_run/#a-standalone-run","title":"A standalone run","text":"<pre><code>trf_split_run.bash /writable/path_to/dna.fasta 2 5 7 80 10 40 500 -d -h\n</code></pre>"},{"location":"trf_split_run/#as-a-substitution-for-the-trf_exe-to-be-used-with-the-trf-stage-of-the-dnafeatures-pipeline","title":"As a substitution for the \"trf_exe\" to be used with the <code>TRF</code> stage of the <code>DNAFeatures</code> pipeline:","text":"<pre><code># change TRF \"program\" parameter, you should have ENSEMBL_ROOT_DIR env defined\ntweak_pipeline.pl -url \"$DNA_FEATURES_EHIVE_DB_URL\" -tweak 'analysis[TRF].param[parameters_hash]={program=&gt;\"'${ENSEMBL_ROOT_DIR}'/ensembl-genomio/scripts/trf_split_run.bash\"}'\n</code></pre> <pre><code># set environment variables if you need to, i.e.\nexport DNA_FEATURES_TRF_SPLIT_TRF_EXE=trf.4.09.1 \nexport DNA_FEATURES_TRF_SPLIT_TRF_OPTIONS='-l 10' # N.B. \"l\" correlated with the chunk size (-l chunk_size / 10^6)\nexport DNA_FEATURES_TRF_SPLIT_SPLITTER_CHUNK_SIZE=10_000_000'\n</code></pre> <pre><code>runWorker.pl ... \n# or\nbeekeeper.pl ... -loop\n</code></pre> <pre><code># revert back (if you need to)\ntweak_pipeline.pl -url $DNA_FEATURES_EHIVE_DB_URL  -tweak 'analysis[TRF].param[parameters_hash]={}'\n</code></pre> <pre><code># revert env settings\nunset DNA_FEATURES_TRF_SPLIT_SPLITTER_CHUNK_SIZE\nunset DNA_FEATURES_TRF_SPLIT_SPLITTER_OPTIONS\nunset DNA_FEATURES_TRF_SPLIT_TRF_EXE\nunset DNA_FEATURES_TRF_SPLIT_TRF_OPTIONS\n#   script stages\nunset DNA_FEATURES_TRF_SPLIT_NO_SPLITTING\nunset DNA_FEATURES_TRF_SPLIT_NO_TRF\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>For full details on python modules and Ensembl API repositories required see install section.</p>"},{"location":"usage/#environment-setup","title":"Environment setup","text":"<pre><code>python3.10 -m venv path/to/virtual_env\n. path/to/virtual_env/bin/activate\npip install -e .\n</code></pre> <p>Do not forget to load this environment by sourcing <code>virtual_env/bin/activate</code> in order to run ensembl-genomio pipeline(s).</p>"},{"location":"reference/summary/","title":"Summary","text":"<ul> <li>ensembl<ul> <li>brc4<ul> <li>runnable<ul> <li>compare_fasta</li> <li>compare_report</li> <li>fill_metadata</li> <li>json_schema_factory</li> <li>load_sequence_data</li> <li>prepare_genome</li> <li>seqregion_parser</li> </ul> </li> </ul> </li> <li>io<ul> <li>genomio<ul> <li>annotation<ul> <li>update_description</li> </ul> </li> <li>assembly<ul> <li>download</li> <li>status</li> </ul> </li> <li>data<ul> <li>external_db_map</li> <li>gff3</li> <li>schemas</li> </ul> </li> <li>database<ul> <li>core_server</li> <li>dbconnection_lite</li> <li>factory</li> <li>meta_getter</li> </ul> </li> <li>events<ul> <li>dump</li> <li>format</li> <li>load</li> </ul> </li> <li>external_db<ul> <li>db_map</li> </ul> </li> <li>fasta<ul> <li>chunk</li> <li>compare</li> <li>process</li> </ul> </li> <li>genbank<ul> <li>download</li> <li>extract_data</li> </ul> </li> <li>genome_metadata<ul> <li>dump</li> <li>extend</li> <li>prepare</li> </ul> </li> <li>genome_stats<ul> <li>compare</li> <li>dump</li> </ul> </li> <li>gff3<ul> <li>exceptions</li> <li>extract_annotation</li> <li>features</li> <li>gene_merger</li> <li>id_allocator</li> <li>overlaps</li> <li>process</li> <li>restructure</li> <li>simplifier</li> </ul> </li> <li>manifest<ul> <li>check_integrity</li> <li>compute_stats</li> <li>generate</li> <li>manifest</li> <li>manifest_stats</li> </ul> </li> <li>schemas<ul> <li>json<ul> <li>factory</li> <li>validate</li> </ul> </li> </ul> </li> <li>seq_region<ul> <li>collection</li> <li>dump</li> <li>exceptions</li> <li>gbff</li> <li>mappings</li> <li>prepare</li> <li>report</li> </ul> </li> <li>utils<ul> <li>json_utils</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/ensembl/brc4/","title":"brc4","text":""},{"location":"reference/ensembl/brc4/#ensembl.brc4","title":"<code>ensembl.brc4</code>","text":""},{"location":"reference/ensembl/brc4/runnable/","title":"runnable","text":""},{"location":"reference/ensembl/brc4/runnable/#ensembl.brc4.runnable","title":"<code>ensembl.brc4.runnable</code>","text":""},{"location":"reference/ensembl/brc4/runnable/compare_fasta/","title":"compare_fasta","text":""},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta","title":"<code>ensembl.brc4.runnable.compare_fasta</code>","text":""},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.SeqGroup","title":"<code>SeqGroup</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>class SeqGroup:\n    def __init__(self, sequence, identifier=None) -&gt; None:\n        self.sequence = sequence\n        self.length = len(self.sequence)\n        self.ids = []\n        if identifier:\n            self.add_id(identifier)\n        self.count = len(self.ids)\n\n    def __str__(self) -&gt; str:\n        return \", \".join(self.ids)\n\n    def add_id(self, identifier) -&gt; None:\n        self.ids.append(identifier)\n        self.count = len(self.ids)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.SeqGroup.count","title":"<code>count = len(self.ids)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.SeqGroup.ids","title":"<code>ids = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.SeqGroup.length","title":"<code>length = len(self.sequence)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.SeqGroup.sequence","title":"<code>sequence = sequence</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.SeqGroup.add_id","title":"<code>add_id(identifier)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def add_id(self, identifier) -&gt; None:\n    self.ids.append(identifier)\n    self.count = len(self.ids)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta","title":"<code>compare_fasta</code>","text":"<p>               Bases: <code>BaseRunnable</code></p> Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>class compare_fasta(eHive.BaseRunnable):\n    def param_defaults(self):\n        return {}\n\n    def run(self) -&gt; None:\n        report = self.param_required(\"report\")\n        fasta1 = self.param_required(\"fasta1\")\n        fasta2 = self.param_required(\"fasta2\")\n        map_dna_path = self.param_required(\"seq_regions\")\n        output_dir = self.param_required(\"output_dir\")\n        species = self.param_required(\"species\")\n        name = self.param_required(\"comparison_name\")\n        accession = self.param_required(\"accession\")\n\n        map_dna = self.get_map(map_dna_path)\n        seq1 = self.get_fasta(fasta1, map_dna)\n        seq2 = self.get_fasta(fasta2, map_dna)\n\n        (stats, diffs, seq_map) = self.compare_seqs(seq1, seq2)\n        # Print mapping to a file (add report data)\n        map_file = output_dir + \"/\" + species + \"_\" + name + \".map\"\n        self.print_map(seq_map, map_file, report, accession)\n\n        # Print full list of results in a file\n        output_file = output_dir + \"/\" + species + \"_\" + name + \".log\"\n        print(f\"Write results in {output_file}\")\n        with open(output_file, \"w\") as out_fh:\n            for line in diffs:\n                out_fh.write(line + \"\\n\")\n\n        # Print the stats separately\n        out = {\"species\": species, \"stats\": stats}\n        self.dataflow(out, 2)\n\n    def print_map(self, seq_map: dict, map_file: str, report_file: str, accession: str) -&gt; None:\n        report_parser = SeqregionParser()\n        report_seq = report_parser.get_report_regions(report_file, accession)\n        report = self.add_report_to_map(seq_map, report_seq)\n\n        print(f\"Write map in {map_file}\")\n        with open(map_file, \"w\") as out_fh:\n            out_fh.write(json.dumps(report, sort_keys=True, indent=4))\n\n    def add_report_to_map(self, seq_map: dict, report_seq: dict) -&gt; List[Any]:\n        accession_version = r\"\\.\\d+$\"\n        report = []\n        for insdc_name, old_name in seq_map.items():\n            if insdc_name not in report_seq:\n                raise Exception(\"No INSDC %s found in report\" % insdc_name)\n            else:\n                seqr = report_seq[insdc_name]\n                seqr[\"name\"] = old_name\n                seqr[\"EBI_seq_region_name\"] = old_name\n                brc4_name = insdc_name\n                brc4_name = re.sub(accession_version, \"\", brc4_name)\n                seqr[\"BRC4_seq_region_name\"] = brc4_name\n                syns = [{\"source\": \"INSDC\", \"name\": insdc_name}]\n                seqr[\"synonyms\"] = syns\n                report.append(seqr)\n\n        return report\n\n    def get_map(self, map_path: str) -&gt; dict:\n        print(f\"Read file {map_path}\")\n        data = self.get_json(map_path)\n\n        map_dna = {}\n\n        for seqr in data:\n            name = seqr[\"name\"]\n            if \"synonyms\" in seqr:\n                for syn in seqr[\"synonyms\"]:\n                    if syn[\"name\"] == \"INSDC\":\n                        map_dna[name] = syn[\"value\"]\n\n        return map_dna\n\n    def get_json(self, json_path: str) -&gt; dict:\n        with open(json_path) as json_file:\n            return json.load(json_file)\n\n    def build_seq_dict(self, seqs: dict) -&gt; dict:\n        \"\"\"Build a seq dict taking duplicates into account\"\"\"\n\n        seqs_dict = dict()\n        for name, seq in seqs.items():\n            if seq in seqs_dict:\n                seqs_dict[seq].add_id(name)\n            else:\n                seqs_dict[seq] = SeqGroup(seq, name)\n\n        return seqs_dict\n\n    def get_fasta(self, fasta_path: str, map_dna: dict) -&gt; dict:\n        print(f\"Read file {fasta_path}\")\n        sequences = {}\n        with open_gz_file(fasta_path) as fasta_fh:\n            for rec in SeqIO.parse(fasta_fh, \"fasta\"):\n                name = rec.id\n                if name in map_dna:\n                    name = map_dna[name]\n                sequences[name] = re.sub(r\"[^CGTA]\", \"N\", str(rec.seq.upper()))\n        return sequences\n\n    def compare_seqs(self, seq1: dict, seq2: dict) -&gt; Tuple[dict, list, dict]:\n        comp = []\n        accession = self.param_required(\"accession\")\n        diff = abs(len(seq1) - len(seq2))\n        stats = {\n            \"accession\": accession,\n            \"seq_count_1\": len(seq1),\n            \"seq_count_2\": len(seq2),\n            \"num_diff_seq\": diff,\n            \"common\": 0,\n            \"only1\": 0,\n            \"only2\": 0,\n            \"max_only1\": 0,\n            \"max_only2\": 0,\n            \"only1_200\": 0,\n            \"only1_1000\": 0,\n            \"only2_200\": 0,\n            \"only2_1000\": 0,\n            \"other_locations\": 0,\n            \"summary\": None,\n            \"organellar_summary\": None,\n            \"Assembly_level_1\": None,\n            \"Assembly_level_2\": None,\n        }\n        value = \"identical\"  # variable used for summary\n        org_value = \"no_organelles_present\"  # variable used for organellar_summary\n\n        # Compare sequences\n        seqs1 = self.build_seq_dict(seq1)\n        seqs2 = self.build_seq_dict(seq2)\n\n        # Compare number of sequences\n        if len(seq1) != len(seq2):\n            comp.append(f\"WARNING: Different number of sequences: {len(seq1)} vs {len(seq2)}\")\n        else:\n            comp.append(f\"Same number of sequences: {len(seq1)}\")\n\n        # Sequences that are not common\n        only1 = {seq: group for seq, group in seqs1.items() if not seq in seqs2}\n\n        only2 = {seq: group for seq, group in seqs2.items() if not seq in seqs1}\n\n        common, group_comp = self.find_common_groups(seqs1, seqs2)\n        comp += group_comp\n\n        if only1 or only2:\n            value = \"mismatch\"\n\n        # Gathering the organellar sequences\n        report = self.param_required(\"report\")\n        report_parser = SeqregionParser()\n        report_seq = report_parser.get_report_regions(report, accession)\n        map_dna_path = self.param_required(\"seq_regions\")\n        seq_data = self.get_json(map_dna_path)\n        org_loc = self.organellar_assembly(report_seq, seq_data)\n        INSDC_assembly_level, core_assembly_level = self.assembly_level(report_seq, seq_data)\n\n        comp.append(f\"Assembly level: {INSDC_assembly_level} vs {core_assembly_level}\")\n\n        names_length = {}\n        # sequences which have extra N at the end\n        if only1 and only2:\n            for seq_1, name1 in only1.items():\n                len1 = len(seq_1)\n                seq1_N = seq_1.count(\"N\")\n                for seq_2, name2 in only2.items():\n                    len2 = len(seq_2)\n                    seq2_N = seq_2.count(\"N\")\n                    sequence_2 = seq_2[:len1]\n                    if sequence_2 == seq_1:\n                        ignored_seq = seq_2[len1:]\n                        N = ignored_seq.count(\"N\")\n                        if len(ignored_seq) == N:\n                            comp.append(f\"Please check extra Ns added in core in {name1} and {name2}\")\n                        else:\n                            comp.append(\n                                f\"ALERT INSERTIONS at the end or diff assembly level {name1} and {name2}\"\n                            )\n                    elif len1 == len2:\n                        if seq2_N &gt; seq1_N:\n                            comp.append(f\"Core has more Ns, check {name1} and {name2}\")\n                        elif seq1_N &gt; seq2_N:\n                            comp.append(f\"INSDC has more Ns, check {name1} and {name2}\")\n                        else:\n                            names_length[name1] = name2\n                    else:\n                        continue\n\n        if names_length:\n            length = len(names_length)\n            comp.append(f\"{length} sequences have the same length\")\n            for insdc, core in names_length.items():\n                comp.append(f\"INSDC: {insdc} and coredb : {core}\")\n\n        # Remove the duplicates\n        for org_name in list(org_loc.keys()):\n            for insdc_id, core_id in common.items():\n                if org_name == core_id:\n                    org_loc.pop(org_name)\n\n        # checking for multiple entries of organellar seq\n        multi_org = [name.split(\".\")[0] for name in org_loc.keys()]\n        multi_org_acc = [j[:-1] for j in multi_org]  # similar accession\n        unique_org_id = list(set(multi_org_acc))\n        location = [location for location in org_loc.values()]\n        unique_location = location.count(\"mitochondrial_chromosome\")\n        unique_apicoplast = location.count(\"apicoplast_chromosome\")\n\n        only1_id = [str(id1) for id1 in only1.values()]\n\n        # comparing organellar sequences with common, only1 and only2\n        count = 0\n        for org_name, loc in org_loc.items():\n            if org_name == \"na\":\n                comp.append(\"MISSING accession in the report (na)\")\n            else:\n                if org_name in common.keys():\n                    count = count + 1\n                    comp.append(f\"{org_name} (both) in location: {loc}\")\n                    if count &gt; 0:\n                        org_value = \"identical\"\n                elif org_name in only1_id:\n                    count = count + 1\n                    comp.append(f\"{org_name} (only1) in  location: {loc}\")\n                    org_value = \"unknown_with_organellar\"\n                else:\n                    count = count + 1\n                    comp.append(f\"{org_name} (only2) in location: {loc}\")\n                    org_value = \"unknown_with_organellar\"\n\n        # if the mistmatch is due to added organellar sequences\n        if len(seqs1) &gt; len(seqs2):\n            greater_len = len(seq1)\n        else:\n            greater_len = len(seq2)\n\n        diff_common = greater_len - len(common)\n        diff = abs(len(only1) + len(only2))\n\n        if diff != 0:\n            if diff == count and diff_common == count:\n                org_value = \"organellar_present\"\n\n        if count == 0:\n            org_value = \"no_organelles_present\"\n\n        # checking if multiple entries of organellar sequences are present\n        if len(multi_org_acc) != len(unique_org_id):\n            if unique_location &gt; 1 or unique_apicoplast &gt; 1:\n                org_value = \"WARNING:Multiple_entry\"\n\n        # updating the stats\n        stats[\"num_diff_seq\"] = diff\n        stats[\"common\"] = len(common)\n        stats[\"only1\"] = len(only1)\n        stats[\"only2\"] = len(only2)\n        stats[\"other_locations\"] = count\n        stats[\"summary\"] = value\n        stats[\"organellar_summary\"] = org_value\n        stats[\"Assembly_level_1\"] = INSDC_assembly_level\n        stats[\"Assembly_level_2\"] = core_assembly_level\n        print(stats)\n\n        if only1:\n            stats[\"max_only1\"] = len(max(only1, key=lambda k: len(k)))\n            # Only list sequences where the length is &gt; 200\n            mini = {seq: name for seq, name in only1.items() if len(seq) &lt;= 200}\n            maxi = {seq: name for seq, name in only1.items() if len(seq) &gt; 200}\n\n            if mini and len(mini) &gt; 3000:\n                comp.append(f\"WARNING: Ignoring {len(mini)} sequences from 1 with length &lt;= 200\")\n                only1 = maxi\n\n        if only1:\n            # Only list sequences where the length is &gt; 1000\n            mini = {seq: name for seq, name in only1.items() if len(seq) &lt;= 1000}\n            maxi = {seq: name for seq, name in only1.items() if len(seq) &gt; 1000}\n            if mini and len(mini) &gt; 3000:\n                comp.append(f\"WARNING: Ignoring {len(mini)} sequences from 1 with length &lt;= 1000\")\n                only1 = maxi\n\n        if only1:\n            total = sum([len(seq) for seq in only1.keys()])\n            comp.append(f\"WARNING: Sequences only in 1: {len(only1)} ({total})\")\n            only_seq1 = {name: len(seq) for seq, name in only1.items()}\n            for name, length in sorted(only_seq1.items(), key=lambda x: x[1]):\n                comp.append(f\"\\tOnly in 1: {name} ({length})\")\n\n        if only2:\n            stats[\"max_only2\"] = len(max(only2, key=lambda k: len(k)))\n            # Only list sequences where the length is &gt; 200\n            mini = {seq: name for seq, name in only2.items() if len(seq) &lt;= 200}\n            maxi = {seq: name for seq, name in only2.items() if len(seq) &gt; 200}\n\n            if mini and len(mini) &gt; 3000:\n                comp.append(f\"WARNING: Ignoring {len(mini)} sequences from 2 with length &lt;= 200\")\n                only2 = maxi\n\n        if only2:\n            # Only list sequences where the length is &gt; 1000\n            mini = {seq: name for seq, name in only2.items() if len(seq) &lt;= 1000}\n            maxi = {seq: name for seq, name in only2.items() if len(seq) &gt; 1000}\n\n            if mini and len(mini) &gt; 3000:\n                comp.append(f\"WARNING: Ignoring {len(mini)} sequences from 2 with length &lt;= 1000\")\n                only2 = maxi\n\n        if only2:\n            total = sum([len(seq) for seq in only2.keys()])\n            comp.append(f\"WARNING: Sequences only in 2: {len(only2)} ({total})\")\n            only_seq2 = {name: len(seq) for seq, name in only2.items()}\n            for name, length in sorted(only_seq2.items(), key=lambda x: x[1]):\n                comp.append(f\"\\tOnly in 2: {name} ({length})\")\n\n        return (stats, comp, common)\n\n    def find_common_groups(self, seqs1: dict, seqs2: dict) -&gt; Tuple[dict, List[Any]]:\n        print(len(seqs1))\n        print(len(seqs2))\n        comp = []\n        common = {}\n        for seq1, group1 in seqs1.items():\n            if seq1 in seqs2:\n                group2 = seqs2[seq1]\n                # Check that the 2 groups have the same number of sequences\n                if group1.count == group2.count:\n                    if group1.count == 1:\n                        common[group1.ids[0]] = group2.ids[0]\n                    else:\n                        comp.append(f\"Matched 2 identical groups of sequences: {group1} and {group2}\")\n                        possible_id2 = \" OR \".join(group2.ids)\n                        for id1 in group1.ids:\n                            common[id1] = possible_id2\n\n                else:\n                    comp.append(\n                        f\"Matched 2 different groups of sequences ({group1.count} vs {group2.count}): {group1} and {group2}\"\n                    )\n\n        print(len(common))\n        return common, comp\n\n    def organellar_assembly(self, report_seq: dict, data: List[dict]) -&gt; dict:\n        org_loc = {}\n\n        # Gathering data from the INSDC report file and storing it into a list\n        for name1, details1 in report_seq.items():\n            if \"location\" in details1:\n                if details1[\"location\"] not in (\n                    \"chromosome\",\n                    \"nuclear_chromosome\",\n                    \"linkage_group\",\n                ):\n                    loc = details1[\"location\"]\n                    org_loc[name1] = loc\n\n        # Gathering data from Seq_json file and storing it into a list\n        for rep in data:\n            for name2, details2 in rep.items():\n                if \"location\" in name2:\n                    if details2 not in (\n                        \"chromosome\",\n                        \"nuclear_chromosome\",\n                        \"linkage_group\",\n                    ):\n                        name = rep[\"BRC4_seq_region_name\"]\n                        org_loc[name] = details2\n\n        return org_loc\n\n    def assembly_level(self, report_seq: dict, core_data: list) -&gt; Tuple[str, str]:\n        INSDC_assembly_level = []\n        core_assembly_level = []\n        core_assembly = {}\n        scaffold_INSDC = 0\n        chromosome_INSDC = 0\n        scaffold_core = 0\n        chromosome_core = 0\n\n        for name, insdc_rep in report_seq.items():\n            if insdc_rep[\"coord_system_level\"] not in (\n                \"chromosome\",\n                \"nuclear_chromosome\",\n            ):\n                scaffold_INSDC += 1\n            else:\n                chromosome_INSDC += 1\n\n        INSDC_assembly_level.extend([scaffold_INSDC, chromosome_INSDC])\n\n        for core_details in core_data:\n            name = core_details[\"BRC4_seq_region_name\"]\n            coord_system_level = core_details[\"coord_system_level\"]\n            core_assembly[name] = coord_system_level\n\n        for name, coord_level in core_assembly.items():\n            if coord_level not in (\"chromosome\", \"nuclear_chromosome\"):\n                scaffold_core += 1\n            else:\n                chromosome_core += 1\n\n        core_assembly_level.extend([scaffold_core, chromosome_core])\n\n        INSDC_assembly_level = \", \".join([str(assembly) for assembly in INSDC_assembly_level])\n        core_assembly_level = \", \".join([str(assembly) for assembly in core_assembly_level])\n\n        return INSDC_assembly_level, core_assembly_level\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.add_report_to_map","title":"<code>add_report_to_map(seq_map, report_seq)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def add_report_to_map(self, seq_map: dict, report_seq: dict) -&gt; List[Any]:\n    accession_version = r\"\\.\\d+$\"\n    report = []\n    for insdc_name, old_name in seq_map.items():\n        if insdc_name not in report_seq:\n            raise Exception(\"No INSDC %s found in report\" % insdc_name)\n        else:\n            seqr = report_seq[insdc_name]\n            seqr[\"name\"] = old_name\n            seqr[\"EBI_seq_region_name\"] = old_name\n            brc4_name = insdc_name\n            brc4_name = re.sub(accession_version, \"\", brc4_name)\n            seqr[\"BRC4_seq_region_name\"] = brc4_name\n            syns = [{\"source\": \"INSDC\", \"name\": insdc_name}]\n            seqr[\"synonyms\"] = syns\n            report.append(seqr)\n\n    return report\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.assembly_level","title":"<code>assembly_level(report_seq, core_data)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def assembly_level(self, report_seq: dict, core_data: list) -&gt; Tuple[str, str]:\n    INSDC_assembly_level = []\n    core_assembly_level = []\n    core_assembly = {}\n    scaffold_INSDC = 0\n    chromosome_INSDC = 0\n    scaffold_core = 0\n    chromosome_core = 0\n\n    for name, insdc_rep in report_seq.items():\n        if insdc_rep[\"coord_system_level\"] not in (\n            \"chromosome\",\n            \"nuclear_chromosome\",\n        ):\n            scaffold_INSDC += 1\n        else:\n            chromosome_INSDC += 1\n\n    INSDC_assembly_level.extend([scaffold_INSDC, chromosome_INSDC])\n\n    for core_details in core_data:\n        name = core_details[\"BRC4_seq_region_name\"]\n        coord_system_level = core_details[\"coord_system_level\"]\n        core_assembly[name] = coord_system_level\n\n    for name, coord_level in core_assembly.items():\n        if coord_level not in (\"chromosome\", \"nuclear_chromosome\"):\n            scaffold_core += 1\n        else:\n            chromosome_core += 1\n\n    core_assembly_level.extend([scaffold_core, chromosome_core])\n\n    INSDC_assembly_level = \", \".join([str(assembly) for assembly in INSDC_assembly_level])\n    core_assembly_level = \", \".join([str(assembly) for assembly in core_assembly_level])\n\n    return INSDC_assembly_level, core_assembly_level\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.build_seq_dict","title":"<code>build_seq_dict(seqs)</code>","text":"<p>Build a seq dict taking duplicates into account</p> Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def build_seq_dict(self, seqs: dict) -&gt; dict:\n    \"\"\"Build a seq dict taking duplicates into account\"\"\"\n\n    seqs_dict = dict()\n    for name, seq in seqs.items():\n        if seq in seqs_dict:\n            seqs_dict[seq].add_id(name)\n        else:\n            seqs_dict[seq] = SeqGroup(seq, name)\n\n    return seqs_dict\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.compare_seqs","title":"<code>compare_seqs(seq1, seq2)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def compare_seqs(self, seq1: dict, seq2: dict) -&gt; Tuple[dict, list, dict]:\n    comp = []\n    accession = self.param_required(\"accession\")\n    diff = abs(len(seq1) - len(seq2))\n    stats = {\n        \"accession\": accession,\n        \"seq_count_1\": len(seq1),\n        \"seq_count_2\": len(seq2),\n        \"num_diff_seq\": diff,\n        \"common\": 0,\n        \"only1\": 0,\n        \"only2\": 0,\n        \"max_only1\": 0,\n        \"max_only2\": 0,\n        \"only1_200\": 0,\n        \"only1_1000\": 0,\n        \"only2_200\": 0,\n        \"only2_1000\": 0,\n        \"other_locations\": 0,\n        \"summary\": None,\n        \"organellar_summary\": None,\n        \"Assembly_level_1\": None,\n        \"Assembly_level_2\": None,\n    }\n    value = \"identical\"  # variable used for summary\n    org_value = \"no_organelles_present\"  # variable used for organellar_summary\n\n    # Compare sequences\n    seqs1 = self.build_seq_dict(seq1)\n    seqs2 = self.build_seq_dict(seq2)\n\n    # Compare number of sequences\n    if len(seq1) != len(seq2):\n        comp.append(f\"WARNING: Different number of sequences: {len(seq1)} vs {len(seq2)}\")\n    else:\n        comp.append(f\"Same number of sequences: {len(seq1)}\")\n\n    # Sequences that are not common\n    only1 = {seq: group for seq, group in seqs1.items() if not seq in seqs2}\n\n    only2 = {seq: group for seq, group in seqs2.items() if not seq in seqs1}\n\n    common, group_comp = self.find_common_groups(seqs1, seqs2)\n    comp += group_comp\n\n    if only1 or only2:\n        value = \"mismatch\"\n\n    # Gathering the organellar sequences\n    report = self.param_required(\"report\")\n    report_parser = SeqregionParser()\n    report_seq = report_parser.get_report_regions(report, accession)\n    map_dna_path = self.param_required(\"seq_regions\")\n    seq_data = self.get_json(map_dna_path)\n    org_loc = self.organellar_assembly(report_seq, seq_data)\n    INSDC_assembly_level, core_assembly_level = self.assembly_level(report_seq, seq_data)\n\n    comp.append(f\"Assembly level: {INSDC_assembly_level} vs {core_assembly_level}\")\n\n    names_length = {}\n    # sequences which have extra N at the end\n    if only1 and only2:\n        for seq_1, name1 in only1.items():\n            len1 = len(seq_1)\n            seq1_N = seq_1.count(\"N\")\n            for seq_2, name2 in only2.items():\n                len2 = len(seq_2)\n                seq2_N = seq_2.count(\"N\")\n                sequence_2 = seq_2[:len1]\n                if sequence_2 == seq_1:\n                    ignored_seq = seq_2[len1:]\n                    N = ignored_seq.count(\"N\")\n                    if len(ignored_seq) == N:\n                        comp.append(f\"Please check extra Ns added in core in {name1} and {name2}\")\n                    else:\n                        comp.append(\n                            f\"ALERT INSERTIONS at the end or diff assembly level {name1} and {name2}\"\n                        )\n                elif len1 == len2:\n                    if seq2_N &gt; seq1_N:\n                        comp.append(f\"Core has more Ns, check {name1} and {name2}\")\n                    elif seq1_N &gt; seq2_N:\n                        comp.append(f\"INSDC has more Ns, check {name1} and {name2}\")\n                    else:\n                        names_length[name1] = name2\n                else:\n                    continue\n\n    if names_length:\n        length = len(names_length)\n        comp.append(f\"{length} sequences have the same length\")\n        for insdc, core in names_length.items():\n            comp.append(f\"INSDC: {insdc} and coredb : {core}\")\n\n    # Remove the duplicates\n    for org_name in list(org_loc.keys()):\n        for insdc_id, core_id in common.items():\n            if org_name == core_id:\n                org_loc.pop(org_name)\n\n    # checking for multiple entries of organellar seq\n    multi_org = [name.split(\".\")[0] for name in org_loc.keys()]\n    multi_org_acc = [j[:-1] for j in multi_org]  # similar accession\n    unique_org_id = list(set(multi_org_acc))\n    location = [location for location in org_loc.values()]\n    unique_location = location.count(\"mitochondrial_chromosome\")\n    unique_apicoplast = location.count(\"apicoplast_chromosome\")\n\n    only1_id = [str(id1) for id1 in only1.values()]\n\n    # comparing organellar sequences with common, only1 and only2\n    count = 0\n    for org_name, loc in org_loc.items():\n        if org_name == \"na\":\n            comp.append(\"MISSING accession in the report (na)\")\n        else:\n            if org_name in common.keys():\n                count = count + 1\n                comp.append(f\"{org_name} (both) in location: {loc}\")\n                if count &gt; 0:\n                    org_value = \"identical\"\n            elif org_name in only1_id:\n                count = count + 1\n                comp.append(f\"{org_name} (only1) in  location: {loc}\")\n                org_value = \"unknown_with_organellar\"\n            else:\n                count = count + 1\n                comp.append(f\"{org_name} (only2) in location: {loc}\")\n                org_value = \"unknown_with_organellar\"\n\n    # if the mistmatch is due to added organellar sequences\n    if len(seqs1) &gt; len(seqs2):\n        greater_len = len(seq1)\n    else:\n        greater_len = len(seq2)\n\n    diff_common = greater_len - len(common)\n    diff = abs(len(only1) + len(only2))\n\n    if diff != 0:\n        if diff == count and diff_common == count:\n            org_value = \"organellar_present\"\n\n    if count == 0:\n        org_value = \"no_organelles_present\"\n\n    # checking if multiple entries of organellar sequences are present\n    if len(multi_org_acc) != len(unique_org_id):\n        if unique_location &gt; 1 or unique_apicoplast &gt; 1:\n            org_value = \"WARNING:Multiple_entry\"\n\n    # updating the stats\n    stats[\"num_diff_seq\"] = diff\n    stats[\"common\"] = len(common)\n    stats[\"only1\"] = len(only1)\n    stats[\"only2\"] = len(only2)\n    stats[\"other_locations\"] = count\n    stats[\"summary\"] = value\n    stats[\"organellar_summary\"] = org_value\n    stats[\"Assembly_level_1\"] = INSDC_assembly_level\n    stats[\"Assembly_level_2\"] = core_assembly_level\n    print(stats)\n\n    if only1:\n        stats[\"max_only1\"] = len(max(only1, key=lambda k: len(k)))\n        # Only list sequences where the length is &gt; 200\n        mini = {seq: name for seq, name in only1.items() if len(seq) &lt;= 200}\n        maxi = {seq: name for seq, name in only1.items() if len(seq) &gt; 200}\n\n        if mini and len(mini) &gt; 3000:\n            comp.append(f\"WARNING: Ignoring {len(mini)} sequences from 1 with length &lt;= 200\")\n            only1 = maxi\n\n    if only1:\n        # Only list sequences where the length is &gt; 1000\n        mini = {seq: name for seq, name in only1.items() if len(seq) &lt;= 1000}\n        maxi = {seq: name for seq, name in only1.items() if len(seq) &gt; 1000}\n        if mini and len(mini) &gt; 3000:\n            comp.append(f\"WARNING: Ignoring {len(mini)} sequences from 1 with length &lt;= 1000\")\n            only1 = maxi\n\n    if only1:\n        total = sum([len(seq) for seq in only1.keys()])\n        comp.append(f\"WARNING: Sequences only in 1: {len(only1)} ({total})\")\n        only_seq1 = {name: len(seq) for seq, name in only1.items()}\n        for name, length in sorted(only_seq1.items(), key=lambda x: x[1]):\n            comp.append(f\"\\tOnly in 1: {name} ({length})\")\n\n    if only2:\n        stats[\"max_only2\"] = len(max(only2, key=lambda k: len(k)))\n        # Only list sequences where the length is &gt; 200\n        mini = {seq: name for seq, name in only2.items() if len(seq) &lt;= 200}\n        maxi = {seq: name for seq, name in only2.items() if len(seq) &gt; 200}\n\n        if mini and len(mini) &gt; 3000:\n            comp.append(f\"WARNING: Ignoring {len(mini)} sequences from 2 with length &lt;= 200\")\n            only2 = maxi\n\n    if only2:\n        # Only list sequences where the length is &gt; 1000\n        mini = {seq: name for seq, name in only2.items() if len(seq) &lt;= 1000}\n        maxi = {seq: name for seq, name in only2.items() if len(seq) &gt; 1000}\n\n        if mini and len(mini) &gt; 3000:\n            comp.append(f\"WARNING: Ignoring {len(mini)} sequences from 2 with length &lt;= 1000\")\n            only2 = maxi\n\n    if only2:\n        total = sum([len(seq) for seq in only2.keys()])\n        comp.append(f\"WARNING: Sequences only in 2: {len(only2)} ({total})\")\n        only_seq2 = {name: len(seq) for seq, name in only2.items()}\n        for name, length in sorted(only_seq2.items(), key=lambda x: x[1]):\n            comp.append(f\"\\tOnly in 2: {name} ({length})\")\n\n    return (stats, comp, common)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.find_common_groups","title":"<code>find_common_groups(seqs1, seqs2)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def find_common_groups(self, seqs1: dict, seqs2: dict) -&gt; Tuple[dict, List[Any]]:\n    print(len(seqs1))\n    print(len(seqs2))\n    comp = []\n    common = {}\n    for seq1, group1 in seqs1.items():\n        if seq1 in seqs2:\n            group2 = seqs2[seq1]\n            # Check that the 2 groups have the same number of sequences\n            if group1.count == group2.count:\n                if group1.count == 1:\n                    common[group1.ids[0]] = group2.ids[0]\n                else:\n                    comp.append(f\"Matched 2 identical groups of sequences: {group1} and {group2}\")\n                    possible_id2 = \" OR \".join(group2.ids)\n                    for id1 in group1.ids:\n                        common[id1] = possible_id2\n\n            else:\n                comp.append(\n                    f\"Matched 2 different groups of sequences ({group1.count} vs {group2.count}): {group1} and {group2}\"\n                )\n\n    print(len(common))\n    return common, comp\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.get_fasta","title":"<code>get_fasta(fasta_path, map_dna)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def get_fasta(self, fasta_path: str, map_dna: dict) -&gt; dict:\n    print(f\"Read file {fasta_path}\")\n    sequences = {}\n    with open_gz_file(fasta_path) as fasta_fh:\n        for rec in SeqIO.parse(fasta_fh, \"fasta\"):\n            name = rec.id\n            if name in map_dna:\n                name = map_dna[name]\n            sequences[name] = re.sub(r\"[^CGTA]\", \"N\", str(rec.seq.upper()))\n    return sequences\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.get_json","title":"<code>get_json(json_path)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def get_json(self, json_path: str) -&gt; dict:\n    with open(json_path) as json_file:\n        return json.load(json_file)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.get_map","title":"<code>get_map(map_path)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def get_map(self, map_path: str) -&gt; dict:\n    print(f\"Read file {map_path}\")\n    data = self.get_json(map_path)\n\n    map_dna = {}\n\n    for seqr in data:\n        name = seqr[\"name\"]\n        if \"synonyms\" in seqr:\n            for syn in seqr[\"synonyms\"]:\n                if syn[\"name\"] == \"INSDC\":\n                    map_dna[name] = syn[\"value\"]\n\n    return map_dna\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.organellar_assembly","title":"<code>organellar_assembly(report_seq, data)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def organellar_assembly(self, report_seq: dict, data: List[dict]) -&gt; dict:\n    org_loc = {}\n\n    # Gathering data from the INSDC report file and storing it into a list\n    for name1, details1 in report_seq.items():\n        if \"location\" in details1:\n            if details1[\"location\"] not in (\n                \"chromosome\",\n                \"nuclear_chromosome\",\n                \"linkage_group\",\n            ):\n                loc = details1[\"location\"]\n                org_loc[name1] = loc\n\n    # Gathering data from Seq_json file and storing it into a list\n    for rep in data:\n        for name2, details2 in rep.items():\n            if \"location\" in name2:\n                if details2 not in (\n                    \"chromosome\",\n                    \"nuclear_chromosome\",\n                    \"linkage_group\",\n                ):\n                    name = rep[\"BRC4_seq_region_name\"]\n                    org_loc[name] = details2\n\n    return org_loc\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.param_defaults","title":"<code>param_defaults()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def param_defaults(self):\n    return {}\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.print_map","title":"<code>print_map(seq_map, map_file, report_file, accession)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def print_map(self, seq_map: dict, map_file: str, report_file: str, accession: str) -&gt; None:\n    report_parser = SeqregionParser()\n    report_seq = report_parser.get_report_regions(report_file, accession)\n    report = self.add_report_to_map(seq_map, report_seq)\n\n    print(f\"Write map in {map_file}\")\n    with open(map_file, \"w\") as out_fh:\n        out_fh.write(json.dumps(report, sort_keys=True, indent=4))\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_fasta/#ensembl.brc4.runnable.compare_fasta.compare_fasta.run","title":"<code>run()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_fasta.py</code> <pre><code>def run(self) -&gt; None:\n    report = self.param_required(\"report\")\n    fasta1 = self.param_required(\"fasta1\")\n    fasta2 = self.param_required(\"fasta2\")\n    map_dna_path = self.param_required(\"seq_regions\")\n    output_dir = self.param_required(\"output_dir\")\n    species = self.param_required(\"species\")\n    name = self.param_required(\"comparison_name\")\n    accession = self.param_required(\"accession\")\n\n    map_dna = self.get_map(map_dna_path)\n    seq1 = self.get_fasta(fasta1, map_dna)\n    seq2 = self.get_fasta(fasta2, map_dna)\n\n    (stats, diffs, seq_map) = self.compare_seqs(seq1, seq2)\n    # Print mapping to a file (add report data)\n    map_file = output_dir + \"/\" + species + \"_\" + name + \".map\"\n    self.print_map(seq_map, map_file, report, accession)\n\n    # Print full list of results in a file\n    output_file = output_dir + \"/\" + species + \"_\" + name + \".log\"\n    print(f\"Write results in {output_file}\")\n    with open(output_file, \"w\") as out_fh:\n        for line in diffs:\n            out_fh.write(line + \"\\n\")\n\n    # Print the stats separately\n    out = {\"species\": species, \"stats\": stats}\n    self.dataflow(out, 2)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_report/","title":"compare_report","text":""},{"location":"reference/ensembl/brc4/runnable/compare_report/#ensembl.brc4.runnable.compare_report","title":"<code>ensembl.brc4.runnable.compare_report</code>","text":""},{"location":"reference/ensembl/brc4/runnable/compare_report/#ensembl.brc4.runnable.compare_report.compare_report","title":"<code>compare_report</code>","text":"<p>               Bases: <code>BaseRunnable</code></p> Source code in <code>src/python/ensembl/brc4/runnable/compare_report.py</code> <pre><code>class compare_report(eHive.BaseRunnable):\n    def param_defaults(self):\n        return {}\n\n    def run(self):\n        stats = self.param(\"stats\")\n        output_dir = self.param_required(\"output_dir\")\n\n        # Print report\n        report = output_dir + \"/report.log\"\n        print(\"Write report in %s\" % report)\n\n        fields = (\n            \"species\",\n            \"accession\",\n            \"seq_count_1\",\n            \"seq_count_2\",\n            \"num_diff_seq\",\n            \"common\",\n            \"only1\",\n            \"only2\",\n            \"max_only1\",\n            \"max_only2\",\n            \"other_locations\",\n            \"summary\",\n            \"organellar_summary\",\n            \"Assembly_level_1\",\n            \"Assembly_level_2\",\n        )\n\n        with open(report, \"w\") as out_fh:\n            out_fh.write(\"#\" + \"\\t\".join(fields) + \"\\n\")\n\n            for species in sorted(stats.keys()):\n                stat = stats[species]\n                stat[\"species\"] = species\n\n                line = []\n                for f in fields:\n                    if f in stat:\n                        line.append(str(stat[f]))\n                out_fh.write(\"\\t\".join(line) + \"\\n\")\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_report/#ensembl.brc4.runnable.compare_report.compare_report.param_defaults","title":"<code>param_defaults()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_report.py</code> <pre><code>def param_defaults(self):\n    return {}\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/compare_report/#ensembl.brc4.runnable.compare_report.compare_report.run","title":"<code>run()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/compare_report.py</code> <pre><code>def run(self):\n    stats = self.param(\"stats\")\n    output_dir = self.param_required(\"output_dir\")\n\n    # Print report\n    report = output_dir + \"/report.log\"\n    print(\"Write report in %s\" % report)\n\n    fields = (\n        \"species\",\n        \"accession\",\n        \"seq_count_1\",\n        \"seq_count_2\",\n        \"num_diff_seq\",\n        \"common\",\n        \"only1\",\n        \"only2\",\n        \"max_only1\",\n        \"max_only2\",\n        \"other_locations\",\n        \"summary\",\n        \"organellar_summary\",\n        \"Assembly_level_1\",\n        \"Assembly_level_2\",\n    )\n\n    with open(report, \"w\") as out_fh:\n        out_fh.write(\"#\" + \"\\t\".join(fields) + \"\\n\")\n\n        for species in sorted(stats.keys()):\n            stat = stats[species]\n            stat[\"species\"] = species\n\n            line = []\n            for f in fields:\n                if f in stat:\n                    line.append(str(stat[f]))\n            out_fh.write(\"\\t\".join(line) + \"\\n\")\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/fill_metadata/","title":"fill_metadata","text":""},{"location":"reference/ensembl/brc4/runnable/fill_metadata/#ensembl.brc4.runnable.fill_metadata","title":"<code>ensembl.brc4.runnable.fill_metadata</code>","text":""},{"location":"reference/ensembl/brc4/runnable/fill_metadata/#ensembl.brc4.runnable.fill_metadata.fill_metadata","title":"<code>fill_metadata</code>","text":"<p>               Bases: <code>BaseRunnable</code></p> Source code in <code>src/python/ensembl/brc4/runnable/fill_metadata.py</code> <pre><code>class fill_metadata(eHive.BaseRunnable):\n    def param_defaults(self):\n        return {\n            \"division\": \"\",\n            \"ignore\": [],\n            \"copy\": {},\n        }\n\n    def run(self):\n        # params\n        wd = self.param_required(\"work_dir\")\n        division = self.param(\"division\")\n        brc4_mode = self.param(\"brc4_mode\")\n        ignore = self.param(\"ignore\")\n        copy = self.param(\"copy\")\n        genome_data = self.param_required(\"genome_data\")\n\n        # update division and url\n        if \"species\" in genome_data:\n            sd = genome_data[\"species\"]\n            # Add division, but not needed for BRC4\n            if (\"division\" not in sd) and not brc4_mode:\n                sd[\"division\"] = division\n            if \"url\" not in sd:\n                if \"production_name\" in sd:\n                    sd[\"url\"] = sd[\"production_name\"].capitalize()\n\n        # RETROCOMPATIBILITY\n        # provider name and url to assembly.provider_*: retrocompatibility\n        if \"provider\" in genome_data:\n            prov = genome_data[\"provider\"]\n            if \"name\" in prov and not \"provider_name\" in genome_data[\"assembly\"]:\n                genome_data[\"assembly\"][\"provider_name\"] = prov[\"name\"]\n            if \"url\" in prov and not \"provider_url\" in genome_data[\"assembly\"]:\n                genome_data[\"assembly\"][\"provider_url\"] = prov[\"url\"]\n            del genome_data[\"provider\"]\n\n        # BRC4 organism abbrev: move from species to BRC4 namespace\n        if \"species\" in genome_data:\n            sd = genome_data[\"species\"]\n            if \"BRC4_organism_abbrev\" in sd:\n                if \"BRC4\" not in genome_data:\n                    genome_data[\"BRC4\"] = {}\n                if \"organism_abbrev\" not in genome_data[\"BRC4\"]:\n                    genome_data[\"BRC4\"][\"organism_abbrev\"] = sd[\"BRC4_organism_abbrev\"]\n                del genome_data[\"species\"][\"BRC4_organism_abbrev\"]\n        # END RETROCOMPATIBILITY\n\n        # Set up display name if not set\n        if \"species\" in genome_data:\n            sd = genome_data[\"species\"]\n            if not \"display_name\" in sd and \"scientific_name\" in sd:\n                genome_data[\"species\"][\"display_name\"] = sd[\"scientific_name\"]\n\n        # flattern and dump\n        flat = self.flattern(genome_data, ignore)\n        flat += list(map(lambda p: (copy[p[0]], p[1]), filter(lambda x: x[0] in copy, flat)))\n        flat = list(filter(lambda x: x[0] not in ignore, flat))\n        if len(flat) &lt;= 0:\n            return\n\n        # dump\n        os.makedirs(wd, exist_ok=True)\n        sql_file = pj(wd, \"insert_meta.sql\")\n        with open(sql_file, \"w\") as sql:\n            print(\"insert ignore into meta (species_id, meta_key, meta_value) values\", file=sql)\n            c = \"\"\n            for _key, _val in flat:\n                if isinstance(_val, bool):\n                    _val = int(_val)\n                if isinstance(_val, str):\n                    _val = '\"%s\"' % (_val)\n                print('%s (1, \"%s\", %s)' % (c, str(_key), str(_val)), file=sql)\n                c = \",\"\n            print(\";\", file=sql)\n        # run insert sql\n        self.run_sql_req(sql_file, log_pfx=sql_file, from_file=True)\n\n    def flattern(self, data, ignore_lst, pfx=None):\n        # vectors with values only\n        if isinstance(data, list):\n            return [(pfx, v) for v in data]\n        elif isinstance(data, dict):\n            ignore_lst = frozenset(ignore_lst)\n            res = []\n            for k, v in data.items():\n                new_pfx = \".\".join(filter(lambda p: p != None, [pfx, k]))\n                res.append(self.flattern(v, ignore_lst, new_pfx))\n            return sum(res, [])\n        return data != None and [(pfx, data)] or []\n\n    def run_sql_req(self, sql, log_pfx, from_file=False):\n        os.makedirs(dirname(log_pfx), exist_ok=True)\n\n        sql_option = r\"\"\" -sql '{_sql}' \"\"\".format(_sql=sql)\n        if from_file:\n            sql_option = r\"\"\" &lt; '{_sql}' \"\"\".format(_sql=sql)\n\n        cmd = r\"\"\"{_dbcmd} -url \"{_srv}{_dbname}\" {_sql_option} &gt; {_out} 2&gt; {_err}\"\"\".format(\n            _dbcmd=\"perl %s/scripts/db_cmd.pl\" % os.getenv(\"EHIVE_ROOT_DIR\"),\n            _srv=self.param(\"dbsrv_url\"),\n            _dbname=self.param(\"db_name\"),\n            _sql_option=sql_option,\n            _out=log_pfx + \".stdout\",\n            _err=log_pfx + \".stderr\",\n        )\n        print(\"running %s\" % (cmd), file=sys.stderr)\n        return sp.run(cmd, shell=True, check=True)\n\n    def db_string(self):\n        return \"-dbhost {host_} -dbport {port_} -dbuser {user_} -dbpass {pass_} -dbname {dbname_} \".format(\n            host_=self.param(\"dbsrv_host\"),\n            port_=self.param(\"dbsrv_port\"),\n            user_=self.param(\"dbsrv_user\"),\n            pass_=self.param(\"dbsrv_pass\"),\n            dbname_=self.param(\"db_name\"),\n        )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/fill_metadata/#ensembl.brc4.runnable.fill_metadata.fill_metadata.db_string","title":"<code>db_string()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/fill_metadata.py</code> <pre><code>def db_string(self):\n    return \"-dbhost {host_} -dbport {port_} -dbuser {user_} -dbpass {pass_} -dbname {dbname_} \".format(\n        host_=self.param(\"dbsrv_host\"),\n        port_=self.param(\"dbsrv_port\"),\n        user_=self.param(\"dbsrv_user\"),\n        pass_=self.param(\"dbsrv_pass\"),\n        dbname_=self.param(\"db_name\"),\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/fill_metadata/#ensembl.brc4.runnable.fill_metadata.fill_metadata.flattern","title":"<code>flattern(data, ignore_lst, pfx=None)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/fill_metadata.py</code> <pre><code>def flattern(self, data, ignore_lst, pfx=None):\n    # vectors with values only\n    if isinstance(data, list):\n        return [(pfx, v) for v in data]\n    elif isinstance(data, dict):\n        ignore_lst = frozenset(ignore_lst)\n        res = []\n        for k, v in data.items():\n            new_pfx = \".\".join(filter(lambda p: p != None, [pfx, k]))\n            res.append(self.flattern(v, ignore_lst, new_pfx))\n        return sum(res, [])\n    return data != None and [(pfx, data)] or []\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/fill_metadata/#ensembl.brc4.runnable.fill_metadata.fill_metadata.param_defaults","title":"<code>param_defaults()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/fill_metadata.py</code> <pre><code>def param_defaults(self):\n    return {\n        \"division\": \"\",\n        \"ignore\": [],\n        \"copy\": {},\n    }\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/fill_metadata/#ensembl.brc4.runnable.fill_metadata.fill_metadata.run","title":"<code>run()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/fill_metadata.py</code> <pre><code>def run(self):\n    # params\n    wd = self.param_required(\"work_dir\")\n    division = self.param(\"division\")\n    brc4_mode = self.param(\"brc4_mode\")\n    ignore = self.param(\"ignore\")\n    copy = self.param(\"copy\")\n    genome_data = self.param_required(\"genome_data\")\n\n    # update division and url\n    if \"species\" in genome_data:\n        sd = genome_data[\"species\"]\n        # Add division, but not needed for BRC4\n        if (\"division\" not in sd) and not brc4_mode:\n            sd[\"division\"] = division\n        if \"url\" not in sd:\n            if \"production_name\" in sd:\n                sd[\"url\"] = sd[\"production_name\"].capitalize()\n\n    # RETROCOMPATIBILITY\n    # provider name and url to assembly.provider_*: retrocompatibility\n    if \"provider\" in genome_data:\n        prov = genome_data[\"provider\"]\n        if \"name\" in prov and not \"provider_name\" in genome_data[\"assembly\"]:\n            genome_data[\"assembly\"][\"provider_name\"] = prov[\"name\"]\n        if \"url\" in prov and not \"provider_url\" in genome_data[\"assembly\"]:\n            genome_data[\"assembly\"][\"provider_url\"] = prov[\"url\"]\n        del genome_data[\"provider\"]\n\n    # BRC4 organism abbrev: move from species to BRC4 namespace\n    if \"species\" in genome_data:\n        sd = genome_data[\"species\"]\n        if \"BRC4_organism_abbrev\" in sd:\n            if \"BRC4\" not in genome_data:\n                genome_data[\"BRC4\"] = {}\n            if \"organism_abbrev\" not in genome_data[\"BRC4\"]:\n                genome_data[\"BRC4\"][\"organism_abbrev\"] = sd[\"BRC4_organism_abbrev\"]\n            del genome_data[\"species\"][\"BRC4_organism_abbrev\"]\n    # END RETROCOMPATIBILITY\n\n    # Set up display name if not set\n    if \"species\" in genome_data:\n        sd = genome_data[\"species\"]\n        if not \"display_name\" in sd and \"scientific_name\" in sd:\n            genome_data[\"species\"][\"display_name\"] = sd[\"scientific_name\"]\n\n    # flattern and dump\n    flat = self.flattern(genome_data, ignore)\n    flat += list(map(lambda p: (copy[p[0]], p[1]), filter(lambda x: x[0] in copy, flat)))\n    flat = list(filter(lambda x: x[0] not in ignore, flat))\n    if len(flat) &lt;= 0:\n        return\n\n    # dump\n    os.makedirs(wd, exist_ok=True)\n    sql_file = pj(wd, \"insert_meta.sql\")\n    with open(sql_file, \"w\") as sql:\n        print(\"insert ignore into meta (species_id, meta_key, meta_value) values\", file=sql)\n        c = \"\"\n        for _key, _val in flat:\n            if isinstance(_val, bool):\n                _val = int(_val)\n            if isinstance(_val, str):\n                _val = '\"%s\"' % (_val)\n            print('%s (1, \"%s\", %s)' % (c, str(_key), str(_val)), file=sql)\n            c = \",\"\n        print(\";\", file=sql)\n    # run insert sql\n    self.run_sql_req(sql_file, log_pfx=sql_file, from_file=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/fill_metadata/#ensembl.brc4.runnable.fill_metadata.fill_metadata.run_sql_req","title":"<code>run_sql_req(sql, log_pfx, from_file=False)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/fill_metadata.py</code> <pre><code>def run_sql_req(self, sql, log_pfx, from_file=False):\n    os.makedirs(dirname(log_pfx), exist_ok=True)\n\n    sql_option = r\"\"\" -sql '{_sql}' \"\"\".format(_sql=sql)\n    if from_file:\n        sql_option = r\"\"\" &lt; '{_sql}' \"\"\".format(_sql=sql)\n\n    cmd = r\"\"\"{_dbcmd} -url \"{_srv}{_dbname}\" {_sql_option} &gt; {_out} 2&gt; {_err}\"\"\".format(\n        _dbcmd=\"perl %s/scripts/db_cmd.pl\" % os.getenv(\"EHIVE_ROOT_DIR\"),\n        _srv=self.param(\"dbsrv_url\"),\n        _dbname=self.param(\"db_name\"),\n        _sql_option=sql_option,\n        _out=log_pfx + \".stdout\",\n        _err=log_pfx + \".stderr\",\n    )\n    print(\"running %s\" % (cmd), file=sys.stderr)\n    return sp.run(cmd, shell=True, check=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/json_schema_factory/","title":"json_schema_factory","text":""},{"location":"reference/ensembl/brc4/runnable/json_schema_factory/#ensembl.brc4.runnable.json_schema_factory","title":"<code>ensembl.brc4.runnable.json_schema_factory</code>","text":""},{"location":"reference/ensembl/brc4/runnable/json_schema_factory/#ensembl.brc4.runnable.json_schema_factory.json_schema_factory","title":"<code>json_schema_factory</code>","text":"<p>               Bases: <code>BaseRunnable</code></p> Source code in <code>src/python/ensembl/brc4/runnable/json_schema_factory.py</code> <pre><code>class json_schema_factory(eHive.BaseRunnable):\n    def run(self):\n        manifest_path = self.param_required(\"manifest\")\n\n        errors = []\n\n        with open(manifest_path) as manifest_file:\n            manifest = json.load(manifest_file)\n\n            # Check the manifest schema itself\n            self.dataflow_json(\"manifest\", manifest_path)\n\n            # Use dir name from the manifest\n            for name in manifest:\n                if \"file\" in manifest[name]:\n                    file_name = manifest[name][\"file\"]\n                    manifest[name] = path.join(path.dirname(manifest_path), file_name)\n                else:\n                    for f in manifest[name]:\n                        if \"file\" in manifest[name][f]:\n                            file_name = manifest[name][f][\"file\"]\n                            manifest[name][f] = path.join(path.dirname(manifest_path), file_name)\n\n            # Check the other jsons schemas\n            for metadata_type in (\"seq_region\", \"genome\", \"functional_annotation\"):\n                if metadata_type in manifest:\n                    self.dataflow_json(metadata_type, manifest[metadata_type])\n\n    def dataflow_json(self, metadata_type, metadata_json):\n        self.dataflow({\"metadata_type\": metadata_type, \"metadata_json\": metadata_json}, 2)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/json_schema_factory/#ensembl.brc4.runnable.json_schema_factory.json_schema_factory.dataflow_json","title":"<code>dataflow_json(metadata_type, metadata_json)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/json_schema_factory.py</code> <pre><code>def dataflow_json(self, metadata_type, metadata_json):\n    self.dataflow({\"metadata_type\": metadata_type, \"metadata_json\": metadata_json}, 2)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/json_schema_factory/#ensembl.brc4.runnable.json_schema_factory.json_schema_factory.run","title":"<code>run()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/json_schema_factory.py</code> <pre><code>def run(self):\n    manifest_path = self.param_required(\"manifest\")\n\n    errors = []\n\n    with open(manifest_path) as manifest_file:\n        manifest = json.load(manifest_file)\n\n        # Check the manifest schema itself\n        self.dataflow_json(\"manifest\", manifest_path)\n\n        # Use dir name from the manifest\n        for name in manifest:\n            if \"file\" in manifest[name]:\n                file_name = manifest[name][\"file\"]\n                manifest[name] = path.join(path.dirname(manifest_path), file_name)\n            else:\n                for f in manifest[name]:\n                    if \"file\" in manifest[name][f]:\n                        file_name = manifest[name][f][\"file\"]\n                        manifest[name][f] = path.join(path.dirname(manifest_path), file_name)\n\n        # Check the other jsons schemas\n        for metadata_type in (\"seq_region\", \"genome\", \"functional_annotation\"):\n            if metadata_type in manifest:\n                self.dataflow_json(metadata_type, manifest[metadata_type])\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/","title":"load_sequence_data","text":""},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data","title":"<code>ensembl.brc4.runnable.load_sequence_data</code>","text":""},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data","title":"<code>load_sequence_data</code>","text":"<p>               Bases: <code>BaseRunnable</code></p> <p>loading sequence data, seq region names, atrributes and synonyms</p> <p>eHive module to load sequnce data, seq region names, atrributes and synonyms from FASTAs AGPs and seq_region.json. Various ensembl-analysis perl scripts are used to create coord_systems, load sequences and set attributes. SQL commands through out the code to be replaces with the proper python API at some point.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>class load_sequence_data(eHive.BaseRunnable):\n    \"\"\"\n    loading sequence data, seq region names, atrributes and synonyms\n\n    eHive module to load sequnce data, seq region names, atrributes and synonyms from FASTAs AGPs and seq_region.json.\n    Various ensembl-analysis perl scripts are used to create coord_systems, load sequences and set attributes.\n    SQL commands through out the code to be replaces with the proper python API at some point.\n    \"\"\"\n\n    def param_defaults(self):\n        \"\"\"\n        default parameter/options values\n        \"\"\"\n        return {\n            # relative order of the coord_systems types to infer their rank from\n            \"cs_order\": \"ensembl_internal,chunk,contig,supercontig,non_ref_scaffold,scaffold,primary_assembly,superscaffold,linkage_group,chromosome\",\n            \"artificial_cs\": \"ensembl_internal,chunk\",  # coord_systems to ignore when adding synonyms for sequence_level cs\n            \"IUPAC\": \"RYKMSWBDHV\",  # symbols to be replaced with N in the DNA sequences (ensembl core(107) doesn't support the whole IUPAC alphabet for DNA)\n            # unversion scaffold, remove \".\\d$\" from seq_region.names if there's a need\n            \"unversion_scaffolds\": 0,\n            \"versioned_sr_syn_src\": \"INSDC\",  # INSDC(50710) # if unversioning non-sequence level cs, store original name (with version) as this synonym\n            \"sr_syn_src\": \"BRC4_Community_Symbol\",  # BRC4_Community_Symbol(211) # if unversioning sequence-level cs, store original name (with version) as this synonym\n            # nullify coord_system version for the given coord_system name\n            \"nullify_cs_version_from\": \"contig\",\n            # default coord_system name for single-level (no AGPs assemblies)\n            \"noagp_cs_name_default\": \"primary_assembly\",\n            # file for additional mapping of the synonym sources to the external_db (ensembl), as used by \"get_external_db_mapping\" function below\n            \"external_db_map\": None,\n            # set \"coord_system_tag\" seq_region attribute to this value if there's a corresponding \"chromosome_display_order\" list in genome.json metadata\n            #   if None, only \"chromosome\" coord system is processed (if present)\n            #   (see add_chr_karyotype_rank definition below )\n            #   if seq_region already has `coord_system_tagi` attribute, it value updated only if \"force_update_coord_system_tag\" module param is True (see below)\n            \"cs_tag_for_ordered\": None,\n            # Force updating of the \"coord_system_tags\" attribute for seq_regions from `cs_tag_for_ordered` (see above)\n            \"force_update_coord_system_tag\": False,\n            # BRC4 compatibility mode; if on, \"(EBI|BRC4)_seq_region_name\" seq_region_attributes are added.\n            #   Blocked by the \"swap_gcf_gca\" option. In this case insertion should be done on later pipeline stage after seq_region name swapping.\n            \"brc4_mode\": True,\n            # Whether to use RefSeq names as additional seq_region synonyms (if available) or not (see add_sr_synonyms definition below)\n            #  Does not swap anything actually, just loads synonyms to be used by a later \"swapping\" stage\n            #  Disables BRC4 compatibilty mode (see the \"brc4_mode\" option comment).\n            \"swap_gcf_gca\": False,\n            # list of coord systems used in \"-ignore_coord_system\" options of the \"ensembl-analysis/scripts/assembly_loading/set_toplevel.pl\" script\n            #   part of the loading process\n            \"not_toplevel_cs\": [],  # i.e. \"contig\", \"non_ref_scaffold\"\n            # explicit list of seq_region properties (keys) to load as seq_region_attrib s (values) (see add_sr_attribs definition below)\n            #   if a dict's used as a value, treat its keys as \"json_path\" (/ as delim) map, i.e.\n            #       { \"added_sequence\" : { \"assembly_provider\" : { \"name\" : ... } } } -&gt; \"added_sequence/assembly_provider/name\"\n            #   only flattable properties can be used, no arrays\n            #   arrays should be processed separately (see `add_sr_synonyms` or `add_karyotype_bands` definitions)\n            # see src/python/ensembl/io/genomio/data/schemas/seq_region.json\n            \"sr_attrib_types\": {\n                \"circular\": \"circular_seq\",\n                \"codon_table\": \"codon_table\",\n                \"location\": \"sequence_location\",\n                \"non_ref\": \"non_ref\",\n                \"coord_system_level\": \"coord_system_tag\",\n                \"added_sequence\": {\n                    # json_path to attrib_type_code(str) mapping\n                    \"added_sequence/accession\": \"added_seq_accession\",\n                    \"added_sequence/assembly_provider/name\": \"added_seq_asm_pr_nam\",\n                    \"added_sequence/assembly_provider/url\": \"added_seq_asm_pr_url\",\n                    \"added_sequence/annotation_provider/name\": \"added_seq_ann_pr_nam\",\n                    \"added_sequence/annotation_provider/url\": \"added_seq_ann_pr_url\",\n                },  # added_sequence\n            },\n            # loading additional sequences to the already exsisting core db\n            \"load_additional_sequences\": 0,\n            # size of the sequence data chunk, if 0 (default), no chunking is performed\n            \"sequence_data_chunk\": 0,\n            #   min size of the sequence chunk, no chunking is done if 'sequence_data_chunk' &lt; 'sequence_data_chunk_min'\n            \"sequence_data_chunk_min_len\": 50_000,\n            # coord system name for chunks\n            \"chunk_cs_name\": \"ensembl_internal\",\n        }\n\n    def run(self):\n        \"\"\"\n        Entry point for the Ehive module. All processing is done here in this case.\n        \"\"\"\n        # params\n        work_dir = self.param_required(\"work_dir\")\n\n        # initial sequence loading, using ensembl-analysis scripts\n        self.initial_sequence_loading(work_dir)\n\n        # load data from the corresponding core db tables\n        external_db_map = self.load_map_from_core_db(\n            \"external_db\", [\"db_name\", \"external_db_id\"], work_dir\n        )  # for external_db\n        attrib_type_map = self.load_map_from_core_db(\n            \"attrib_type\", [\"code\", \"attrib_type_id\"], work_dir\n        )  # for attrib_type\n        seq_region_map = self.load_map_from_core_db(\n            \"seq_region\", [\"name\", \"seq_region_id\"], work_dir\n        )  # for seq_region\n\n        # update synonyms and seq_region_attribs\n        unversion = self.param(\"unversion_scaffolds\")\n        is_primary_assembly = self.from_param(\"manifest_data\", \"agp\", not_throw=True) is None\n        seq_region_file = self.from_param(\"manifest_data\", \"seq_region\", not_throw=True)\n\n        #   add seq_region synonyms\n        self.add_sr_synonyms(\n            seq_region_file,\n            seq_region_map,\n            external_db_map,\n            self.pjc(work_dir, \"seq_region_syns\"),\n            unversion=unversion,\n        )\n\n        #   add seq_region attributes\n        self.add_sr_attribs(\n            seq_region_file,\n            seq_region_map,\n            attrib_type_map,\n            self.pjc(work_dir, \"seq_region_attr\"),\n            unversion=unversion,\n        )\n\n        #   add seq_region EBI and BRC4 name attributes in the \"BRC4 mode\"\n        #     special case of attributes adding with default values derived from seq_region names\n        #     do not add if preparing to swap RefSeq and GeneBank ids; in this case attributes to be added at a later stage in pipeline\n        #     (easier to insert then to update)\n        if self.param(\"brc4_mode\") and not self.param(\"swap_gcf_gca\"):\n            self.add_sr_ebi_brc4_names(\n                seq_region_file,\n                seq_region_map,\n                attrib_type_map,\n                self.pjc(work_dir, \"seq_region_ebi_brc4_name\"),\n                unversion=unversion,\n            )\n\n        # add karyotype related data\n        self.add_karyotype_data(\n            seq_region_file,\n            seq_region_map,\n            attrib_type_map,\n            self.pjc(work_dir, \"karyotype\"),\n            unversion=unversion,\n        )\n\n    def initial_sequence_loading(self, work_dir: str):\n        \"\"\"\n        initial preparation and loading of AGPs and fasta data.\n\n        initial preparation and loading of AGPs and fasta data using ensembl-analysis perl scripts\n        \"\"\"\n        # preprocess FASTA with sequences\n        #   rename IUPAC to N symbols using sed\n        fasta_clean = self.from_param(\"manifest_data\", \"fasta_dna\")\n\n        # start coord system ranking and agps processing\n        agps = self.from_param(\"manifest_data\", \"agp\", not_throw=True)\n\n        # get the deafult coord_system order\n        #   use noagp_cs_name_default for \"noagp\" assemblies\n        cs_order = self.coord_sys_order(self.param(\"cs_order\"))\n        noagps_cs = self.param(\"noagp_cs_name_default\")\n\n        # remove gaps and lower_level mappings if the are coveres by higher level ones\n        #   i.e.: remove 'contigN to chromosomeZ', if 'contigN to scaffoldM' and 'scaffoldM to chromosomeZ' are in place\n        #   returns None if no agps provided\n        agps_pruned_dir = self.pjc(work_dir, \"agps_pruned\")\n        agps_pruned = self.prune_agps(agps, cs_order, agps_pruned_dir, self.param_bool(\"prune_agp\"))\n\n        # order\n        # rank cs_names, met in agps.keys (\"-\" separated, i.e. \"scaffold-contig\") based on cs_order\n        cs_rank = self.used_cs_ranks(agps_pruned, cs_order, noagps_cs)\n\n        # chunk sequence data if needed\n        #   no chunking if chunk_size &lt; 50k\n        chunk_size = int(self.param(\"sequence_data_chunk\"))\n        chunk_cs_name = self.param(\"chunk_cs_name\")\n        fasta_clean, cs_rank, agps_pruned = self.chunk_contigs(\n            fasta_clean,\n            cs_rank,\n            agps_pruned,\n            pj(work_dir, \"chunking\"),\n            chunk_size=chunk_size,\n            chunks_cs_name=chunk_cs_name,\n        )\n\n        # empty agps_pruned ignored\n        self.load_seq_data(fasta_clean, agps_pruned, cs_rank, self.pjc(work_dir, \"load\"))\n\n        # mark all the \"contig\"s or noagp_cs as being sourced from ENA\n        if not self.param_bool(\"no_contig_ena_attrib\"):\n            # NB using original \"agps\" parameter (with no chunking data added)\n            agps_raw = self.from_param(\"manifest_data\", \"agp\", not_throw=True)\n            if agps_raw is None:\n                self.add_contig_ena_attrib(self.pjc(work_dir, \"load\", \"set_ena\"), cs_name=noagps_cs)\n            else:\n                self.add_contig_ena_attrib(self.pjc(work_dir, \"load\", \"set_ena\"))\n\n        # unversion scaffold, remove \".\\d$\" from names if there's a need\n        if self.param_bool(\"unversion_scaffolds\"):\n            self.unversion_scaffolds(cs_rank, self.pjc(work_dir, \"unversion_scaffolds\"))\n\n        # add assembly mappings between various cs to meta table for the mapper to work properly\n        cs_pairs = agps_pruned and agps_pruned.keys() or None\n        self.add_asm_mappings(cs_pairs, self.pjc(work_dir, \"asm_mappings\"))\n\n        # set toplevel seq_region attribute\n        self.set_toplevel(self.pjc(work_dir, \"set_toplevel\"), self.param(\"not_toplevel_cs\"))\n\n        # nullify contig version and update mappings strings accordingly; ignore for \"load_additional_sequences\" mode\n        if not self.param_bool(\"load_additional_sequences\"):\n            self.nullify_ctg_cs_version(cs_order, self.pjc(work_dir, \"asm_mapping\", \"nullify_cs_versions\"))\n\n    def add_sr_synonyms(\n        self,\n        seq_region_file: str,\n        seq_region_map: dict,\n        external_db_map: dict,\n        work_dir: str,\n        unversion: bool = False,\n        unversionable_sources_set: frozenset = frozenset([\"INSDC\", \"RefSeq\"]),\n    ):\n        \"\"\"\n        Add seq_region_synonym from the seq_region_file meta data file.\n\n        Add seq_region_synonym from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file.\n        Merge with the already existing ones in the db.\n\n        If unversion is true:\n          * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n          * the unversioned synonyms from the unversionable_sources_set will be added as well as the original ones\n\n        Too close to the DB schema.\n        \"\"\"\n        os.makedirs(work_dir, exist_ok=True)\n\n        # return if there's nothing to add\n        if not seq_region_file:\n            return\n\n        # get seq_region ids, names, syns from db\n        synonyms_trios_db = self.load_seq_region_synonyms_trios_from_core_db(\n            self.pjc(work_dir, \"syns_from_core\")\n        )\n\n        # form set of synonyms already present in db\n        synonyms_in_db = frozenset([trio[2] for trio in synonyms_trios_db if trio[2] != \"NULL\"])\n\n        # subset of sources to use the allowed the unversion synonyms\n        unversionable_sources = unversion and unversionable_sources_set or frozenset()\n\n        # technical / optimization. get external_db_id for \"ensembl_internal_synonym\"\n        ensembl_internal_synonym_ext_db_id = self.id_from_map_or_die(\n            \"ensembl_internal_synonym\", external_db_map, \"external_db_map\"\n        )\n\n        # get dict for additional mapping for sources to external_db names if there's one specified by \"external_db_map\" module param\n        #   not to be confused with the external_db_map function parameter above\n        additional_sources_mapping = self.get_external_db_mapping()\n\n        # load synonyms from the json file\n        synonyms_from_json = (\n            []\n        )  # [ (seq_region_id, synonym, external_db_id)... ] list of trios for inserting into db\n        with open(seq_region_file) as in_file:\n            seq_regions = list(json.load(in_file))\n            for seq_region in filter(lambda sr: sr.get(\"synonyms\", False), seq_regions):\n                # iterate through all seq_regions having \"synonyms\"\n                seq_region_name, seq_region_id, _ = self.name_and_id_from_seq_region_item(\n                    seq_region, seq_region_map, try_unversion=unversion\n                )\n\n                # fill synonyms_from_json list of trios\n                for synonym_item in list(seq_region[\"synonyms\"]):\n                    synonym_name = synonym_item[\"name\"]\n                    source = synonym_item[\"source\"]\n                    unversioned_name = \"\"\n\n                    # check if there's any addtional mapping for the source, remap if so\n                    if additional_sources_mapping:\n                        source = additional_sources_mapping.get(\n                            source, source\n                        )  # use the same name if no matches in additional_sources_mapping dict\n\n                    # try to get unversioned name if applicable\n                    if source in unversionable_sources:\n                        unversioned_name = re.sub(r\"\\.\\d+$\", \"\", synonym_name)\n\n                    # put trios if names are not already seen in db\n                    if synonym_name not in synonyms_in_db:\n                        external_db_id = self.id_from_map_or_die(source, external_db_map, \"external_db_map\")\n                        synonyms_from_json.append(\n                            (seq_region_id, self.quote_or_null(synonym_name), external_db_id)\n                        )\n\n                    #   put additional unversioned synonyms if there's a sane one\n                    if (\n                        unversioned_name\n                        and unversioned_name != synonym_name\n                        and unversioned_name not in synonyms_in_db\n                    ):\n                        synonyms_from_json.append(\n                            (\n                                seq_region_id,\n                                self.quote_or_null(unversioned_name),\n                                ensembl_internal_synonym_ext_db_id,\n                            )\n                        )\n\n        # run insertion SQL\n        self.insert_to_db(\n            synonyms_from_json,\n            \"seq_region_synonym\",\n            [\"seq_region_id\", \"synonym\", \"external_db_id\"],\n            self.pjc(work_dir, \"new_seq_region_synonyms\"),\n            ignore=True,\n        )\n\n    def add_sr_attribs(\n        self,\n        seq_region_file: str,\n        seq_region_map: dict,\n        attrib_type_map: dict,\n        work_dir,\n        unversion: bool = False,\n    ):\n        \"\"\"\n        Add seq_region_attrib(s) from the seq_region_file meta data file.\n\n        Explicit list is taken from \"sr_attrib_types\" module param.\n\n        Add seq_region_attrib(s) from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file.\n        Explicit list is taken from \"sr_attrib_types\" module param.\n\n        \"sr_attrib_types\" defines { json_property -&gt; attrib_type.name } map. If the value is dict,\n        its keys are treated as \"/\"-delimited \"json_path\" (i.e. \"added_sequence/assembly_provider/name\").\n        No arrays can be processed. Only simple or \"flattable\" types.\n\n        If unversion is true:\n          * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n        Too close to the DB schema.\n        \"\"\"\n        os.makedirs(work_dir, exist_ok=True)\n\n        # return if there's nothing to add\n        if not seq_region_file:\n            return\n\n        # technical / optimization. get atttib_type_id(s)\n        # create a smaller map with attrib_type_id(s) as values\n        properties_to_use = (\n            []\n        )  # [frozen]set with the top-level \"seq_region\" properties, that should be processed\n        path_attrib_id_map = dict()  # { \"flatterned/json/paths\" : attrib_id_map ))}\n        # fill set and map\n        for prop, attrib_type in self.param(\"sr_attrib_types\").items():\n            # adding high level properties to process\n            properties_to_use.append(prop)\n            # adding json paths (or properties themselves) to atrrib_type_id map\n            if isinstance(attrib_type, dict):  # if using json paths (delimeterd with \"/\")\n                for path, inner_attrib_type in attrib_type.items():\n                    path_attrib_id_map[path] = self.id_from_map_or_die(\n                        inner_attrib_type, attrib_type_map, \"attrib_type_map\"\n                    )\n            else:\n                path_attrib_id_map[prop] = self.id_from_map_or_die(\n                    attrib_type, attrib_type_map, \"attrib_type_map\"\n                )\n        # return if there's nothing to add\n        if not properties_to_use:\n            return\n\n        properties_to_use = frozenset(properties_to_use)\n\n        # load attributes from seq_region file\n        attrib_trios = []  # [ (seq_region_id, attrib_id, value)... ] list of trios for inserting into db\n        with open(seq_region_file) as in_file:\n            seq_regions = list(json.load(in_file))\n            for seq_region in seq_regions:\n                # get seq_region_id (perhaps, by using unversioned name)\n                seq_region_name, seq_region_id, unversioned_name = self.name_and_id_from_seq_region_item(\n                    seq_region, seq_region_map, try_unversion=unversion\n                )\n\n                # iterate through properties\n                for prop_name in properties_to_use:\n                    if prop_name not in seq_region:\n                        continue\n                    # flattern path\n                    path_attrib_id_values_list = self.flattern_seq_region_item(\n                        seq_region, prop_name, path_attrib_id_map\n                    )\n                    # fill attrib_trios\n                    for path, attrib_id, value in path_attrib_id_values_list:\n                        attrib_trios.append((seq_region_id, attrib_id, self.quote_or_null(value)))\n\n        # run insertion SQL\n        self.insert_to_db(\n            attrib_trios,\n            \"seq_region_attrib\",\n            [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n            self.pjc(work_dir, \"brc4_ebi_seq_region_synonyms\"),\n            ignore=True,\n        )\n\n    def flattern_seq_region_item(\n        self, seq_region: dict, prop_name: str, path_attrib_id_map: dict, sep: str = \"/\"\n    ) -&gt; list:\n        \"\"\"\n        Flattern seq_region[property] and store corresponding [ (json_path, attrib_id, value)... ] (as list of trios).\n\n        Only works for simple properties or dicts with no arrays on the path. Basically, implemets tree traversal.\n        Utility function used by the `add_sr_attribs` method\n        \"\"\"\n        res = []\n        # is there anything to do\n        if prop_name not in seq_region:\n            return res\n\n        # set up\n        value = seq_region[prop_name]\n        paths_to_go = [\n            (prop_name, value)\n        ]  # storing path and the corresponding value, to prevent repetetive traversals\n        # iterate\n        while paths_to_go:\n            (path, value) = paths_to_go.pop()  # get last item\n            if isinstance(value, list):\n                # perhaps, it's better to raise exception then to continue silently\n                continue\n            if isinstance(value, dict):\n                # if value is a complex object, add its leaves\n                for key, val in value.items():\n                    paths_to_go.append((f\"{path}{sep}{key}\", val))\n                continue\n            # if value is simple\n            attrib_id = path_attrib_id_map.get(path, None)\n            if attrib_id:\n                res.append((path, attrib_id, value))\n        # return what ever we have\n        return res\n\n    def add_sr_ebi_brc4_names(\n        self,\n        seq_region_file: str,\n        seq_region_map: dict,\n        attrib_type_map: dict,\n        work_dir: str,\n        unversion: bool = False,\n    ):\n        \"\"\"\n        Add \"(EBI|BRC4)_seq_region_name\" seq_region_attrib(s) either from the seq_region_file meta data file, or from original seq_region names.\n\n        Add \"(EBI|BRC4)_seq_region_name\" seq_region_synonym from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file or from the original seq_region_names.\n        A special case of attributes adding with default values derived from seq_region names.\n\n        If unversion is true:\n          * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n        Too close to the DB schema.\n        \"\"\"\n        os.makedirs(work_dir, exist_ok=True)\n\n        # return if there's nothing to add\n        if not seq_region_file:\n            return\n\n        # technical / optimization. get atttib_type_id(s) for \"(EBI|BRC4)_seq_region_name\"\n        tagged_sr_name_attrib_id = {\n            tag: self.id_from_map_or_die(f\"{tag}_seq_region_name\", attrib_type_map, \"attrib_type_map\")\n            for tag in [\"EBI\", \"BRC4\"]\n        }\n\n        # load BRC4/EBI name from seq_region file\n        brc4_ebi_name_attrib_trios = (\n            []\n        )  # [ (seq_region_id, attrib_id, value)... ] list of trios for inserting into db\n        with open(seq_region_file) as in_file:\n            seq_regions = list(json.load(in_file))\n            for seq_region in seq_regions:\n                # get seq_region_id (perhaps, by using unversioned name)\n                seq_region_name, seq_region_id, unversioned_name = self.name_and_id_from_seq_region_item(\n                    seq_region, seq_region_map, try_unversion=unversion\n                )\n                # append attribs to the brc4_ebi_name_attrib_trios list\n                for tag in [\"BRC4\", \"EBI\"]:\n                    attrib_name = f\"{tag}_seq_region_name\"\n                    attrib_id = tagged_sr_name_attrib_id[tag]\n                    value = seq_region.get(attrib_name, seq_region_name)\n                    brc4_ebi_name_attrib_trios.append((seq_region_id, attrib_id, self.quote_or_null(value)))\n\n        # run insertion SQL\n        self.insert_to_db(\n            brc4_ebi_name_attrib_trios,\n            \"seq_region_attrib\",\n            [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n            self.pjc(work_dir, \"brc4_ebi_seq_region_synonyms\"),\n            ignore=True,\n        )\n\n    def add_karyotype_data(\n        self,\n        seq_region_file: str,\n        seq_region_map: dict,\n        attrib_type_map: dict,\n        work_dir: str,\n        unversion: bool = False,\n    ):\n        \"\"\"\n        Adds various karyotypic data from seq_region file and assembly metadata (if present).\n\n        Adds various karyotypic data from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file and assembly metadata (if present).\n\n        If unversion is true:\n          * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n        \"\"\"\n        # add karyotyope bands data\n        regions_with_karyotype_bands = self.add_karyotype_bands(\n            seq_region_file,\n            seq_region_map,\n            attrib_type_map,\n            self.pjc(work_dir, \"karyotype_bands\"),\n            unversion=unversion,\n        )\n\n        # try to add karyotype ranks for regions listed in genome_data/assembly/chromosome_display_order metadata\n        regions_with_ranks_from_assembly_metadata = self.add_karyotype_rank_based_on_assembly_metadata(\n            seq_region_map,\n            attrib_type_map,\n            self.pjc(work_dir, \"karyotype_ranks_from_meta\"),\n            unversion=unversion,\n        )\n\n        regions_with_ranks_from_chromosome_cs = []\n        if not regions_with_ranks_from_assembly_metadata:\n            # try to add karyotype_ranks for top-level regions from the \"chromosome\" coord_system\n            regions_with_ranks_from_chromosome_cs = self.add_karyotype_rank_for_chromosomes(\n                attrib_type_map, self.pjc(work_dir, \"karyotype_ranks_for_chromosomes\")\n            )\n\n        # make sure that regions with bands have karyotype_ranks\n        self.add_karyotype_rank_from_bands_info(\n            regions_with_karyotype_bands,\n            regions_with_ranks_from_chromosome_cs + regions_with_ranks_from_assembly_metadata,\n            attrib_type_map,\n            self.pjc(work_dir, \"karyotype_ranks_from_bands\"),\n        )\n\n    def add_karyotype_bands(\n        self,\n        seq_region_file: str,\n        seq_region_map: dict,\n        attrib_type_map: dict,\n        work_dir: str,\n        unversion: bool = False,\n        karyotype_bands_property=\"karyotype_bands\",\n    ) -&gt; list:  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n        \"\"\"\n        Add karyotypic data from the seq_region metafile.\n\n        Add karyotypic data from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file.\n        Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions having karyotype bands info.\n\n        If unversion is true:\n          * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n        Too close to the DB schema.\n        \"\"\"\n        os.makedirs(work_dir, exist_ok=True)\n\n        # return if there's nothing to add\n        if not seq_region_file:\n            return\n\n        # resulting list of seq regions with bands\n        seq_regions_with_karyotype_bands = []  # [ ( seq_region_name, seq_region_id, unversioned_name )... ]\n\n        # load BRC4/EBI name from seq_region file\n        band_tuples = (\n            []\n        )  # [ (seq_region_id, seq_region_start, seq_region_end, band|\"NULL\", stain|\"NULL\")... ] list of tuples for inserting into db\n        with open(seq_region_file) as in_file:\n            seq_regions = list(json.load(in_file))\n            for seq_region in filter(lambda sr: sr.get(karyotype_bands_property, False), seq_regions):\n                # iterate through all seq_regions having non-empty \"karyotype_bands\"\n\n                # get seq_region_id (perhaps, by using unversioned name)\n                seq_region_name, seq_region_id, unversioned_name = self.name_and_id_from_seq_region_item(\n                    seq_region, seq_region_map, try_unversion=unversion\n                )\n\n                # append trio to the resulting list\n                seq_regions_with_karyotype_bands.append((seq_region_name, seq_region_id, unversioned_name))\n\n                # append bands to the band_tuples list\n                for band in seq_region[karyotype_bands_property]:\n                    # print(\"BAND: \" + str(band), file = sys.stderr)\n                    # coords\n                    seq_region_start = band[\"start\"]\n                    seq_region_end = band[\"end\"]\n                    # band_name and stain\n                    band_name = band.get(\"name\", None)\n                    stain = band.get(\"stain\", None)\n                    # special cases for stain\n                    structure = band.get(\"structure\", None)\n                    if structure == \"telomere\":\n                        stain = \"TEL\"\n                    elif structure == \"centromere\":\n                        stain = \"ACEN\"\n\n                    # append tuple\n                    band_tuples.append(\n                        (\n                            seq_region_id,\n                            seq_region_start,\n                            seq_region_end,\n                            self.quote_or_null(band_name),\n                            self.quote_or_null(stain),\n                        )\n                    )\n\n        # run insertion SQL\n        self.insert_to_db(\n            band_tuples,\n            \"karyotype\",\n            [\"seq_region_id\", \"seq_region_start\", \"seq_region_end\", \"band\", \"stain\"],\n            self.pjc(work_dir, \"karyotype_insertion\"),\n            ignore=True,\n        )\n\n        # return resulting list of regions with bands trios\n        return seq_regions_with_karyotype_bands\n\n    def add_karyotype_rank_based_on_assembly_metadata(\n        self, seq_region_map: dict, attrib_type_map: dict, work_dir: str, unversion: bool = True\n    ) -&gt; list:  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n        \"\"\"\n        Add `karyotype_rank` attributes for seq region data from based on metadata from the \"genome_data\" module parameter.\n        Add only to the seq_regions with ids listed in the array corresponding to 'genome_data/assembly/chromosome_display_order'.\n\n        Set \"coord_system_tag\" attribute to the one listed in the \"cs_tag_for_ordered\" module param; or \"chromosome\" if param value is underfined.\n        Force updating of the \"coord_system_tags\" if `force_update_coord_system_tag` module param is True.\n\n        Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions with updated karyotype_ranks.\n\n        If unversion is true:\n          * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n        Too close to the DB schema.\n        \"\"\"\n\n        # resulting list of seq_region with karyotype_rank\n        regions_with_ranks_from_assembly_metadata = (\n            []\n        )  # [ ( seq_region_name, seq_region_id, unversioned_name )... ]\n\n        # get `chromosome_display_order` list from the assembly metadata\n        assembly_metadata = self.from_param(\"genome_data\", \"assembly\", not_throw=True) or dict()\n        chromosome_display_order_list = assembly_metadata.get(\"chromosome_display_order\", [])\n\n        # technical / optimization. get external_db_id for \"karyotype_rank\" and \"coord_system_tag\"\n        karyotype_rank_attrib_id = self.id_from_map_or_die(\n            \"karyotype_rank\", attrib_type_map, \"attrib_type_map\"\n        )\n        coord_system_tag_attrib_id = self.id_from_map_or_die(\n            \"coord_system_tag\", attrib_type_map, \"attrib_type_map\"\n        )\n        coord_system_tag = self.param(\"cs_tag_for_ordered\") or \"chromosome\"\n        force_update_coord_system_tag = self.param(\"force_update_coord_system_tag\") or False\n\n        # set/update proper attributes for `chromosome_display_order_list` regions\n        rank_insertions_trios = []\n        coord_system_tag_attrib_insertion_trios = []\n        coord_system_tag_attrib_seq_region_update_ids = []\n\n        for seq_region_name_raw in chromosome_display_order_list:\n            # wrap seq_region_name_raw into seq_region struct { \"name\": seq_region_name_raw } and\n            # get seq_region_id (perhaps, by using unversioned name)\n            seq_region_name, seq_region_id, unversioned_name = self.name_and_id_from_seq_region_item(\n                {\"name\": seq_region_name_raw}, seq_region_map, try_unversion=unversion\n            )\n\n            # append trio to the resulting list\n            regions_with_ranks_from_assembly_metadata.append(\n                (seq_region_name, seq_region_id, unversioned_name)\n            )\n\n            # filling insert lists for \"karyotype_rank\" and \"coord_system_tag\" attributes\n            rank_insertions_trios.append(\n                (seq_region_id, karyotype_rank_attrib_id, len(rank_insertions_trios) + 1)\n            )\n            coord_system_tag_attrib_insertion_trios.append(\n                (seq_region_id, coord_system_tag_attrib_id, self.quote_or_null(coord_system_tag))\n            )\n\n            # filling update list for \"coord_system_tag\" with seq_region_ids\n            coord_system_tag_attrib_seq_region_update_ids.append(seq_region_id)\n\n        # run insertion SQL for \"karyotype_rank\"\n        self.insert_to_db(\n            rank_insertions_trios,\n            \"seq_region_attrib\",\n            [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n            self.pjc(work_dir, \"karyotype_rank_insertion\"),\n            ignore=True,\n        )\n\n        # run insertion SQL for \"coord_system_tag\"\n        self.insert_to_db(\n            coord_system_tag_attrib_insertion_trios,\n            \"seq_region_attrib\",\n            [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n            self.pjc(work_dir, \"coord_system_tag_insertion\"),\n            ignore=True,\n        )\n\n        # forcing update of the \"coord_system_tag\"\n        if force_update_coord_system_tag and coord_system_tag_attrib_seq_region_update_ids:\n            seq_region_ids_str = \",\".join(map(str, coord_system_tag_attrib_seq_region_update_ids))\n            self.update_db_single_group(\n                {\"value\": self.quote_or_null(coord_system_tag)},\n                \"seq_region_attrib\",\n                self.pjc(work_dir, \"coord_system_tag_update\"),\n                where=f\"attrib_type_id = {coord_system_tag_attrib_id} and seq_region_id in ({seq_region_ids_str})\",\n            )\n\n        # return resulting list of regions with bands trios\n        return regions_with_ranks_from_assembly_metadata\n\n    def add_karyotype_rank_for_chromosomes(\n        self, attrib_type_map: dict, work_dir: str, chromosome_coord_system_name=\"chromosome\"\n    ) -&gt; list:  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n        \"\"\"\n        Add `karyotype_rank` attributes for seq region data from the \"chromosome\" coordinate system.\n\n        Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions with updated karyotype_ranks.\n        Not altering \"coord_system_tag\" tag attributes.\n\n        If unversion is true:\n          * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n        Too close to the DB schema.\n        \"\"\"\n\n        # resulting list of seq_region with karyotype_rank\n        #   list of top level seq regions from the `chromosome_coord_system_name`\n        chromomes_seq_regions = self.get_toplevel_from_cs(\n            chromosome_coord_system_name, self.pjc(work_dir, \"chromosome_seq_regions\")\n        )\n\n        if not chromomes_seq_regions:\n            return chromomes_seq_regions\n\n        # technical / optimization. get external_db_id for \"karyotype_rank\"\n        karyotype_rank_attrib_id = self.id_from_map_or_die(\n            \"karyotype_rank\", attrib_type_map, \"attrib_type_map\"\n        )\n\n        # set/update proper attributes for \"chromomosome\" regions\n        rank_insertions_trios = []\n        for _, seq_region_id, _ in chromomes_seq_regions:\n            rank_insertions_trios.append(\n                (seq_region_id, karyotype_rank_attrib_id, len(rank_insertions_trios) + 1)\n            )\n\n        # run insertion SQL for \"karyotype_rank\"\n        #    do not alter \"coord_system_tag\" anyhow in the case of the \"chromosome\" coord_system\n        self.insert_to_db(\n            rank_insertions_trios,\n            \"seq_region_attrib\",\n            [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n            self.pjc(work_dir, \"karyotype_rank_insertion\"),\n            ignore=True,\n        )\n\n        return chromomes_seq_regions\n\n    def add_karyotype_rank_from_bands_info(\n        self,\n        regions_with_karyotype_bands: list,  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n        other_regions_with_ranks: list,  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n        attrib_type_map: dict,\n        work_dir: str,\n    ):\n        \"\"\"\n        Add karyotype_ranks for `regions_with_karyotype_bands` (those with karyotype bands in seq_region metadata) but not present in `other_regions_with_ranks` list.\n\n        Too close to the DB schema.\n        \"\"\"\n        # form set of used seq_region_id(s)\n        regions_with_ranks = frozenset(map(lambda el: el[1], other_regions_with_ranks))\n\n        # get set of seq_region_ids with bands\n        regions_with_bands = set(map(lambda el: el[1], regions_with_karyotype_bands))\n\n        # seq_region_ids list to add ranks for\n        region_ids_with_bands_but_no_karyotype_ranks = sorted(list(regions_with_bands - regions_with_ranks))\n\n        # return if nothing to add\n        if not region_ids_with_bands_but_no_karyotype_ranks:\n            return\n\n        # technical / optimization. get external_db_id for \"karyotype_rank\"\n        karyotype_rank_attrib_id = self.id_from_map_or_die(\n            \"karyotype_rank\", attrib_type_map, \"attrib_type_map\"\n        )\n\n        # set/update proper attributes for \"chromomosome\" regions\n        rank_insertions_trios = []\n        for seq_region_id in region_ids_with_bands_but_no_karyotype_ranks:\n            rank_insertions_trios.append(\n                (\n                    seq_region_id,\n                    karyotype_rank_attrib_id,\n                    len(rank_insertions_trios) + 1 + len(regions_with_ranks),\n                )\n            )\n\n        # run insertion SQL for \"karyotype_rank\"\n        #    do not alter \"coord_system_tag\" anyhow in the case of the \"chromosome\" coord_system\n        self.insert_to_db(\n            rank_insertions_trios,\n            \"seq_region_attrib\",\n            [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n            self.pjc(work_dir, \"karyotype_rank_insertion\"),\n            ignore=True,\n        )\n\n    def unversion_scaffolds(self, cs_rank, logs):\n        \"\"\"\n        Unversion scaffold, remove \".\\d$\" from seq_region.names if there's a need\n\n        Non-versioned syns for contigs (lower, sequence level), versioned for the rest.\n        \"\"\"\n        # coord_systems to ignore when adding synonyms for sequence_level cs\n        artificial_cs = frozenset(self.param(\"artificial_cs\").split(\",\"))\n        seq_cs, max_rank = max(\n            [(c, r) for c, r in cs_rank.items() if c not in artificial_cs], key=lambda k: k[1]\n        )\n        for cs in cs_rank:\n            if cs == seq_cs:\n                # for non-sequence level cs, store original name (with version) as \"sr_syn_src\" synonym\n                xdb = self.param(\"sr_syn_src\")\n                self.copy_sr_name_to_syn(cs, xdb, self.pjc(logs, \"cp2syn\", cs))\n                self.sr_name_unversion(cs, \"seq_region_synonym\", \"synonym\", self.pjc(logs, \"unv_srs\", cs))\n            else:\n                # for sequence-level cs, store original name (with version) as \"versioned_sr_syn_src\" synonym\n                xdb = self.param(\"versioned_sr_syn_src\")\n                self.copy_sr_name_to_syn(cs, xdb, self.pjc(logs, \"cp2syn\", cs))\n                self.sr_name_unversion(cs, \"seq_region\", \"name\", self.pjc(logs, \"unv_sr\", cs))\n\n    def coord_sys_order(self, cs_order_str):\n        cs_order_lst = map(lambda x: x.strip(), cs_order_str.split(\",\"))\n        return {e: i for i, e in enumerate(filter(lambda x: len(x) &gt; 0, cs_order_lst))}\n\n    def used_cs_ranks(self, agps, cs_order, noagp_default=None):\n        # rank cs_names, met in agps.keys (\"-\" separated), i.e. \"scaffold-contig\"\n        #   only agps keys used, values are ignored\n        #   use noagp_cs_name_default for \"noagp\" assemblies\n        if agps is None:\n            if noagp_default is None:\n                raise Exception(\"NoAGP assembly with no default coordinate system name\")\n            cs_used_set = frozenset([noagp_default])\n        else:\n            cs_used_set = frozenset(sum(map(lambda x: x.split(\"-\"), agps.keys()), []))\n\n        cs_unknown = cs_used_set.difference(cs_order.keys())\n        if len(cs_unknown) &gt; 0:\n            raise Exception(\"Unknown coordinate system(s) %s\" % {str(cs_unknown)})\n        return {e: i for i, e in enumerate(sorted(cs_used_set, key=lambda x: -cs_order[x]), start=1)}\n\n    def chunk_contigs(self, fasta, cs_ranks, agps, work_dir, chunk_size=0, chunks_cs_name=\"ensembl_internal\"):\n        \"\"\"\n        chunk dna sequence fasta\n          no chunking if chunk_size &lt; 50k\n        \"\"\"\n        chunk_size_min_len = self.param_required(\"sequence_data_chunk_min_len\")\n        if chunk_size &lt; chunk_size_min_len:\n            return fasta, cs_ranks, agps\n\n        # split using script\n        os.makedirs(work_dir, exist_ok=True)\n        _stderr = f\"{work_dir}/chunking.stderr\"\n        _out_agp = f\"{work_dir}/chunks.agp\"\n        _out_fasta = f\"{work_dir}/chunks.fasta\"\n\n        _splitter = r\"fasta_chunk\"\n        split_cmd = f\"{_splitter} --chunk_size {chunk_size} --agp_out {_out_agp} --out {_out_fasta} --fasta_dna {fasta} 2&gt; {_stderr}\"\n\n        print(f\"running {split_cmd}\", file=sys.stderr)\n        # NB throws CalledProcessError if failed\n        sp.run(split_cmd, shell=True, check=True)\n\n        # add rank for chunks\n        _cs_name, _cs_rank = sorted(cs_ranks.items(), key=lambda k: k[1])[-1]\n        cs_ranks[chunks_cs_name] = _cs_rank + 1\n\n        # add agps entry\n        if agps is None:\n            agps = dict()\n        agps[f\"{_cs_name}-{chunks_cs_name}\"] = _out_agp\n\n        return _out_fasta, cs_ranks, agps\n\n    def prune_agps(self, agps, cs_order, agps_pruned_dir, pruning=True):\n        # when loading agp sort by:\n        #   highest component (cmp) cs level (lowest rank)\n        #   lowest difference between cs ranks (asm - cmp)\n        #   i.e: chromosome-scaffold scaffold-chunk chromosome-chunk\n        #   if no agps return empty pruned result\n\n        if not agps:\n            return None\n\n        agp_levels_sorted = self.order_agp_levels(agps, cs_order)\n\n        # prune agps\n        agps_pruned = dict()\n        used_components = set()\n        if not pruning:\n            used_components = None\n        for asm_cmp in agp_levels_sorted:\n            agp_file_src = agps[asm_cmp]\n            agp_file_dst = self.pjc(agps_pruned_dir, asm_cmp + \".agp\")\n            if self.agp_prune(agp_file_src, agp_file_dst, used_components) &gt; 0:\n                agps_pruned[asm_cmp] = agp_file_dst\n        return agps_pruned\n\n    def order_agp_levels(self, agps, cs_order):\n        # sort agp for loading by:\n        #   highest component (cmp) cs level (lowest rank)\n        #   lowest difference between cs ranks (asm - cmp)\n        #   i.e: chromosome-scaffold scaffold-chunk chromosome-chunk\n        if not agps:\n            return []\n\n        agp_cs_pairs = list(map(lambda x: [x] + x.split(\"-\"), agps.keys()))\n        agp_levels = [(x[0], cs_order[x[1]], cs_order[x[2]]) for x in agp_cs_pairs]\n\n        bad_agps = list(filter(lambda x: x[1] &lt; x[2], agp_levels))\n        if len(bad_agps) &gt; 0:\n            raise Exception(\"component cs has higher order than assembled cs %s\" % (str(bad_agps)))\n\n        agp_levels_sorted = [e[0] for e in sorted(agp_levels, key=lambda x: (-x[2], x[1] - x[2]))]\n        return agp_levels_sorted\n\n    def load_seq_data(self, fasta, agps, cs_rank, log_pfx):\n        \"\"\"loads sequence data for various coordinate systems accordingly with their rank\"\"\"\n        asm_v = self.asm_name()\n\n        sequence_rank = max(cs_rank.values())\n        for cs, rank in sorted(cs_rank.items(), key=lambda p: -p[1]):\n            logs = self.pjc(log_pfx, \"%02d_%s\" % (rank, cs))\n            if rank == sequence_rank:\n                self.load_cs_data(cs, rank, \"fasta\", asm_v, fasta, logs, loaded_regions=None, seq_level=True)\n            else:\n                useful_agps = list(filter(lambda x: cs in x, agps and agps.keys() or []))\n                if len(useful_agps) == 0:\n                    raise Exception(\"non-seq_level cs %s has no agps to assemble it from\" % (cs))\n                loaded_regions = set()\n                for pair, agp_file_pruned in map(lambda k: (k, agps[k]), useful_agps):\n                    if not pair.startswith(cs + \"-\"):\n                        continue\n                    self.load_cs_data(cs, rank, pair, asm_v, agp_file_pruned, logs, loaded_regions)\n\n    def load_cs_data(self, cs, rank, pair, asm_v, src_file, log_pfx, loaded_regions=None, seq_level=False):\n        \"\"\"creates a coord_system and loads sequence or assembly(AGP) data for corresponding seqregions\n\n        doesn't load already seen sequences\n        \"\"\"\n        # NB load_seq_region.pl and load_agp.pl are not failing on parameter errors (0 exit code)\n        os.makedirs(dirname(log_pfx), exist_ok=True)\n        additional_load = self.param_bool(\"load_additional_sequences\")\n        if seq_level:\n            self.load_seq_region(cs, rank, asm_v, src_file, log_pfx, seq_level, additional_load)\n        elif loaded_regions is not None:\n            new_regions = set()\n            clean_file = src_file + \".regions_deduped\"\n            self.filter_already_loaded_regions_from_agp(src_file, clean_file, loaded_regions, new_regions)\n            self.load_seq_region(cs, rank, asm_v, clean_file, log_pfx, seq_level, additional_load)\n            loaded_regions.update(new_regions)\n        if not seq_level:\n            self.load_agp(pair, asm_v, src_file, log_pfx)\n\n    def filter_already_loaded_regions_from_agp(self, src_file, dst_file, loaded_regions, new_regions):\n        with open(src_file) as src:\n            with open(dst_file, \"w\") as dst:\n                for line in src:\n                    fields = line.strip().split(\"\\t\")\n                    (\n                        asm_id,\n                        asm_start,\n                        asm_end,\n                        asm_part,\n                        type_,\n                        cmp_id,\n                        cmp_start,\n                        cmp_end,\n                        cmp_strand,\n                    ) = fields\n                    if type_ in \"NU\" or asm_id in loaded_regions:\n                        continue\n                    new_regions.add(asm_id)\n                    print(line.strip(), file=dst)\n\n    def agp_prune(self, from_file: str, to_file: str, used: set = None):\n        \"\"\"\n        Remove already components from the AGP file if they are seen in \"used\" set\n        \"\"\"\n        # reomve used component\n        #   and GAPS as they are not used by 'ensembl-analysis/scripts/assembly_loading/load_agp.pl'\n        os.makedirs(dirname(to_file), exist_ok=True)\n        open_ = self.is_gz(from_file) and gzip.open or open\n        if used is None:\n            cmd = r\"\"\"{_cat} {_file} &gt; {_out}\"\"\".format(\n                _cat=self.is_gz(from_file) and \"zcat\" or \"cat\", _file=from_file, _out=to_file\n            )\n            print(\"running %s\" % (cmd), file=sys.stderr)\n            sp.run(cmd, shell=True, check=True)\n            return 1\n        writes = 0\n        with open_(from_file, \"r\") as src:\n            with open(to_file, \"w\") as dst:\n                for line in src:\n                    fields = line.strip().split(\"\\t\")\n                    (\n                        asm_id,\n                        asm_start,\n                        asm_end,\n                        asm_part,\n                        type_,\n                        cmp_id,\n                        cmp_start,\n                        cmp_end,\n                        cmp_strand,\n                    ) = fields\n                    if type_ in \"NU\" or cmp_id in used:\n                        continue\n                    used.add(cmp_id)\n                    print(line.strip(), file=dst)\n                    writes += 1\n        return writes\n\n    def get_external_db_mapping(self) -&gt; dict:\n        \"\"\"\n        Get a map from a file for external_dbs to Ensembl dbnames from \"external_db_map\" module(!) param\n        \"\"\"\n        external_map_path = self.param(\"external_db_map\")\n        db_map = dict()\n        if external_map_path is None:\n            return db_map\n\n        # Load the map\n        with open(external_map_path, \"r\") as map_file:\n            for line in map_file:\n                if line.startswith(\"#\"):\n                    continue\n                line = re.sub(r\"#.*\", \"\", line)\n                if re.match(r\"^\\s*$\", line):\n                    continue\n                (from_name, to_name, *rest) = line.strip().split(\"\\t\")\n                if len(rest) &gt; 0 and rest[0].upper() != \"SEQ_REGION\":\n                    continue\n                if to_name == \"_IGNORE_\":\n                    continue\n                db_map[from_name] = to_name\n        return db_map\n\n    # UTILS\n    def db_string(self):\n        return \"-dbhost {host_} -dbport {port_} -dbuser {user_} -dbpass {pass_} -dbname {dbname_} \".format(\n            host_=self.param(\"dbsrv_host\"),\n            port_=self.param(\"dbsrv_port\"),\n            user_=self.param(\"dbsrv_user\"),\n            pass_=self.param(\"dbsrv_pass\"),\n            dbname_=self.param(\"db_name\"),\n        )\n\n    def pjc(self, *parts: list) -&gt; str:\n        \"\"\"\n        Join path parts and try to create every directory but the last one.\n        \"\"\"\n        if not parts:\n            return None\n\n        parts = list(parts)\n        last = parts.pop()\n        prefix = pj(*parts)\n\n        os.makedirs(prefix, exist_ok=True)\n\n        return pj(prefix, last)\n\n    def is_gz(self, filename):\n        return filename.endswith(\".gz\")\n\n    def asm_name(self):\n        asm = self.from_param(\"genome_data\", \"assembly\")\n        if \"name\" not in asm:\n            raise Exception(\"no assembly/name in genome_data\")\n        return asm[\"name\"]\n\n    # TODO: add some metafunc setter getter\n    def from_param(self, param, key, not_throw=False):\n        data = self.param_required(param)\n        if key not in data:\n            if not_throw:\n                return None\n            else:\n                raise Exception(\"Missing required %s data: %s\" % (param, key))\n        return data[key]\n\n    def param_bool(self, param):\n        val = self.param(param)\n        return bool(val) and \"0\" != val\n\n    def load_map_from_sql_stdout(self, in_file, skip_header=False):\n        \"\"\"\n        Load map from the SQL output\n\n        Process input in_file with \"key  value\" pairs and load then\n        into the {key : value} map.\n        Skips header if skip_header.\n        \"\"\"\n        data = dict()\n        with open(in_file) as pairs_file:\n            for line in pairs_file:\n                if skip_header:\n                    skip_header = False\n                    continue\n                (key, val) = line.strip().split(\"\\t\")\n                data[key] = val\n        return data\n\n    def name_and_id_from_seq_region_item(\n        self,\n        seq_region_item: dict,\n        seq_region_map: dict,\n        try_unversion: bool = False,\n        throw_missing: bool = True,\n    ) -&gt; (str, str, str):\n        \"\"\"\n        Get (seq_region_name, seq_region_id, unversioned_name) from seq_region_item struct(dict)\n\n        Gets unversioned_name only if \"try_unversion\" is True.\n        Throws exception if not able to get seq_region_id from \"seq_region_map\" and \"throw_missing\" is true.\n        \"\"\"\n        #   get seq_region_id (perhaps, by using unversioned name)\n        seq_region_name = seq_region_item[\"name\"]\n        seq_region_id = seq_region_map.get(seq_region_name, None)\n        unversioned_name = None\n        if seq_region_id is None and try_unversion:\n            # try to get seq_region_id for the unversioned name\n            unversioned_name = re.sub(r\"\\.\\d+$\", \"\", seq_region_name)\n            seq_region_id = seq_region_map.get(unversioned_name, \"\")\n\n        # oops, we don't know such seq_region name\n        if not seq_region_id and throw_missing:\n            raise Exception(f\"Not able to find seq_region for '{seq_region_name}'\")\n\n        return (seq_region_name, seq_region_id, unversioned_name)\n\n    def id_from_map_or_die(self, key: str, map_dict: dict, name_for_panic):\n        value = map_dict.get(key, None)\n        if value is None:\n            raise Exception(f\"no such key '{key}' in '{name_for_panic}' map\")\n        return value\n\n    ## Utilities using external scripts\n    def remove_IUPAC(self, from_file: str, to_file: str):\n        \"\"\"remove non-valid symbols from FASTA file (using sed) ans store the result in a different location\"\"\"\n        IUPAC = self.param(\"IUPAC\")\n        os.makedirs(dirname(to_file), exist_ok=True)\n        cmd = r\"\"\"{_cat} {_file} | sed -r '/^[^&gt;]/ {{ s/[{_IUPAC}]/N/g; s/{_iupac}/n/g }}' &gt; {_out}\"\"\".format(\n            _cat=self.is_gz(from_file) and \"zcat\" or \"cat\",\n            _file=from_file,\n            _IUPAC=IUPAC.upper(),\n            _iupac=IUPAC.lower(),\n            _out=to_file,\n        )\n        print(\"running %s\" % (cmd), file=sys.stderr)\n        return sp.run(cmd, shell=True, check=True)\n\n    def load_seq_region(\n        self,\n        cs: str,\n        rank: str,\n        asm_v: str,\n        src_file: str,\n        log_pfx: str,\n        seq_level=False,\n        additional_load=False,\n    ):\n        \"\"\"ensembl-analysis script (load_seq_region.pl) based utility for loading seq_regions FASTA sequences\"\"\"\n        en_root = self.param_required(\"ensembl_root_dir\")\n        cmd = (\n            r\"\"\"{_loader} {_db_string} {_asm_v_flag} -default_version -ignore_ambiguous_bases \"\"\"\n            + r\"\"\"    -rank {_rank} -coord_system_name {_cs} {_sl_flag} -{_tag}_file {_file}\"\"\"\n            + r\"\"\"     &gt; {_log}.stdout 2&gt; {_log}.stderr\"\"\"\n        ).format(\n            _loader=\"perl %s\"\n            % (self.pjc(en_root, r\"ensembl-analysis/scripts/assembly_loading/load_seq_region.pl\")),\n            _db_string=self.db_string(),\n            _asm_v_flag=not additional_load and f\"-coord_system_version {asm_v}\" or \"\",\n            _rank=rank,\n            _cs=cs,\n            _sl_flag=seq_level and \"-sequence_level\" or \"\",\n            _tag=seq_level and \"fasta\" or \"agp\",\n            _file=src_file,\n            _log=\"%s_seq\" % (log_pfx),\n        )\n        print(\"running %s\" % (cmd), file=sys.stderr)\n        return sp.run(cmd, shell=True, check=True)\n\n    def load_agp(self, pair, asm_v, src_file, log_pfx):\n        \"\"\"ensembl script (load_agp.pl) based utility for loading seq_regions assembly data (AGPs)\"\"\"\n        en_root = self.param_required(\"ensembl_root_dir\")\n        (asm_n, cmp_n) = pair.strip().split(\"-\")\n        cmd = (\n            r\"\"\"{_loader} {_db_string} -assembled_version {_asm_v} \"\"\"\n            + r\"\"\"    -assembled_name {_asm} -component_name {_cmp} \"\"\"\n            + r\"\"\"    -agp_file {_file} \"\"\"\n            + r\"\"\"    &gt; {_log}.stdout 2&gt; {_log}.stderr\"\"\"\n        ).format(\n            _loader=\"perl %s\" % (self.pjc(en_root, r\"ensembl-analysis/scripts/assembly_loading/load_agp.pl\")),\n            _db_string=self.db_string(),\n            _asm_v=asm_v,\n            _asm=asm_n,\n            _cmp=cmp_n,\n            _file=src_file,\n            _log=\"%s_agp_%s\" % (log_pfx, pair.replace(\"-\", \"_\")),\n        )\n        print(\"running %s\" % (cmd), file=sys.stderr)\n        return sp.run(cmd, shell=True, check=True)\n\n    def set_toplevel(self, log_pfx, ignored_cs=[]):\n        \"\"\"\n        Set toplevel(6) seq_region_attrib using ensembl script.\n\n        Uses set_toplevel.pl ensembl script.\n        \"\"\"\n        # set top_level(6) seq_region_attrib\n        os.makedirs(dirname(log_pfx), exist_ok=True)\n        en_root = self.param_required(\"ensembl_root_dir\")\n        cmd = (\n            r\"\"\"{_set_tl} {_db_string} {_ignored_cs} \"\"\" + r\"\"\"     &gt; {_log}.stdout 2&gt; {_log}.stderr\"\"\"\n        ).format(\n            _set_tl=\"perl %s\"\n            % (self.pjc(en_root, r\"ensembl-analysis/scripts/assembly_loading/set_toplevel.pl\")),\n            _db_string=self.db_string(),\n            _ignored_cs=\" \".join(map(lambda x: \"-ignore_coord_system %s\" % (x), ignored_cs)),\n            _log=log_pfx,\n        )\n        print(\"running %s\" % (cmd), file=sys.stderr)\n        sp.run(cmd, shell=True, check=True)\n\n        # remove toplevel attribute for seq_regions that are components\n        self.remove_components_from_toplevel(log_pfx)\n\n    ## SQL executor and utilities using plain SQL\n    def run_sql_req(self, sql, log_pfx, from_file=False):\n        os.makedirs(dirname(log_pfx), exist_ok=True)\n\n        sql_option = r\"\"\" -sql '{_sql}' \"\"\".format(_sql=sql)\n        if from_file:\n            sql_option = r\"\"\" &lt; '{_sql}' \"\"\".format(_sql=sql)\n\n        cmd = r\"\"\"{_dbcmd} -url \"{_srv}{_dbname}\" {_sql_option} &gt; {_out} 2&gt; {_err}\"\"\".format(\n            _dbcmd=\"perl %s/scripts/db_cmd.pl\" % os.getenv(\"EHIVE_ROOT_DIR\"),\n            _srv=self.param(\"dbsrv_url\"),\n            _dbname=self.param(\"db_name\"),\n            _sql_option=sql_option,\n            _out=log_pfx + \".stdout\",\n            _err=log_pfx + \".stderr\",\n        )\n        print(\"running %s\" % (cmd), file=sys.stderr)\n        return sp.run(cmd, shell=True, check=True)\n\n    def add_contig_ena_attrib(self, log_pfx, cs_name=\"contig\"):\n        \"\"\"\n        Add ENA attrib for contigs if their names are ENA accessions\n\n        Nno sequence_level checks are used -- just cs name.\n        See ensembl-datacheck/lib/Bio/EnsEMBL/DataCheck/Checks/SeqRegionNamesINSDC.pm .\n        SQL code.\n        \"\"\"\n        sql = r\"\"\"insert ignore into seq_region_attrib (seq_region_id, attrib_type_id, value)\n                select\n                  sr.seq_region_id, at.attrib_type_id, \"ENA\"\n                from\n                  seq_region sr, coord_system cs, attrib_type at\n                where   sr.coord_system_id = cs.coord_system_id\n                    and cs.name = \"%s\"\n                    and at.code = \"external_db\"\n              ;\"\"\" % (\n            cs_name\n        )\n        return self.run_sql_req(sql, log_pfx)\n\n    def copy_sr_name_to_syn(self, cs, x_db, log_pfx):\n        \"\"\"\n        Store original seq_region names as seq_region_synonym\n\n        Store original seq_region names (from a given cood_systen, \"cs\" param) as seq_region_synonyms (using \"x_db\" external source name)\n        SQL code.\n        \"\"\"\n        asm_v = self.asm_name()\n        sql = r\"\"\"insert into seq_region_synonym (seq_region_id, synonym, external_db_id)\n                  select\n                      sr.seq_region_id, sr.name, xdb.external_db_id\n                  from\n                     seq_region sr, external_db xdb, coord_system cs\n                  where   xdb.db_name = \"%s\"\n                      and sr.coord_system_id = cs.coord_system_id\n                      and cs.name = \"%s\"\n                      and cs.version = \"%s\"\n                      and sr.name like \"%%._\"\n                ;\"\"\" % (\n            x_db,\n            cs,\n            asm_v,\n        )\n        return self.run_sql_req(sql, log_pfx)\n\n    def add_asm_mappings(self, cs_pairs, log_pfx):\n        \"\"\"\n        Adds \"assembly.mapping\" strings to meta table.\n\n        Nullifies asm_mappings contig versions as well, but don't nullify toplevel\n        Doesn't add mapping id there is a single CS\n        SQL code.\n        \"\"\"\n        if cs_pairs is None or len(cs_pairs) &lt; 1:\n            return\n        asm_v = self.asm_name()\n        for pair in cs_pairs:\n            higher, lower = pair.strip().split(\"-\")\n            sql = r\"\"\"insert ignore into meta (species_id, meta_key, meta_value) values\n                    (1, \"assembly.mapping\", \"{_higher}:{_v}|{_lower}:{_v}\")\n                  ;\"\"\".format(\n                _v=asm_v, _higher=higher, _lower=lower\n            )\n            self.run_sql_req(sql, self.pjc(log_pfx, pair))\n\n    def remove_components_from_toplevel(self, log_pfx):\n        \"\"\"\n        Remove toplevel attribute for seq_regions that are \"components\" (parts of different seq_regions).\n\n        SQL code.\n        \"\"\"\n\n        # get list of seq_regions that are components\n        sql_not_toplevel_list = r\"\"\"\n          select distinct a.cmp_seq_region_id, sr_c.name, cs_c.name\n            from assembly a,\n                 seq_region sr_c, seq_region sr_a,\n                 coord_system cs_c, coord_system cs_a\n            where a.cmp_seq_region_id = sr_c.seq_region_id\n              and a.asm_seq_region_id = sr_a.seq_region_id\n              and sr_c.coord_system_id = cs_c.coord_system_id\n              and sr_a.coord_system_id = cs_a.coord_system_id\n              and cs_c.attrib like \"%default_version%\"\n              and cs_a.attrib like \"%default_version%\"\n              and sr_c.seq_region_id in (\n                select distinct seq_region_id\n                  from seq_region_attrib\n                  where attrib_type_id = 6 and value = 1\n              )\n        \"\"\"\n        # perhaps, make sense to check sr_c.coord_system_id != sr_a.coord_system_id\n        self.run_sql_req(sql_not_toplevel_list, \".\".join([log_pfx, \"not_toplevel_list\"]))\n\n        # delete wrongly assigned attribs\n        sql_not_toplevel_delete = r\"\"\"\n          delete from seq_region_attrib\n            where attrib_type_id = 6 and value = 1\n              and seq_region_id in (\n                select distinct a.cmp_seq_region_id\n                  from assembly a,\n                       seq_region sr_c, seq_region sr_a,\n                       coord_system cs_c, coord_system cs_a\n                  where a.cmp_seq_region_id = sr_c.seq_region_id\n                    and a.asm_seq_region_id = sr_a.seq_region_id\n                    and sr_c.coord_system_id = cs_c.coord_system_id\n                    and sr_a.coord_system_id = cs_a.coord_system_id\n                    and cs_c.attrib like \"%default_version%\"\n                    and cs_a.attrib like \"%default_version%\"\n              );\n        \"\"\"\n        # perhaps, check sr_c.coord_system_id != sr_a.coord_system_id\n        self.run_sql_req(sql_not_toplevel_delete, \".\".join([log_pfx, \"not_toplevel_delete\"]))\n\n    def sr_name_unversion(self, cs, tbl, fld, log_pfx):\n        \"\"\"\n        Remove version suffix from the seq_region names\n\n        Removes '\\.\\d+$' suffices from the seq_region names\n        SQL code.\n        \"\"\"\n        # select synonym, substr(synonym,  1, locate(\".\", synonym, length(synonym)-2)-1)\n        #     from seq_region_synonym  where synonym like \"%._\"\n        asm_v = self.asm_name()\n        sql = r\"\"\"update {_tbl} t, seq_region sr, coord_system cs\n                    set\n                      t.{_fld} = substr(t.{_fld},  1, locate(\".\", t.{_fld}, length(t.{_fld})-2)-1)\n                    where t.{_fld} like \"%._\"\n                      and t.seq_region_id = sr.seq_region_id\n                      and sr.coord_system_id = cs.coord_system_id\n                      and cs.name = \"{_cs}\"\n                      and cs.version = \"{_asm_v}\"\n                ;\"\"\".format(\n            _tbl=tbl, _fld=fld, _cs=cs, _asm_v=asm_v\n        )\n        return self.run_sql_req(sql, log_pfx)\n\n    def nullify_ctg_cs_version(self, cs_order, log_pfx: str):\n        \"\"\"\n        Nullify every CS version with rank larger than that of \"contig\", but don't nullify toplevel ones.\n\n        SQL code\n        \"\"\"\n        asm_v = self.asm_name()\n        # get cs_info (and if they have toplevel regions)\n        sql = r\"\"\"select cs.coord_system_id as coord_system_id,\n                         cs.name, cs.rank, (tl.coord_system_id is NULL) as no_toplevel\n                    from coord_system cs\n                      left join (\n                        select distinct sr.coord_system_id\n                          from seq_region sr, seq_region_attrib sra, attrib_type at\n                          where at.code = \"toplevel\"\n                            and sra.attrib_type_id = at.attrib_type_id\n                            and sra.value = 1\n                            and sra.seq_region_id = sr.seq_region_id\n                      ) as tl on tl.coord_system_id = cs.coord_system_id\n                    where cs.version = \"{_asm_v}\"\n                    order by rank\n              ;\"\"\".format(\n            _asm_v=asm_v\n        )\n        # run_sql\n        toplvl_pfx = self.pjc(log_pfx, \"toplvl_info\")\n        self.run_sql_req(sql, toplvl_pfx)\n        # load info\n        cs_info = []\n        with open(toplvl_pfx + \".stdout\") as f:\n            header = None\n            for line in f:\n                if header is None:\n                    header = line.strip().split(\"\\t\")\n                    continue\n                cs_info.append(dict(zip(header, line.strip().split())))\n        # return if there's no coord_systems to nullify versions for\n        if not cs_info:\n            return\n        # get list of known cs from cs_order to clean version from\n        nullify_cs_version_from = self.param(\"nullify_cs_version_from\")\n        if not nullify_cs_version_from or nullify_cs_version_from not in cs_order:\n            return\n        cs_thr_index = cs_order[nullify_cs_version_from]\n        cs_names_to_keep_ver = frozenset([nm for (nm, ind) in cs_order.items() if ind &gt; cs_thr_index])\n\n        # choose cs rank threshold to start clearing version from\n        clear_lst = [\n            (cs[\"coord_system_id\"], cs[\"name\"])\n            for cs in cs_info\n            if (bool(int(cs[\"no_toplevel\"])) and cs[\"name\"] not in cs_names_to_keep_ver)\n        ]\n\n        # run sql\n        if clear_lst:\n            clear_pfx = self.pjc(log_pfx, \"clear\")\n            with open(clear_pfx + \".sql\", \"w\") as clear_sql:\n                for cs_id, cs_name in clear_lst:\n                    sql = r\"\"\"\n                        update meta set\n                            meta_value=replace(meta_value, \"|{_cs_name}:{_asm_v}\", \"|{_cs_name}\")\n                            where meta_key=\"assembly.mapping\";\n                        update coord_system set version = NULL where coord_system_id = {_cs_id};\n                    \"\"\".format(\n                        _asm_v=asm_v, _cs_name=cs_name, _cs_id=cs_id\n                    )\n                    print(sql, file=clear_sql)\n            self.run_sql_req(clear_pfx + \".sql\", clear_pfx, from_file=True)\n\n    def load_map_from_core_db(self, table, cols, work_dir) -&gt; dict:\n        \"\"\"\n        Load 2 \"cols\" from core db \"table\" as map\n\n        Load { cols[0] : cols[1] } map from the core db \"table\"\n        SQL code\n        \"\"\"\n        out_pfx = self.pjc(work_dir, f\"{table}_map\")\n        sql = f\"\"\"select {cols[0]}, {cols[1]} FROM {table};\"\"\"\n        res = self.run_sql_req(sql, out_pfx)\n\n        out_file = out_pfx + \".stdout\"\n        data = self.load_map_from_sql_stdout(out_file, skip_header=True)\n        if not data:\n            raise Exception(f\"No '{table}' map loaded from '{out_file}'\")\n        return data\n\n    def load_seq_region_synonyms_trios_from_core_db(self, work_dir: str) -&gt; list:\n        # was get_db_syns\n        \"\"\"\n        Load seq_region_synonyms from from core db into [(seq_region_id, name, synonym)...] list\n\n        SQL code\n        \"\"\"\n        out_pfx = self.pjc(work_dir, f\"seq_region_synonyms\")\n        sql = r\"\"\"select sr.seq_region_id as seq_region_id, sr.name, srs.synonym\n                 from seq_region sr left join seq_region_synonym srs\n                 on sr.seq_region_id = srs.seq_region_id\n                 order by sr.seq_region_id\n              ;\"\"\"\n\n        res = self.run_sql_req(sql, out_pfx)\n\n        syn_trios = []\n        out_file = out_pfx + \".stdout\"\n        with open(out_file) as syns_file:\n            skip_header = True\n            for line in syns_file:\n                if skip_header:\n                    skip_header = False\n                    continue\n                (sr_id, name, syn) = line.strip().split(\"\\t\")\n                syn_trios.append((sr_id, name, syn))\n        return syn_trios\n\n    def insert_to_db(\n        self, list_of_tuples: list, table_name: str, col_names: list, work_dir: str, ignore: bool = True\n    ):\n        \"\"\"\n        Insert into the core db's {table_name} tuples from {list_of_tuples} as col_names.\n\n        Use `quote_or_null` (see definition below) method for string values, when putting values into `list_of_tuples`\n        SQL code\n        \"\"\"\n        # return if nothing to do\n        if not list_of_tuples:\n            return\n\n        # prepare request parts\n        ignore_str = ignore and \"IGNORE\" or \"\"\n        cols_str = \", \".join(col_names)\n\n        # generate file with the insert SQL command\n        insert_sql_file = self.pjc(work_dir, \"insert.sql\")\n        with open(insert_sql_file, \"w\") as sql:\n            print(f\"INSERT {ignore_str} INTO {table_name} ({cols_str}) VALUES\", file=sql)\n            values_sep = \"\"\n            for tpl in list_of_tuples:\n                tpl_str = \", \".join(map(str, tpl))\n                print(f\"{values_sep}({tpl_str})\", file=sql)\n                values_sep = \", \"\n            print(\";\", file=sql)\n\n        # run insert SQL from file\n        self.run_sql_req(insert_sql_file, self.pjc(work_dir, \"insert\"), from_file=True)\n\n    def quote_or_null(self, val: str, quotes: str = \"'\", null: str = \"NULL\", strings_only=True) -&gt; str:\n        \"\"\"\n        Return `val` wrapped in `quotes` or `null` value\n\n        Quotes only strings (instances of `str`) if strings_only is True.\n        \"\"\"\n        if val is None:\n            return null\n        if strings_only and isinstance(val, str):\n            return f\"{quotes}{val}{quotes}\"\n        return val\n\n    def update_db_single_group(\n        self, dict_of_col_to_value: dict, table_name: str, work_dir: str, where: str = None\n    ):\n        \"\"\"\n        Update given `table` name in db; set `col = val` for all key/value pairs from `dict_of_cols_to_values`\n\n        If `where` condition is present its value is used for the \"WHERE\" SQL clause.\n        Use `quote_or_null` (see definition below) method for string values, when putting values into `list_of_tuples`\n\n        SQL code\n        \"\"\"\n        # return if nothing to do\n        if not dict_of_col_to_value:\n            return\n\n        # prepare request parts\n        where_str = where and f\"WHERE {where}\" or \"\"\n        col_val_str = \", \".join([f\"{col} = {val}\" for col, val in dict_of_col_to_value.items()])\n\n        # generate file with the insert SQL command\n        update_sql_file = self.pjc(work_dir, \"update.sql\")\n        with open(insert_sql_file, \"w\") as sql:\n            print(f\"UPDATE {table_name} SET {col_val_str} {where_str};\", file=sql)\n            values_sep = \"\"\n            for tpl in list_of_tuples:\n                tpl_str = \", \".join(map(str, tpl))\n                print(f\"{values_sep}({tpl_str})\", file=sql)\n                values_sep = \", \"\n            print(\";\", file=sql)\n\n        # run insert SQL from file\n        self.run_sql_req(update_sql_file, self.pjc(work_dir, \"update\"), from_file=True)\n\n    def get_toplevel_from_cs(self, coord_system_name, work_dir) -&gt; list:\n        \"\"\"\n        Returns list of [ (seq_region_name, seq_region_id, \"\") ] trios for toplevel seq_regions from coord system with `coord_system_name`\n          or having  \"coord_system_tag\" attribute with the `coord_system_name` value\n\n        SQL code\n        \"\"\"\n        out_pfx = self.pjc(work_dir, f\"toplevel_from_{coord_system_name}\")\n        sql = f\"\"\"SELECT DISTINCT sr.name, sr.seq_region_id\n                FROM seq_region sr,\n                     seq_region_attrib sra,\n                     coord_system cs,\n                     attrib_type at\n                WHERE sr.seq_region_id = sra.seq_region_id\n                  AND sr.coord_system_id = cs.coord_system_id\n                  AND sra.attrib_type_id = at.attrib_type_id\n                  AND (  ( cs.name = \"{coord_system_name}\" and at.code = \"toplevel\" )\n                      OR ( at.code = \"coord_system_tag\" and sra.value = \"{coord_system_name}\" )\n                      )\n                  ORDER BY sr.seq_region_id;\n               \"\"\"\n\n        res = self.run_sql_req(sql, out_pfx)\n\n        sr_trios = []\n        out_file = out_pfx + \".stdout\"\n        with open(out_file) as sr_file:\n            skip_header = True\n            for line in sr_file:\n                if skip_header:\n                    skip_header = False\n                    continue\n                (name, sr_id) = line.strip().split(\"\\t\")\n                sr_trios.append((name, sr_id, \"\"))\n\n        return sr_trios\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_asm_mappings","title":"<code>add_asm_mappings(cs_pairs, log_pfx)</code>","text":"<p>Adds \"assembly.mapping\" strings to meta table.</p> <p>Nullifies asm_mappings contig versions as well, but don't nullify toplevel Doesn't add mapping id there is a single CS SQL code.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_asm_mappings(self, cs_pairs, log_pfx):\n    \"\"\"\n    Adds \"assembly.mapping\" strings to meta table.\n\n    Nullifies asm_mappings contig versions as well, but don't nullify toplevel\n    Doesn't add mapping id there is a single CS\n    SQL code.\n    \"\"\"\n    if cs_pairs is None or len(cs_pairs) &lt; 1:\n        return\n    asm_v = self.asm_name()\n    for pair in cs_pairs:\n        higher, lower = pair.strip().split(\"-\")\n        sql = r\"\"\"insert ignore into meta (species_id, meta_key, meta_value) values\n                (1, \"assembly.mapping\", \"{_higher}:{_v}|{_lower}:{_v}\")\n              ;\"\"\".format(\n            _v=asm_v, _higher=higher, _lower=lower\n        )\n        self.run_sql_req(sql, self.pjc(log_pfx, pair))\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_contig_ena_attrib","title":"<code>add_contig_ena_attrib(log_pfx, cs_name='contig')</code>","text":"<p>Add ENA attrib for contigs if their names are ENA accessions</p> <p>Nno sequence_level checks are used -- just cs name. See ensembl-datacheck/lib/Bio/EnsEMBL/DataCheck/Checks/SeqRegionNamesINSDC.pm . SQL code.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_contig_ena_attrib(self, log_pfx, cs_name=\"contig\"):\n    \"\"\"\n    Add ENA attrib for contigs if their names are ENA accessions\n\n    Nno sequence_level checks are used -- just cs name.\n    See ensembl-datacheck/lib/Bio/EnsEMBL/DataCheck/Checks/SeqRegionNamesINSDC.pm .\n    SQL code.\n    \"\"\"\n    sql = r\"\"\"insert ignore into seq_region_attrib (seq_region_id, attrib_type_id, value)\n            select\n              sr.seq_region_id, at.attrib_type_id, \"ENA\"\n            from\n              seq_region sr, coord_system cs, attrib_type at\n            where   sr.coord_system_id = cs.coord_system_id\n                and cs.name = \"%s\"\n                and at.code = \"external_db\"\n          ;\"\"\" % (\n        cs_name\n    )\n    return self.run_sql_req(sql, log_pfx)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_karyotype_bands","title":"<code>add_karyotype_bands(seq_region_file, seq_region_map, attrib_type_map, work_dir, unversion=False, karyotype_bands_property='karyotype_bands')</code>","text":"<p>Add karyotypic data from the seq_region metafile.</p> <p>Add karyotypic data from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file. Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions having karyotype bands info.</p> If unversion is true <ul> <li>the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible</li> </ul> <p>Too close to the DB schema.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_karyotype_bands(\n    self,\n    seq_region_file: str,\n    seq_region_map: dict,\n    attrib_type_map: dict,\n    work_dir: str,\n    unversion: bool = False,\n    karyotype_bands_property=\"karyotype_bands\",\n) -&gt; list:  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n    \"\"\"\n    Add karyotypic data from the seq_region metafile.\n\n    Add karyotypic data from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file.\n    Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions having karyotype bands info.\n\n    If unversion is true:\n      * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n    Too close to the DB schema.\n    \"\"\"\n    os.makedirs(work_dir, exist_ok=True)\n\n    # return if there's nothing to add\n    if not seq_region_file:\n        return\n\n    # resulting list of seq regions with bands\n    seq_regions_with_karyotype_bands = []  # [ ( seq_region_name, seq_region_id, unversioned_name )... ]\n\n    # load BRC4/EBI name from seq_region file\n    band_tuples = (\n        []\n    )  # [ (seq_region_id, seq_region_start, seq_region_end, band|\"NULL\", stain|\"NULL\")... ] list of tuples for inserting into db\n    with open(seq_region_file) as in_file:\n        seq_regions = list(json.load(in_file))\n        for seq_region in filter(lambda sr: sr.get(karyotype_bands_property, False), seq_regions):\n            # iterate through all seq_regions having non-empty \"karyotype_bands\"\n\n            # get seq_region_id (perhaps, by using unversioned name)\n            seq_region_name, seq_region_id, unversioned_name = self.name_and_id_from_seq_region_item(\n                seq_region, seq_region_map, try_unversion=unversion\n            )\n\n            # append trio to the resulting list\n            seq_regions_with_karyotype_bands.append((seq_region_name, seq_region_id, unversioned_name))\n\n            # append bands to the band_tuples list\n            for band in seq_region[karyotype_bands_property]:\n                # print(\"BAND: \" + str(band), file = sys.stderr)\n                # coords\n                seq_region_start = band[\"start\"]\n                seq_region_end = band[\"end\"]\n                # band_name and stain\n                band_name = band.get(\"name\", None)\n                stain = band.get(\"stain\", None)\n                # special cases for stain\n                structure = band.get(\"structure\", None)\n                if structure == \"telomere\":\n                    stain = \"TEL\"\n                elif structure == \"centromere\":\n                    stain = \"ACEN\"\n\n                # append tuple\n                band_tuples.append(\n                    (\n                        seq_region_id,\n                        seq_region_start,\n                        seq_region_end,\n                        self.quote_or_null(band_name),\n                        self.quote_or_null(stain),\n                    )\n                )\n\n    # run insertion SQL\n    self.insert_to_db(\n        band_tuples,\n        \"karyotype\",\n        [\"seq_region_id\", \"seq_region_start\", \"seq_region_end\", \"band\", \"stain\"],\n        self.pjc(work_dir, \"karyotype_insertion\"),\n        ignore=True,\n    )\n\n    # return resulting list of regions with bands trios\n    return seq_regions_with_karyotype_bands\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_karyotype_data","title":"<code>add_karyotype_data(seq_region_file, seq_region_map, attrib_type_map, work_dir, unversion=False)</code>","text":"<p>Adds various karyotypic data from seq_region file and assembly metadata (if present).</p> <p>Adds various karyotypic data from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file and assembly metadata (if present).</p> If unversion is true <ul> <li>the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible</li> </ul> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_karyotype_data(\n    self,\n    seq_region_file: str,\n    seq_region_map: dict,\n    attrib_type_map: dict,\n    work_dir: str,\n    unversion: bool = False,\n):\n    \"\"\"\n    Adds various karyotypic data from seq_region file and assembly metadata (if present).\n\n    Adds various karyotypic data from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file and assembly metadata (if present).\n\n    If unversion is true:\n      * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n    \"\"\"\n    # add karyotyope bands data\n    regions_with_karyotype_bands = self.add_karyotype_bands(\n        seq_region_file,\n        seq_region_map,\n        attrib_type_map,\n        self.pjc(work_dir, \"karyotype_bands\"),\n        unversion=unversion,\n    )\n\n    # try to add karyotype ranks for regions listed in genome_data/assembly/chromosome_display_order metadata\n    regions_with_ranks_from_assembly_metadata = self.add_karyotype_rank_based_on_assembly_metadata(\n        seq_region_map,\n        attrib_type_map,\n        self.pjc(work_dir, \"karyotype_ranks_from_meta\"),\n        unversion=unversion,\n    )\n\n    regions_with_ranks_from_chromosome_cs = []\n    if not regions_with_ranks_from_assembly_metadata:\n        # try to add karyotype_ranks for top-level regions from the \"chromosome\" coord_system\n        regions_with_ranks_from_chromosome_cs = self.add_karyotype_rank_for_chromosomes(\n            attrib_type_map, self.pjc(work_dir, \"karyotype_ranks_for_chromosomes\")\n        )\n\n    # make sure that regions with bands have karyotype_ranks\n    self.add_karyotype_rank_from_bands_info(\n        regions_with_karyotype_bands,\n        regions_with_ranks_from_chromosome_cs + regions_with_ranks_from_assembly_metadata,\n        attrib_type_map,\n        self.pjc(work_dir, \"karyotype_ranks_from_bands\"),\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_karyotype_rank_based_on_assembly_metadata","title":"<code>add_karyotype_rank_based_on_assembly_metadata(seq_region_map, attrib_type_map, work_dir, unversion=True)</code>","text":"<p>Add <code>karyotype_rank</code> attributes for seq region data from based on metadata from the \"genome_data\" module parameter. Add only to the seq_regions with ids listed in the array corresponding to 'genome_data/assembly/chromosome_display_order'.</p> <p>Set \"coord_system_tag\" attribute to the one listed in the \"cs_tag_for_ordered\" module param; or \"chromosome\" if param value is underfined. Force updating of the \"coord_system_tags\" if <code>force_update_coord_system_tag</code> module param is True.</p> <p>Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions with updated karyotype_ranks.</p> If unversion is true <ul> <li>the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible</li> </ul> <p>Too close to the DB schema.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_karyotype_rank_based_on_assembly_metadata(\n    self, seq_region_map: dict, attrib_type_map: dict, work_dir: str, unversion: bool = True\n) -&gt; list:  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n    \"\"\"\n    Add `karyotype_rank` attributes for seq region data from based on metadata from the \"genome_data\" module parameter.\n    Add only to the seq_regions with ids listed in the array corresponding to 'genome_data/assembly/chromosome_display_order'.\n\n    Set \"coord_system_tag\" attribute to the one listed in the \"cs_tag_for_ordered\" module param; or \"chromosome\" if param value is underfined.\n    Force updating of the \"coord_system_tags\" if `force_update_coord_system_tag` module param is True.\n\n    Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions with updated karyotype_ranks.\n\n    If unversion is true:\n      * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n    Too close to the DB schema.\n    \"\"\"\n\n    # resulting list of seq_region with karyotype_rank\n    regions_with_ranks_from_assembly_metadata = (\n        []\n    )  # [ ( seq_region_name, seq_region_id, unversioned_name )... ]\n\n    # get `chromosome_display_order` list from the assembly metadata\n    assembly_metadata = self.from_param(\"genome_data\", \"assembly\", not_throw=True) or dict()\n    chromosome_display_order_list = assembly_metadata.get(\"chromosome_display_order\", [])\n\n    # technical / optimization. get external_db_id for \"karyotype_rank\" and \"coord_system_tag\"\n    karyotype_rank_attrib_id = self.id_from_map_or_die(\n        \"karyotype_rank\", attrib_type_map, \"attrib_type_map\"\n    )\n    coord_system_tag_attrib_id = self.id_from_map_or_die(\n        \"coord_system_tag\", attrib_type_map, \"attrib_type_map\"\n    )\n    coord_system_tag = self.param(\"cs_tag_for_ordered\") or \"chromosome\"\n    force_update_coord_system_tag = self.param(\"force_update_coord_system_tag\") or False\n\n    # set/update proper attributes for `chromosome_display_order_list` regions\n    rank_insertions_trios = []\n    coord_system_tag_attrib_insertion_trios = []\n    coord_system_tag_attrib_seq_region_update_ids = []\n\n    for seq_region_name_raw in chromosome_display_order_list:\n        # wrap seq_region_name_raw into seq_region struct { \"name\": seq_region_name_raw } and\n        # get seq_region_id (perhaps, by using unversioned name)\n        seq_region_name, seq_region_id, unversioned_name = self.name_and_id_from_seq_region_item(\n            {\"name\": seq_region_name_raw}, seq_region_map, try_unversion=unversion\n        )\n\n        # append trio to the resulting list\n        regions_with_ranks_from_assembly_metadata.append(\n            (seq_region_name, seq_region_id, unversioned_name)\n        )\n\n        # filling insert lists for \"karyotype_rank\" and \"coord_system_tag\" attributes\n        rank_insertions_trios.append(\n            (seq_region_id, karyotype_rank_attrib_id, len(rank_insertions_trios) + 1)\n        )\n        coord_system_tag_attrib_insertion_trios.append(\n            (seq_region_id, coord_system_tag_attrib_id, self.quote_or_null(coord_system_tag))\n        )\n\n        # filling update list for \"coord_system_tag\" with seq_region_ids\n        coord_system_tag_attrib_seq_region_update_ids.append(seq_region_id)\n\n    # run insertion SQL for \"karyotype_rank\"\n    self.insert_to_db(\n        rank_insertions_trios,\n        \"seq_region_attrib\",\n        [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n        self.pjc(work_dir, \"karyotype_rank_insertion\"),\n        ignore=True,\n    )\n\n    # run insertion SQL for \"coord_system_tag\"\n    self.insert_to_db(\n        coord_system_tag_attrib_insertion_trios,\n        \"seq_region_attrib\",\n        [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n        self.pjc(work_dir, \"coord_system_tag_insertion\"),\n        ignore=True,\n    )\n\n    # forcing update of the \"coord_system_tag\"\n    if force_update_coord_system_tag and coord_system_tag_attrib_seq_region_update_ids:\n        seq_region_ids_str = \",\".join(map(str, coord_system_tag_attrib_seq_region_update_ids))\n        self.update_db_single_group(\n            {\"value\": self.quote_or_null(coord_system_tag)},\n            \"seq_region_attrib\",\n            self.pjc(work_dir, \"coord_system_tag_update\"),\n            where=f\"attrib_type_id = {coord_system_tag_attrib_id} and seq_region_id in ({seq_region_ids_str})\",\n        )\n\n    # return resulting list of regions with bands trios\n    return regions_with_ranks_from_assembly_metadata\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_karyotype_rank_for_chromosomes","title":"<code>add_karyotype_rank_for_chromosomes(attrib_type_map, work_dir, chromosome_coord_system_name='chromosome')</code>","text":"<p>Add <code>karyotype_rank</code> attributes for seq region data from the \"chromosome\" coordinate system.</p> <p>Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions with updated karyotype_ranks. Not altering \"coord_system_tag\" tag attributes.</p> If unversion is true <ul> <li>the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible</li> </ul> <p>Too close to the DB schema.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_karyotype_rank_for_chromosomes(\n    self, attrib_type_map: dict, work_dir: str, chromosome_coord_system_name=\"chromosome\"\n) -&gt; list:  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n    \"\"\"\n    Add `karyotype_rank` attributes for seq region data from the \"chromosome\" coordinate system.\n\n    Returns list of [ (seq_region_name, seq_region_id, unversioned_name) ] trios for seq_regions with updated karyotype_ranks.\n    Not altering \"coord_system_tag\" tag attributes.\n\n    If unversion is true:\n      * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n    Too close to the DB schema.\n    \"\"\"\n\n    # resulting list of seq_region with karyotype_rank\n    #   list of top level seq regions from the `chromosome_coord_system_name`\n    chromomes_seq_regions = self.get_toplevel_from_cs(\n        chromosome_coord_system_name, self.pjc(work_dir, \"chromosome_seq_regions\")\n    )\n\n    if not chromomes_seq_regions:\n        return chromomes_seq_regions\n\n    # technical / optimization. get external_db_id for \"karyotype_rank\"\n    karyotype_rank_attrib_id = self.id_from_map_or_die(\n        \"karyotype_rank\", attrib_type_map, \"attrib_type_map\"\n    )\n\n    # set/update proper attributes for \"chromomosome\" regions\n    rank_insertions_trios = []\n    for _, seq_region_id, _ in chromomes_seq_regions:\n        rank_insertions_trios.append(\n            (seq_region_id, karyotype_rank_attrib_id, len(rank_insertions_trios) + 1)\n        )\n\n    # run insertion SQL for \"karyotype_rank\"\n    #    do not alter \"coord_system_tag\" anyhow in the case of the \"chromosome\" coord_system\n    self.insert_to_db(\n        rank_insertions_trios,\n        \"seq_region_attrib\",\n        [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n        self.pjc(work_dir, \"karyotype_rank_insertion\"),\n        ignore=True,\n    )\n\n    return chromomes_seq_regions\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_karyotype_rank_from_bands_info","title":"<code>add_karyotype_rank_from_bands_info(regions_with_karyotype_bands, other_regions_with_ranks, attrib_type_map, work_dir)</code>","text":"<p>Add karyotype_ranks for <code>regions_with_karyotype_bands</code> (those with karyotype bands in seq_region metadata) but not present in <code>other_regions_with_ranks</code> list.</p> <p>Too close to the DB schema.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_karyotype_rank_from_bands_info(\n    self,\n    regions_with_karyotype_bands: list,  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n    other_regions_with_ranks: list,  # [ (seq_region_name, seq_region_id, unversioned_name) ]\n    attrib_type_map: dict,\n    work_dir: str,\n):\n    \"\"\"\n    Add karyotype_ranks for `regions_with_karyotype_bands` (those with karyotype bands in seq_region metadata) but not present in `other_regions_with_ranks` list.\n\n    Too close to the DB schema.\n    \"\"\"\n    # form set of used seq_region_id(s)\n    regions_with_ranks = frozenset(map(lambda el: el[1], other_regions_with_ranks))\n\n    # get set of seq_region_ids with bands\n    regions_with_bands = set(map(lambda el: el[1], regions_with_karyotype_bands))\n\n    # seq_region_ids list to add ranks for\n    region_ids_with_bands_but_no_karyotype_ranks = sorted(list(regions_with_bands - regions_with_ranks))\n\n    # return if nothing to add\n    if not region_ids_with_bands_but_no_karyotype_ranks:\n        return\n\n    # technical / optimization. get external_db_id for \"karyotype_rank\"\n    karyotype_rank_attrib_id = self.id_from_map_or_die(\n        \"karyotype_rank\", attrib_type_map, \"attrib_type_map\"\n    )\n\n    # set/update proper attributes for \"chromomosome\" regions\n    rank_insertions_trios = []\n    for seq_region_id in region_ids_with_bands_but_no_karyotype_ranks:\n        rank_insertions_trios.append(\n            (\n                seq_region_id,\n                karyotype_rank_attrib_id,\n                len(rank_insertions_trios) + 1 + len(regions_with_ranks),\n            )\n        )\n\n    # run insertion SQL for \"karyotype_rank\"\n    #    do not alter \"coord_system_tag\" anyhow in the case of the \"chromosome\" coord_system\n    self.insert_to_db(\n        rank_insertions_trios,\n        \"seq_region_attrib\",\n        [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n        self.pjc(work_dir, \"karyotype_rank_insertion\"),\n        ignore=True,\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_sr_attribs","title":"<code>add_sr_attribs(seq_region_file, seq_region_map, attrib_type_map, work_dir, unversion=False)</code>","text":"<p>Add seq_region_attrib(s) from the seq_region_file meta data file.</p> <p>Explicit list is taken from \"sr_attrib_types\" module param.</p> <p>Add seq_region_attrib(s) from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file. Explicit list is taken from \"sr_attrib_types\" module param.</p> <p>\"sr_attrib_types\" defines { json_property -&gt; attrib_type.name } map. If the value is dict, its keys are treated as \"/\"-delimited \"json_path\" (i.e. \"added_sequence/assembly_provider/name\"). No arrays can be processed. Only simple or \"flattable\" types.</p> If unversion is true <ul> <li>the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible</li> </ul> <p>Too close to the DB schema.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_sr_attribs(\n    self,\n    seq_region_file: str,\n    seq_region_map: dict,\n    attrib_type_map: dict,\n    work_dir,\n    unversion: bool = False,\n):\n    \"\"\"\n    Add seq_region_attrib(s) from the seq_region_file meta data file.\n\n    Explicit list is taken from \"sr_attrib_types\" module param.\n\n    Add seq_region_attrib(s) from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file.\n    Explicit list is taken from \"sr_attrib_types\" module param.\n\n    \"sr_attrib_types\" defines { json_property -&gt; attrib_type.name } map. If the value is dict,\n    its keys are treated as \"/\"-delimited \"json_path\" (i.e. \"added_sequence/assembly_provider/name\").\n    No arrays can be processed. Only simple or \"flattable\" types.\n\n    If unversion is true:\n      * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n    Too close to the DB schema.\n    \"\"\"\n    os.makedirs(work_dir, exist_ok=True)\n\n    # return if there's nothing to add\n    if not seq_region_file:\n        return\n\n    # technical / optimization. get atttib_type_id(s)\n    # create a smaller map with attrib_type_id(s) as values\n    properties_to_use = (\n        []\n    )  # [frozen]set with the top-level \"seq_region\" properties, that should be processed\n    path_attrib_id_map = dict()  # { \"flatterned/json/paths\" : attrib_id_map ))}\n    # fill set and map\n    for prop, attrib_type in self.param(\"sr_attrib_types\").items():\n        # adding high level properties to process\n        properties_to_use.append(prop)\n        # adding json paths (or properties themselves) to atrrib_type_id map\n        if isinstance(attrib_type, dict):  # if using json paths (delimeterd with \"/\")\n            for path, inner_attrib_type in attrib_type.items():\n                path_attrib_id_map[path] = self.id_from_map_or_die(\n                    inner_attrib_type, attrib_type_map, \"attrib_type_map\"\n                )\n        else:\n            path_attrib_id_map[prop] = self.id_from_map_or_die(\n                attrib_type, attrib_type_map, \"attrib_type_map\"\n            )\n    # return if there's nothing to add\n    if not properties_to_use:\n        return\n\n    properties_to_use = frozenset(properties_to_use)\n\n    # load attributes from seq_region file\n    attrib_trios = []  # [ (seq_region_id, attrib_id, value)... ] list of trios for inserting into db\n    with open(seq_region_file) as in_file:\n        seq_regions = list(json.load(in_file))\n        for seq_region in seq_regions:\n            # get seq_region_id (perhaps, by using unversioned name)\n            seq_region_name, seq_region_id, unversioned_name = self.name_and_id_from_seq_region_item(\n                seq_region, seq_region_map, try_unversion=unversion\n            )\n\n            # iterate through properties\n            for prop_name in properties_to_use:\n                if prop_name not in seq_region:\n                    continue\n                # flattern path\n                path_attrib_id_values_list = self.flattern_seq_region_item(\n                    seq_region, prop_name, path_attrib_id_map\n                )\n                # fill attrib_trios\n                for path, attrib_id, value in path_attrib_id_values_list:\n                    attrib_trios.append((seq_region_id, attrib_id, self.quote_or_null(value)))\n\n    # run insertion SQL\n    self.insert_to_db(\n        attrib_trios,\n        \"seq_region_attrib\",\n        [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n        self.pjc(work_dir, \"brc4_ebi_seq_region_synonyms\"),\n        ignore=True,\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_sr_ebi_brc4_names","title":"<code>add_sr_ebi_brc4_names(seq_region_file, seq_region_map, attrib_type_map, work_dir, unversion=False)</code>","text":"<p>Add \"(EBI|BRC4)_seq_region_name\" seq_region_attrib(s) either from the seq_region_file meta data file, or from original seq_region names.</p> <p>Add \"(EBI|BRC4)_seq_region_name\" seq_region_synonym from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file or from the original seq_region_names. A special case of attributes adding with default values derived from seq_region names.</p> If unversion is true <ul> <li>the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible</li> </ul> <p>Too close to the DB schema.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_sr_ebi_brc4_names(\n    self,\n    seq_region_file: str,\n    seq_region_map: dict,\n    attrib_type_map: dict,\n    work_dir: str,\n    unversion: bool = False,\n):\n    \"\"\"\n    Add \"(EBI|BRC4)_seq_region_name\" seq_region_attrib(s) either from the seq_region_file meta data file, or from original seq_region names.\n\n    Add \"(EBI|BRC4)_seq_region_name\" seq_region_synonym from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file or from the original seq_region_names.\n    A special case of attributes adding with default values derived from seq_region names.\n\n    If unversion is true:\n      * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n\n    Too close to the DB schema.\n    \"\"\"\n    os.makedirs(work_dir, exist_ok=True)\n\n    # return if there's nothing to add\n    if not seq_region_file:\n        return\n\n    # technical / optimization. get atttib_type_id(s) for \"(EBI|BRC4)_seq_region_name\"\n    tagged_sr_name_attrib_id = {\n        tag: self.id_from_map_or_die(f\"{tag}_seq_region_name\", attrib_type_map, \"attrib_type_map\")\n        for tag in [\"EBI\", \"BRC4\"]\n    }\n\n    # load BRC4/EBI name from seq_region file\n    brc4_ebi_name_attrib_trios = (\n        []\n    )  # [ (seq_region_id, attrib_id, value)... ] list of trios for inserting into db\n    with open(seq_region_file) as in_file:\n        seq_regions = list(json.load(in_file))\n        for seq_region in seq_regions:\n            # get seq_region_id (perhaps, by using unversioned name)\n            seq_region_name, seq_region_id, unversioned_name = self.name_and_id_from_seq_region_item(\n                seq_region, seq_region_map, try_unversion=unversion\n            )\n            # append attribs to the brc4_ebi_name_attrib_trios list\n            for tag in [\"BRC4\", \"EBI\"]:\n                attrib_name = f\"{tag}_seq_region_name\"\n                attrib_id = tagged_sr_name_attrib_id[tag]\n                value = seq_region.get(attrib_name, seq_region_name)\n                brc4_ebi_name_attrib_trios.append((seq_region_id, attrib_id, self.quote_or_null(value)))\n\n    # run insertion SQL\n    self.insert_to_db(\n        brc4_ebi_name_attrib_trios,\n        \"seq_region_attrib\",\n        [\"seq_region_id\", \"attrib_type_id\", \"value\"],\n        self.pjc(work_dir, \"brc4_ebi_seq_region_synonyms\"),\n        ignore=True,\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.add_sr_synonyms","title":"<code>add_sr_synonyms(seq_region_file, seq_region_map, external_db_map, work_dir, unversion=False, unversionable_sources_set=frozenset(['INSDC', 'RefSeq']))</code>","text":"<p>Add seq_region_synonym from the seq_region_file meta data file.</p> <p>Add seq_region_synonym from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file. Merge with the already existing ones in the db.</p> If unversion is true <ul> <li>the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible</li> <li>the unversioned synonyms from the unversionable_sources_set will be added as well as the original ones</li> </ul> <p>Too close to the DB schema.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def add_sr_synonyms(\n    self,\n    seq_region_file: str,\n    seq_region_map: dict,\n    external_db_map: dict,\n    work_dir: str,\n    unversion: bool = False,\n    unversionable_sources_set: frozenset = frozenset([\"INSDC\", \"RefSeq\"]),\n):\n    \"\"\"\n    Add seq_region_synonym from the seq_region_file meta data file.\n\n    Add seq_region_synonym from the src/python/ensembl/io/genomio/data/schemas/seq_region.json compatible meta data file.\n    Merge with the already existing ones in the db.\n\n    If unversion is true:\n      * the unversioned synonym would be used to get the seq_region_id from \"seq_region_map\" if possible\n      * the unversioned synonyms from the unversionable_sources_set will be added as well as the original ones\n\n    Too close to the DB schema.\n    \"\"\"\n    os.makedirs(work_dir, exist_ok=True)\n\n    # return if there's nothing to add\n    if not seq_region_file:\n        return\n\n    # get seq_region ids, names, syns from db\n    synonyms_trios_db = self.load_seq_region_synonyms_trios_from_core_db(\n        self.pjc(work_dir, \"syns_from_core\")\n    )\n\n    # form set of synonyms already present in db\n    synonyms_in_db = frozenset([trio[2] for trio in synonyms_trios_db if trio[2] != \"NULL\"])\n\n    # subset of sources to use the allowed the unversion synonyms\n    unversionable_sources = unversion and unversionable_sources_set or frozenset()\n\n    # technical / optimization. get external_db_id for \"ensembl_internal_synonym\"\n    ensembl_internal_synonym_ext_db_id = self.id_from_map_or_die(\n        \"ensembl_internal_synonym\", external_db_map, \"external_db_map\"\n    )\n\n    # get dict for additional mapping for sources to external_db names if there's one specified by \"external_db_map\" module param\n    #   not to be confused with the external_db_map function parameter above\n    additional_sources_mapping = self.get_external_db_mapping()\n\n    # load synonyms from the json file\n    synonyms_from_json = (\n        []\n    )  # [ (seq_region_id, synonym, external_db_id)... ] list of trios for inserting into db\n    with open(seq_region_file) as in_file:\n        seq_regions = list(json.load(in_file))\n        for seq_region in filter(lambda sr: sr.get(\"synonyms\", False), seq_regions):\n            # iterate through all seq_regions having \"synonyms\"\n            seq_region_name, seq_region_id, _ = self.name_and_id_from_seq_region_item(\n                seq_region, seq_region_map, try_unversion=unversion\n            )\n\n            # fill synonyms_from_json list of trios\n            for synonym_item in list(seq_region[\"synonyms\"]):\n                synonym_name = synonym_item[\"name\"]\n                source = synonym_item[\"source\"]\n                unversioned_name = \"\"\n\n                # check if there's any addtional mapping for the source, remap if so\n                if additional_sources_mapping:\n                    source = additional_sources_mapping.get(\n                        source, source\n                    )  # use the same name if no matches in additional_sources_mapping dict\n\n                # try to get unversioned name if applicable\n                if source in unversionable_sources:\n                    unversioned_name = re.sub(r\"\\.\\d+$\", \"\", synonym_name)\n\n                # put trios if names are not already seen in db\n                if synonym_name not in synonyms_in_db:\n                    external_db_id = self.id_from_map_or_die(source, external_db_map, \"external_db_map\")\n                    synonyms_from_json.append(\n                        (seq_region_id, self.quote_or_null(synonym_name), external_db_id)\n                    )\n\n                #   put additional unversioned synonyms if there's a sane one\n                if (\n                    unversioned_name\n                    and unversioned_name != synonym_name\n                    and unversioned_name not in synonyms_in_db\n                ):\n                    synonyms_from_json.append(\n                        (\n                            seq_region_id,\n                            self.quote_or_null(unversioned_name),\n                            ensembl_internal_synonym_ext_db_id,\n                        )\n                    )\n\n    # run insertion SQL\n    self.insert_to_db(\n        synonyms_from_json,\n        \"seq_region_synonym\",\n        [\"seq_region_id\", \"synonym\", \"external_db_id\"],\n        self.pjc(work_dir, \"new_seq_region_synonyms\"),\n        ignore=True,\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.agp_prune","title":"<code>agp_prune(from_file, to_file, used=None)</code>","text":"<p>Remove already components from the AGP file if they are seen in \"used\" set</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def agp_prune(self, from_file: str, to_file: str, used: set = None):\n    \"\"\"\n    Remove already components from the AGP file if they are seen in \"used\" set\n    \"\"\"\n    # reomve used component\n    #   and GAPS as they are not used by 'ensembl-analysis/scripts/assembly_loading/load_agp.pl'\n    os.makedirs(dirname(to_file), exist_ok=True)\n    open_ = self.is_gz(from_file) and gzip.open or open\n    if used is None:\n        cmd = r\"\"\"{_cat} {_file} &gt; {_out}\"\"\".format(\n            _cat=self.is_gz(from_file) and \"zcat\" or \"cat\", _file=from_file, _out=to_file\n        )\n        print(\"running %s\" % (cmd), file=sys.stderr)\n        sp.run(cmd, shell=True, check=True)\n        return 1\n    writes = 0\n    with open_(from_file, \"r\") as src:\n        with open(to_file, \"w\") as dst:\n            for line in src:\n                fields = line.strip().split(\"\\t\")\n                (\n                    asm_id,\n                    asm_start,\n                    asm_end,\n                    asm_part,\n                    type_,\n                    cmp_id,\n                    cmp_start,\n                    cmp_end,\n                    cmp_strand,\n                ) = fields\n                if type_ in \"NU\" or cmp_id in used:\n                    continue\n                used.add(cmp_id)\n                print(line.strip(), file=dst)\n                writes += 1\n    return writes\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.asm_name","title":"<code>asm_name()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def asm_name(self):\n    asm = self.from_param(\"genome_data\", \"assembly\")\n    if \"name\" not in asm:\n        raise Exception(\"no assembly/name in genome_data\")\n    return asm[\"name\"]\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.chunk_contigs","title":"<code>chunk_contigs(fasta, cs_ranks, agps, work_dir, chunk_size=0, chunks_cs_name='ensembl_internal')</code>","text":"<p>chunk dna sequence fasta   no chunking if chunk_size &lt; 50k</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def chunk_contigs(self, fasta, cs_ranks, agps, work_dir, chunk_size=0, chunks_cs_name=\"ensembl_internal\"):\n    \"\"\"\n    chunk dna sequence fasta\n      no chunking if chunk_size &lt; 50k\n    \"\"\"\n    chunk_size_min_len = self.param_required(\"sequence_data_chunk_min_len\")\n    if chunk_size &lt; chunk_size_min_len:\n        return fasta, cs_ranks, agps\n\n    # split using script\n    os.makedirs(work_dir, exist_ok=True)\n    _stderr = f\"{work_dir}/chunking.stderr\"\n    _out_agp = f\"{work_dir}/chunks.agp\"\n    _out_fasta = f\"{work_dir}/chunks.fasta\"\n\n    _splitter = r\"fasta_chunk\"\n    split_cmd = f\"{_splitter} --chunk_size {chunk_size} --agp_out {_out_agp} --out {_out_fasta} --fasta_dna {fasta} 2&gt; {_stderr}\"\n\n    print(f\"running {split_cmd}\", file=sys.stderr)\n    # NB throws CalledProcessError if failed\n    sp.run(split_cmd, shell=True, check=True)\n\n    # add rank for chunks\n    _cs_name, _cs_rank = sorted(cs_ranks.items(), key=lambda k: k[1])[-1]\n    cs_ranks[chunks_cs_name] = _cs_rank + 1\n\n    # add agps entry\n    if agps is None:\n        agps = dict()\n    agps[f\"{_cs_name}-{chunks_cs_name}\"] = _out_agp\n\n    return _out_fasta, cs_ranks, agps\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.coord_sys_order","title":"<code>coord_sys_order(cs_order_str)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def coord_sys_order(self, cs_order_str):\n    cs_order_lst = map(lambda x: x.strip(), cs_order_str.split(\",\"))\n    return {e: i for i, e in enumerate(filter(lambda x: len(x) &gt; 0, cs_order_lst))}\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.copy_sr_name_to_syn","title":"<code>copy_sr_name_to_syn(cs, x_db, log_pfx)</code>","text":"<p>Store original seq_region names as seq_region_synonym</p> <p>Store original seq_region names (from a given cood_systen, \"cs\" param) as seq_region_synonyms (using \"x_db\" external source name) SQL code.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def copy_sr_name_to_syn(self, cs, x_db, log_pfx):\n    \"\"\"\n    Store original seq_region names as seq_region_synonym\n\n    Store original seq_region names (from a given cood_systen, \"cs\" param) as seq_region_synonyms (using \"x_db\" external source name)\n    SQL code.\n    \"\"\"\n    asm_v = self.asm_name()\n    sql = r\"\"\"insert into seq_region_synonym (seq_region_id, synonym, external_db_id)\n              select\n                  sr.seq_region_id, sr.name, xdb.external_db_id\n              from\n                 seq_region sr, external_db xdb, coord_system cs\n              where   xdb.db_name = \"%s\"\n                  and sr.coord_system_id = cs.coord_system_id\n                  and cs.name = \"%s\"\n                  and cs.version = \"%s\"\n                  and sr.name like \"%%._\"\n            ;\"\"\" % (\n        x_db,\n        cs,\n        asm_v,\n    )\n    return self.run_sql_req(sql, log_pfx)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.db_string","title":"<code>db_string()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def db_string(self):\n    return \"-dbhost {host_} -dbport {port_} -dbuser {user_} -dbpass {pass_} -dbname {dbname_} \".format(\n        host_=self.param(\"dbsrv_host\"),\n        port_=self.param(\"dbsrv_port\"),\n        user_=self.param(\"dbsrv_user\"),\n        pass_=self.param(\"dbsrv_pass\"),\n        dbname_=self.param(\"db_name\"),\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.filter_already_loaded_regions_from_agp","title":"<code>filter_already_loaded_regions_from_agp(src_file, dst_file, loaded_regions, new_regions)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def filter_already_loaded_regions_from_agp(self, src_file, dst_file, loaded_regions, new_regions):\n    with open(src_file) as src:\n        with open(dst_file, \"w\") as dst:\n            for line in src:\n                fields = line.strip().split(\"\\t\")\n                (\n                    asm_id,\n                    asm_start,\n                    asm_end,\n                    asm_part,\n                    type_,\n                    cmp_id,\n                    cmp_start,\n                    cmp_end,\n                    cmp_strand,\n                ) = fields\n                if type_ in \"NU\" or asm_id in loaded_regions:\n                    continue\n                new_regions.add(asm_id)\n                print(line.strip(), file=dst)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.flattern_seq_region_item","title":"<code>flattern_seq_region_item(seq_region, prop_name, path_attrib_id_map, sep='/')</code>","text":"<p>Flattern seq_region[property] and store corresponding [ (json_path, attrib_id, value)... ] (as list of trios).</p> <p>Only works for simple properties or dicts with no arrays on the path. Basically, implemets tree traversal. Utility function used by the <code>add_sr_attribs</code> method</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def flattern_seq_region_item(\n    self, seq_region: dict, prop_name: str, path_attrib_id_map: dict, sep: str = \"/\"\n) -&gt; list:\n    \"\"\"\n    Flattern seq_region[property] and store corresponding [ (json_path, attrib_id, value)... ] (as list of trios).\n\n    Only works for simple properties or dicts with no arrays on the path. Basically, implemets tree traversal.\n    Utility function used by the `add_sr_attribs` method\n    \"\"\"\n    res = []\n    # is there anything to do\n    if prop_name not in seq_region:\n        return res\n\n    # set up\n    value = seq_region[prop_name]\n    paths_to_go = [\n        (prop_name, value)\n    ]  # storing path and the corresponding value, to prevent repetetive traversals\n    # iterate\n    while paths_to_go:\n        (path, value) = paths_to_go.pop()  # get last item\n        if isinstance(value, list):\n            # perhaps, it's better to raise exception then to continue silently\n            continue\n        if isinstance(value, dict):\n            # if value is a complex object, add its leaves\n            for key, val in value.items():\n                paths_to_go.append((f\"{path}{sep}{key}\", val))\n            continue\n        # if value is simple\n        attrib_id = path_attrib_id_map.get(path, None)\n        if attrib_id:\n            res.append((path, attrib_id, value))\n    # return what ever we have\n    return res\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.from_param","title":"<code>from_param(param, key, not_throw=False)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def from_param(self, param, key, not_throw=False):\n    data = self.param_required(param)\n    if key not in data:\n        if not_throw:\n            return None\n        else:\n            raise Exception(\"Missing required %s data: %s\" % (param, key))\n    return data[key]\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.get_external_db_mapping","title":"<code>get_external_db_mapping()</code>","text":"<p>Get a map from a file for external_dbs to Ensembl dbnames from \"external_db_map\" module(!) param</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def get_external_db_mapping(self) -&gt; dict:\n    \"\"\"\n    Get a map from a file for external_dbs to Ensembl dbnames from \"external_db_map\" module(!) param\n    \"\"\"\n    external_map_path = self.param(\"external_db_map\")\n    db_map = dict()\n    if external_map_path is None:\n        return db_map\n\n    # Load the map\n    with open(external_map_path, \"r\") as map_file:\n        for line in map_file:\n            if line.startswith(\"#\"):\n                continue\n            line = re.sub(r\"#.*\", \"\", line)\n            if re.match(r\"^\\s*$\", line):\n                continue\n            (from_name, to_name, *rest) = line.strip().split(\"\\t\")\n            if len(rest) &gt; 0 and rest[0].upper() != \"SEQ_REGION\":\n                continue\n            if to_name == \"_IGNORE_\":\n                continue\n            db_map[from_name] = to_name\n    return db_map\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.get_toplevel_from_cs","title":"<code>get_toplevel_from_cs(coord_system_name, work_dir)</code>","text":"<p>Returns list of [ (seq_region_name, seq_region_id, \"\") ] trios for toplevel seq_regions from coord system with <code>coord_system_name</code>   or having  \"coord_system_tag\" attribute with the <code>coord_system_name</code> value</p> <p>SQL code</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def get_toplevel_from_cs(self, coord_system_name, work_dir) -&gt; list:\n    \"\"\"\n    Returns list of [ (seq_region_name, seq_region_id, \"\") ] trios for toplevel seq_regions from coord system with `coord_system_name`\n      or having  \"coord_system_tag\" attribute with the `coord_system_name` value\n\n    SQL code\n    \"\"\"\n    out_pfx = self.pjc(work_dir, f\"toplevel_from_{coord_system_name}\")\n    sql = f\"\"\"SELECT DISTINCT sr.name, sr.seq_region_id\n            FROM seq_region sr,\n                 seq_region_attrib sra,\n                 coord_system cs,\n                 attrib_type at\n            WHERE sr.seq_region_id = sra.seq_region_id\n              AND sr.coord_system_id = cs.coord_system_id\n              AND sra.attrib_type_id = at.attrib_type_id\n              AND (  ( cs.name = \"{coord_system_name}\" and at.code = \"toplevel\" )\n                  OR ( at.code = \"coord_system_tag\" and sra.value = \"{coord_system_name}\" )\n                  )\n              ORDER BY sr.seq_region_id;\n           \"\"\"\n\n    res = self.run_sql_req(sql, out_pfx)\n\n    sr_trios = []\n    out_file = out_pfx + \".stdout\"\n    with open(out_file) as sr_file:\n        skip_header = True\n        for line in sr_file:\n            if skip_header:\n                skip_header = False\n                continue\n            (name, sr_id) = line.strip().split(\"\\t\")\n            sr_trios.append((name, sr_id, \"\"))\n\n    return sr_trios\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.id_from_map_or_die","title":"<code>id_from_map_or_die(key, map_dict, name_for_panic)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def id_from_map_or_die(self, key: str, map_dict: dict, name_for_panic):\n    value = map_dict.get(key, None)\n    if value is None:\n        raise Exception(f\"no such key '{key}' in '{name_for_panic}' map\")\n    return value\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.initial_sequence_loading","title":"<code>initial_sequence_loading(work_dir)</code>","text":"<p>initial preparation and loading of AGPs and fasta data.</p> <p>initial preparation and loading of AGPs and fasta data using ensembl-analysis perl scripts</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def initial_sequence_loading(self, work_dir: str):\n    \"\"\"\n    initial preparation and loading of AGPs and fasta data.\n\n    initial preparation and loading of AGPs and fasta data using ensembl-analysis perl scripts\n    \"\"\"\n    # preprocess FASTA with sequences\n    #   rename IUPAC to N symbols using sed\n    fasta_clean = self.from_param(\"manifest_data\", \"fasta_dna\")\n\n    # start coord system ranking and agps processing\n    agps = self.from_param(\"manifest_data\", \"agp\", not_throw=True)\n\n    # get the deafult coord_system order\n    #   use noagp_cs_name_default for \"noagp\" assemblies\n    cs_order = self.coord_sys_order(self.param(\"cs_order\"))\n    noagps_cs = self.param(\"noagp_cs_name_default\")\n\n    # remove gaps and lower_level mappings if the are coveres by higher level ones\n    #   i.e.: remove 'contigN to chromosomeZ', if 'contigN to scaffoldM' and 'scaffoldM to chromosomeZ' are in place\n    #   returns None if no agps provided\n    agps_pruned_dir = self.pjc(work_dir, \"agps_pruned\")\n    agps_pruned = self.prune_agps(agps, cs_order, agps_pruned_dir, self.param_bool(\"prune_agp\"))\n\n    # order\n    # rank cs_names, met in agps.keys (\"-\" separated, i.e. \"scaffold-contig\") based on cs_order\n    cs_rank = self.used_cs_ranks(agps_pruned, cs_order, noagps_cs)\n\n    # chunk sequence data if needed\n    #   no chunking if chunk_size &lt; 50k\n    chunk_size = int(self.param(\"sequence_data_chunk\"))\n    chunk_cs_name = self.param(\"chunk_cs_name\")\n    fasta_clean, cs_rank, agps_pruned = self.chunk_contigs(\n        fasta_clean,\n        cs_rank,\n        agps_pruned,\n        pj(work_dir, \"chunking\"),\n        chunk_size=chunk_size,\n        chunks_cs_name=chunk_cs_name,\n    )\n\n    # empty agps_pruned ignored\n    self.load_seq_data(fasta_clean, agps_pruned, cs_rank, self.pjc(work_dir, \"load\"))\n\n    # mark all the \"contig\"s or noagp_cs as being sourced from ENA\n    if not self.param_bool(\"no_contig_ena_attrib\"):\n        # NB using original \"agps\" parameter (with no chunking data added)\n        agps_raw = self.from_param(\"manifest_data\", \"agp\", not_throw=True)\n        if agps_raw is None:\n            self.add_contig_ena_attrib(self.pjc(work_dir, \"load\", \"set_ena\"), cs_name=noagps_cs)\n        else:\n            self.add_contig_ena_attrib(self.pjc(work_dir, \"load\", \"set_ena\"))\n\n    # unversion scaffold, remove \".\\d$\" from names if there's a need\n    if self.param_bool(\"unversion_scaffolds\"):\n        self.unversion_scaffolds(cs_rank, self.pjc(work_dir, \"unversion_scaffolds\"))\n\n    # add assembly mappings between various cs to meta table for the mapper to work properly\n    cs_pairs = agps_pruned and agps_pruned.keys() or None\n    self.add_asm_mappings(cs_pairs, self.pjc(work_dir, \"asm_mappings\"))\n\n    # set toplevel seq_region attribute\n    self.set_toplevel(self.pjc(work_dir, \"set_toplevel\"), self.param(\"not_toplevel_cs\"))\n\n    # nullify contig version and update mappings strings accordingly; ignore for \"load_additional_sequences\" mode\n    if not self.param_bool(\"load_additional_sequences\"):\n        self.nullify_ctg_cs_version(cs_order, self.pjc(work_dir, \"asm_mapping\", \"nullify_cs_versions\"))\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.insert_to_db","title":"<code>insert_to_db(list_of_tuples, table_name, col_names, work_dir, ignore=True)</code>","text":"<p>Insert into the core db's {table_name} tuples from {list_of_tuples} as col_names.</p> <p>Use <code>quote_or_null</code> (see definition below) method for string values, when putting values into <code>list_of_tuples</code> SQL code</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def insert_to_db(\n    self, list_of_tuples: list, table_name: str, col_names: list, work_dir: str, ignore: bool = True\n):\n    \"\"\"\n    Insert into the core db's {table_name} tuples from {list_of_tuples} as col_names.\n\n    Use `quote_or_null` (see definition below) method for string values, when putting values into `list_of_tuples`\n    SQL code\n    \"\"\"\n    # return if nothing to do\n    if not list_of_tuples:\n        return\n\n    # prepare request parts\n    ignore_str = ignore and \"IGNORE\" or \"\"\n    cols_str = \", \".join(col_names)\n\n    # generate file with the insert SQL command\n    insert_sql_file = self.pjc(work_dir, \"insert.sql\")\n    with open(insert_sql_file, \"w\") as sql:\n        print(f\"INSERT {ignore_str} INTO {table_name} ({cols_str}) VALUES\", file=sql)\n        values_sep = \"\"\n        for tpl in list_of_tuples:\n            tpl_str = \", \".join(map(str, tpl))\n            print(f\"{values_sep}({tpl_str})\", file=sql)\n            values_sep = \", \"\n        print(\";\", file=sql)\n\n    # run insert SQL from file\n    self.run_sql_req(insert_sql_file, self.pjc(work_dir, \"insert\"), from_file=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.is_gz","title":"<code>is_gz(filename)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def is_gz(self, filename):\n    return filename.endswith(\".gz\")\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.load_agp","title":"<code>load_agp(pair, asm_v, src_file, log_pfx)</code>","text":"<p>ensembl script (load_agp.pl) based utility for loading seq_regions assembly data (AGPs)</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def load_agp(self, pair, asm_v, src_file, log_pfx):\n    \"\"\"ensembl script (load_agp.pl) based utility for loading seq_regions assembly data (AGPs)\"\"\"\n    en_root = self.param_required(\"ensembl_root_dir\")\n    (asm_n, cmp_n) = pair.strip().split(\"-\")\n    cmd = (\n        r\"\"\"{_loader} {_db_string} -assembled_version {_asm_v} \"\"\"\n        + r\"\"\"    -assembled_name {_asm} -component_name {_cmp} \"\"\"\n        + r\"\"\"    -agp_file {_file} \"\"\"\n        + r\"\"\"    &gt; {_log}.stdout 2&gt; {_log}.stderr\"\"\"\n    ).format(\n        _loader=\"perl %s\" % (self.pjc(en_root, r\"ensembl-analysis/scripts/assembly_loading/load_agp.pl\")),\n        _db_string=self.db_string(),\n        _asm_v=asm_v,\n        _asm=asm_n,\n        _cmp=cmp_n,\n        _file=src_file,\n        _log=\"%s_agp_%s\" % (log_pfx, pair.replace(\"-\", \"_\")),\n    )\n    print(\"running %s\" % (cmd), file=sys.stderr)\n    return sp.run(cmd, shell=True, check=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.load_cs_data","title":"<code>load_cs_data(cs, rank, pair, asm_v, src_file, log_pfx, loaded_regions=None, seq_level=False)</code>","text":"<p>creates a coord_system and loads sequence or assembly(AGP) data for corresponding seqregions</p> <p>doesn't load already seen sequences</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def load_cs_data(self, cs, rank, pair, asm_v, src_file, log_pfx, loaded_regions=None, seq_level=False):\n    \"\"\"creates a coord_system and loads sequence or assembly(AGP) data for corresponding seqregions\n\n    doesn't load already seen sequences\n    \"\"\"\n    # NB load_seq_region.pl and load_agp.pl are not failing on parameter errors (0 exit code)\n    os.makedirs(dirname(log_pfx), exist_ok=True)\n    additional_load = self.param_bool(\"load_additional_sequences\")\n    if seq_level:\n        self.load_seq_region(cs, rank, asm_v, src_file, log_pfx, seq_level, additional_load)\n    elif loaded_regions is not None:\n        new_regions = set()\n        clean_file = src_file + \".regions_deduped\"\n        self.filter_already_loaded_regions_from_agp(src_file, clean_file, loaded_regions, new_regions)\n        self.load_seq_region(cs, rank, asm_v, clean_file, log_pfx, seq_level, additional_load)\n        loaded_regions.update(new_regions)\n    if not seq_level:\n        self.load_agp(pair, asm_v, src_file, log_pfx)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.load_map_from_core_db","title":"<code>load_map_from_core_db(table, cols, work_dir)</code>","text":"<p>Load 2 \"cols\" from core db \"table\" as map</p> <p>Load { cols[0] : cols[1] } map from the core db \"table\" SQL code</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def load_map_from_core_db(self, table, cols, work_dir) -&gt; dict:\n    \"\"\"\n    Load 2 \"cols\" from core db \"table\" as map\n\n    Load { cols[0] : cols[1] } map from the core db \"table\"\n    SQL code\n    \"\"\"\n    out_pfx = self.pjc(work_dir, f\"{table}_map\")\n    sql = f\"\"\"select {cols[0]}, {cols[1]} FROM {table};\"\"\"\n    res = self.run_sql_req(sql, out_pfx)\n\n    out_file = out_pfx + \".stdout\"\n    data = self.load_map_from_sql_stdout(out_file, skip_header=True)\n    if not data:\n        raise Exception(f\"No '{table}' map loaded from '{out_file}'\")\n    return data\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.load_map_from_sql_stdout","title":"<code>load_map_from_sql_stdout(in_file, skip_header=False)</code>","text":"<p>Load map from the SQL output</p> <p>Process input in_file with \"key  value\" pairs and load then into the {key : value} map. Skips header if skip_header.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def load_map_from_sql_stdout(self, in_file, skip_header=False):\n    \"\"\"\n    Load map from the SQL output\n\n    Process input in_file with \"key  value\" pairs and load then\n    into the {key : value} map.\n    Skips header if skip_header.\n    \"\"\"\n    data = dict()\n    with open(in_file) as pairs_file:\n        for line in pairs_file:\n            if skip_header:\n                skip_header = False\n                continue\n            (key, val) = line.strip().split(\"\\t\")\n            data[key] = val\n    return data\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.load_seq_data","title":"<code>load_seq_data(fasta, agps, cs_rank, log_pfx)</code>","text":"<p>loads sequence data for various coordinate systems accordingly with their rank</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def load_seq_data(self, fasta, agps, cs_rank, log_pfx):\n    \"\"\"loads sequence data for various coordinate systems accordingly with their rank\"\"\"\n    asm_v = self.asm_name()\n\n    sequence_rank = max(cs_rank.values())\n    for cs, rank in sorted(cs_rank.items(), key=lambda p: -p[1]):\n        logs = self.pjc(log_pfx, \"%02d_%s\" % (rank, cs))\n        if rank == sequence_rank:\n            self.load_cs_data(cs, rank, \"fasta\", asm_v, fasta, logs, loaded_regions=None, seq_level=True)\n        else:\n            useful_agps = list(filter(lambda x: cs in x, agps and agps.keys() or []))\n            if len(useful_agps) == 0:\n                raise Exception(\"non-seq_level cs %s has no agps to assemble it from\" % (cs))\n            loaded_regions = set()\n            for pair, agp_file_pruned in map(lambda k: (k, agps[k]), useful_agps):\n                if not pair.startswith(cs + \"-\"):\n                    continue\n                self.load_cs_data(cs, rank, pair, asm_v, agp_file_pruned, logs, loaded_regions)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.load_seq_region","title":"<code>load_seq_region(cs, rank, asm_v, src_file, log_pfx, seq_level=False, additional_load=False)</code>","text":"<p>ensembl-analysis script (load_seq_region.pl) based utility for loading seq_regions FASTA sequences</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def load_seq_region(\n    self,\n    cs: str,\n    rank: str,\n    asm_v: str,\n    src_file: str,\n    log_pfx: str,\n    seq_level=False,\n    additional_load=False,\n):\n    \"\"\"ensembl-analysis script (load_seq_region.pl) based utility for loading seq_regions FASTA sequences\"\"\"\n    en_root = self.param_required(\"ensembl_root_dir\")\n    cmd = (\n        r\"\"\"{_loader} {_db_string} {_asm_v_flag} -default_version -ignore_ambiguous_bases \"\"\"\n        + r\"\"\"    -rank {_rank} -coord_system_name {_cs} {_sl_flag} -{_tag}_file {_file}\"\"\"\n        + r\"\"\"     &gt; {_log}.stdout 2&gt; {_log}.stderr\"\"\"\n    ).format(\n        _loader=\"perl %s\"\n        % (self.pjc(en_root, r\"ensembl-analysis/scripts/assembly_loading/load_seq_region.pl\")),\n        _db_string=self.db_string(),\n        _asm_v_flag=not additional_load and f\"-coord_system_version {asm_v}\" or \"\",\n        _rank=rank,\n        _cs=cs,\n        _sl_flag=seq_level and \"-sequence_level\" or \"\",\n        _tag=seq_level and \"fasta\" or \"agp\",\n        _file=src_file,\n        _log=\"%s_seq\" % (log_pfx),\n    )\n    print(\"running %s\" % (cmd), file=sys.stderr)\n    return sp.run(cmd, shell=True, check=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.load_seq_region_synonyms_trios_from_core_db","title":"<code>load_seq_region_synonyms_trios_from_core_db(work_dir)</code>","text":"<p>Load seq_region_synonyms from from core db into [(seq_region_id, name, synonym)...] list</p> <p>SQL code</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def load_seq_region_synonyms_trios_from_core_db(self, work_dir: str) -&gt; list:\n    # was get_db_syns\n    \"\"\"\n    Load seq_region_synonyms from from core db into [(seq_region_id, name, synonym)...] list\n\n    SQL code\n    \"\"\"\n    out_pfx = self.pjc(work_dir, f\"seq_region_synonyms\")\n    sql = r\"\"\"select sr.seq_region_id as seq_region_id, sr.name, srs.synonym\n             from seq_region sr left join seq_region_synonym srs\n             on sr.seq_region_id = srs.seq_region_id\n             order by sr.seq_region_id\n          ;\"\"\"\n\n    res = self.run_sql_req(sql, out_pfx)\n\n    syn_trios = []\n    out_file = out_pfx + \".stdout\"\n    with open(out_file) as syns_file:\n        skip_header = True\n        for line in syns_file:\n            if skip_header:\n                skip_header = False\n                continue\n            (sr_id, name, syn) = line.strip().split(\"\\t\")\n            syn_trios.append((sr_id, name, syn))\n    return syn_trios\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.name_and_id_from_seq_region_item","title":"<code>name_and_id_from_seq_region_item(seq_region_item, seq_region_map, try_unversion=False, throw_missing=True)</code>","text":"<p>Get (seq_region_name, seq_region_id, unversioned_name) from seq_region_item struct(dict)</p> <p>Gets unversioned_name only if \"try_unversion\" is True. Throws exception if not able to get seq_region_id from \"seq_region_map\" and \"throw_missing\" is true.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def name_and_id_from_seq_region_item(\n    self,\n    seq_region_item: dict,\n    seq_region_map: dict,\n    try_unversion: bool = False,\n    throw_missing: bool = True,\n) -&gt; (str, str, str):\n    \"\"\"\n    Get (seq_region_name, seq_region_id, unversioned_name) from seq_region_item struct(dict)\n\n    Gets unversioned_name only if \"try_unversion\" is True.\n    Throws exception if not able to get seq_region_id from \"seq_region_map\" and \"throw_missing\" is true.\n    \"\"\"\n    #   get seq_region_id (perhaps, by using unversioned name)\n    seq_region_name = seq_region_item[\"name\"]\n    seq_region_id = seq_region_map.get(seq_region_name, None)\n    unversioned_name = None\n    if seq_region_id is None and try_unversion:\n        # try to get seq_region_id for the unversioned name\n        unversioned_name = re.sub(r\"\\.\\d+$\", \"\", seq_region_name)\n        seq_region_id = seq_region_map.get(unversioned_name, \"\")\n\n    # oops, we don't know such seq_region name\n    if not seq_region_id and throw_missing:\n        raise Exception(f\"Not able to find seq_region for '{seq_region_name}'\")\n\n    return (seq_region_name, seq_region_id, unversioned_name)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.nullify_ctg_cs_version","title":"<code>nullify_ctg_cs_version(cs_order, log_pfx)</code>","text":"<p>Nullify every CS version with rank larger than that of \"contig\", but don't nullify toplevel ones.</p> <p>SQL code</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def nullify_ctg_cs_version(self, cs_order, log_pfx: str):\n    \"\"\"\n    Nullify every CS version with rank larger than that of \"contig\", but don't nullify toplevel ones.\n\n    SQL code\n    \"\"\"\n    asm_v = self.asm_name()\n    # get cs_info (and if they have toplevel regions)\n    sql = r\"\"\"select cs.coord_system_id as coord_system_id,\n                     cs.name, cs.rank, (tl.coord_system_id is NULL) as no_toplevel\n                from coord_system cs\n                  left join (\n                    select distinct sr.coord_system_id\n                      from seq_region sr, seq_region_attrib sra, attrib_type at\n                      where at.code = \"toplevel\"\n                        and sra.attrib_type_id = at.attrib_type_id\n                        and sra.value = 1\n                        and sra.seq_region_id = sr.seq_region_id\n                  ) as tl on tl.coord_system_id = cs.coord_system_id\n                where cs.version = \"{_asm_v}\"\n                order by rank\n          ;\"\"\".format(\n        _asm_v=asm_v\n    )\n    # run_sql\n    toplvl_pfx = self.pjc(log_pfx, \"toplvl_info\")\n    self.run_sql_req(sql, toplvl_pfx)\n    # load info\n    cs_info = []\n    with open(toplvl_pfx + \".stdout\") as f:\n        header = None\n        for line in f:\n            if header is None:\n                header = line.strip().split(\"\\t\")\n                continue\n            cs_info.append(dict(zip(header, line.strip().split())))\n    # return if there's no coord_systems to nullify versions for\n    if not cs_info:\n        return\n    # get list of known cs from cs_order to clean version from\n    nullify_cs_version_from = self.param(\"nullify_cs_version_from\")\n    if not nullify_cs_version_from or nullify_cs_version_from not in cs_order:\n        return\n    cs_thr_index = cs_order[nullify_cs_version_from]\n    cs_names_to_keep_ver = frozenset([nm for (nm, ind) in cs_order.items() if ind &gt; cs_thr_index])\n\n    # choose cs rank threshold to start clearing version from\n    clear_lst = [\n        (cs[\"coord_system_id\"], cs[\"name\"])\n        for cs in cs_info\n        if (bool(int(cs[\"no_toplevel\"])) and cs[\"name\"] not in cs_names_to_keep_ver)\n    ]\n\n    # run sql\n    if clear_lst:\n        clear_pfx = self.pjc(log_pfx, \"clear\")\n        with open(clear_pfx + \".sql\", \"w\") as clear_sql:\n            for cs_id, cs_name in clear_lst:\n                sql = r\"\"\"\n                    update meta set\n                        meta_value=replace(meta_value, \"|{_cs_name}:{_asm_v}\", \"|{_cs_name}\")\n                        where meta_key=\"assembly.mapping\";\n                    update coord_system set version = NULL where coord_system_id = {_cs_id};\n                \"\"\".format(\n                    _asm_v=asm_v, _cs_name=cs_name, _cs_id=cs_id\n                )\n                print(sql, file=clear_sql)\n        self.run_sql_req(clear_pfx + \".sql\", clear_pfx, from_file=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.order_agp_levels","title":"<code>order_agp_levels(agps, cs_order)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def order_agp_levels(self, agps, cs_order):\n    # sort agp for loading by:\n    #   highest component (cmp) cs level (lowest rank)\n    #   lowest difference between cs ranks (asm - cmp)\n    #   i.e: chromosome-scaffold scaffold-chunk chromosome-chunk\n    if not agps:\n        return []\n\n    agp_cs_pairs = list(map(lambda x: [x] + x.split(\"-\"), agps.keys()))\n    agp_levels = [(x[0], cs_order[x[1]], cs_order[x[2]]) for x in agp_cs_pairs]\n\n    bad_agps = list(filter(lambda x: x[1] &lt; x[2], agp_levels))\n    if len(bad_agps) &gt; 0:\n        raise Exception(\"component cs has higher order than assembled cs %s\" % (str(bad_agps)))\n\n    agp_levels_sorted = [e[0] for e in sorted(agp_levels, key=lambda x: (-x[2], x[1] - x[2]))]\n    return agp_levels_sorted\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.param_bool","title":"<code>param_bool(param)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def param_bool(self, param):\n    val = self.param(param)\n    return bool(val) and \"0\" != val\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.param_defaults","title":"<code>param_defaults()</code>","text":"<p>default parameter/options values</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def param_defaults(self):\n    \"\"\"\n    default parameter/options values\n    \"\"\"\n    return {\n        # relative order of the coord_systems types to infer their rank from\n        \"cs_order\": \"ensembl_internal,chunk,contig,supercontig,non_ref_scaffold,scaffold,primary_assembly,superscaffold,linkage_group,chromosome\",\n        \"artificial_cs\": \"ensembl_internal,chunk\",  # coord_systems to ignore when adding synonyms for sequence_level cs\n        \"IUPAC\": \"RYKMSWBDHV\",  # symbols to be replaced with N in the DNA sequences (ensembl core(107) doesn't support the whole IUPAC alphabet for DNA)\n        # unversion scaffold, remove \".\\d$\" from seq_region.names if there's a need\n        \"unversion_scaffolds\": 0,\n        \"versioned_sr_syn_src\": \"INSDC\",  # INSDC(50710) # if unversioning non-sequence level cs, store original name (with version) as this synonym\n        \"sr_syn_src\": \"BRC4_Community_Symbol\",  # BRC4_Community_Symbol(211) # if unversioning sequence-level cs, store original name (with version) as this synonym\n        # nullify coord_system version for the given coord_system name\n        \"nullify_cs_version_from\": \"contig\",\n        # default coord_system name for single-level (no AGPs assemblies)\n        \"noagp_cs_name_default\": \"primary_assembly\",\n        # file for additional mapping of the synonym sources to the external_db (ensembl), as used by \"get_external_db_mapping\" function below\n        \"external_db_map\": None,\n        # set \"coord_system_tag\" seq_region attribute to this value if there's a corresponding \"chromosome_display_order\" list in genome.json metadata\n        #   if None, only \"chromosome\" coord system is processed (if present)\n        #   (see add_chr_karyotype_rank definition below )\n        #   if seq_region already has `coord_system_tagi` attribute, it value updated only if \"force_update_coord_system_tag\" module param is True (see below)\n        \"cs_tag_for_ordered\": None,\n        # Force updating of the \"coord_system_tags\" attribute for seq_regions from `cs_tag_for_ordered` (see above)\n        \"force_update_coord_system_tag\": False,\n        # BRC4 compatibility mode; if on, \"(EBI|BRC4)_seq_region_name\" seq_region_attributes are added.\n        #   Blocked by the \"swap_gcf_gca\" option. In this case insertion should be done on later pipeline stage after seq_region name swapping.\n        \"brc4_mode\": True,\n        # Whether to use RefSeq names as additional seq_region synonyms (if available) or not (see add_sr_synonyms definition below)\n        #  Does not swap anything actually, just loads synonyms to be used by a later \"swapping\" stage\n        #  Disables BRC4 compatibilty mode (see the \"brc4_mode\" option comment).\n        \"swap_gcf_gca\": False,\n        # list of coord systems used in \"-ignore_coord_system\" options of the \"ensembl-analysis/scripts/assembly_loading/set_toplevel.pl\" script\n        #   part of the loading process\n        \"not_toplevel_cs\": [],  # i.e. \"contig\", \"non_ref_scaffold\"\n        # explicit list of seq_region properties (keys) to load as seq_region_attrib s (values) (see add_sr_attribs definition below)\n        #   if a dict's used as a value, treat its keys as \"json_path\" (/ as delim) map, i.e.\n        #       { \"added_sequence\" : { \"assembly_provider\" : { \"name\" : ... } } } -&gt; \"added_sequence/assembly_provider/name\"\n        #   only flattable properties can be used, no arrays\n        #   arrays should be processed separately (see `add_sr_synonyms` or `add_karyotype_bands` definitions)\n        # see src/python/ensembl/io/genomio/data/schemas/seq_region.json\n        \"sr_attrib_types\": {\n            \"circular\": \"circular_seq\",\n            \"codon_table\": \"codon_table\",\n            \"location\": \"sequence_location\",\n            \"non_ref\": \"non_ref\",\n            \"coord_system_level\": \"coord_system_tag\",\n            \"added_sequence\": {\n                # json_path to attrib_type_code(str) mapping\n                \"added_sequence/accession\": \"added_seq_accession\",\n                \"added_sequence/assembly_provider/name\": \"added_seq_asm_pr_nam\",\n                \"added_sequence/assembly_provider/url\": \"added_seq_asm_pr_url\",\n                \"added_sequence/annotation_provider/name\": \"added_seq_ann_pr_nam\",\n                \"added_sequence/annotation_provider/url\": \"added_seq_ann_pr_url\",\n            },  # added_sequence\n        },\n        # loading additional sequences to the already exsisting core db\n        \"load_additional_sequences\": 0,\n        # size of the sequence data chunk, if 0 (default), no chunking is performed\n        \"sequence_data_chunk\": 0,\n        #   min size of the sequence chunk, no chunking is done if 'sequence_data_chunk' &lt; 'sequence_data_chunk_min'\n        \"sequence_data_chunk_min_len\": 50_000,\n        # coord system name for chunks\n        \"chunk_cs_name\": \"ensembl_internal\",\n    }\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.pjc","title":"<code>pjc(*parts)</code>","text":"<p>Join path parts and try to create every directory but the last one.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def pjc(self, *parts: list) -&gt; str:\n    \"\"\"\n    Join path parts and try to create every directory but the last one.\n    \"\"\"\n    if not parts:\n        return None\n\n    parts = list(parts)\n    last = parts.pop()\n    prefix = pj(*parts)\n\n    os.makedirs(prefix, exist_ok=True)\n\n    return pj(prefix, last)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.prune_agps","title":"<code>prune_agps(agps, cs_order, agps_pruned_dir, pruning=True)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def prune_agps(self, agps, cs_order, agps_pruned_dir, pruning=True):\n    # when loading agp sort by:\n    #   highest component (cmp) cs level (lowest rank)\n    #   lowest difference between cs ranks (asm - cmp)\n    #   i.e: chromosome-scaffold scaffold-chunk chromosome-chunk\n    #   if no agps return empty pruned result\n\n    if not agps:\n        return None\n\n    agp_levels_sorted = self.order_agp_levels(agps, cs_order)\n\n    # prune agps\n    agps_pruned = dict()\n    used_components = set()\n    if not pruning:\n        used_components = None\n    for asm_cmp in agp_levels_sorted:\n        agp_file_src = agps[asm_cmp]\n        agp_file_dst = self.pjc(agps_pruned_dir, asm_cmp + \".agp\")\n        if self.agp_prune(agp_file_src, agp_file_dst, used_components) &gt; 0:\n            agps_pruned[asm_cmp] = agp_file_dst\n    return agps_pruned\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.quote_or_null","title":"<code>quote_or_null(val, quotes=\"'\", null='NULL', strings_only=True)</code>","text":"<p>Return <code>val</code> wrapped in <code>quotes</code> or <code>null</code> value</p> <p>Quotes only strings (instances of <code>str</code>) if strings_only is True.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def quote_or_null(self, val: str, quotes: str = \"'\", null: str = \"NULL\", strings_only=True) -&gt; str:\n    \"\"\"\n    Return `val` wrapped in `quotes` or `null` value\n\n    Quotes only strings (instances of `str`) if strings_only is True.\n    \"\"\"\n    if val is None:\n        return null\n    if strings_only and isinstance(val, str):\n        return f\"{quotes}{val}{quotes}\"\n    return val\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.remove_IUPAC","title":"<code>remove_IUPAC(from_file, to_file)</code>","text":"<p>remove non-valid symbols from FASTA file (using sed) ans store the result in a different location</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def remove_IUPAC(self, from_file: str, to_file: str):\n    \"\"\"remove non-valid symbols from FASTA file (using sed) ans store the result in a different location\"\"\"\n    IUPAC = self.param(\"IUPAC\")\n    os.makedirs(dirname(to_file), exist_ok=True)\n    cmd = r\"\"\"{_cat} {_file} | sed -r '/^[^&gt;]/ {{ s/[{_IUPAC}]/N/g; s/{_iupac}/n/g }}' &gt; {_out}\"\"\".format(\n        _cat=self.is_gz(from_file) and \"zcat\" or \"cat\",\n        _file=from_file,\n        _IUPAC=IUPAC.upper(),\n        _iupac=IUPAC.lower(),\n        _out=to_file,\n    )\n    print(\"running %s\" % (cmd), file=sys.stderr)\n    return sp.run(cmd, shell=True, check=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.remove_components_from_toplevel","title":"<code>remove_components_from_toplevel(log_pfx)</code>","text":"<p>Remove toplevel attribute for seq_regions that are \"components\" (parts of different seq_regions).</p> <p>SQL code.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def remove_components_from_toplevel(self, log_pfx):\n    \"\"\"\n    Remove toplevel attribute for seq_regions that are \"components\" (parts of different seq_regions).\n\n    SQL code.\n    \"\"\"\n\n    # get list of seq_regions that are components\n    sql_not_toplevel_list = r\"\"\"\n      select distinct a.cmp_seq_region_id, sr_c.name, cs_c.name\n        from assembly a,\n             seq_region sr_c, seq_region sr_a,\n             coord_system cs_c, coord_system cs_a\n        where a.cmp_seq_region_id = sr_c.seq_region_id\n          and a.asm_seq_region_id = sr_a.seq_region_id\n          and sr_c.coord_system_id = cs_c.coord_system_id\n          and sr_a.coord_system_id = cs_a.coord_system_id\n          and cs_c.attrib like \"%default_version%\"\n          and cs_a.attrib like \"%default_version%\"\n          and sr_c.seq_region_id in (\n            select distinct seq_region_id\n              from seq_region_attrib\n              where attrib_type_id = 6 and value = 1\n          )\n    \"\"\"\n    # perhaps, make sense to check sr_c.coord_system_id != sr_a.coord_system_id\n    self.run_sql_req(sql_not_toplevel_list, \".\".join([log_pfx, \"not_toplevel_list\"]))\n\n    # delete wrongly assigned attribs\n    sql_not_toplevel_delete = r\"\"\"\n      delete from seq_region_attrib\n        where attrib_type_id = 6 and value = 1\n          and seq_region_id in (\n            select distinct a.cmp_seq_region_id\n              from assembly a,\n                   seq_region sr_c, seq_region sr_a,\n                   coord_system cs_c, coord_system cs_a\n              where a.cmp_seq_region_id = sr_c.seq_region_id\n                and a.asm_seq_region_id = sr_a.seq_region_id\n                and sr_c.coord_system_id = cs_c.coord_system_id\n                and sr_a.coord_system_id = cs_a.coord_system_id\n                and cs_c.attrib like \"%default_version%\"\n                and cs_a.attrib like \"%default_version%\"\n          );\n    \"\"\"\n    # perhaps, check sr_c.coord_system_id != sr_a.coord_system_id\n    self.run_sql_req(sql_not_toplevel_delete, \".\".join([log_pfx, \"not_toplevel_delete\"]))\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.run","title":"<code>run()</code>","text":"<p>Entry point for the Ehive module. All processing is done here in this case.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def run(self):\n    \"\"\"\n    Entry point for the Ehive module. All processing is done here in this case.\n    \"\"\"\n    # params\n    work_dir = self.param_required(\"work_dir\")\n\n    # initial sequence loading, using ensembl-analysis scripts\n    self.initial_sequence_loading(work_dir)\n\n    # load data from the corresponding core db tables\n    external_db_map = self.load_map_from_core_db(\n        \"external_db\", [\"db_name\", \"external_db_id\"], work_dir\n    )  # for external_db\n    attrib_type_map = self.load_map_from_core_db(\n        \"attrib_type\", [\"code\", \"attrib_type_id\"], work_dir\n    )  # for attrib_type\n    seq_region_map = self.load_map_from_core_db(\n        \"seq_region\", [\"name\", \"seq_region_id\"], work_dir\n    )  # for seq_region\n\n    # update synonyms and seq_region_attribs\n    unversion = self.param(\"unversion_scaffolds\")\n    is_primary_assembly = self.from_param(\"manifest_data\", \"agp\", not_throw=True) is None\n    seq_region_file = self.from_param(\"manifest_data\", \"seq_region\", not_throw=True)\n\n    #   add seq_region synonyms\n    self.add_sr_synonyms(\n        seq_region_file,\n        seq_region_map,\n        external_db_map,\n        self.pjc(work_dir, \"seq_region_syns\"),\n        unversion=unversion,\n    )\n\n    #   add seq_region attributes\n    self.add_sr_attribs(\n        seq_region_file,\n        seq_region_map,\n        attrib_type_map,\n        self.pjc(work_dir, \"seq_region_attr\"),\n        unversion=unversion,\n    )\n\n    #   add seq_region EBI and BRC4 name attributes in the \"BRC4 mode\"\n    #     special case of attributes adding with default values derived from seq_region names\n    #     do not add if preparing to swap RefSeq and GeneBank ids; in this case attributes to be added at a later stage in pipeline\n    #     (easier to insert then to update)\n    if self.param(\"brc4_mode\") and not self.param(\"swap_gcf_gca\"):\n        self.add_sr_ebi_brc4_names(\n            seq_region_file,\n            seq_region_map,\n            attrib_type_map,\n            self.pjc(work_dir, \"seq_region_ebi_brc4_name\"),\n            unversion=unversion,\n        )\n\n    # add karyotype related data\n    self.add_karyotype_data(\n        seq_region_file,\n        seq_region_map,\n        attrib_type_map,\n        self.pjc(work_dir, \"karyotype\"),\n        unversion=unversion,\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.run_sql_req","title":"<code>run_sql_req(sql, log_pfx, from_file=False)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def run_sql_req(self, sql, log_pfx, from_file=False):\n    os.makedirs(dirname(log_pfx), exist_ok=True)\n\n    sql_option = r\"\"\" -sql '{_sql}' \"\"\".format(_sql=sql)\n    if from_file:\n        sql_option = r\"\"\" &lt; '{_sql}' \"\"\".format(_sql=sql)\n\n    cmd = r\"\"\"{_dbcmd} -url \"{_srv}{_dbname}\" {_sql_option} &gt; {_out} 2&gt; {_err}\"\"\".format(\n        _dbcmd=\"perl %s/scripts/db_cmd.pl\" % os.getenv(\"EHIVE_ROOT_DIR\"),\n        _srv=self.param(\"dbsrv_url\"),\n        _dbname=self.param(\"db_name\"),\n        _sql_option=sql_option,\n        _out=log_pfx + \".stdout\",\n        _err=log_pfx + \".stderr\",\n    )\n    print(\"running %s\" % (cmd), file=sys.stderr)\n    return sp.run(cmd, shell=True, check=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.set_toplevel","title":"<code>set_toplevel(log_pfx, ignored_cs=[])</code>","text":"<p>Set toplevel(6) seq_region_attrib using ensembl script.</p> <p>Uses set_toplevel.pl ensembl script.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def set_toplevel(self, log_pfx, ignored_cs=[]):\n    \"\"\"\n    Set toplevel(6) seq_region_attrib using ensembl script.\n\n    Uses set_toplevel.pl ensembl script.\n    \"\"\"\n    # set top_level(6) seq_region_attrib\n    os.makedirs(dirname(log_pfx), exist_ok=True)\n    en_root = self.param_required(\"ensembl_root_dir\")\n    cmd = (\n        r\"\"\"{_set_tl} {_db_string} {_ignored_cs} \"\"\" + r\"\"\"     &gt; {_log}.stdout 2&gt; {_log}.stderr\"\"\"\n    ).format(\n        _set_tl=\"perl %s\"\n        % (self.pjc(en_root, r\"ensembl-analysis/scripts/assembly_loading/set_toplevel.pl\")),\n        _db_string=self.db_string(),\n        _ignored_cs=\" \".join(map(lambda x: \"-ignore_coord_system %s\" % (x), ignored_cs)),\n        _log=log_pfx,\n    )\n    print(\"running %s\" % (cmd), file=sys.stderr)\n    sp.run(cmd, shell=True, check=True)\n\n    # remove toplevel attribute for seq_regions that are components\n    self.remove_components_from_toplevel(log_pfx)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.sr_name_unversion","title":"<code>sr_name_unversion(cs, tbl, fld, log_pfx)</code>","text":"<p>Remove version suffix from the seq_region names</p> <p>Removes '.\\d+$' suffices from the seq_region names SQL code.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def sr_name_unversion(self, cs, tbl, fld, log_pfx):\n    \"\"\"\n    Remove version suffix from the seq_region names\n\n    Removes '\\.\\d+$' suffices from the seq_region names\n    SQL code.\n    \"\"\"\n    # select synonym, substr(synonym,  1, locate(\".\", synonym, length(synonym)-2)-1)\n    #     from seq_region_synonym  where synonym like \"%._\"\n    asm_v = self.asm_name()\n    sql = r\"\"\"update {_tbl} t, seq_region sr, coord_system cs\n                set\n                  t.{_fld} = substr(t.{_fld},  1, locate(\".\", t.{_fld}, length(t.{_fld})-2)-1)\n                where t.{_fld} like \"%._\"\n                  and t.seq_region_id = sr.seq_region_id\n                  and sr.coord_system_id = cs.coord_system_id\n                  and cs.name = \"{_cs}\"\n                  and cs.version = \"{_asm_v}\"\n            ;\"\"\".format(\n        _tbl=tbl, _fld=fld, _cs=cs, _asm_v=asm_v\n    )\n    return self.run_sql_req(sql, log_pfx)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.unversion_scaffolds","title":"<code>unversion_scaffolds(cs_rank, logs)</code>","text":"<p>Unversion scaffold, remove \".\\d$\" from seq_region.names if there's a need</p> <p>Non-versioned syns for contigs (lower, sequence level), versioned for the rest.</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def unversion_scaffolds(self, cs_rank, logs):\n    \"\"\"\n    Unversion scaffold, remove \".\\d$\" from seq_region.names if there's a need\n\n    Non-versioned syns for contigs (lower, sequence level), versioned for the rest.\n    \"\"\"\n    # coord_systems to ignore when adding synonyms for sequence_level cs\n    artificial_cs = frozenset(self.param(\"artificial_cs\").split(\",\"))\n    seq_cs, max_rank = max(\n        [(c, r) for c, r in cs_rank.items() if c not in artificial_cs], key=lambda k: k[1]\n    )\n    for cs in cs_rank:\n        if cs == seq_cs:\n            # for non-sequence level cs, store original name (with version) as \"sr_syn_src\" synonym\n            xdb = self.param(\"sr_syn_src\")\n            self.copy_sr_name_to_syn(cs, xdb, self.pjc(logs, \"cp2syn\", cs))\n            self.sr_name_unversion(cs, \"seq_region_synonym\", \"synonym\", self.pjc(logs, \"unv_srs\", cs))\n        else:\n            # for sequence-level cs, store original name (with version) as \"versioned_sr_syn_src\" synonym\n            xdb = self.param(\"versioned_sr_syn_src\")\n            self.copy_sr_name_to_syn(cs, xdb, self.pjc(logs, \"cp2syn\", cs))\n            self.sr_name_unversion(cs, \"seq_region\", \"name\", self.pjc(logs, \"unv_sr\", cs))\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.update_db_single_group","title":"<code>update_db_single_group(dict_of_col_to_value, table_name, work_dir, where=None)</code>","text":"<p>Update given <code>table</code> name in db; set <code>col = val</code> for all key/value pairs from <code>dict_of_cols_to_values</code></p> <p>If <code>where</code> condition is present its value is used for the \"WHERE\" SQL clause. Use <code>quote_or_null</code> (see definition below) method for string values, when putting values into <code>list_of_tuples</code></p> <p>SQL code</p> Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def update_db_single_group(\n    self, dict_of_col_to_value: dict, table_name: str, work_dir: str, where: str = None\n):\n    \"\"\"\n    Update given `table` name in db; set `col = val` for all key/value pairs from `dict_of_cols_to_values`\n\n    If `where` condition is present its value is used for the \"WHERE\" SQL clause.\n    Use `quote_or_null` (see definition below) method for string values, when putting values into `list_of_tuples`\n\n    SQL code\n    \"\"\"\n    # return if nothing to do\n    if not dict_of_col_to_value:\n        return\n\n    # prepare request parts\n    where_str = where and f\"WHERE {where}\" or \"\"\n    col_val_str = \", \".join([f\"{col} = {val}\" for col, val in dict_of_col_to_value.items()])\n\n    # generate file with the insert SQL command\n    update_sql_file = self.pjc(work_dir, \"update.sql\")\n    with open(insert_sql_file, \"w\") as sql:\n        print(f\"UPDATE {table_name} SET {col_val_str} {where_str};\", file=sql)\n        values_sep = \"\"\n        for tpl in list_of_tuples:\n            tpl_str = \", \".join(map(str, tpl))\n            print(f\"{values_sep}({tpl_str})\", file=sql)\n            values_sep = \", \"\n        print(\";\", file=sql)\n\n    # run insert SQL from file\n    self.run_sql_req(update_sql_file, self.pjc(work_dir, \"update\"), from_file=True)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/load_sequence_data/#ensembl.brc4.runnable.load_sequence_data.load_sequence_data.used_cs_ranks","title":"<code>used_cs_ranks(agps, cs_order, noagp_default=None)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/load_sequence_data.py</code> <pre><code>def used_cs_ranks(self, agps, cs_order, noagp_default=None):\n    # rank cs_names, met in agps.keys (\"-\" separated), i.e. \"scaffold-contig\"\n    #   only agps keys used, values are ignored\n    #   use noagp_cs_name_default for \"noagp\" assemblies\n    if agps is None:\n        if noagp_default is None:\n            raise Exception(\"NoAGP assembly with no default coordinate system name\")\n        cs_used_set = frozenset([noagp_default])\n    else:\n        cs_used_set = frozenset(sum(map(lambda x: x.split(\"-\"), agps.keys()), []))\n\n    cs_unknown = cs_used_set.difference(cs_order.keys())\n    if len(cs_unknown) &gt; 0:\n        raise Exception(\"Unknown coordinate system(s) %s\" % {str(cs_unknown)})\n    return {e: i for i, e in enumerate(sorted(cs_used_set, key=lambda x: -cs_order[x]), start=1)}\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/","title":"prepare_genome","text":""},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome","title":"<code>ensembl.brc4.runnable.prepare_genome</code>","text":""},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome","title":"<code>prepare_genome</code>","text":"<p>               Bases: <code>BaseRunnable</code></p> Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>class prepare_genome(eHive.BaseRunnable):\n    def param_defaults(self):\n        return {\"ensembl_mode\": False, \"db_prefix\": \"\"}\n\n    def run(self):\n        manifest_path = self.param_required(\"manifest\")\n\n        errors = []\n\n        manifest = self.get_manifest(manifest_path)\n        genome = self.get_genome(manifest)\n        self.update_accession(genome)\n        self.update_assembly_name(genome)\n\n        print(manifest)\n        print(\"\")\n        print(genome)\n\n        db_name = self.make_db_name(genome)\n        print(\"db_name = %s\" % db_name)\n        self.param(\"db_name\", db_name)\n\n        # FLOW\n        self.dataflow(\n            {\n                \"db_name\": db_name,\n                \"manifest_data\": manifest,\n                \"genome_data\": genome,\n                \"species\": genome[\"species\"][\"production_name\"],\n                \"has_gff3\": (1 if \"gff3\" in manifest and manifest[\"gff3\"] else 0),\n            },\n            2,\n        )\n\n        # DB metadata for registry\n        self.dataflow(\n            {\n                \"db_data\": {\n                    \"db_name\": db_name,\n                    \"genome_data\": genome,\n                }\n            },\n            3,\n        )\n\n    def get_manifest(self, manifest_path):\n        with open(manifest_path) as manifest_file:\n            manifest = json.load(manifest_file)\n\n            # Use dir name from the manifest\n            for name in manifest:\n                if \"file\" in manifest[name]:\n                    file_name = manifest[name][\"file\"]\n                    manifest[name] = path.join(path.dirname(manifest_path), file_name)\n                else:\n                    for f in manifest[name]:\n                        if \"file\" in manifest[name][f]:\n                            file_name = manifest[name][f][\"file\"]\n                            manifest[name][f] = path.join(path.dirname(manifest_path), file_name)\n            return manifest\n\n    def get_genome(self, manifest):\n        # Get genome metadata\n        if \"genome\" in manifest:\n            genome_path = manifest[\"genome\"]\n            print(genome_path)\n\n            with open(genome_path) as genome_file:\n                return json.load(genome_file)\n\n    def make_db_name(self, genome):\n        prod_name = self.make_production_name(genome)\n        prod_name = prod_name.replace(\".\", \"\")\n        ensembl_version = str(self.param_required(\"ensembl_version\"))\n        release = str(self.param_required(\"release\"))\n        assembly_version = str(self.get_assembly_version(genome))\n        db_prefix = self.param(\"db_prefix\")\n\n        # Check the db name is shorter than the limit: reduce it to \"Genus sp\"\n        db_prod_name = prod_name\n        max_prod_length = (\n            64 - len(\"core\") - len(str(release)) - len(str(ensembl_version)) - len(str(assembly_version)) - 4\n        )\n        if db_prefix:\n            max_prod_length = max_prod_length - len(db_prefix) - 1\n        if len(db_prod_name) &gt; max_prod_length:\n            print(\"DB name is too long! Trying to shorten it...\")\n            (genus_str, species_str, gca_str) = db_prod_name.split(\"_\")\n            db_prod_name = \"_\".join([genus_str, \"sp\", gca_str])\n\n            # Still too long? Die\n            if len(db_prod_name) &gt; max_prod_length:\n                raise Exception(\n                    \"Can't use the db name for %s (len = %d, max = %d)\"\n                    % (db_prod_name, len(db_prod_name), max_prod_length)\n                )\n            else:\n                prod_name = db_prod_name\n\n        # Store this production name\n        genome[\"species\"][\"production_name\"] = prod_name\n\n        name_parts = [prod_name, \"core\", release, ensembl_version, assembly_version]\n\n        db_name = \"_\".join(name_parts)\n        db_name = db_name.replace(\".\", \"\")\n        self.check_db_name_format(db_name)\n\n        if db_prefix:\n            db_name = db_prefix + \"_\" + db_name\n\n        return db_name\n\n    def make_production_name(self, genome):\n        if \"species\" in genome:\n            genome_sp = genome[\"species\"]\n            if \"production_name\" in genome_sp:\n                prod_name = genome_sp[\"production_name\"]\n            else:\n                # Create prod name from taxonomy\n                if \"taxonomy_id\" in genome_sp:\n                    taxon_id = genome_sp[\"taxonomy_id\"]\n                    scientific_name = self.get_scientific_name(taxon_id)\n\n                    # If what we get is not a species name (only 1 word), use the input name\n                    if \" \" not in scientific_name:\n                        print(\"Use input scientific name\")\n                        scientific_name = genome_sp[\"scientific_name\"]\n\n                    # Name in bracket means that it may be renamed by the community\n                    # But we don't want those...\n                    if \"[\" in scientific_name:\n                        scientific_name = scientific_name.replace(\"[\", \"\").replace(\"]\", \"\")\n\n                    if \"-\" in scientific_name:\n                        scientific_name = scientific_name.replace(\"-\", \"\")\n\n                    # Only keep the first 2 words\n                    split_name = scientific_name.split(\" \")\n                    genus = split_name[0].lower()\n                    species = split_name[1].lower()\n\n                    # Special case\n                    if species == \"sp.\":\n                        species = \"sp\"\n\n                    # Check for special characters\n                    if not re.match(r\"^[a-zA-Z0-9]+$\", genus):\n                        raise Exception(\"The genus has special characters: \" + genus)\n                    if re.match(r\"^[a-zA-Z0-9]$\", species):\n                        raise Exception(\"The species has special characters: \" + species)\n                    print(genus + \" \" + species)\n\n                    # Production name, with INSDC accession for uniqueness\n                    accession = genome[\"assembly\"][\"accession\"]\n                    if not accession or accession == \"\":\n                        raise Exception(\"The INSDC accession is needed\")\n                    accession = re.sub(\"\\.\\d+$\", \"\", accession).replace(\"_\", \"\")\n                    accession = accession.lower()\n                    prod_name = genus + \"_\" + species + \"_\" + accession\n                else:\n                    raise Exception(\"Can't find taxonomy id for genome: %s\" % genome)\n            return prod_name\n        else:\n            raise Exception(\"Can't make production name for genome: %s\" % genome)\n\n    def get_scientific_name(self, taxon_id):\n        host = self.param(\"taxonomy_host\")\n        user = self.param(\"taxonomy_user\")\n        port = self.param(\"taxonomy_port\")\n        dbname = self.param(\"taxonomy_dbname\")\n\n        # Get connector to taxon db\n        mydb = mysql.connector.connect(host=host, user=user, port=port, database=dbname)\n        cur = mydb.cursor()\n\n        # Get scientific name\n        select_st = \"SELECT name FROM ncbi_taxa_name WHERE name_class=%s and taxon_id=%s\"\n        data = (\"scientific name\", taxon_id)\n        cur.execute(select_st, data)\n        row = cur.fetchone()\n\n        if row:\n            for s in row:\n                return s\n        else:\n            return\n\n    def get_assembly_version(self, genome):\n        if \"assembly\" in genome:\n            assembly = genome[\"assembly\"]\n            if \"version\" in assembly:\n                aversion = assembly[\"version\"]\n\n                if str(aversion) == \"0\":\n                    raise Exception(\"Assembly version cannot be 0\")\n\n                if isinstance(aversion, int):\n                    return aversion\n                else:\n                    try:\n                        aversion = int(aversion)\n                        genome[\"assembly\"][\"version\"] = aversion\n                        return aversion\n                    except:\n                        raise Exception(\"Assembly version is not an integer: %s\" % aversion)\n            elif \"name\" in assembly:\n                # Get last number at the end of the assembly name\n                matches = re.match(\"\\w+?(\\d+?)$\", assembly[\"name\"])\n                if matches:\n                    aversion = matches.group(1)\n                    genome[\"assembly\"][\"version\"] = aversion\n                    return aversion\n                else:\n                    raise Exception(\"No assembly version found in %s\" % str(genome))\n            else:\n                raise Exception(\"Can't get assembly version from name in from %s\" % str(genome))\n        else:\n            raise Exception(\"Can't get assembly data in genome %s\" % str(genome))\n\n    def check_db_name_format(self, db_name):\n        match = re.match(\"[a-z]+_[a-z]+(_[A-z0-9]+){0,2}_core_\\d+_\\d+_\\d+$\", db_name)\n\n        if not match:\n            raise Exception(\n                \"Generated DB name is not the right format: %s (in %s)\"\n                % (db_name, self.param_required(\"manifest\"))\n            )\n\n    def update_assembly_name(self, data):\n        if data and \"assembly\" in data:\n            asm = data[\"assembly\"]\n            if \"name\" not in asm:\n                if \"accession\" not in asm:\n                    raise Exception(\"no accession or name in genome_data/assembly\")\n                acc = asm[\"accession\"].replace(\"_\", \"\").replace(\".\", \"v\")\n                asm[\"name\"] = acc\n                print('using \"%s\" as assembly.name' % (data[\"assembly\"][\"name\"]), file=sys.stderr)\n        else:\n            raise Exception(\"no 'assembly' data provided in genome_data\")\n\n    def update_accession(self, data):\n        if data and \"assembly\" in data:\n            asm = data[\"assembly\"]\n            if \"accession\" in asm and asm[\"accession\"].startswith(\"GCF_\"):\n                ### CHANGE TO GCA\n                data[\"assembly\"][\"accession\"] = data[\"assembly\"][\"accession\"].replace(\"GCF_\", \"GCA_\")\n                print('using \"%s\" as assembly.accession' % (data[\"assembly\"][\"accession\"]), file=sys.stderr)\n        else:\n            raise Exception(\"no 'assembly' data provided in genome_data\")\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.check_db_name_format","title":"<code>check_db_name_format(db_name)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def check_db_name_format(self, db_name):\n    match = re.match(\"[a-z]+_[a-z]+(_[A-z0-9]+){0,2}_core_\\d+_\\d+_\\d+$\", db_name)\n\n    if not match:\n        raise Exception(\n            \"Generated DB name is not the right format: %s (in %s)\"\n            % (db_name, self.param_required(\"manifest\"))\n        )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.get_assembly_version","title":"<code>get_assembly_version(genome)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def get_assembly_version(self, genome):\n    if \"assembly\" in genome:\n        assembly = genome[\"assembly\"]\n        if \"version\" in assembly:\n            aversion = assembly[\"version\"]\n\n            if str(aversion) == \"0\":\n                raise Exception(\"Assembly version cannot be 0\")\n\n            if isinstance(aversion, int):\n                return aversion\n            else:\n                try:\n                    aversion = int(aversion)\n                    genome[\"assembly\"][\"version\"] = aversion\n                    return aversion\n                except:\n                    raise Exception(\"Assembly version is not an integer: %s\" % aversion)\n        elif \"name\" in assembly:\n            # Get last number at the end of the assembly name\n            matches = re.match(\"\\w+?(\\d+?)$\", assembly[\"name\"])\n            if matches:\n                aversion = matches.group(1)\n                genome[\"assembly\"][\"version\"] = aversion\n                return aversion\n            else:\n                raise Exception(\"No assembly version found in %s\" % str(genome))\n        else:\n            raise Exception(\"Can't get assembly version from name in from %s\" % str(genome))\n    else:\n        raise Exception(\"Can't get assembly data in genome %s\" % str(genome))\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.get_genome","title":"<code>get_genome(manifest)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def get_genome(self, manifest):\n    # Get genome metadata\n    if \"genome\" in manifest:\n        genome_path = manifest[\"genome\"]\n        print(genome_path)\n\n        with open(genome_path) as genome_file:\n            return json.load(genome_file)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.get_manifest","title":"<code>get_manifest(manifest_path)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def get_manifest(self, manifest_path):\n    with open(manifest_path) as manifest_file:\n        manifest = json.load(manifest_file)\n\n        # Use dir name from the manifest\n        for name in manifest:\n            if \"file\" in manifest[name]:\n                file_name = manifest[name][\"file\"]\n                manifest[name] = path.join(path.dirname(manifest_path), file_name)\n            else:\n                for f in manifest[name]:\n                    if \"file\" in manifest[name][f]:\n                        file_name = manifest[name][f][\"file\"]\n                        manifest[name][f] = path.join(path.dirname(manifest_path), file_name)\n        return manifest\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.get_scientific_name","title":"<code>get_scientific_name(taxon_id)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def get_scientific_name(self, taxon_id):\n    host = self.param(\"taxonomy_host\")\n    user = self.param(\"taxonomy_user\")\n    port = self.param(\"taxonomy_port\")\n    dbname = self.param(\"taxonomy_dbname\")\n\n    # Get connector to taxon db\n    mydb = mysql.connector.connect(host=host, user=user, port=port, database=dbname)\n    cur = mydb.cursor()\n\n    # Get scientific name\n    select_st = \"SELECT name FROM ncbi_taxa_name WHERE name_class=%s and taxon_id=%s\"\n    data = (\"scientific name\", taxon_id)\n    cur.execute(select_st, data)\n    row = cur.fetchone()\n\n    if row:\n        for s in row:\n            return s\n    else:\n        return\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.make_db_name","title":"<code>make_db_name(genome)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def make_db_name(self, genome):\n    prod_name = self.make_production_name(genome)\n    prod_name = prod_name.replace(\".\", \"\")\n    ensembl_version = str(self.param_required(\"ensembl_version\"))\n    release = str(self.param_required(\"release\"))\n    assembly_version = str(self.get_assembly_version(genome))\n    db_prefix = self.param(\"db_prefix\")\n\n    # Check the db name is shorter than the limit: reduce it to \"Genus sp\"\n    db_prod_name = prod_name\n    max_prod_length = (\n        64 - len(\"core\") - len(str(release)) - len(str(ensembl_version)) - len(str(assembly_version)) - 4\n    )\n    if db_prefix:\n        max_prod_length = max_prod_length - len(db_prefix) - 1\n    if len(db_prod_name) &gt; max_prod_length:\n        print(\"DB name is too long! Trying to shorten it...\")\n        (genus_str, species_str, gca_str) = db_prod_name.split(\"_\")\n        db_prod_name = \"_\".join([genus_str, \"sp\", gca_str])\n\n        # Still too long? Die\n        if len(db_prod_name) &gt; max_prod_length:\n            raise Exception(\n                \"Can't use the db name for %s (len = %d, max = %d)\"\n                % (db_prod_name, len(db_prod_name), max_prod_length)\n            )\n        else:\n            prod_name = db_prod_name\n\n    # Store this production name\n    genome[\"species\"][\"production_name\"] = prod_name\n\n    name_parts = [prod_name, \"core\", release, ensembl_version, assembly_version]\n\n    db_name = \"_\".join(name_parts)\n    db_name = db_name.replace(\".\", \"\")\n    self.check_db_name_format(db_name)\n\n    if db_prefix:\n        db_name = db_prefix + \"_\" + db_name\n\n    return db_name\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.make_production_name","title":"<code>make_production_name(genome)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def make_production_name(self, genome):\n    if \"species\" in genome:\n        genome_sp = genome[\"species\"]\n        if \"production_name\" in genome_sp:\n            prod_name = genome_sp[\"production_name\"]\n        else:\n            # Create prod name from taxonomy\n            if \"taxonomy_id\" in genome_sp:\n                taxon_id = genome_sp[\"taxonomy_id\"]\n                scientific_name = self.get_scientific_name(taxon_id)\n\n                # If what we get is not a species name (only 1 word), use the input name\n                if \" \" not in scientific_name:\n                    print(\"Use input scientific name\")\n                    scientific_name = genome_sp[\"scientific_name\"]\n\n                # Name in bracket means that it may be renamed by the community\n                # But we don't want those...\n                if \"[\" in scientific_name:\n                    scientific_name = scientific_name.replace(\"[\", \"\").replace(\"]\", \"\")\n\n                if \"-\" in scientific_name:\n                    scientific_name = scientific_name.replace(\"-\", \"\")\n\n                # Only keep the first 2 words\n                split_name = scientific_name.split(\" \")\n                genus = split_name[0].lower()\n                species = split_name[1].lower()\n\n                # Special case\n                if species == \"sp.\":\n                    species = \"sp\"\n\n                # Check for special characters\n                if not re.match(r\"^[a-zA-Z0-9]+$\", genus):\n                    raise Exception(\"The genus has special characters: \" + genus)\n                if re.match(r\"^[a-zA-Z0-9]$\", species):\n                    raise Exception(\"The species has special characters: \" + species)\n                print(genus + \" \" + species)\n\n                # Production name, with INSDC accession for uniqueness\n                accession = genome[\"assembly\"][\"accession\"]\n                if not accession or accession == \"\":\n                    raise Exception(\"The INSDC accession is needed\")\n                accession = re.sub(\"\\.\\d+$\", \"\", accession).replace(\"_\", \"\")\n                accession = accession.lower()\n                prod_name = genus + \"_\" + species + \"_\" + accession\n            else:\n                raise Exception(\"Can't find taxonomy id for genome: %s\" % genome)\n        return prod_name\n    else:\n        raise Exception(\"Can't make production name for genome: %s\" % genome)\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.param_defaults","title":"<code>param_defaults()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def param_defaults(self):\n    return {\"ensembl_mode\": False, \"db_prefix\": \"\"}\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.run","title":"<code>run()</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def run(self):\n    manifest_path = self.param_required(\"manifest\")\n\n    errors = []\n\n    manifest = self.get_manifest(manifest_path)\n    genome = self.get_genome(manifest)\n    self.update_accession(genome)\n    self.update_assembly_name(genome)\n\n    print(manifest)\n    print(\"\")\n    print(genome)\n\n    db_name = self.make_db_name(genome)\n    print(\"db_name = %s\" % db_name)\n    self.param(\"db_name\", db_name)\n\n    # FLOW\n    self.dataflow(\n        {\n            \"db_name\": db_name,\n            \"manifest_data\": manifest,\n            \"genome_data\": genome,\n            \"species\": genome[\"species\"][\"production_name\"],\n            \"has_gff3\": (1 if \"gff3\" in manifest and manifest[\"gff3\"] else 0),\n        },\n        2,\n    )\n\n    # DB metadata for registry\n    self.dataflow(\n        {\n            \"db_data\": {\n                \"db_name\": db_name,\n                \"genome_data\": genome,\n            }\n        },\n        3,\n    )\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.update_accession","title":"<code>update_accession(data)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def update_accession(self, data):\n    if data and \"assembly\" in data:\n        asm = data[\"assembly\"]\n        if \"accession\" in asm and asm[\"accession\"].startswith(\"GCF_\"):\n            ### CHANGE TO GCA\n            data[\"assembly\"][\"accession\"] = data[\"assembly\"][\"accession\"].replace(\"GCF_\", \"GCA_\")\n            print('using \"%s\" as assembly.accession' % (data[\"assembly\"][\"accession\"]), file=sys.stderr)\n    else:\n        raise Exception(\"no 'assembly' data provided in genome_data\")\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/prepare_genome/#ensembl.brc4.runnable.prepare_genome.prepare_genome.update_assembly_name","title":"<code>update_assembly_name(data)</code>","text":"Source code in <code>src/python/ensembl/brc4/runnable/prepare_genome.py</code> <pre><code>def update_assembly_name(self, data):\n    if data and \"assembly\" in data:\n        asm = data[\"assembly\"]\n        if \"name\" not in asm:\n            if \"accession\" not in asm:\n                raise Exception(\"no accession or name in genome_data/assembly\")\n            acc = asm[\"accession\"].replace(\"_\", \"\").replace(\".\", \"v\")\n            asm[\"name\"] = acc\n            print('using \"%s\" as assembly.name' % (data[\"assembly\"][\"name\"]), file=sys.stderr)\n    else:\n        raise Exception(\"no 'assembly' data provided in genome_data\")\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/seqregion_parser/","title":"seqregion_parser","text":""},{"location":"reference/ensembl/brc4/runnable/seqregion_parser/#ensembl.brc4.runnable.seqregion_parser","title":"<code>ensembl.brc4.runnable.seqregion_parser</code>","text":""},{"location":"reference/ensembl/brc4/runnable/seqregion_parser/#ensembl.brc4.runnable.seqregion_parser.SeqregionParser","title":"<code>SeqregionParser</code>","text":"<p>Parser of a seq_region report from INSDC/RefSeq.</p> <p>The main method of the Parser is get_report_regions, which returns a Dict of seq_regions, where the keys are the names.</p> Source code in <code>src/python/ensembl/brc4/runnable/seqregion_parser.py</code> <pre><code>class SeqregionParser:\n    \"\"\"Parser of a seq_region report from INSDC/RefSeq.\n\n    The main method of the Parser is get_report_regions, which returns a Dict of seq_regions,\n    where the keys are the names.\n    \"\"\"\n\n    synonym_map = {\n        \"Sequence-Name\": \"INSDC_submitted_name\",\n        \"GenBank-Accn\": \"INSDC\",\n        \"RefSeq-Accn\": \"RefSeq\",\n        \"Assigned-Molecule\": \"GenBank\",\n    }\n\n    molecule_location = {\n        \"chromosome\": \"nuclear_chromosome\",\n        \"mitochondrion\": \"mitochondrial_chromosome\",\n        \"apicoplast\": \"apicoplast_chromosome\",\n        \"plasmid\": \"plasmid\",\n        \"linkage group\": \"linkage_group\",\n        \"kinetoplast\": \"kinetoplast\",\n    }\n\n    def get_report_regions(\n        self, report_path: Path, accession: str, use_refseq: bool = False\n    ) -&gt; Dict[str, dict]:\n        \"\"\"Get seq_region data from report file.\n\n        Args:\n            report_path: Path to the INSDC seq_region report.\n            use_refseq: Expect a RefSeq seq_region report.\n        Returns:\n            A dict of seq_regions dicts, with their name as the key\n        \"\"\"\n        if accession.startswith(\"GCF\"):\n            use_refseq = True\n        # Get the report in a CSV format, easier to manipulate\n        report_csv, metadata = self.report_to_csv(report_path)\n\n        # Feed the csv string to the CSV reader\n        reader = csv.DictReader(report_csv.splitlines(), delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n\n        # Metadata\n        assembly_level = \"contig\"\n        if \"Assembly level\" in metadata:\n            assembly_level = metadata[\"Assembly level\"].lower()\n\n        # Create the seq_regions\n        seq_regions = {}\n        for row in reader:\n            seq_region = self.make_seq_region(row, assembly_level, use_refseq)\n            name = seq_region[\"name\"]\n            seq_regions[name] = seq_region\n\n        return seq_regions\n\n    def report_to_csv(self, report_path: Path) -&gt; Tuple[str, dict]:\n        \"\"\"Load an assembly report as a csv string.\n\n        Args:\n            report_path: Path to the INSDC seq_region report.\n        Returns:\n            The csv as a string, and the head metadata as a dict.\n        \"\"\"\n\n        with open_gz_file(report_path) as report:\n            data = \"\"\n            metadata = {}\n            last_head = \"\"\n            for line in report:\n                # Ignore header\n                if line.startswith(\"#\"):\n                    # Get metadata values if possible\n                    match = re.search(\"# (.+?): (.+?)$\", line)\n                    if match:\n                        metadata[match.group(1)] = match.group(2)\n                    last_head = line\n                    continue\n                else:\n                    if last_head:\n                        data += last_head[2:].strip() + \"\\n\"\n                        last_head = \"\"\n                    data += line\n            return data, metadata\n\n    def make_seq_region(self, row: Dict[str, str], assembly_level: str, use_refseq: bool) -&gt; Dict[str, Any]:\n        \"\"\"From a row of the report, create one seq_region dict.\n\n        Args:\n            row: A seq_region row from the INSDC report.\n            assembly_level: what level is the seq_region (chromosome, contig, etc.)\n            use_refseq: Expect a RefSeq seq_region report.\n\n        Returns:\n            A seq_region dict.\n        \"\"\"\n        seq_region: Dict[str, Any] = {}\n\n        # Map the fields to their synonym name\n        synonym_map = self.synonym_map\n        molecule_location = self.molecule_location\n\n        # Synonyms\n        synonyms = []\n        for field, source in synonym_map.items():\n            if field in row and row[field].lower() != \"na\":\n                synonym = {\"source\": source, \"name\": row[field]}\n                synonyms.append(synonym)\n        if len(synonyms) &gt; 0:\n            synonyms.sort(key=lambda x: x[\"source\"])\n            seq_region[\"synonyms\"] = synonyms\n\n        # Length\n        field = \"Sequence-Length\"\n        if field in row and row[field].lower() != \"na\":\n            seq_region[\"length\"] = int(row[field])\n\n        if use_refseq:\n            if \"RefSeq-Accn\" in row:\n                seq_region[\"name\"] = row[\"RefSeq-Accn\"]\n            else:\n                raise Exception(f\"No RefSeq name for {row['Sequence-Name']}\")\n\n        else:\n            if \"GenBank-Accn\" in row:\n                seq_region[\"name\"] = row[\"GenBank-Accn\"]\n            else:\n                raise Exception(f\"No INSDC name for {row['Sequence-Name']}\")\n\n        # Coord system and location\n        seq_role = row[\"Sequence-Role\"]\n\n        # Scaffold?\n        if seq_role in (\"unplaced-scaffold\", \"unlocalized-scaffold\", \"alt-scaffold\"):\n            seq_region[\"coord_system_level\"] = \"scaffold\"\n\n        # Chromosome? Check location\n        elif seq_role == \"assembled-molecule\":\n            seq_region[\"coord_system_level\"] = \"chromosome\"\n            location = row[\"Assigned-Molecule-Location/Type\"].lower()\n\n            # Get location metadata\n            if location in molecule_location:\n                seq_location = molecule_location[location]\n                seq_region[\"location\"] = seq_location\n            else:\n                raise Exception(f\"Unrecognized sequence location: {location}\")\n        else:\n            raise Exception(f\"Unrecognized sequence role: {seq_role}\")\n        return seq_region\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/seqregion_parser/#ensembl.brc4.runnable.seqregion_parser.SeqregionParser.molecule_location","title":"<code>molecule_location = {'chromosome': 'nuclear_chromosome', 'mitochondrion': 'mitochondrial_chromosome', 'apicoplast': 'apicoplast_chromosome', 'plasmid': 'plasmid', 'linkage group': 'linkage_group', 'kinetoplast': 'kinetoplast'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/brc4/runnable/seqregion_parser/#ensembl.brc4.runnable.seqregion_parser.SeqregionParser.synonym_map","title":"<code>synonym_map = {'Sequence-Name': 'INSDC_submitted_name', 'GenBank-Accn': 'INSDC', 'RefSeq-Accn': 'RefSeq', 'Assigned-Molecule': 'GenBank'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/brc4/runnable/seqregion_parser/#ensembl.brc4.runnable.seqregion_parser.SeqregionParser.get_report_regions","title":"<code>get_report_regions(report_path, accession, use_refseq=False)</code>","text":"<p>Get seq_region data from report file.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>Path</code> <p>Path to the INSDC seq_region report.</p> required <code>use_refseq</code> <code>bool</code> <p>Expect a RefSeq seq_region report.</p> <code>False</code> <p>Returns:     A dict of seq_regions dicts, with their name as the key</p> Source code in <code>src/python/ensembl/brc4/runnable/seqregion_parser.py</code> <pre><code>def get_report_regions(\n    self, report_path: Path, accession: str, use_refseq: bool = False\n) -&gt; Dict[str, dict]:\n    \"\"\"Get seq_region data from report file.\n\n    Args:\n        report_path: Path to the INSDC seq_region report.\n        use_refseq: Expect a RefSeq seq_region report.\n    Returns:\n        A dict of seq_regions dicts, with their name as the key\n    \"\"\"\n    if accession.startswith(\"GCF\"):\n        use_refseq = True\n    # Get the report in a CSV format, easier to manipulate\n    report_csv, metadata = self.report_to_csv(report_path)\n\n    # Feed the csv string to the CSV reader\n    reader = csv.DictReader(report_csv.splitlines(), delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n\n    # Metadata\n    assembly_level = \"contig\"\n    if \"Assembly level\" in metadata:\n        assembly_level = metadata[\"Assembly level\"].lower()\n\n    # Create the seq_regions\n    seq_regions = {}\n    for row in reader:\n        seq_region = self.make_seq_region(row, assembly_level, use_refseq)\n        name = seq_region[\"name\"]\n        seq_regions[name] = seq_region\n\n    return seq_regions\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/seqregion_parser/#ensembl.brc4.runnable.seqregion_parser.SeqregionParser.make_seq_region","title":"<code>make_seq_region(row, assembly_level, use_refseq)</code>","text":"<p>From a row of the report, create one seq_region dict.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Dict[str, str]</code> <p>A seq_region row from the INSDC report.</p> required <code>assembly_level</code> <code>str</code> <p>what level is the seq_region (chromosome, contig, etc.)</p> required <code>use_refseq</code> <code>bool</code> <p>Expect a RefSeq seq_region report.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A seq_region dict.</p> Source code in <code>src/python/ensembl/brc4/runnable/seqregion_parser.py</code> <pre><code>def make_seq_region(self, row: Dict[str, str], assembly_level: str, use_refseq: bool) -&gt; Dict[str, Any]:\n    \"\"\"From a row of the report, create one seq_region dict.\n\n    Args:\n        row: A seq_region row from the INSDC report.\n        assembly_level: what level is the seq_region (chromosome, contig, etc.)\n        use_refseq: Expect a RefSeq seq_region report.\n\n    Returns:\n        A seq_region dict.\n    \"\"\"\n    seq_region: Dict[str, Any] = {}\n\n    # Map the fields to their synonym name\n    synonym_map = self.synonym_map\n    molecule_location = self.molecule_location\n\n    # Synonyms\n    synonyms = []\n    for field, source in synonym_map.items():\n        if field in row and row[field].lower() != \"na\":\n            synonym = {\"source\": source, \"name\": row[field]}\n            synonyms.append(synonym)\n    if len(synonyms) &gt; 0:\n        synonyms.sort(key=lambda x: x[\"source\"])\n        seq_region[\"synonyms\"] = synonyms\n\n    # Length\n    field = \"Sequence-Length\"\n    if field in row and row[field].lower() != \"na\":\n        seq_region[\"length\"] = int(row[field])\n\n    if use_refseq:\n        if \"RefSeq-Accn\" in row:\n            seq_region[\"name\"] = row[\"RefSeq-Accn\"]\n        else:\n            raise Exception(f\"No RefSeq name for {row['Sequence-Name']}\")\n\n    else:\n        if \"GenBank-Accn\" in row:\n            seq_region[\"name\"] = row[\"GenBank-Accn\"]\n        else:\n            raise Exception(f\"No INSDC name for {row['Sequence-Name']}\")\n\n    # Coord system and location\n    seq_role = row[\"Sequence-Role\"]\n\n    # Scaffold?\n    if seq_role in (\"unplaced-scaffold\", \"unlocalized-scaffold\", \"alt-scaffold\"):\n        seq_region[\"coord_system_level\"] = \"scaffold\"\n\n    # Chromosome? Check location\n    elif seq_role == \"assembled-molecule\":\n        seq_region[\"coord_system_level\"] = \"chromosome\"\n        location = row[\"Assigned-Molecule-Location/Type\"].lower()\n\n        # Get location metadata\n        if location in molecule_location:\n            seq_location = molecule_location[location]\n            seq_region[\"location\"] = seq_location\n        else:\n            raise Exception(f\"Unrecognized sequence location: {location}\")\n    else:\n        raise Exception(f\"Unrecognized sequence role: {seq_role}\")\n    return seq_region\n</code></pre>"},{"location":"reference/ensembl/brc4/runnable/seqregion_parser/#ensembl.brc4.runnable.seqregion_parser.SeqregionParser.report_to_csv","title":"<code>report_to_csv(report_path)</code>","text":"<p>Load an assembly report as a csv string.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>Path</code> <p>Path to the INSDC seq_region report.</p> required <p>Returns:     The csv as a string, and the head metadata as a dict.</p> Source code in <code>src/python/ensembl/brc4/runnable/seqregion_parser.py</code> <pre><code>def report_to_csv(self, report_path: Path) -&gt; Tuple[str, dict]:\n    \"\"\"Load an assembly report as a csv string.\n\n    Args:\n        report_path: Path to the INSDC seq_region report.\n    Returns:\n        The csv as a string, and the head metadata as a dict.\n    \"\"\"\n\n    with open_gz_file(report_path) as report:\n        data = \"\"\n        metadata = {}\n        last_head = \"\"\n        for line in report:\n            # Ignore header\n            if line.startswith(\"#\"):\n                # Get metadata values if possible\n                match = re.search(\"# (.+?): (.+?)$\", line)\n                if match:\n                    metadata[match.group(1)] = match.group(2)\n                last_head = line\n                continue\n            else:\n                if last_head:\n                    data += last_head[2:].strip() + \"\\n\"\n                    last_head = \"\"\n                data += line\n        return data, metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/","title":"genomio","text":""},{"location":"reference/ensembl/io/genomio/#ensembl.io.genomio","title":"<code>ensembl.io.genomio</code>","text":"<p>Genome Input/Output (GenomIO) handling library.</p>"},{"location":"reference/ensembl/io/genomio/annotation/","title":"annotation","text":""},{"location":"reference/ensembl/io/genomio/annotation/#ensembl.io.genomio.annotation","title":"<code>ensembl.io.genomio.annotation</code>","text":"<p>Annotation files processing module.</p>"},{"location":"reference/ensembl/io/genomio/annotation/#ensembl.io.genomio.annotation.get_core_data","title":"<code>get_core_data(session, table, match_xrefs=False)</code>","text":"<p>Returns the table descriptions from a core database.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session open on a core database.</p> required <code>table</code> <code>str</code> <p>\"gene\" or \"transcript\" table from the core database.</p> required <code>match_xrefs</code> <code>bool</code> <p>If the IDs do not match, try to match an Xref ID instead.</p> <code>False</code> Source code in <code>src/python/ensembl/io/genomio/annotation/update_description.py</code> <pre><code>def get_core_data(session: Session, table: str, match_xrefs: bool = False) -&gt; Dict[str, FeatStruct]:\n    \"\"\"Returns the table descriptions from a core database.\n\n    Args:\n        session: Session open on a core database.\n        table: \"gene\" or \"transcript\" table from the core database.\n        match_xrefs: If the IDs do not match, try to match an Xref ID instead.\n    \"\"\"\n\n    if table == \"gene\":\n        stmt = (\n            select(Gene.gene_id, Gene.stable_id, Gene.description, Xref.dbprimary_acc)\n            .select_from(Gene)\n            .outerjoin(\n                ObjectXref,\n                and_(Gene.gene_id == ObjectXref.ensembl_id, ObjectXref.ensembl_object_type == \"gene\"),\n            )\n            .outerjoin(Xref)\n        )\n    elif table == \"transcript\":\n        stmt = (\n            select(Transcript.transcript_id, Transcript.stable_id, Transcript.description, Xref.dbprimary_acc)\n            .select_from(Transcript)\n            .outerjoin(\n                ObjectXref,\n                and_(\n                    Transcript.transcript_id == ObjectXref.ensembl_id,\n                    ObjectXref.ensembl_object_type == \"transcript\",\n                ),\n            )\n            .outerjoin(Xref)\n        )\n    else:\n        raise ValueError(f\"Table {table} is not supported\")\n\n    feat_data = {}\n    for row in session.execute(stmt):\n        (feat_id, stable_id, desc, xref_name) = row\n        feat_struct: FeatStruct = (feat_id, stable_id, desc)\n        feat_data[stable_id.lower()] = feat_struct\n        if match_xrefs and xref_name:\n            feat_data[xref_name.lower()] = feat_struct\n\n    return feat_data\n</code></pre>"},{"location":"reference/ensembl/io/genomio/annotation/#ensembl.io.genomio.annotation.load_descriptions","title":"<code>load_descriptions(session, func_file, report=False, do_update=False, match_xrefs=True)</code>","text":"<p>Loads gene and transcript descriptions into a core database.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session open on a core database.</p> required <code>func_file</code> <code>Path</code> <p>JSON file with the annotation information.</p> required <code>report</code> <code>bool</code> <p>Print the mapping of changes to perform in the standard output.</p> <code>False</code> <code>do_update</code> <code>bool</code> <p>Actually update the core database.</p> <code>False</code> <code>match_xrefs</code> <code>bool</code> <p>If the IDs do not match, try to match an Xref ID instead.</p> <code>True</code> Source code in <code>src/python/ensembl/io/genomio/annotation/update_description.py</code> <pre><code>def load_descriptions(\n    session: Session,\n    func_file: Path,\n    report: bool = False,\n    do_update: bool = False,\n    match_xrefs: bool = True,\n) -&gt; None:\n    \"\"\"Loads gene and transcript descriptions into a core database.\n\n    Args:\n        session: Session open on a core database.\n        func_file: JSON file with the annotation information.\n        report: Print the mapping of changes to perform in the standard output.\n        do_update: Actually update the core database.\n        match_xrefs: If the IDs do not match, try to match an Xref ID instead.\n    \"\"\"\n    func = get_json(func_file)\n    logging.info(f\"{len(func)} annotations from {func_file}\")\n    table_to_update = {\"gene\": Gene, \"transcript\": Transcript}\n    for table, mapped_table in table_to_update.items():\n        logging.info(f\"Checking {table} descriptions\")\n        feat_func = [feat for feat in func if feat[\"object_type\"] == table]\n        logging.info(f\"{len(feat_func)} {table} annotations from {func_file}\")\n        feat_data = get_core_data(session, table, match_xrefs)\n        logging.info(f\"Loaded {len(feat_data)} {table} data\")\n\n        stats = {\n            \"not_supported\": 0,\n            \"not_found\": 0,\n            \"same\": 0,\n            \"same_empty\": 0,\n            \"empty_but_xref\": 0,\n            \"to_update_replace\": 0,\n            \"to_update_remove\": 0,\n        }\n        # Compare, only keep the descriptions that have changed\n        features_to_update = _get_features_to_update(\n            table, feat_func, feat_data, stats, report=report, do_update=do_update, match_xrefs=match_xrefs\n        )\n\n        # Show stats for this feature type\n        for stat, count in stats.items():\n            if count == 0:\n                continue\n            logging.info(f\"{stat} = {count}\")\n\n        if do_update:\n            logging.info(f\"Now updating {len(features_to_update)} rows...\")\n            session.bulk_update_mappings(mapped_table, features_to_update)\n            session.commit()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/annotation/update_description/","title":"update_description","text":""},{"location":"reference/ensembl/io/genomio/annotation/update_description/#ensembl.io.genomio.annotation.update_description","title":"<code>ensembl.io.genomio.annotation.update_description</code>","text":"<p>Update descriptions from a functional annotation file into a core database.</p>"},{"location":"reference/ensembl/io/genomio/annotation/update_description/#ensembl.io.genomio.annotation.update_description.FEAT_TABLE","title":"<code>FEAT_TABLE = {'gene': 'gene', 'mobile_element': 'gene', 'transcript': 'transcript'}</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/annotation/update_description/#ensembl.io.genomio.annotation.update_description.FeatStruct","title":"<code>FeatStruct = Tuple[str, str, str]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/annotation/update_description/#ensembl.io.genomio.annotation.update_description.get_core_data","title":"<code>get_core_data(session, table, match_xrefs=False)</code>","text":"<p>Returns the table descriptions from a core database.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session open on a core database.</p> required <code>table</code> <code>str</code> <p>\"gene\" or \"transcript\" table from the core database.</p> required <code>match_xrefs</code> <code>bool</code> <p>If the IDs do not match, try to match an Xref ID instead.</p> <code>False</code> Source code in <code>src/python/ensembl/io/genomio/annotation/update_description.py</code> <pre><code>def get_core_data(session: Session, table: str, match_xrefs: bool = False) -&gt; Dict[str, FeatStruct]:\n    \"\"\"Returns the table descriptions from a core database.\n\n    Args:\n        session: Session open on a core database.\n        table: \"gene\" or \"transcript\" table from the core database.\n        match_xrefs: If the IDs do not match, try to match an Xref ID instead.\n    \"\"\"\n\n    if table == \"gene\":\n        stmt = (\n            select(Gene.gene_id, Gene.stable_id, Gene.description, Xref.dbprimary_acc)\n            .select_from(Gene)\n            .outerjoin(\n                ObjectXref,\n                and_(Gene.gene_id == ObjectXref.ensembl_id, ObjectXref.ensembl_object_type == \"gene\"),\n            )\n            .outerjoin(Xref)\n        )\n    elif table == \"transcript\":\n        stmt = (\n            select(Transcript.transcript_id, Transcript.stable_id, Transcript.description, Xref.dbprimary_acc)\n            .select_from(Transcript)\n            .outerjoin(\n                ObjectXref,\n                and_(\n                    Transcript.transcript_id == ObjectXref.ensembl_id,\n                    ObjectXref.ensembl_object_type == \"transcript\",\n                ),\n            )\n            .outerjoin(Xref)\n        )\n    else:\n        raise ValueError(f\"Table {table} is not supported\")\n\n    feat_data = {}\n    for row in session.execute(stmt):\n        (feat_id, stable_id, desc, xref_name) = row\n        feat_struct: FeatStruct = (feat_id, stable_id, desc)\n        feat_data[stable_id.lower()] = feat_struct\n        if match_xrefs and xref_name:\n            feat_data[xref_name.lower()] = feat_struct\n\n    return feat_data\n</code></pre>"},{"location":"reference/ensembl/io/genomio/annotation/update_description/#ensembl.io.genomio.annotation.update_description.load_descriptions","title":"<code>load_descriptions(session, func_file, report=False, do_update=False, match_xrefs=True)</code>","text":"<p>Loads gene and transcript descriptions into a core database.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session open on a core database.</p> required <code>func_file</code> <code>Path</code> <p>JSON file with the annotation information.</p> required <code>report</code> <code>bool</code> <p>Print the mapping of changes to perform in the standard output.</p> <code>False</code> <code>do_update</code> <code>bool</code> <p>Actually update the core database.</p> <code>False</code> <code>match_xrefs</code> <code>bool</code> <p>If the IDs do not match, try to match an Xref ID instead.</p> <code>True</code> Source code in <code>src/python/ensembl/io/genomio/annotation/update_description.py</code> <pre><code>def load_descriptions(\n    session: Session,\n    func_file: Path,\n    report: bool = False,\n    do_update: bool = False,\n    match_xrefs: bool = True,\n) -&gt; None:\n    \"\"\"Loads gene and transcript descriptions into a core database.\n\n    Args:\n        session: Session open on a core database.\n        func_file: JSON file with the annotation information.\n        report: Print the mapping of changes to perform in the standard output.\n        do_update: Actually update the core database.\n        match_xrefs: If the IDs do not match, try to match an Xref ID instead.\n    \"\"\"\n    func = get_json(func_file)\n    logging.info(f\"{len(func)} annotations from {func_file}\")\n    table_to_update = {\"gene\": Gene, \"transcript\": Transcript}\n    for table, mapped_table in table_to_update.items():\n        logging.info(f\"Checking {table} descriptions\")\n        feat_func = [feat for feat in func if feat[\"object_type\"] == table]\n        logging.info(f\"{len(feat_func)} {table} annotations from {func_file}\")\n        feat_data = get_core_data(session, table, match_xrefs)\n        logging.info(f\"Loaded {len(feat_data)} {table} data\")\n\n        stats = {\n            \"not_supported\": 0,\n            \"not_found\": 0,\n            \"same\": 0,\n            \"same_empty\": 0,\n            \"empty_but_xref\": 0,\n            \"to_update_replace\": 0,\n            \"to_update_remove\": 0,\n        }\n        # Compare, only keep the descriptions that have changed\n        features_to_update = _get_features_to_update(\n            table, feat_func, feat_data, stats, report=report, do_update=do_update, match_xrefs=match_xrefs\n        )\n\n        # Show stats for this feature type\n        for stat, count in stats.items():\n            if count == 0:\n                continue\n            logging.info(f\"{stat} = {count}\")\n\n        if do_update:\n            logging.info(f\"Now updating {len(features_to_update)} rows...\")\n            session.bulk_update_mappings(mapped_table, features_to_update)\n            session.commit()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/annotation/update_description/#ensembl.io.genomio.annotation.update_description.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/annotation/update_description.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_server_arguments(include_database=True)\n    parser.add_argument_src_path(\"--func_file\", required=True, help=\"Input functional annotation JSON\")\n    parser.add_argument(\"--report\", action=\"store_true\", help=\"Show what change would be made\")\n    parser.add_argument(\"--update\", action=\"store_true\", help=\"Make the changes to the database\")\n    parser.add_argument(\n        \"--match_xrefs\", action=\"store_true\", help=\"Use xref IDs to match features if IDs do not work\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    dbc = DBConnection(args.url)\n    with dbc.session_scope() as session:\n        load_descriptions(session, args.func_file, args.report, args.update, match_xrefs=args.match_xrefs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/","title":"assembly","text":""},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly","title":"<code>ensembl.io.genomio.assembly</code>","text":"<p>Assembly preparation module.</p>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.FTPConnectionError","title":"<code>FTPConnectionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error while initialising an FTP connection.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>class FTPConnectionError(Exception):\n    \"\"\"Error while initialising an FTP connection.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.FileDownloadError","title":"<code>FileDownloadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a file download fails or there is a problem with that file.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>class FileDownloadError(Exception):\n    \"\"\"When a file download fails or there is a problem with that file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.UnsupportedFormatError","title":"<code>UnsupportedFormatError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a string does not have the expected format.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>class UnsupportedFormatError(Exception):\n    \"\"\"When a string does not have the expected format.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.download_files","title":"<code>download_files(ftp_connection, accession, dl_dir, max_redo)</code>","text":"<p>Given an INSDC accession, download all available files from the ftp to the download dir</p> <p>Parameters:</p> Name Type Description Default <code>ftp_connection</code> <code>FTP</code> <p>An open FTP connection object</p> required <code>accession</code> <code>str</code> <p>Genome assembly accession.</p> required <code>dl_dir</code> <code>Path</code> <p>Path to downloaded FTP files.</p> required <code>max_redo</code> <code>int</code> <p>Maximum FTP connection retry attempts.</p> required Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def download_files(ftp_connection: FTP, accession: str, dl_dir: Path, max_redo: int) -&gt; None:\n    \"\"\"\n    Given an INSDC accession, download all available files from the ftp to the download dir\n\n    Args:\n        ftp_connection: An open FTP connection object\n        accession: Genome assembly accession.\n        dl_dir: Path to downloaded FTP files.\n        max_redo: Maximum FTP connection retry attempts.\n    \"\"\"\n\n    # Get the list of assemblies for this accession\n    for ftp_dir, _ in ftp_connection.mlsd():\n        if re.search(accession, ftp_dir):\n            ftp_connection.cwd(ftp_dir)\n\n            # First, get the md5sum file\n            md5_file = \"md5checksums.txt\"\n            md5_path = dl_dir / md5_file\n            with md5_path.open(\"wb\") as fp:\n                ftp_connection.retrbinary(f\"RETR {md5_file}\", fp.write)\n            md5_sums = get_checksums(md5_path)\n\n            # Get all the files\n            for ftp_file, _ in ftp_connection.mlsd():\n                for end in _FILE_ENDS:\n                    if ftp_file.endswith(end) and not ftp_file.endswith(f\"_from_{end}\"):\n                        _download_file(ftp_connection, ftp_file, md5_sums, dl_dir, max_redo)\n        else:\n            logging.warning(\n                f\"Could not find accession '{accession}' from ftp {ftp_dir} in open FTP connection\"\n            )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.establish_ftp","title":"<code>establish_ftp(ftp_conn, ftp_url, accession)</code>","text":"<p>Return an FTP connection based on the provided <code>accession</code> and <code>sub_dir</code>.</p> <p>Parameters:</p> Name Type Description Default <code>ftp_conn</code> <code>FTP</code> <p>FTP class object.</p> required <code>ftp_url</code> <code>str</code> <p>Specific FTP URL in connection request.</p> required <code>accession</code> <code>str</code> <p>Genome accession required data for download.</p> required <p>Raises:</p> Type Description <code>UnsupportedFormatError</code> <p>If <code>accession</code> does not follow INSDC's accession format.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def establish_ftp(ftp_conn: FTP, ftp_url: str, accession: str) -&gt; FTP:\n    \"\"\"Return an FTP connection based on the provided `accession` and `sub_dir`.\n\n    Args:\n        ftp_conn: FTP class object.\n        ftp_url: Specific FTP URL in connection request.\n        accession: Genome accession required data for download.\n\n    Raises:\n        UnsupportedFormatError: If `accession` does not follow INSDC's accession format.\n    \"\"\"\n\n    match = re.match(r\"^(GC[AF])_([0-9]{3})([0-9]{3})([0-9]{3})(\\.[0-9]+)?$\", accession)\n    if not match:\n        raise UnsupportedFormatError(f\"Could not recognize GCA accession format: {accession}\")\n    gca = match.group(1)\n    part1 = match.group(2)\n    part2 = match.group(3)\n    part3 = match.group(4)\n    sub_dir = Path(\"genomes\", \"all\", gca, part1, part2, part3)\n\n    # Try now to establish connection to remote FTP server\n    ftp_conn.connect(ftp_url)\n    ftp_conn.login()\n    ftp_conn.cwd(str(sub_dir))\n\n    return ftp_conn\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.extract_assembly_metadata","title":"<code>extract_assembly_metadata(assembly_reports)</code>","text":"<p>Parse assembly reports and extract specific key information on status and related fields.</p> <p>Parameters:</p> Name Type Description Default <code>assembly_reports</code> <code>dict[str, dict]</code> <p>Key value pair of source name &lt;&gt; assembly report.</p> required <p>Returns:</p> Type Description <code>dict[str, ReportStructure]</code> <p>Parsed assembly report meta (source, meta).</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def extract_assembly_metadata(assembly_reports: dict[str, dict]) -&gt; dict[str, ReportStructure]:\n    \"\"\"Parse assembly reports and extract specific key information on status and related fields.\n\n    Args:\n        assembly_reports: Key value pair of source name &lt;&gt; assembly report.\n\n    Returns:\n        Parsed assembly report meta (source, meta).\n    \"\"\"\n    parsed_meta = {}\n\n    for source, asm_report in assembly_reports.items():\n        asm_meta_info = ReportStructure()\n\n        # Mandatory meta key parsing:\n        asm_meta_info.accession = asm_report[\"accession\"]\n        asm_meta_info.assembly_name = asm_report[\"assembly_info\"][\"assembly_name\"]\n        asm_meta_info.assembly_type = asm_report[\"assembly_info\"][\"assembly_type\"]\n        asm_meta_info.assembly_status = asm_report[\"assembly_info\"][\"assembly_status\"]\n        asm_meta_info.species_name = asm_report[\"organism\"][\"organism_name\"]\n        asm_meta_info.taxon_id = int(asm_report[\"organism\"][\"tax_id\"])\n\n        ## Non-mandatory meta key parsing:\n        assembly_meta_keys = asm_report[\"assembly_info\"].keys()\n        organism_keys = asm_report[\"organism\"].keys()\n\n        # check for genome_notes:\n        if \"genome_notes\" in assembly_meta_keys:\n            complete_notes = \", \".join(asm_report[\"assembly_info\"][\"genome_notes\"])\n            asm_meta_info.assembly_notes = complete_notes\n\n        # check for biosample:\n        if \"biosample\" in assembly_meta_keys:\n            asm_meta_info.last_updated = asm_report[\"assembly_info\"][\"biosample\"][\"last_updated\"]\n\n        # check for paired assembly:\n        if \"paired_assembly\" in assembly_meta_keys:\n            asm_meta_info.paired_assembly = asm_report[\"assembly_info\"][\"paired_assembly\"][\"accession\"]\n\n        # check for isolate/strain type:\n        if \"infraspecific_names\" in organism_keys:\n            organism_type_keys = asm_report[\"organism\"][\"infraspecific_names\"].keys()\n            if \"isolate\" in organism_type_keys:\n                asm_meta_info.strain = asm_report[\"organism\"][\"infraspecific_names\"][\"isolate\"]\n            elif \"strain\" in organism_type_keys:\n                asm_meta_info.strain = asm_report[\"organism\"][\"infraspecific_names\"][\"strain\"]\n\n        parsed_meta[source] = asm_meta_info\n\n    return parsed_meta\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.fetch_accessions_from_core_dbs","title":"<code>fetch_accessions_from_core_dbs(src_file, server_url)</code>","text":"<p>Obtain the associated INSDC accession given a set of core database names and a database server URL.</p> <p>The accession information is obtained from the <code>meta</code> table's meta key <code>assembly.accession</code>.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>StrPath</code> <p>File path with list of core database names.</p> required <code>server_url</code> <code>URL</code> <p>Database server URL.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dict of core database names (key) and their corresponding INSDC assembly accession (value).</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def fetch_accessions_from_core_dbs(src_file: StrPath, server_url: URL) -&gt; dict[str, str]:\n    \"\"\"Obtain the associated INSDC accession given a set of core database names and a database server URL.\n\n    The accession information is obtained from the `meta` table's meta key `assembly.accession`.\n\n    Args:\n        src_file: File path with list of core database names.\n        server_url: Database server URL.\n\n    Returns:\n        Dict of core database names (key) and their corresponding INSDC assembly accession (value).\n    \"\"\"\n\n    core_accn_meta = {}\n    database_count = 0\n    count_accn_found = 0\n\n    with Path(src_file).open(\"r\") as fin:\n        for line in fin.readlines():\n            core_db = line.strip()\n            database_count += 1\n            db_connection_url = server_url.set(database=core_db)\n            db_connection = DBConnection(db_connection_url)\n            with db_connection.begin() as conn:\n                query_result = conn.execute(\n                    text('SELECT meta_value FROM meta WHERE meta_key = \"assembly.accession\";')\n                ).fetchall()\n\n            if not query_result:\n                logging.warning(f\"No accessions found in core: {core_db}\")\n            elif len(query_result) == 1:\n                count_accn_found += 1\n                asm_accession = query_result.pop()[0]\n                logging.info(f\"{core_db} -&gt; assembly.accession[{asm_accession}]\")\n                core_accn_meta[core_db] = asm_accession\n            else:\n                logging.warning(f\"Core {core_db} has {len(query_result)} assembly.accessions\")\n\n    logging.info(\n        f\"From initial input core databases ({database_count}), obtained ({count_accn_found}) accessions\"\n    )\n\n    return core_accn_meta\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.fetch_datasets_reports","title":"<code>fetch_datasets_reports(sif_image, assembly_accessions, download_directory, batch_size)</code>","text":"<p>Obtain assembly reports in JSON format for each assembly accession via <code>datasets</code> CLI.</p> <p>Parameters:</p> Name Type Description Default <code>sif_image</code> <code>Client</code> <p>Instance of <code>Client.loaded()</code> singularity image.</p> required <code>assembly_accessions</code> <code>dict[str, str]</code> <p>Dictionary of accession source &lt;&gt; assembly accessions pairs.</p> required <code>download_directory</code> <code>StrPath</code> <p>Directory path to store assembly report JSON files.</p> required <code>batch_size</code> <code>int</code> <p>Number of assembly accessions to batch submit to <code>datasets</code>.</p> required <p>Returns:</p> Type Description <code>dict[str, dict]</code> <p>Dictionary of accession source and its associated assembly report.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If result returned by <code>datasets</code> is not a string.</p> <code>RuntimeError</code> <p>If there was an error raised by <code>datasets</code>.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def fetch_datasets_reports(\n    sif_image: Client, assembly_accessions: dict[str, str], download_directory: StrPath, batch_size: int\n) -&gt; dict[str, dict]:\n    \"\"\"Obtain assembly reports in JSON format for each assembly accession via `datasets` CLI.\n\n    Args:\n        sif_image: Instance of `Client.loaded()` singularity image.\n        assembly_accessions: Dictionary of accession source &lt;&gt; assembly accessions pairs.\n        download_directory: Directory path to store assembly report JSON files.\n        batch_size: Number of assembly accessions to batch submit to `datasets`.\n\n    Returns:\n        Dictionary of accession source and its associated assembly report.\n\n    Raises:\n        ValueError: If result returned by `datasets` is not a string.\n        RuntimeError: If there was an error raised by `datasets`.\n\n    \"\"\"\n    master_accn_list = list(assembly_accessions.values())\n    combined_asm_reports = {}\n\n    # Setting the number of combined accessions to query in a single call to datasets\n    list_split = list(range(0, len(master_accn_list), batch_size))\n    accn_subsample = [master_accn_list[ind : ind + batch_size] for ind in list_split]\n\n    datasets_command = [\"datasets\", \"summary\", \"genome\", \"accession\"]\n    for accessions in accn_subsample:\n        # Make call to singularity datasets providing a multi-accession query\n        client_return = Client.execute(\n            image=sif_image, command=datasets_command + accessions, return_result=True, quiet=True\n        )\n        raw_result = client_return[\"message\"]\n\n        ## Test what result we have obtained following execution of sif image and accession value\n        # Returned a list, i.e. datasets returned a result to client.execute\n        # Returned a str, i.e. no datasets result obtained exited with fatal error\n        if isinstance(raw_result, list):\n            result = raw_result[0]\n        else:\n            result = raw_result\n        if not isinstance(result, str):\n            raise ValueError(\"Result obtained from datasets is not a string\")\n        if re.search(\"^FATAL\", result):\n            raise RuntimeError(f\"Singularity image execution failed! -&gt; '{result.strip()}'\")\n\n        tmp_asm_dict = json.loads(result)\n        if not tmp_asm_dict[\"total_count\"]:\n            logging.warning(f\"No assembly report found for accession(s) {accessions}\")\n            continue\n\n        logging.info(f\"Assembly report obtained for accession(s) {accessions}\")\n        batch_reports_json = tmp_asm_dict[\"reports\"]\n        for assembly_report in batch_reports_json:\n            accession = assembly_report[\"accession\"]\n            asm_json_outfile = Path(download_directory, f\"{accession}.asm_report.json\")\n            print_json(asm_json_outfile, assembly_report)\n            # Save assembly report into source key&lt;&gt;report dict\n            for src_key, accession_core in assembly_accessions.items():\n                if accession == accession_core:\n                    combined_asm_reports[src_key] = assembly_report\n\n    return combined_asm_reports\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.generate_report_tsv","title":"<code>generate_report_tsv(parsed_asm_reports, query_type, output_directory=Path(), outfile_name='AssemblyStatusReport')</code>","text":"<p>Generate and write the assembly report to a TSV file.</p> <p>Parameters:</p> Name Type Description Default <code>parsed_asm_reports</code> <code>dict[str, ReportStructure]</code> <p>Parsed assembly report meta.</p> required <code>query_type</code> <code>str</code> <p>Type of query (either core databases or accessions).</p> required <code>output_directory</code> <code>StrPath</code> <p>Directory to store report TSV file.</p> <code>Path()</code> <code>outfile_name</code> <code>str</code> <p>Name to give to the output TSV file.</p> <code>'AssemblyStatusReport'</code> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def generate_report_tsv(\n    parsed_asm_reports: dict[str, ReportStructure],\n    query_type: str,\n    output_directory: StrPath = Path(),\n    outfile_name: str = \"AssemblyStatusReport\",\n) -&gt; None:\n    \"\"\"Generate and write the assembly report to a TSV file.\n\n    Args:\n        parsed_asm_reports: Parsed assembly report meta.\n        query_type: Type of query (either core databases or accessions).\n        output_directory: Directory to store report TSV file.\n        outfile_name: Name to give to the output TSV file.\n    \"\"\"\n    tsv_outfile = Path(output_directory, f\"{outfile_name}.tsv\")\n\n    header_list = next(iter(parsed_asm_reports.values())).header()\n    header_list = [query_type.capitalize().replace(\"_\", \" \")] + header_list\n\n    with open(tsv_outfile, \"w+\") as tsv_out:\n        writer = csv.writer(tsv_out, delimiter=\"\\t\", lineterminator=\"\\n\")\n        writer.writerow(header_list)\n        for core, report_meta in parsed_asm_reports.items():\n            final_asm_report = [core] + report_meta.values()\n            writer.writerow(final_asm_report)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.get_assembly_accessions","title":"<code>get_assembly_accessions(src_file)</code>","text":"<p>Returns the list of assembly accessions found in the provided file.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>StrPath</code> <p>Path to file with one line per INSDC assembly accession.</p> required <p>Raises:</p> Type Description <code>UnsupportedFormatError</code> <p>If an accession does not match the INSDC assembly accession format.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def get_assembly_accessions(src_file: StrPath) -&gt; list[str]:\n    \"\"\"Returns the list of assembly accessions found in the provided file.\n\n    Args:\n        src_file: Path to file with one line per INSDC assembly accession.\n\n    Raises:\n        UnsupportedFormatError: If an accession does not match the INSDC assembly accession format.\n    \"\"\"\n    query_accessions: list[str] = []\n    with Path(src_file).open(mode=\"r\") as fin:\n        for line in fin.readlines():\n            line = line.strip()\n            match = re.match(r\"^GC[AF]_[0-9]{9}\\.[1-9][0-9]*$\", line)\n            if not match:\n                raise UnsupportedFormatError(f\"Could not recognize GCA/GCF accession format: {line}\")\n            query_accessions.append(line)\n    return query_accessions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.get_checksums","title":"<code>get_checksums(checksum_path)</code>","text":"<p>Get a dict of checksums from a file, with file names as keys and sums as values</p> <p>Parameters:</p> Name Type Description Default <code>checksum_path</code> <code>Path</code> <p>Path location to MD5 checksum file.</p> required Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def get_checksums(checksum_path: Path) -&gt; Dict[str, str]:\n    \"\"\"\n    Get a dict of checksums from a file, with file names as keys and sums as values\n\n    Args:\n        checksum_path: Path location to MD5 checksum file.\n    \"\"\"\n    sums: Dict[str, str] = {}\n    if not checksum_path.is_file():\n        return sums\n    with checksum_path.open(mode=\"r\") as fh:\n        for line in fh:\n            checksum, file_path = line.strip().split(\"  \")\n            file_path = file_path[2:]\n            if not file_path.find(\"/\") &gt;= 0:\n                sums[file_path] = checksum\n    return sums\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.get_files_selection","title":"<code>get_files_selection(dl_dir)</code>","text":"<p>Returns a dictionary with the relevant downloaded files classified.</p> <p>Parameters:</p> Name Type Description Default <code>dl_dir</code> <code>Path</code> <p>Local path to downloaded FTP files.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dictionary of file type (e.g.<code>\"report\"</code>) as keys and the relative file path (from <code>dl_dir</code>) as values.</p> <p>Raises:</p> Type Description <code>FileDownloadError</code> <p>If <code>dl_dir</code> tree does not include a file named <code>*_assembly_report.txt</code>.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def get_files_selection(dl_dir: Path) -&gt; Dict[str, str]:\n    \"\"\"Returns a dictionary with the relevant downloaded files classified.\n\n    Args:\n        dl_dir: Local path to downloaded FTP files.\n\n    Returns:\n        Dictionary of file type (e.g.`\"report\"`) as keys and the relative file path (from `dl_dir`) as values.\n\n    Raises:\n        FileDownloadError: If `dl_dir` tree does not include a file named `*_assembly_report.txt`.\n    \"\"\"\n    files = {}\n    root_name = get_root_name(dl_dir)\n    if root_name == \"\":\n        raise FileDownloadError(f\"Could not determine the files root name in {dl_dir}\")\n    for dl_file in dl_dir.iterdir():\n        for end, name in _FILE_ENDS.items():\n            file_with_end = dl_file.name.endswith(end) and not dl_file.name.endswith(f\"_from_{end}\")\n            if (root_name and dl_file.name == root_name + end) or file_with_end:\n                files[name] = str(dl_file)\n    return files\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.get_root_name","title":"<code>get_root_name(dl_dir)</code>","text":"<p>Returns the root name, i.e. shared files basename prefix, using the assembly report file as base.</p> <p>Parameters:</p> Name Type Description Default <code>dl_dir</code> <code>Path</code> <p>Path location of downloaded FTP files.</p> required Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def get_root_name(dl_dir: Path) -&gt; str:\n    \"\"\"Returns the root name, i.e. shared files basename prefix, using the assembly report file as base.\n\n    Args:\n        dl_dir: Path location of downloaded FTP files.\n    \"\"\"\n    root_name = \"\"\n    for dl_file in dl_dir.iterdir():\n        matches = re.search(\"^(.+_)assembly_report.txt\", dl_file.name)\n        if matches:\n            root_name = matches.group(1)\n            break\n    return root_name\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.md5_files","title":"<code>md5_files(dl_dir, md5_path=None, md5_filename='md5checksums.txt')</code>","text":"<p>Check all files checksums with the sums listed in a checksum file, if available. Return False if there is no checksum file, or a file is missing, or has a wrong checksum.</p> <p>Parameters:</p> Name Type Description Default <code>dl_dir</code> <code>Path</code> <p>Path location to containing downloaded FTP files.</p> required <code>md5_path</code> <code>Optional[Path]</code> <p>Full path to an MD5 checksum file.</p> <code>None</code> <code>md5_filename</code> <code>str</code> <p>Name of a checksum file in the <code>dl_dir</code> (used if no <code>md5_path</code> is given).</p> <code>'md5checksums.txt'</code> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def md5_files(dl_dir: Path, md5_path: Optional[Path] = None, md5_filename: str = \"md5checksums.txt\") -&gt; bool:\n    \"\"\"\n    Check all files checksums with the sums listed in a checksum file, if available.\n    Return False if there is no checksum file, or a file is missing, or has a wrong checksum.\n\n    Args:\n        dl_dir: Path location to containing downloaded FTP files.\n        md5_path: Full path to an MD5 checksum file.\n        md5_filename: Name of a checksum file in the `dl_dir` (used if no `md5_path` is given).\n    \"\"\"\n    # Get or set md5 file to user or default setting\n    if md5_path is None:\n        md5_path = dl_dir / md5_filename\n\n    # Get checksums and compare\n    sums = get_checksums(md5_path)\n    if not sums:\n        return False\n    logging.info(f\" File sums from {md5_path}: {len(sums)}\")\n    for dl_file, checksum in sums.items():\n        for end in _FILE_ENDS:\n            if dl_file.endswith(end) and not dl_file.endswith(f\"_from_{end}\"):\n                file_path = dl_dir / dl_file\n                if not file_path.is_file():\n                    logging.warning(f\" No file {file_path} found\")\n                    return False\n                # Check the file checksum\n                with file_path.open(mode=\"rb\") as f:\n                    content = f.read()\n                    file_sum = hashlib.md5(content).hexdigest()\n                if file_sum != checksum:\n                    logging.warning(f\" File {file_path} checksum doesn't match\")\n                    return False\n                logging.info(f\" File checksum ok {file_path}\")\n    logging.info(\" All checksums OK\")\n    return True\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.retrieve_assembly_data","title":"<code>retrieve_assembly_data(accession, download_dir, max_increment=0, max_redo=3)</code>","text":"<p>Establishes an FTP connection and downloads a predefined subset of assembly data files from either INSDC or RefSeq.</p> <p>Parameters:</p> Name Type Description Default <code>accession</code> <code>str</code> <p>Genome assembly accession.</p> required <code>download_dir</code> <code>PathLike</code> <p>Path to where to download FTP files.</p> required <code>max_increment</code> <code>int</code> <p>If you want to allow assembly versions.</p> <code>0</code> <code>max_redo</code> <code>int</code> <p>Maximum FTP connection retry attempts.</p> <code>3</code> <p>Raises:</p> Type Description <code>FileDownloadError</code> <p>If no files are downloaded or if any does not match its MD5 checksum.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def retrieve_assembly_data(\n    accession: str,\n    download_dir: PathLike,\n    max_increment: int = 0,\n    max_redo: int = 3,\n) -&gt; None:\n    \"\"\"Establishes an FTP connection and downloads a predefined subset of assembly data files from either\n    INSDC or RefSeq.\n\n    Args:\n        accession: Genome assembly accession.\n        download_dir: Path to where to download FTP files.\n        max_increment: If you want to allow assembly versions.\n        max_redo: Maximum FTP connection retry attempts.\n\n    Raises:\n        FileDownloadError: If no files are downloaded or if any does not match its MD5 checksum.\n    \"\"\"\n    download_dir = Path(download_dir)\n\n    # Set and create dedicated dir for download\n    download_dir.mkdir(parents=True, exist_ok=True)\n\n    # Download if files don't exist or fail checksum\n    if not md5_files(download_dir, None):\n        logging.info(\" Download the files\")\n\n        for increment in range(0, max_increment + 1):\n            if increment &gt; 0:\n                logging.info(f\" Increment accession version once from {accession}\")\n                version = int(accession[-1])\n                version += 1\n                accession = accession[:-1] + str(version)\n                download_dir.mkdir(parents=True, exist_ok=True)\n            ftp_url = \"ftp.ncbi.nlm.nih.gov\"\n            ftp_instance = FTP()\n            open_ftp_connection = establish_ftp(ftp_instance, ftp_url, accession)\n            download_files(open_ftp_connection, accession, download_dir, max_redo)\n\n        if not md5_files(download_dir, None):\n            raise FileDownloadError(\"Failed md5sum of downloaded files\")\n\n    # Select specific files and give them a name\n    files = get_files_selection(download_dir)\n\n    if len(files) == 0:\n        raise FileDownloadError(\"No file downloaded\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/#ensembl.io.genomio.assembly.singularity_image_setter","title":"<code>singularity_image_setter(sif_cache_dir, datasets_version)</code>","text":"<p>Parse ENV and User specified variables related to <code>datasets</code> singularity SIF container and define version and location of container.</p> <p>Parameters:</p> Name Type Description Default <code>sif_cache_dir</code> <code>Path | None</code> <p>Path to locate existing, or download new SIF container image.</p> required <code>datasets_version</code> <code>str | None</code> <p>URL of singularity container (custom <code>datasets</code> version if desired).</p> required <p>Returns:</p> Type Description <code>Client</code> <p><code>spython.main.client</code> instance of singularity container image housing <code>datasets</code>.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def singularity_image_setter(sif_cache_dir: Path | None, datasets_version: str | None) -&gt; Client:\n    \"\"\"Parse ENV and User specified variables related to `datasets` singularity SIF\n    container and define version and location of container.\n\n    Args:\n        sif_cache_dir: Path to locate existing, or download new SIF container image.\n        datasets_version: URL of singularity container (custom `datasets` version if desired).\n\n    Returns:\n        `spython.main.client` instance of singularity container image housing `datasets`.\n    \"\"\"\n\n    # Set singularity cache dir from user defined path or use environment\n    if sif_cache_dir and sif_cache_dir.is_dir():\n        image_dl_path = sif_cache_dir\n        logging.info(f\"Using user-defined cache_dir: '{image_dl_path}'\")\n    elif os.environ.get(\"NXF_SINGULARITY_CACHEDIR\"):\n        image_dl_path = Path(os.environ[\"NXF_SINGULARITY_CACHEDIR\"])\n        logging.info(\n            f\"Using preferred nextflow singularity cache dir 'NXF_SINGULARITY_CACHEDIR': {image_dl_path}\"\n        )\n    elif os.environ.get(\"SINGULARITY_CACHEDIR\"):\n        image_dl_path = Path(os.environ[\"SINGULARITY_CACHEDIR\"])\n        logging.info(\n            f\"Using the default singularity installation cache dir 'SINGULARITY_CACHEDIR': {image_dl_path}\"\n        )\n    else:\n        image_dl_path = Path()\n        logging.warning(f\"Unable to set singularity cache dir properly, using CWD {image_dl_path}\")\n\n    # Set the datasets version URL\n    if datasets_version is None:\n        container_url = DATASETS_SINGULARITY[\"datasets_version_url\"]\n        logging.info(f\"Using default 'ncbi datasets' version '{container_url}'\")\n    else:\n        container_url = datasets_version\n        logging.info(f\"Using user defined 'ncbi datasets' version '{container_url}'\")\n\n    # Pull or load pre-existing 'datasets' singularity container image.\n    datasets_image = Client.pull(container_url, stream=False, pull_folder=image_dl_path, quiet=True)\n\n    return datasets_image\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/","title":"download","text":""},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download","title":"<code>ensembl.io.genomio.assembly.download</code>","text":"<p>Download an assembly data files from INSDC or RefSeq.</p>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.FTPConnectionError","title":"<code>FTPConnectionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error while initialising an FTP connection.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>class FTPConnectionError(Exception):\n    \"\"\"Error while initialising an FTP connection.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.FileDownloadError","title":"<code>FileDownloadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a file download fails or there is a problem with that file.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>class FileDownloadError(Exception):\n    \"\"\"When a file download fails or there is a problem with that file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.UnsupportedFormatError","title":"<code>UnsupportedFormatError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a string does not have the expected format.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>class UnsupportedFormatError(Exception):\n    \"\"\"When a string does not have the expected format.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.download_files","title":"<code>download_files(ftp_connection, accession, dl_dir, max_redo)</code>","text":"<p>Given an INSDC accession, download all available files from the ftp to the download dir</p> <p>Parameters:</p> Name Type Description Default <code>ftp_connection</code> <code>FTP</code> <p>An open FTP connection object</p> required <code>accession</code> <code>str</code> <p>Genome assembly accession.</p> required <code>dl_dir</code> <code>Path</code> <p>Path to downloaded FTP files.</p> required <code>max_redo</code> <code>int</code> <p>Maximum FTP connection retry attempts.</p> required Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def download_files(ftp_connection: FTP, accession: str, dl_dir: Path, max_redo: int) -&gt; None:\n    \"\"\"\n    Given an INSDC accession, download all available files from the ftp to the download dir\n\n    Args:\n        ftp_connection: An open FTP connection object\n        accession: Genome assembly accession.\n        dl_dir: Path to downloaded FTP files.\n        max_redo: Maximum FTP connection retry attempts.\n    \"\"\"\n\n    # Get the list of assemblies for this accession\n    for ftp_dir, _ in ftp_connection.mlsd():\n        if re.search(accession, ftp_dir):\n            ftp_connection.cwd(ftp_dir)\n\n            # First, get the md5sum file\n            md5_file = \"md5checksums.txt\"\n            md5_path = dl_dir / md5_file\n            with md5_path.open(\"wb\") as fp:\n                ftp_connection.retrbinary(f\"RETR {md5_file}\", fp.write)\n            md5_sums = get_checksums(md5_path)\n\n            # Get all the files\n            for ftp_file, _ in ftp_connection.mlsd():\n                for end in _FILE_ENDS:\n                    if ftp_file.endswith(end) and not ftp_file.endswith(f\"_from_{end}\"):\n                        _download_file(ftp_connection, ftp_file, md5_sums, dl_dir, max_redo)\n        else:\n            logging.warning(\n                f\"Could not find accession '{accession}' from ftp {ftp_dir} in open FTP connection\"\n            )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.establish_ftp","title":"<code>establish_ftp(ftp_conn, ftp_url, accession)</code>","text":"<p>Return an FTP connection based on the provided <code>accession</code> and <code>sub_dir</code>.</p> <p>Parameters:</p> Name Type Description Default <code>ftp_conn</code> <code>FTP</code> <p>FTP class object.</p> required <code>ftp_url</code> <code>str</code> <p>Specific FTP URL in connection request.</p> required <code>accession</code> <code>str</code> <p>Genome accession required data for download.</p> required <p>Raises:</p> Type Description <code>UnsupportedFormatError</code> <p>If <code>accession</code> does not follow INSDC's accession format.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def establish_ftp(ftp_conn: FTP, ftp_url: str, accession: str) -&gt; FTP:\n    \"\"\"Return an FTP connection based on the provided `accession` and `sub_dir`.\n\n    Args:\n        ftp_conn: FTP class object.\n        ftp_url: Specific FTP URL in connection request.\n        accession: Genome accession required data for download.\n\n    Raises:\n        UnsupportedFormatError: If `accession` does not follow INSDC's accession format.\n    \"\"\"\n\n    match = re.match(r\"^(GC[AF])_([0-9]{3})([0-9]{3})([0-9]{3})(\\.[0-9]+)?$\", accession)\n    if not match:\n        raise UnsupportedFormatError(f\"Could not recognize GCA accession format: {accession}\")\n    gca = match.group(1)\n    part1 = match.group(2)\n    part2 = match.group(3)\n    part3 = match.group(4)\n    sub_dir = Path(\"genomes\", \"all\", gca, part1, part2, part3)\n\n    # Try now to establish connection to remote FTP server\n    ftp_conn.connect(ftp_url)\n    ftp_conn.login()\n    ftp_conn.cwd(str(sub_dir))\n\n    return ftp_conn\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.get_checksums","title":"<code>get_checksums(checksum_path)</code>","text":"<p>Get a dict of checksums from a file, with file names as keys and sums as values</p> <p>Parameters:</p> Name Type Description Default <code>checksum_path</code> <code>Path</code> <p>Path location to MD5 checksum file.</p> required Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def get_checksums(checksum_path: Path) -&gt; Dict[str, str]:\n    \"\"\"\n    Get a dict of checksums from a file, with file names as keys and sums as values\n\n    Args:\n        checksum_path: Path location to MD5 checksum file.\n    \"\"\"\n    sums: Dict[str, str] = {}\n    if not checksum_path.is_file():\n        return sums\n    with checksum_path.open(mode=\"r\") as fh:\n        for line in fh:\n            checksum, file_path = line.strip().split(\"  \")\n            file_path = file_path[2:]\n            if not file_path.find(\"/\") &gt;= 0:\n                sums[file_path] = checksum\n    return sums\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.get_files_selection","title":"<code>get_files_selection(dl_dir)</code>","text":"<p>Returns a dictionary with the relevant downloaded files classified.</p> <p>Parameters:</p> Name Type Description Default <code>dl_dir</code> <code>Path</code> <p>Local path to downloaded FTP files.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dictionary of file type (e.g.<code>\"report\"</code>) as keys and the relative file path (from <code>dl_dir</code>) as values.</p> <p>Raises:</p> Type Description <code>FileDownloadError</code> <p>If <code>dl_dir</code> tree does not include a file named <code>*_assembly_report.txt</code>.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def get_files_selection(dl_dir: Path) -&gt; Dict[str, str]:\n    \"\"\"Returns a dictionary with the relevant downloaded files classified.\n\n    Args:\n        dl_dir: Local path to downloaded FTP files.\n\n    Returns:\n        Dictionary of file type (e.g.`\"report\"`) as keys and the relative file path (from `dl_dir`) as values.\n\n    Raises:\n        FileDownloadError: If `dl_dir` tree does not include a file named `*_assembly_report.txt`.\n    \"\"\"\n    files = {}\n    root_name = get_root_name(dl_dir)\n    if root_name == \"\":\n        raise FileDownloadError(f\"Could not determine the files root name in {dl_dir}\")\n    for dl_file in dl_dir.iterdir():\n        for end, name in _FILE_ENDS.items():\n            file_with_end = dl_file.name.endswith(end) and not dl_file.name.endswith(f\"_from_{end}\")\n            if (root_name and dl_file.name == root_name + end) or file_with_end:\n                files[name] = str(dl_file)\n    return files\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.get_root_name","title":"<code>get_root_name(dl_dir)</code>","text":"<p>Returns the root name, i.e. shared files basename prefix, using the assembly report file as base.</p> <p>Parameters:</p> Name Type Description Default <code>dl_dir</code> <code>Path</code> <p>Path location of downloaded FTP files.</p> required Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def get_root_name(dl_dir: Path) -&gt; str:\n    \"\"\"Returns the root name, i.e. shared files basename prefix, using the assembly report file as base.\n\n    Args:\n        dl_dir: Path location of downloaded FTP files.\n    \"\"\"\n    root_name = \"\"\n    for dl_file in dl_dir.iterdir():\n        matches = re.search(\"^(.+_)assembly_report.txt\", dl_file.name)\n        if matches:\n            root_name = matches.group(1)\n            break\n    return root_name\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.main","title":"<code>main()</code>","text":"<p>Module's entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module's entry-point.\"\"\"\n    parser = ArgumentParser(description=\"Download an assembly data files from INSDC or RefSeq.\")\n    parser.add_argument(\"--accession\", required=True, help=\"Genome assembly accession\")\n    parser.add_argument_dst_path(\n        \"--download_dir\", default=Path.cwd(), help=\"Folder where the data will be downloaded\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    retrieve_assembly_data(args.accession, args.download_dir)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.md5_files","title":"<code>md5_files(dl_dir, md5_path=None, md5_filename='md5checksums.txt')</code>","text":"<p>Check all files checksums with the sums listed in a checksum file, if available. Return False if there is no checksum file, or a file is missing, or has a wrong checksum.</p> <p>Parameters:</p> Name Type Description Default <code>dl_dir</code> <code>Path</code> <p>Path location to containing downloaded FTP files.</p> required <code>md5_path</code> <code>Optional[Path]</code> <p>Full path to an MD5 checksum file.</p> <code>None</code> <code>md5_filename</code> <code>str</code> <p>Name of a checksum file in the <code>dl_dir</code> (used if no <code>md5_path</code> is given).</p> <code>'md5checksums.txt'</code> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def md5_files(dl_dir: Path, md5_path: Optional[Path] = None, md5_filename: str = \"md5checksums.txt\") -&gt; bool:\n    \"\"\"\n    Check all files checksums with the sums listed in a checksum file, if available.\n    Return False if there is no checksum file, or a file is missing, or has a wrong checksum.\n\n    Args:\n        dl_dir: Path location to containing downloaded FTP files.\n        md5_path: Full path to an MD5 checksum file.\n        md5_filename: Name of a checksum file in the `dl_dir` (used if no `md5_path` is given).\n    \"\"\"\n    # Get or set md5 file to user or default setting\n    if md5_path is None:\n        md5_path = dl_dir / md5_filename\n\n    # Get checksums and compare\n    sums = get_checksums(md5_path)\n    if not sums:\n        return False\n    logging.info(f\" File sums from {md5_path}: {len(sums)}\")\n    for dl_file, checksum in sums.items():\n        for end in _FILE_ENDS:\n            if dl_file.endswith(end) and not dl_file.endswith(f\"_from_{end}\"):\n                file_path = dl_dir / dl_file\n                if not file_path.is_file():\n                    logging.warning(f\" No file {file_path} found\")\n                    return False\n                # Check the file checksum\n                with file_path.open(mode=\"rb\") as f:\n                    content = f.read()\n                    file_sum = hashlib.md5(content).hexdigest()\n                if file_sum != checksum:\n                    logging.warning(f\" File {file_path} checksum doesn't match\")\n                    return False\n                logging.info(f\" File checksum ok {file_path}\")\n    logging.info(\" All checksums OK\")\n    return True\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/download/#ensembl.io.genomio.assembly.download.retrieve_assembly_data","title":"<code>retrieve_assembly_data(accession, download_dir, max_increment=0, max_redo=3)</code>","text":"<p>Establishes an FTP connection and downloads a predefined subset of assembly data files from either INSDC or RefSeq.</p> <p>Parameters:</p> Name Type Description Default <code>accession</code> <code>str</code> <p>Genome assembly accession.</p> required <code>download_dir</code> <code>PathLike</code> <p>Path to where to download FTP files.</p> required <code>max_increment</code> <code>int</code> <p>If you want to allow assembly versions.</p> <code>0</code> <code>max_redo</code> <code>int</code> <p>Maximum FTP connection retry attempts.</p> <code>3</code> <p>Raises:</p> Type Description <code>FileDownloadError</code> <p>If no files are downloaded or if any does not match its MD5 checksum.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/download.py</code> <pre><code>def retrieve_assembly_data(\n    accession: str,\n    download_dir: PathLike,\n    max_increment: int = 0,\n    max_redo: int = 3,\n) -&gt; None:\n    \"\"\"Establishes an FTP connection and downloads a predefined subset of assembly data files from either\n    INSDC or RefSeq.\n\n    Args:\n        accession: Genome assembly accession.\n        download_dir: Path to where to download FTP files.\n        max_increment: If you want to allow assembly versions.\n        max_redo: Maximum FTP connection retry attempts.\n\n    Raises:\n        FileDownloadError: If no files are downloaded or if any does not match its MD5 checksum.\n    \"\"\"\n    download_dir = Path(download_dir)\n\n    # Set and create dedicated dir for download\n    download_dir.mkdir(parents=True, exist_ok=True)\n\n    # Download if files don't exist or fail checksum\n    if not md5_files(download_dir, None):\n        logging.info(\" Download the files\")\n\n        for increment in range(0, max_increment + 1):\n            if increment &gt; 0:\n                logging.info(f\" Increment accession version once from {accession}\")\n                version = int(accession[-1])\n                version += 1\n                accession = accession[:-1] + str(version)\n                download_dir.mkdir(parents=True, exist_ok=True)\n            ftp_url = \"ftp.ncbi.nlm.nih.gov\"\n            ftp_instance = FTP()\n            open_ftp_connection = establish_ftp(ftp_instance, ftp_url, accession)\n            download_files(open_ftp_connection, accession, download_dir, max_redo)\n\n        if not md5_files(download_dir, None):\n            raise FileDownloadError(\"Failed md5sum of downloaded files\")\n\n    # Select specific files and give them a name\n    files = get_files_selection(download_dir)\n\n    if len(files) == 0:\n        raise FileDownloadError(\"No file downloaded\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/","title":"status","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status","title":"<code>ensembl.io.genomio.assembly.status</code>","text":"<p>Obtain and record the assembly status for a set of INSDC accession(s) using NCBI's datasets CLI tool.</p>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.DATASETS_SINGULARITY","title":"<code>DATASETS_SINGULARITY = {'datasets_version_url': 'docker://ensemblorg/datasets-cli:latest'}</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure","title":"<code>ReportStructure</code>  <code>dataclass</code>","text":"<p>Stores key report meta information.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>@dataclass\nclass ReportStructure:\n    \"\"\"Stores key report meta information.\"\"\"\n\n    species_name: str = \"\"\n    taxon_id: int = 0\n    strain: str = \"NA\"\n    assembly_name: str = \"\"\n    assembly_type: str = \"\"\n    accession: str = \"\"\n    paired_assembly: str = \"NA\"\n    last_updated: str = \"\"\n    assembly_status: str = \"NA\"\n    assembly_notes: str = \"NA\"\n\n    def to_dict(self) -&gt; dict[str, str]:\n        \"\"\"Returns a dictionary representation of this object.\"\"\"\n        return {\n            \"Species Name\": self.species_name,\n            \"Taxon ID\": str(self.taxon_id),\n            \"Isolate/Strain\": self.strain,\n            \"Asm name\": self.assembly_name,\n            \"Assembly type\": self.assembly_type,\n            \"Asm accession\": self.accession,\n            \"Paired assembly\": self.paired_assembly,\n            \"Asm last updated\": self.last_updated,\n            \"Asm status\": self.assembly_status,\n            \"Asm notes\": self.assembly_notes,\n        }\n\n    def header(self) -&gt; list[str]:\n        \"\"\"Returns the dictionary keys matching each of the properties of the report.\"\"\"\n        return list(self.to_dict().keys())\n\n    def values(self) -&gt; list[str]:\n        \"\"\"Returns the values of each of the properties of the report.\"\"\"\n        return list(self.to_dict().values())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.accession","title":"<code>accession = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.assembly_name","title":"<code>assembly_name = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.assembly_notes","title":"<code>assembly_notes = 'NA'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.assembly_status","title":"<code>assembly_status = 'NA'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.assembly_type","title":"<code>assembly_type = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.last_updated","title":"<code>last_updated = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.paired_assembly","title":"<code>paired_assembly = 'NA'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.species_name","title":"<code>species_name = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.strain","title":"<code>strain = 'NA'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.taxon_id","title":"<code>taxon_id = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.header","title":"<code>header()</code>","text":"<p>Returns the dictionary keys matching each of the properties of the report.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def header(self) -&gt; list[str]:\n    \"\"\"Returns the dictionary keys matching each of the properties of the report.\"\"\"\n    return list(self.to_dict().keys())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.to_dict","title":"<code>to_dict()</code>","text":"<p>Returns a dictionary representation of this object.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def to_dict(self) -&gt; dict[str, str]:\n    \"\"\"Returns a dictionary representation of this object.\"\"\"\n    return {\n        \"Species Name\": self.species_name,\n        \"Taxon ID\": str(self.taxon_id),\n        \"Isolate/Strain\": self.strain,\n        \"Asm name\": self.assembly_name,\n        \"Assembly type\": self.assembly_type,\n        \"Asm accession\": self.accession,\n        \"Paired assembly\": self.paired_assembly,\n        \"Asm last updated\": self.last_updated,\n        \"Asm status\": self.assembly_status,\n        \"Asm notes\": self.assembly_notes,\n    }\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.ReportStructure.values","title":"<code>values()</code>","text":"<p>Returns the values of each of the properties of the report.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def values(self) -&gt; list[str]:\n    \"\"\"Returns the values of each of the properties of the report.\"\"\"\n    return list(self.to_dict().values())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.UnsupportedFormatError","title":"<code>UnsupportedFormatError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a string does not have the expected format.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>class UnsupportedFormatError(Exception):\n    \"\"\"When a string does not have the expected format.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.extract_assembly_metadata","title":"<code>extract_assembly_metadata(assembly_reports)</code>","text":"<p>Parse assembly reports and extract specific key information on status and related fields.</p> <p>Parameters:</p> Name Type Description Default <code>assembly_reports</code> <code>dict[str, dict]</code> <p>Key value pair of source name &lt;&gt; assembly report.</p> required <p>Returns:</p> Type Description <code>dict[str, ReportStructure]</code> <p>Parsed assembly report meta (source, meta).</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def extract_assembly_metadata(assembly_reports: dict[str, dict]) -&gt; dict[str, ReportStructure]:\n    \"\"\"Parse assembly reports and extract specific key information on status and related fields.\n\n    Args:\n        assembly_reports: Key value pair of source name &lt;&gt; assembly report.\n\n    Returns:\n        Parsed assembly report meta (source, meta).\n    \"\"\"\n    parsed_meta = {}\n\n    for source, asm_report in assembly_reports.items():\n        asm_meta_info = ReportStructure()\n\n        # Mandatory meta key parsing:\n        asm_meta_info.accession = asm_report[\"accession\"]\n        asm_meta_info.assembly_name = asm_report[\"assembly_info\"][\"assembly_name\"]\n        asm_meta_info.assembly_type = asm_report[\"assembly_info\"][\"assembly_type\"]\n        asm_meta_info.assembly_status = asm_report[\"assembly_info\"][\"assembly_status\"]\n        asm_meta_info.species_name = asm_report[\"organism\"][\"organism_name\"]\n        asm_meta_info.taxon_id = int(asm_report[\"organism\"][\"tax_id\"])\n\n        ## Non-mandatory meta key parsing:\n        assembly_meta_keys = asm_report[\"assembly_info\"].keys()\n        organism_keys = asm_report[\"organism\"].keys()\n\n        # check for genome_notes:\n        if \"genome_notes\" in assembly_meta_keys:\n            complete_notes = \", \".join(asm_report[\"assembly_info\"][\"genome_notes\"])\n            asm_meta_info.assembly_notes = complete_notes\n\n        # check for biosample:\n        if \"biosample\" in assembly_meta_keys:\n            asm_meta_info.last_updated = asm_report[\"assembly_info\"][\"biosample\"][\"last_updated\"]\n\n        # check for paired assembly:\n        if \"paired_assembly\" in assembly_meta_keys:\n            asm_meta_info.paired_assembly = asm_report[\"assembly_info\"][\"paired_assembly\"][\"accession\"]\n\n        # check for isolate/strain type:\n        if \"infraspecific_names\" in organism_keys:\n            organism_type_keys = asm_report[\"organism\"][\"infraspecific_names\"].keys()\n            if \"isolate\" in organism_type_keys:\n                asm_meta_info.strain = asm_report[\"organism\"][\"infraspecific_names\"][\"isolate\"]\n            elif \"strain\" in organism_type_keys:\n                asm_meta_info.strain = asm_report[\"organism\"][\"infraspecific_names\"][\"strain\"]\n\n        parsed_meta[source] = asm_meta_info\n\n    return parsed_meta\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.fetch_accessions_from_core_dbs","title":"<code>fetch_accessions_from_core_dbs(src_file, server_url)</code>","text":"<p>Obtain the associated INSDC accession given a set of core database names and a database server URL.</p> <p>The accession information is obtained from the <code>meta</code> table's meta key <code>assembly.accession</code>.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>StrPath</code> <p>File path with list of core database names.</p> required <code>server_url</code> <code>URL</code> <p>Database server URL.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dict of core database names (key) and their corresponding INSDC assembly accession (value).</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def fetch_accessions_from_core_dbs(src_file: StrPath, server_url: URL) -&gt; dict[str, str]:\n    \"\"\"Obtain the associated INSDC accession given a set of core database names and a database server URL.\n\n    The accession information is obtained from the `meta` table's meta key `assembly.accession`.\n\n    Args:\n        src_file: File path with list of core database names.\n        server_url: Database server URL.\n\n    Returns:\n        Dict of core database names (key) and their corresponding INSDC assembly accession (value).\n    \"\"\"\n\n    core_accn_meta = {}\n    database_count = 0\n    count_accn_found = 0\n\n    with Path(src_file).open(\"r\") as fin:\n        for line in fin.readlines():\n            core_db = line.strip()\n            database_count += 1\n            db_connection_url = server_url.set(database=core_db)\n            db_connection = DBConnection(db_connection_url)\n            with db_connection.begin() as conn:\n                query_result = conn.execute(\n                    text('SELECT meta_value FROM meta WHERE meta_key = \"assembly.accession\";')\n                ).fetchall()\n\n            if not query_result:\n                logging.warning(f\"No accessions found in core: {core_db}\")\n            elif len(query_result) == 1:\n                count_accn_found += 1\n                asm_accession = query_result.pop()[0]\n                logging.info(f\"{core_db} -&gt; assembly.accession[{asm_accession}]\")\n                core_accn_meta[core_db] = asm_accession\n            else:\n                logging.warning(f\"Core {core_db} has {len(query_result)} assembly.accessions\")\n\n    logging.info(\n        f\"From initial input core databases ({database_count}), obtained ({count_accn_found}) accessions\"\n    )\n\n    return core_accn_meta\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.fetch_datasets_reports","title":"<code>fetch_datasets_reports(sif_image, assembly_accessions, download_directory, batch_size)</code>","text":"<p>Obtain assembly reports in JSON format for each assembly accession via <code>datasets</code> CLI.</p> <p>Parameters:</p> Name Type Description Default <code>sif_image</code> <code>Client</code> <p>Instance of <code>Client.loaded()</code> singularity image.</p> required <code>assembly_accessions</code> <code>dict[str, str]</code> <p>Dictionary of accession source &lt;&gt; assembly accessions pairs.</p> required <code>download_directory</code> <code>StrPath</code> <p>Directory path to store assembly report JSON files.</p> required <code>batch_size</code> <code>int</code> <p>Number of assembly accessions to batch submit to <code>datasets</code>.</p> required <p>Returns:</p> Type Description <code>dict[str, dict]</code> <p>Dictionary of accession source and its associated assembly report.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If result returned by <code>datasets</code> is not a string.</p> <code>RuntimeError</code> <p>If there was an error raised by <code>datasets</code>.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def fetch_datasets_reports(\n    sif_image: Client, assembly_accessions: dict[str, str], download_directory: StrPath, batch_size: int\n) -&gt; dict[str, dict]:\n    \"\"\"Obtain assembly reports in JSON format for each assembly accession via `datasets` CLI.\n\n    Args:\n        sif_image: Instance of `Client.loaded()` singularity image.\n        assembly_accessions: Dictionary of accession source &lt;&gt; assembly accessions pairs.\n        download_directory: Directory path to store assembly report JSON files.\n        batch_size: Number of assembly accessions to batch submit to `datasets`.\n\n    Returns:\n        Dictionary of accession source and its associated assembly report.\n\n    Raises:\n        ValueError: If result returned by `datasets` is not a string.\n        RuntimeError: If there was an error raised by `datasets`.\n\n    \"\"\"\n    master_accn_list = list(assembly_accessions.values())\n    combined_asm_reports = {}\n\n    # Setting the number of combined accessions to query in a single call to datasets\n    list_split = list(range(0, len(master_accn_list), batch_size))\n    accn_subsample = [master_accn_list[ind : ind + batch_size] for ind in list_split]\n\n    datasets_command = [\"datasets\", \"summary\", \"genome\", \"accession\"]\n    for accessions in accn_subsample:\n        # Make call to singularity datasets providing a multi-accession query\n        client_return = Client.execute(\n            image=sif_image, command=datasets_command + accessions, return_result=True, quiet=True\n        )\n        raw_result = client_return[\"message\"]\n\n        ## Test what result we have obtained following execution of sif image and accession value\n        # Returned a list, i.e. datasets returned a result to client.execute\n        # Returned a str, i.e. no datasets result obtained exited with fatal error\n        if isinstance(raw_result, list):\n            result = raw_result[0]\n        else:\n            result = raw_result\n        if not isinstance(result, str):\n            raise ValueError(\"Result obtained from datasets is not a string\")\n        if re.search(\"^FATAL\", result):\n            raise RuntimeError(f\"Singularity image execution failed! -&gt; '{result.strip()}'\")\n\n        tmp_asm_dict = json.loads(result)\n        if not tmp_asm_dict[\"total_count\"]:\n            logging.warning(f\"No assembly report found for accession(s) {accessions}\")\n            continue\n\n        logging.info(f\"Assembly report obtained for accession(s) {accessions}\")\n        batch_reports_json = tmp_asm_dict[\"reports\"]\n        for assembly_report in batch_reports_json:\n            accession = assembly_report[\"accession\"]\n            asm_json_outfile = Path(download_directory, f\"{accession}.asm_report.json\")\n            print_json(asm_json_outfile, assembly_report)\n            # Save assembly report into source key&lt;&gt;report dict\n            for src_key, accession_core in assembly_accessions.items():\n                if accession == accession_core:\n                    combined_asm_reports[src_key] = assembly_report\n\n    return combined_asm_reports\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.generate_report_tsv","title":"<code>generate_report_tsv(parsed_asm_reports, query_type, output_directory=Path(), outfile_name='AssemblyStatusReport')</code>","text":"<p>Generate and write the assembly report to a TSV file.</p> <p>Parameters:</p> Name Type Description Default <code>parsed_asm_reports</code> <code>dict[str, ReportStructure]</code> <p>Parsed assembly report meta.</p> required <code>query_type</code> <code>str</code> <p>Type of query (either core databases or accessions).</p> required <code>output_directory</code> <code>StrPath</code> <p>Directory to store report TSV file.</p> <code>Path()</code> <code>outfile_name</code> <code>str</code> <p>Name to give to the output TSV file.</p> <code>'AssemblyStatusReport'</code> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def generate_report_tsv(\n    parsed_asm_reports: dict[str, ReportStructure],\n    query_type: str,\n    output_directory: StrPath = Path(),\n    outfile_name: str = \"AssemblyStatusReport\",\n) -&gt; None:\n    \"\"\"Generate and write the assembly report to a TSV file.\n\n    Args:\n        parsed_asm_reports: Parsed assembly report meta.\n        query_type: Type of query (either core databases or accessions).\n        output_directory: Directory to store report TSV file.\n        outfile_name: Name to give to the output TSV file.\n    \"\"\"\n    tsv_outfile = Path(output_directory, f\"{outfile_name}.tsv\")\n\n    header_list = next(iter(parsed_asm_reports.values())).header()\n    header_list = [query_type.capitalize().replace(\"_\", \" \")] + header_list\n\n    with open(tsv_outfile, \"w+\") as tsv_out:\n        writer = csv.writer(tsv_out, delimiter=\"\\t\", lineterminator=\"\\n\")\n        writer.writerow(header_list)\n        for core, report_meta in parsed_asm_reports.items():\n            final_asm_report = [core] + report_meta.values()\n            writer.writerow(final_asm_report)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.get_assembly_accessions","title":"<code>get_assembly_accessions(src_file)</code>","text":"<p>Returns the list of assembly accessions found in the provided file.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>StrPath</code> <p>Path to file with one line per INSDC assembly accession.</p> required <p>Raises:</p> Type Description <code>UnsupportedFormatError</code> <p>If an accession does not match the INSDC assembly accession format.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def get_assembly_accessions(src_file: StrPath) -&gt; list[str]:\n    \"\"\"Returns the list of assembly accessions found in the provided file.\n\n    Args:\n        src_file: Path to file with one line per INSDC assembly accession.\n\n    Raises:\n        UnsupportedFormatError: If an accession does not match the INSDC assembly accession format.\n    \"\"\"\n    query_accessions: list[str] = []\n    with Path(src_file).open(mode=\"r\") as fin:\n        for line in fin.readlines():\n            line = line.strip()\n            match = re.match(r\"^GC[AF]_[0-9]{9}\\.[1-9][0-9]*$\", line)\n            if not match:\n                raise UnsupportedFormatError(f\"Could not recognize GCA/GCF accession format: {line}\")\n            query_accessions.append(line)\n    return query_accessions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.main","title":"<code>main()</code>","text":"<p>Module's entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module's entry-point.\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    # Create parser with common arguments to be used by both subparsers\n    base_parser = ArgumentParser(add_help=False)\n    base_parser.add_argument_dst_path(\n        \"--reports_dir\",\n        default=Path(\"assembly_report_jsons\"),\n        help=\"path to folder where the assembly report JSON files is stored\",\n    )\n    base_parser.add_argument(\n        \"--assembly_report_name\",\n        metavar=\"NAME\",\n        default=\"AssemblyStatusReport\",\n        help=\"file name used for the assembly report TSV output file\",\n    )\n    base_parser.add_argument(\n        \"--datasets_version_url\",\n        type=str,\n        metavar=\"URL\",\n        help=\"datasets version, e.g. docker://ensemblorg/datasets-cli:latest\",\n    )\n    base_parser.add_argument_src_path(\n        \"--cache_dir\",\n        default=Path(os.environ.get(\"NXF_SINGULARITY_CACHEDIR\", \"\")),\n        metavar=\"SINGULARITY_CACHE\",\n        help=\"folder path to user generated singularity container housing NCBI tool 'datasets'\",\n    )\n    base_parser.add_numeric_argument(\n        \"--datasets_batch_size\",\n        type=int,\n        min_value=1,\n        default=100,\n        metavar=\"BATCH_SIZE\",\n        help=\"number of accessions requested in one query to datasets\",\n    )\n    base_parser.add_log_arguments(add_log_file=True)\n    # Add subparsers with their parent being the base parser with the common arguments\n    subparsers = parser.add_subparsers(title=\"report assembly status from\", required=True, dest=\"src\")\n    # Specific arguments required when using Ensembl core database names as source\n    core_db_parser = subparsers.add_parser(\n        \"core_db\", parents=[base_parser], help=\"list of Ensembl core databases\"\n    )\n    core_db_parser.add_argument_src_path(\n        \"--input\",\n        required=True,\n        help=\"file path with list of Ensembl core database(s) to retrieve query accessions from\",\n    )\n    core_db_parser.add_server_arguments()\n    # Specific arguments required when using assembly accessions as source\n    accessions_parser = subparsers.add_parser(\n        \"accession\", parents=[base_parser], help=\"list of INSDC accessions\"\n    )\n    accessions_parser.add_argument_src_path(\n        \"--input\", required=True, help=\"file path with list of assembly INSDC query accessions\"\n    )\n\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    # Get accessions on cores list or use user accession list directly\n    if args.src == \"core_db\":\n        query_accessions = fetch_accessions_from_core_dbs(args.input, args.url)\n    else:\n        query_accessions = {x: x for x in get_assembly_accessions(args.input)}\n\n    # Parse singularity setting and define the SIF image for 'datasets'\n    datasets_image = singularity_image_setter(args.cache_dir, args.datasets_version_url)\n\n    # Datasets query implementation for one or more batched accessions\n    assembly_reports = fetch_datasets_reports(\n        datasets_image, query_accessions, args.reports_dir, args.datasets_batch_size\n    )\n\n    # Extract the key assembly report meta information for reporting status\n    key_assembly_report_meta = extract_assembly_metadata(assembly_reports)\n\n    # Produce the finalized assembly status report TSV from set of parsed 'datasets summary report'\n    generate_report_tsv(key_assembly_report_meta, args.src, args.reports_dir, args.assembly_report_name)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/assembly/status/#ensembl.io.genomio.assembly.status.singularity_image_setter","title":"<code>singularity_image_setter(sif_cache_dir, datasets_version)</code>","text":"<p>Parse ENV and User specified variables related to <code>datasets</code> singularity SIF container and define version and location of container.</p> <p>Parameters:</p> Name Type Description Default <code>sif_cache_dir</code> <code>Path | None</code> <p>Path to locate existing, or download new SIF container image.</p> required <code>datasets_version</code> <code>str | None</code> <p>URL of singularity container (custom <code>datasets</code> version if desired).</p> required <p>Returns:</p> Type Description <code>Client</code> <p><code>spython.main.client</code> instance of singularity container image housing <code>datasets</code>.</p> Source code in <code>src/python/ensembl/io/genomio/assembly/status.py</code> <pre><code>def singularity_image_setter(sif_cache_dir: Path | None, datasets_version: str | None) -&gt; Client:\n    \"\"\"Parse ENV and User specified variables related to `datasets` singularity SIF\n    container and define version and location of container.\n\n    Args:\n        sif_cache_dir: Path to locate existing, or download new SIF container image.\n        datasets_version: URL of singularity container (custom `datasets` version if desired).\n\n    Returns:\n        `spython.main.client` instance of singularity container image housing `datasets`.\n    \"\"\"\n\n    # Set singularity cache dir from user defined path or use environment\n    if sif_cache_dir and sif_cache_dir.is_dir():\n        image_dl_path = sif_cache_dir\n        logging.info(f\"Using user-defined cache_dir: '{image_dl_path}'\")\n    elif os.environ.get(\"NXF_SINGULARITY_CACHEDIR\"):\n        image_dl_path = Path(os.environ[\"NXF_SINGULARITY_CACHEDIR\"])\n        logging.info(\n            f\"Using preferred nextflow singularity cache dir 'NXF_SINGULARITY_CACHEDIR': {image_dl_path}\"\n        )\n    elif os.environ.get(\"SINGULARITY_CACHEDIR\"):\n        image_dl_path = Path(os.environ[\"SINGULARITY_CACHEDIR\"])\n        logging.info(\n            f\"Using the default singularity installation cache dir 'SINGULARITY_CACHEDIR': {image_dl_path}\"\n        )\n    else:\n        image_dl_path = Path()\n        logging.warning(f\"Unable to set singularity cache dir properly, using CWD {image_dl_path}\")\n\n    # Set the datasets version URL\n    if datasets_version is None:\n        container_url = DATASETS_SINGULARITY[\"datasets_version_url\"]\n        logging.info(f\"Using default 'ncbi datasets' version '{container_url}'\")\n    else:\n        container_url = datasets_version\n        logging.info(f\"Using user defined 'ncbi datasets' version '{container_url}'\")\n\n    # Pull or load pre-existing 'datasets' singularity container image.\n    datasets_image = Client.pull(container_url, stream=False, pull_folder=image_dl_path, quiet=True)\n\n    return datasets_image\n</code></pre>"},{"location":"reference/ensembl/io/genomio/data/","title":"data","text":""},{"location":"reference/ensembl/io/genomio/data/#ensembl.io.genomio.data","title":"<code>ensembl.io.genomio.data</code>","text":"<p>Data files.</p>"},{"location":"reference/ensembl/io/genomio/data/external_db_map/","title":"external_db_map","text":""},{"location":"reference/ensembl/io/genomio/data/external_db_map/#ensembl.io.genomio.data.external_db_map","title":"<code>ensembl.io.genomio.data.external_db_map</code>","text":"<p>External db mapping files.</p>"},{"location":"reference/ensembl/io/genomio/data/gff3/","title":"gff3","text":""},{"location":"reference/ensembl/io/genomio/data/gff3/#ensembl.io.genomio.data.gff3","title":"<code>ensembl.io.genomio.data.gff3</code>","text":"<p>GFF3-related data files.</p>"},{"location":"reference/ensembl/io/genomio/data/schemas/","title":"schemas","text":""},{"location":"reference/ensembl/io/genomio/data/schemas/#ensembl.io.genomio.data.schemas","title":"<code>ensembl.io.genomio.data.schemas</code>","text":"<p>Schema-related data files.</p>"},{"location":"reference/ensembl/io/genomio/database/","title":"database","text":""},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database","title":"<code>ensembl.io.genomio.database</code>","text":"<p>Ensembl core database interface module.</p>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.CoreServer","title":"<code>CoreServer</code>","text":"<p>Basic interface to a MySQL server with core databases.</p> <p>Allows to get a filtered list of databases.</p> Source code in <code>src/python/ensembl/io/genomio/database/core_server.py</code> <pre><code>class CoreServer:\n    \"\"\"Basic interface to a MySQL server with core databases.\n\n    Allows to get a filtered list of databases.\n    \"\"\"\n\n    def __init__(self, server_url: URL) -&gt; None:\n        logging.debug(f\"Connect to {server_url}\")\n        self.engine = sqlalchemy.create_engine(server_url)\n\n    def get_all_core_names(self) -&gt; List[str]:\n        \"\"\"Query the server and retrieve all database names that look like Ensembl cores.\"\"\"\n\n        with self.engine.connect() as connection:\n            all_query = connection.execute(text(r\"SHOW DATABASES LIKE '%%_core_%%'\"))\n            dbs = [row[0] for row in all_query.fetchall()]\n        logging.info(f\"{len(dbs)} core databases on the server\")\n        return dbs\n\n    def get_cores(\n        self,\n        *,\n        prefix: str = \"\",\n        build: Optional[int] = None,\n        version: Optional[int] = None,\n        dbname_re: str = \"\",\n        db_list: Optional[List[str]] = None,\n    ) -&gt; List[str]:\n        \"\"\"Returns a list of core databases, filtered if requested.\n\n        Args:\n            prefix: Filter by prefix (no \"_\" is added automatically).\n            build: Filter by VEuPathDB build number.\n            version: Filter by Ensembl version.\n            dbname_re: Filter by dbname regular expression.\n            db_list: Explicit list of database names.\n        \"\"\"\n        dbs = []\n\n        dbs = self.get_all_core_names()\n\n        # Check if there are databases returned from query to host\n        if not dbs:\n            logging.warning(\"No databases returned from query\")\n\n        if db_list:\n            logging.debug(f\"Filter with db list: {db_list}\")\n            dbs = [db for db in dbs if db in db_list]\n        if prefix:\n            dbs = [db for db in dbs if db.startswith(f\"{prefix}\")]\n        if dbname_re:\n            dbname_m = re.compile(dbname_re)\n            dbs = list(filter(dbname_m.search, dbs))\n        if build is not None:\n            dbs = [db for db in dbs if re.search(rf\"_core_{build}_\\d+_\\d+$\", db)]\n        if version is not None:\n            dbs = [db for db in dbs if re.search(rf\"_core_\\d+_{version}_\\d+$\", db)]\n\n        logging.info(f\"{len(dbs)} core databases remain after filtering\")\n\n        return dbs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.CoreServer.engine","title":"<code>engine = sqlalchemy.create_engine(server_url)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.CoreServer.get_all_core_names","title":"<code>get_all_core_names()</code>","text":"<p>Query the server and retrieve all database names that look like Ensembl cores.</p> Source code in <code>src/python/ensembl/io/genomio/database/core_server.py</code> <pre><code>def get_all_core_names(self) -&gt; List[str]:\n    \"\"\"Query the server and retrieve all database names that look like Ensembl cores.\"\"\"\n\n    with self.engine.connect() as connection:\n        all_query = connection.execute(text(r\"SHOW DATABASES LIKE '%%_core_%%'\"))\n        dbs = [row[0] for row in all_query.fetchall()]\n    logging.info(f\"{len(dbs)} core databases on the server\")\n    return dbs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.CoreServer.get_cores","title":"<code>get_cores(*, prefix='', build=None, version=None, dbname_re='', db_list=None)</code>","text":"<p>Returns a list of core databases, filtered if requested.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Filter by prefix (no \"_\" is added automatically).</p> <code>''</code> <code>build</code> <code>Optional[int]</code> <p>Filter by VEuPathDB build number.</p> <code>None</code> <code>version</code> <code>Optional[int]</code> <p>Filter by Ensembl version.</p> <code>None</code> <code>dbname_re</code> <code>str</code> <p>Filter by dbname regular expression.</p> <code>''</code> <code>db_list</code> <code>Optional[List[str]]</code> <p>Explicit list of database names.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/database/core_server.py</code> <pre><code>def get_cores(\n    self,\n    *,\n    prefix: str = \"\",\n    build: Optional[int] = None,\n    version: Optional[int] = None,\n    dbname_re: str = \"\",\n    db_list: Optional[List[str]] = None,\n) -&gt; List[str]:\n    \"\"\"Returns a list of core databases, filtered if requested.\n\n    Args:\n        prefix: Filter by prefix (no \"_\" is added automatically).\n        build: Filter by VEuPathDB build number.\n        version: Filter by Ensembl version.\n        dbname_re: Filter by dbname regular expression.\n        db_list: Explicit list of database names.\n    \"\"\"\n    dbs = []\n\n    dbs = self.get_all_core_names()\n\n    # Check if there are databases returned from query to host\n    if not dbs:\n        logging.warning(\"No databases returned from query\")\n\n    if db_list:\n        logging.debug(f\"Filter with db list: {db_list}\")\n        dbs = [db for db in dbs if db in db_list]\n    if prefix:\n        dbs = [db for db in dbs if db.startswith(f\"{prefix}\")]\n    if dbname_re:\n        dbname_m = re.compile(dbname_re)\n        dbs = list(filter(dbname_m.search, dbs))\n    if build is not None:\n        dbs = [db for db in dbs if re.search(rf\"_core_{build}_\\d+_\\d+$\", db)]\n    if version is not None:\n        dbs = [db for db in dbs if re.search(rf\"_core_\\d+_{version}_\\d+$\", db)]\n\n    logging.info(f\"{len(dbs)} core databases remain after filtering\")\n\n    return dbs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.DBConnectionLite","title":"<code>DBConnectionLite</code>","text":"<p>               Bases: <code>DBConnection</code></p> <p>Extension to get metadata directly from a database, assuming it has a metadata table.</p> Source code in <code>src/python/ensembl/io/genomio/database/dbconnection_lite.py</code> <pre><code>class DBConnectionLite(DBConnection):\n    \"\"\"Extension to get metadata directly from a database, assuming it has a metadata table.\"\"\"\n\n    def __init__(self, url: StrURL, reflect: bool = False, **kwargs: Any) -&gt; None:\n        super().__init__(url, reflect, **kwargs)\n        self._metadata: Dict[str, List] = {}\n\n    def get_metadata(self) -&gt; Dict[str, List]:\n        \"\"\"Retrieves all metadata from the `meta` table in the database.\n\n        Returns:\n            A dict of with key meta_key, and value=List of meta_value.\n\n        \"\"\"\n        self._load_metadata()\n        return self._metadata\n\n    def _load_metadata(self) -&gt; None:\n        \"\"\"Caches the metadata values.\"\"\"\n\n        if self._metadata:\n            return\n\n        with Session(self._engine) as session:\n            meta_stmt = select(Meta)\n\n            for meta_row in session.scalars(meta_stmt).unique().all():\n                meta_key = meta_row.meta_key\n                meta_value = meta_row.meta_value\n                if meta_key in self._metadata:\n                    self._metadata[meta_key].append(meta_value)\n                else:\n                    self._metadata[meta_key] = [meta_value]\n\n    def get_meta_value(self, meta_key: str) -&gt; Optional[str]:\n        \"\"\"Returns the first meta_value for a given meta_key.\"\"\"\n\n        self._load_metadata()\n        try:\n            return self._metadata[meta_key][0]\n        except KeyError:\n            logging.debug(f\"No meta_key {meta_key}\")\n            return None\n\n    def get_project_release(self) -&gt; str:\n        \"\"\"Returns the project release number from the database name. Returns empty string if not found.\"\"\"\n\n        match = re.search(_DB_PATTERN_RELEASE, self.db_name)\n        if match:\n            return match.group(1)\n        return \"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.DBConnectionLite.get_meta_value","title":"<code>get_meta_value(meta_key)</code>","text":"<p>Returns the first meta_value for a given meta_key.</p> Source code in <code>src/python/ensembl/io/genomio/database/dbconnection_lite.py</code> <pre><code>def get_meta_value(self, meta_key: str) -&gt; Optional[str]:\n    \"\"\"Returns the first meta_value for a given meta_key.\"\"\"\n\n    self._load_metadata()\n    try:\n        return self._metadata[meta_key][0]\n    except KeyError:\n        logging.debug(f\"No meta_key {meta_key}\")\n        return None\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.DBConnectionLite.get_metadata","title":"<code>get_metadata()</code>","text":"<p>Retrieves all metadata from the <code>meta</code> table in the database.</p> <p>Returns:</p> Type Description <code>Dict[str, List]</code> <p>A dict of with key meta_key, and value=List of meta_value.</p> Source code in <code>src/python/ensembl/io/genomio/database/dbconnection_lite.py</code> <pre><code>def get_metadata(self) -&gt; Dict[str, List]:\n    \"\"\"Retrieves all metadata from the `meta` table in the database.\n\n    Returns:\n        A dict of with key meta_key, and value=List of meta_value.\n\n    \"\"\"\n    self._load_metadata()\n    return self._metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.DBConnectionLite.get_project_release","title":"<code>get_project_release()</code>","text":"<p>Returns the project release number from the database name. Returns empty string if not found.</p> Source code in <code>src/python/ensembl/io/genomio/database/dbconnection_lite.py</code> <pre><code>def get_project_release(self) -&gt; str:\n    \"\"\"Returns the project release number from the database name. Returns empty string if not found.\"\"\"\n\n    match = re.search(_DB_PATTERN_RELEASE, self.db_name)\n    if match:\n        return match.group(1)\n    return \"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.format_db_data","title":"<code>format_db_data(server_url, dbs, brc_mode=False)</code>","text":"<p>Returns a metadata list from the given databases on a server.</p> <p>Parameters:</p> Name Type Description Default <code>server_url</code> <code>URL</code> <p>Server URL where all the databases are hosted.</p> required <code>dbs</code> <code>list[str]</code> <p>List of database names.</p> required <code>brc_mode</code> <code>bool</code> <p>If true, assign <code>BRC4.organism_abbrev</code> as the species, and <code>BRC4.component</code> as the division. Otherwise, the species will be <code>species.production_name</code> and the division will be <code>species.division</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of dictionaries with 3 keys: \"database\", \"species\" and \"division\".</p> Source code in <code>src/python/ensembl/io/genomio/database/factory.py</code> <pre><code>def format_db_data(server_url: URL, dbs: list[str], brc_mode: bool = False) -&gt; list[dict]:\n    \"\"\"Returns a metadata list from the given databases on a server.\n\n    Args:\n        server_url: Server URL where all the databases are hosted.\n        dbs: List of database names.\n        brc_mode: If true, assign ``BRC4.organism_abbrev`` as the species, and ``BRC4.component`` as the\n            division. Otherwise, the species will be ``species.production_name`` and the division will be\n            ``species.division``.\n\n    Returns:\n        List of dictionaries with 3 keys: \"database\", \"species\" and \"division\".\n    \"\"\"\n    databases_data = []\n    for db_name in dbs:\n        logging.debug(f\"Get metadata for {db_name}\")\n        db_url = server_url.set(database=db_name)\n        core_db = DBConnectionLite(db_url)\n\n        prod_name = core_db.get_meta_value(\"species.production_name\")\n        species = prod_name\n        division = core_db.get_meta_value(\"species.division\")\n        accession = core_db.get_meta_value(\"assembly.accession\")\n        project_release = core_db.get_project_release()\n\n        if brc_mode:\n            brc_organism = core_db.get_meta_value(\"BRC4.organism_abbrev\")\n            brc_component = core_db.get_meta_value(\"BRC4.component\")\n            if brc_organism is not None:\n                species = brc_organism\n            if brc_component is not None:\n                division = brc_component\n\n        if not division:\n            division = \"all\"\n\n        server_data = {\n            \"host\": db_url.host,\n            \"user\": db_url.username,\n            \"port\": db_url.port,\n            \"password\": db_url.password,\n            \"database\": db_url.database,\n        }\n        db_data = {\n            \"server\": server_data,\n            \"production_name\": prod_name,\n            \"species\": species,\n            \"division\": division,\n            \"accession\": accession,\n            \"release\": project_release,\n        }\n\n        databases_data.append(db_data)\n    return databases_data\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.get_core_dbs_metadata","title":"<code>get_core_dbs_metadata(server_url, *, prefix='', build=None, version=None, db_regex='', db_list=None, brc_mode=False)</code>","text":"<p>Returns all the metadata fetched for the selected core databases.</p> <p>Parameters:</p> Name Type Description Default <code>server_url</code> <code>URL</code> <p>Server URL where the core databases are stored.</p> required <code>prefix</code> <code>str</code> <p>Filter by prefix (no \"_\" is added automatically).</p> <code>''</code> <code>build</code> <code>int | None</code> <p>Filter by VEuPathDB build number.</p> <code>None</code> <code>version</code> <code>int | None</code> <p>Filter by Ensembl version.</p> <code>None</code> <code>db_regex</code> <code>str</code> <p>Filter by dbname regular expression.</p> <code>''</code> <code>db_list</code> <code>Path | None</code> <p>Explicit list of database names.</p> <code>None</code> <code>brc_mode</code> <code>bool</code> <p>Enable BRC mode.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of dictionaries with 3 keys: \"database\", \"species\" and \"division\".</p> Source code in <code>src/python/ensembl/io/genomio/database/factory.py</code> <pre><code>def get_core_dbs_metadata(\n    server_url: URL,\n    *,\n    prefix: str = \"\",\n    build: int | None = None,\n    version: int | None = None,\n    db_regex: str = \"\",\n    db_list: Path | None = None,\n    brc_mode: bool = False,\n) -&gt; list[dict]:\n    \"\"\"Returns all the metadata fetched for the selected core databases.\n\n    Args:\n        server_url: Server URL where the core databases are stored.\n        prefix: Filter by prefix (no \"_\" is added automatically).\n        build: Filter by VEuPathDB build number.\n        version: Filter by Ensembl version.\n        db_regex: Filter by dbname regular expression.\n        db_list: Explicit list of database names.\n        brc_mode: Enable BRC mode.\n\n    Returns:\n        List of dictionaries with 3 keys: \"database\", \"species\" and \"division\".\n    \"\"\"\n    db_list_file = None\n    if db_list:\n        with db_list.open(\"r\") as infile_fh:\n            db_list_file = [line.strip() for line in infile_fh]\n    # Get all database names\n    server = CoreServer(server_url)\n    logging.debug(\"Fetching databases...\")\n    databases = server.get_cores(\n        prefix=prefix, build=build, version=version, dbname_re=db_regex, db_list=db_list_file\n    )\n    logging.info(f\"Got {len(databases)} databases\")\n    logging.debug(\"\\n\".join(databases))\n    return format_db_data(server_url, databases, brc_mode)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/#ensembl.io.genomio.database.get_meta_values","title":"<code>get_meta_values(db_url, meta_keys)</code>","text":"<p>Returns a set of meta values based on set of 1 or more input DB meta_keys.</p> <p>Parameters:</p> Name Type Description Default <code>db_url</code> <code>URL</code> <p>Target core database URL.</p> required <code>meta_keys</code> <code>StrPath | list[str]</code> <p>File path with one meta key per line or list of meta keys.</p> required Source code in <code>src/python/ensembl/io/genomio/database/meta_getter.py</code> <pre><code>def get_meta_values(db_url: URL, meta_keys: StrPath | list[str]) -&gt; dict[str, str]:\n    \"\"\"Returns a set of meta values based on set of 1 or more input DB meta_keys.\n\n    Args:\n        db_url: Target core database URL.\n        meta_keys: File path with one meta key per line or list of meta keys.\n\n    \"\"\"\n    db_name = db_url.database\n    core_db = DBConnectionLite(db_url)\n    query_meta_keys = []\n    unpopulated_meta_keys = []\n    meta_values_located = {}\n    input_keys_count = 0\n    meta_populated = False\n\n    # Check input type and populated query list\n    if isinstance(meta_keys, PosixPath):\n        with Path(meta_keys).open(mode=\"r\", encoding=\"UTF-8\") as fh:\n            for line in fh.readlines():\n                meta_key = line.strip()\n                query_meta_keys.append(meta_key)\n    elif isinstance(meta_keys, list):\n        query_meta_keys = meta_keys\n\n    # Loop over input meta_key(s) and query DB\n    for meta_key in query_meta_keys:\n        input_keys_count += 1\n        meta_value = core_db.get_meta_value(f\"{meta_key}\")\n\n        if meta_value is not None:\n            meta_values_located[f\"{meta_key}\"] = meta_value\n        else:\n            unpopulated_meta_keys.append(f\"{meta_key}\")\n            logging.info(f\"Meta query returned no entry on meta_key: '{meta_key}'\")\n\n    # Now assess what meta info was recovered and dump to JSON\n    total_queries_located = len(meta_values_located)\n    if total_queries_located &gt;= 1:\n        meta_populated = True\n        if total_queries_located &lt; input_keys_count:\n            logging.info(f\"Missing meta_key(s)-&gt; {unpopulated_meta_keys}\")\n    else:\n        logging.warning(\"Zero input query meta_keys present/populated.\")\n\n    if meta_populated:\n        meta_values_located[\"database_name\"] = f\"{db_name}\"\n        print(json.dumps(meta_values_located, sort_keys=True, indent=2))\n        return meta_values_located\n    return {}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/core_server/","title":"core_server","text":""},{"location":"reference/ensembl/io/genomio/database/core_server/#ensembl.io.genomio.database.core_server","title":"<code>ensembl.io.genomio.database.core_server</code>","text":"<p>Interface to a Mysql server with core databases.</p>"},{"location":"reference/ensembl/io/genomio/database/core_server/#ensembl.io.genomio.database.core_server.CoreServer","title":"<code>CoreServer</code>","text":"<p>Basic interface to a MySQL server with core databases.</p> <p>Allows to get a filtered list of databases.</p> Source code in <code>src/python/ensembl/io/genomio/database/core_server.py</code> <pre><code>class CoreServer:\n    \"\"\"Basic interface to a MySQL server with core databases.\n\n    Allows to get a filtered list of databases.\n    \"\"\"\n\n    def __init__(self, server_url: URL) -&gt; None:\n        logging.debug(f\"Connect to {server_url}\")\n        self.engine = sqlalchemy.create_engine(server_url)\n\n    def get_all_core_names(self) -&gt; List[str]:\n        \"\"\"Query the server and retrieve all database names that look like Ensembl cores.\"\"\"\n\n        with self.engine.connect() as connection:\n            all_query = connection.execute(text(r\"SHOW DATABASES LIKE '%%_core_%%'\"))\n            dbs = [row[0] for row in all_query.fetchall()]\n        logging.info(f\"{len(dbs)} core databases on the server\")\n        return dbs\n\n    def get_cores(\n        self,\n        *,\n        prefix: str = \"\",\n        build: Optional[int] = None,\n        version: Optional[int] = None,\n        dbname_re: str = \"\",\n        db_list: Optional[List[str]] = None,\n    ) -&gt; List[str]:\n        \"\"\"Returns a list of core databases, filtered if requested.\n\n        Args:\n            prefix: Filter by prefix (no \"_\" is added automatically).\n            build: Filter by VEuPathDB build number.\n            version: Filter by Ensembl version.\n            dbname_re: Filter by dbname regular expression.\n            db_list: Explicit list of database names.\n        \"\"\"\n        dbs = []\n\n        dbs = self.get_all_core_names()\n\n        # Check if there are databases returned from query to host\n        if not dbs:\n            logging.warning(\"No databases returned from query\")\n\n        if db_list:\n            logging.debug(f\"Filter with db list: {db_list}\")\n            dbs = [db for db in dbs if db in db_list]\n        if prefix:\n            dbs = [db for db in dbs if db.startswith(f\"{prefix}\")]\n        if dbname_re:\n            dbname_m = re.compile(dbname_re)\n            dbs = list(filter(dbname_m.search, dbs))\n        if build is not None:\n            dbs = [db for db in dbs if re.search(rf\"_core_{build}_\\d+_\\d+$\", db)]\n        if version is not None:\n            dbs = [db for db in dbs if re.search(rf\"_core_\\d+_{version}_\\d+$\", db)]\n\n        logging.info(f\"{len(dbs)} core databases remain after filtering\")\n\n        return dbs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/core_server/#ensembl.io.genomio.database.core_server.CoreServer.engine","title":"<code>engine = sqlalchemy.create_engine(server_url)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/database/core_server/#ensembl.io.genomio.database.core_server.CoreServer.get_all_core_names","title":"<code>get_all_core_names()</code>","text":"<p>Query the server and retrieve all database names that look like Ensembl cores.</p> Source code in <code>src/python/ensembl/io/genomio/database/core_server.py</code> <pre><code>def get_all_core_names(self) -&gt; List[str]:\n    \"\"\"Query the server and retrieve all database names that look like Ensembl cores.\"\"\"\n\n    with self.engine.connect() as connection:\n        all_query = connection.execute(text(r\"SHOW DATABASES LIKE '%%_core_%%'\"))\n        dbs = [row[0] for row in all_query.fetchall()]\n    logging.info(f\"{len(dbs)} core databases on the server\")\n    return dbs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/core_server/#ensembl.io.genomio.database.core_server.CoreServer.get_cores","title":"<code>get_cores(*, prefix='', build=None, version=None, dbname_re='', db_list=None)</code>","text":"<p>Returns a list of core databases, filtered if requested.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Filter by prefix (no \"_\" is added automatically).</p> <code>''</code> <code>build</code> <code>Optional[int]</code> <p>Filter by VEuPathDB build number.</p> <code>None</code> <code>version</code> <code>Optional[int]</code> <p>Filter by Ensembl version.</p> <code>None</code> <code>dbname_re</code> <code>str</code> <p>Filter by dbname regular expression.</p> <code>''</code> <code>db_list</code> <code>Optional[List[str]]</code> <p>Explicit list of database names.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/database/core_server.py</code> <pre><code>def get_cores(\n    self,\n    *,\n    prefix: str = \"\",\n    build: Optional[int] = None,\n    version: Optional[int] = None,\n    dbname_re: str = \"\",\n    db_list: Optional[List[str]] = None,\n) -&gt; List[str]:\n    \"\"\"Returns a list of core databases, filtered if requested.\n\n    Args:\n        prefix: Filter by prefix (no \"_\" is added automatically).\n        build: Filter by VEuPathDB build number.\n        version: Filter by Ensembl version.\n        dbname_re: Filter by dbname regular expression.\n        db_list: Explicit list of database names.\n    \"\"\"\n    dbs = []\n\n    dbs = self.get_all_core_names()\n\n    # Check if there are databases returned from query to host\n    if not dbs:\n        logging.warning(\"No databases returned from query\")\n\n    if db_list:\n        logging.debug(f\"Filter with db list: {db_list}\")\n        dbs = [db for db in dbs if db in db_list]\n    if prefix:\n        dbs = [db for db in dbs if db.startswith(f\"{prefix}\")]\n    if dbname_re:\n        dbname_m = re.compile(dbname_re)\n        dbs = list(filter(dbname_m.search, dbs))\n    if build is not None:\n        dbs = [db for db in dbs if re.search(rf\"_core_{build}_\\d+_\\d+$\", db)]\n    if version is not None:\n        dbs = [db for db in dbs if re.search(rf\"_core_\\d+_{version}_\\d+$\", db)]\n\n    logging.info(f\"{len(dbs)} core databases remain after filtering\")\n\n    return dbs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/dbconnection_lite/","title":"dbconnection_lite","text":""},{"location":"reference/ensembl/io/genomio/database/dbconnection_lite/#ensembl.io.genomio.database.dbconnection_lite","title":"<code>ensembl.io.genomio.database.dbconnection_lite</code>","text":"<p>Simplified Database interface to an Ensembl database, to make access to metadata easier and faster.</p>"},{"location":"reference/ensembl/io/genomio/database/dbconnection_lite/#ensembl.io.genomio.database.dbconnection_lite.DBConnectionLite","title":"<code>DBConnectionLite</code>","text":"<p>               Bases: <code>DBConnection</code></p> <p>Extension to get metadata directly from a database, assuming it has a metadata table.</p> Source code in <code>src/python/ensembl/io/genomio/database/dbconnection_lite.py</code> <pre><code>class DBConnectionLite(DBConnection):\n    \"\"\"Extension to get metadata directly from a database, assuming it has a metadata table.\"\"\"\n\n    def __init__(self, url: StrURL, reflect: bool = False, **kwargs: Any) -&gt; None:\n        super().__init__(url, reflect, **kwargs)\n        self._metadata: Dict[str, List] = {}\n\n    def get_metadata(self) -&gt; Dict[str, List]:\n        \"\"\"Retrieves all metadata from the `meta` table in the database.\n\n        Returns:\n            A dict of with key meta_key, and value=List of meta_value.\n\n        \"\"\"\n        self._load_metadata()\n        return self._metadata\n\n    def _load_metadata(self) -&gt; None:\n        \"\"\"Caches the metadata values.\"\"\"\n\n        if self._metadata:\n            return\n\n        with Session(self._engine) as session:\n            meta_stmt = select(Meta)\n\n            for meta_row in session.scalars(meta_stmt).unique().all():\n                meta_key = meta_row.meta_key\n                meta_value = meta_row.meta_value\n                if meta_key in self._metadata:\n                    self._metadata[meta_key].append(meta_value)\n                else:\n                    self._metadata[meta_key] = [meta_value]\n\n    def get_meta_value(self, meta_key: str) -&gt; Optional[str]:\n        \"\"\"Returns the first meta_value for a given meta_key.\"\"\"\n\n        self._load_metadata()\n        try:\n            return self._metadata[meta_key][0]\n        except KeyError:\n            logging.debug(f\"No meta_key {meta_key}\")\n            return None\n\n    def get_project_release(self) -&gt; str:\n        \"\"\"Returns the project release number from the database name. Returns empty string if not found.\"\"\"\n\n        match = re.search(_DB_PATTERN_RELEASE, self.db_name)\n        if match:\n            return match.group(1)\n        return \"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/dbconnection_lite/#ensembl.io.genomio.database.dbconnection_lite.DBConnectionLite.get_meta_value","title":"<code>get_meta_value(meta_key)</code>","text":"<p>Returns the first meta_value for a given meta_key.</p> Source code in <code>src/python/ensembl/io/genomio/database/dbconnection_lite.py</code> <pre><code>def get_meta_value(self, meta_key: str) -&gt; Optional[str]:\n    \"\"\"Returns the first meta_value for a given meta_key.\"\"\"\n\n    self._load_metadata()\n    try:\n        return self._metadata[meta_key][0]\n    except KeyError:\n        logging.debug(f\"No meta_key {meta_key}\")\n        return None\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/dbconnection_lite/#ensembl.io.genomio.database.dbconnection_lite.DBConnectionLite.get_metadata","title":"<code>get_metadata()</code>","text":"<p>Retrieves all metadata from the <code>meta</code> table in the database.</p> <p>Returns:</p> Type Description <code>Dict[str, List]</code> <p>A dict of with key meta_key, and value=List of meta_value.</p> Source code in <code>src/python/ensembl/io/genomio/database/dbconnection_lite.py</code> <pre><code>def get_metadata(self) -&gt; Dict[str, List]:\n    \"\"\"Retrieves all metadata from the `meta` table in the database.\n\n    Returns:\n        A dict of with key meta_key, and value=List of meta_value.\n\n    \"\"\"\n    self._load_metadata()\n    return self._metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/dbconnection_lite/#ensembl.io.genomio.database.dbconnection_lite.DBConnectionLite.get_project_release","title":"<code>get_project_release()</code>","text":"<p>Returns the project release number from the database name. Returns empty string if not found.</p> Source code in <code>src/python/ensembl/io/genomio/database/dbconnection_lite.py</code> <pre><code>def get_project_release(self) -&gt; str:\n    \"\"\"Returns the project release number from the database name. Returns empty string if not found.\"\"\"\n\n    match = re.search(_DB_PATTERN_RELEASE, self.db_name)\n    if match:\n        return match.group(1)\n    return \"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/factory/","title":"factory","text":""},{"location":"reference/ensembl/io/genomio/database/factory/#ensembl.io.genomio.database.factory","title":"<code>ensembl.io.genomio.database.factory</code>","text":"<p>Generates one JSON file per metadata type inside <code>manifest</code>, including the manifest itself.</p>"},{"location":"reference/ensembl/io/genomio/database/factory/#ensembl.io.genomio.database.factory.format_db_data","title":"<code>format_db_data(server_url, dbs, brc_mode=False)</code>","text":"<p>Returns a metadata list from the given databases on a server.</p> <p>Parameters:</p> Name Type Description Default <code>server_url</code> <code>URL</code> <p>Server URL where all the databases are hosted.</p> required <code>dbs</code> <code>list[str]</code> <p>List of database names.</p> required <code>brc_mode</code> <code>bool</code> <p>If true, assign <code>BRC4.organism_abbrev</code> as the species, and <code>BRC4.component</code> as the division. Otherwise, the species will be <code>species.production_name</code> and the division will be <code>species.division</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of dictionaries with 3 keys: \"database\", \"species\" and \"division\".</p> Source code in <code>src/python/ensembl/io/genomio/database/factory.py</code> <pre><code>def format_db_data(server_url: URL, dbs: list[str], brc_mode: bool = False) -&gt; list[dict]:\n    \"\"\"Returns a metadata list from the given databases on a server.\n\n    Args:\n        server_url: Server URL where all the databases are hosted.\n        dbs: List of database names.\n        brc_mode: If true, assign ``BRC4.organism_abbrev`` as the species, and ``BRC4.component`` as the\n            division. Otherwise, the species will be ``species.production_name`` and the division will be\n            ``species.division``.\n\n    Returns:\n        List of dictionaries with 3 keys: \"database\", \"species\" and \"division\".\n    \"\"\"\n    databases_data = []\n    for db_name in dbs:\n        logging.debug(f\"Get metadata for {db_name}\")\n        db_url = server_url.set(database=db_name)\n        core_db = DBConnectionLite(db_url)\n\n        prod_name = core_db.get_meta_value(\"species.production_name\")\n        species = prod_name\n        division = core_db.get_meta_value(\"species.division\")\n        accession = core_db.get_meta_value(\"assembly.accession\")\n        project_release = core_db.get_project_release()\n\n        if brc_mode:\n            brc_organism = core_db.get_meta_value(\"BRC4.organism_abbrev\")\n            brc_component = core_db.get_meta_value(\"BRC4.component\")\n            if brc_organism is not None:\n                species = brc_organism\n            if brc_component is not None:\n                division = brc_component\n\n        if not division:\n            division = \"all\"\n\n        server_data = {\n            \"host\": db_url.host,\n            \"user\": db_url.username,\n            \"port\": db_url.port,\n            \"password\": db_url.password,\n            \"database\": db_url.database,\n        }\n        db_data = {\n            \"server\": server_data,\n            \"production_name\": prod_name,\n            \"species\": species,\n            \"division\": division,\n            \"accession\": accession,\n            \"release\": project_release,\n        }\n\n        databases_data.append(db_data)\n    return databases_data\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/factory/#ensembl.io.genomio.database.factory.get_core_dbs_metadata","title":"<code>get_core_dbs_metadata(server_url, *, prefix='', build=None, version=None, db_regex='', db_list=None, brc_mode=False)</code>","text":"<p>Returns all the metadata fetched for the selected core databases.</p> <p>Parameters:</p> Name Type Description Default <code>server_url</code> <code>URL</code> <p>Server URL where the core databases are stored.</p> required <code>prefix</code> <code>str</code> <p>Filter by prefix (no \"_\" is added automatically).</p> <code>''</code> <code>build</code> <code>int | None</code> <p>Filter by VEuPathDB build number.</p> <code>None</code> <code>version</code> <code>int | None</code> <p>Filter by Ensembl version.</p> <code>None</code> <code>db_regex</code> <code>str</code> <p>Filter by dbname regular expression.</p> <code>''</code> <code>db_list</code> <code>Path | None</code> <p>Explicit list of database names.</p> <code>None</code> <code>brc_mode</code> <code>bool</code> <p>Enable BRC mode.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of dictionaries with 3 keys: \"database\", \"species\" and \"division\".</p> Source code in <code>src/python/ensembl/io/genomio/database/factory.py</code> <pre><code>def get_core_dbs_metadata(\n    server_url: URL,\n    *,\n    prefix: str = \"\",\n    build: int | None = None,\n    version: int | None = None,\n    db_regex: str = \"\",\n    db_list: Path | None = None,\n    brc_mode: bool = False,\n) -&gt; list[dict]:\n    \"\"\"Returns all the metadata fetched for the selected core databases.\n\n    Args:\n        server_url: Server URL where the core databases are stored.\n        prefix: Filter by prefix (no \"_\" is added automatically).\n        build: Filter by VEuPathDB build number.\n        version: Filter by Ensembl version.\n        db_regex: Filter by dbname regular expression.\n        db_list: Explicit list of database names.\n        brc_mode: Enable BRC mode.\n\n    Returns:\n        List of dictionaries with 3 keys: \"database\", \"species\" and \"division\".\n    \"\"\"\n    db_list_file = None\n    if db_list:\n        with db_list.open(\"r\") as infile_fh:\n            db_list_file = [line.strip() for line in infile_fh]\n    # Get all database names\n    server = CoreServer(server_url)\n    logging.debug(\"Fetching databases...\")\n    databases = server.get_cores(\n        prefix=prefix, build=build, version=version, dbname_re=db_regex, db_list=db_list_file\n    )\n    logging.info(f\"Got {len(databases)} databases\")\n    logging.debug(\"\\n\".join(databases))\n    return format_db_data(server_url, databases, brc_mode)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/factory/#ensembl.io.genomio.database.factory.main","title":"<code>main(arg_list=None)</code>","text":"<p>Main script entry-point.</p> <p>Parameters:</p> Name Type Description Default <code>arg_list</code> <code>list[str] | None</code> <p>Arguments to parse passing list to parse_args().</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/database/factory.py</code> <pre><code>def main(arg_list: list[str] | None = None) -&gt; None:\n    \"\"\"Main script entry-point.\n\n    Args:\n        arg_list: Arguments to parse passing list to parse_args().\n\n    \"\"\"\n    args = parse_args(arg_list)\n    init_logging_with_args(args)\n\n    databases_data = get_core_dbs_metadata(\n        server_url=args.url,\n        prefix=args.prefix,\n        build=args.build,\n        version=args.release,\n        db_regex=args.db_regex,\n        db_list=args.db_list,\n        brc_mode=args.brc_mode,\n    )\n    print(json.dumps(databases_data, sort_keys=True, indent=4))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/factory/#ensembl.io.genomio.database.factory.parse_args","title":"<code>parse_args(arg_list)</code>","text":"<p>Return a populated namespace with the arguments parsed from a list or from the command line.</p> <p>Parameters:</p> Name Type Description Default <code>arg_list</code> <code>list[str] | None</code> <p>List of arguments to parse. If <code>None</code>, grab them from the command line.</p> required Source code in <code>src/python/ensembl/io/genomio/database/factory.py</code> <pre><code>def parse_args(arg_list: list[str] | None) -&gt; argparse.Namespace:\n    \"\"\"Return a populated namespace with the arguments parsed from a list or from the command line.\n\n    Args:\n        arg_list: List of arguments to parse. If `None`, grab them from the command line.\n\n    \"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_server_arguments()\n    # Add filter arguments\n    parser.add_argument(\"--prefix\", default=\"\", help=\"Prefix to filter the databases\")\n    parser.add_argument(\"--build\", type=int, default=None, help=\"Build to filter the databases\")\n    parser.add_argument(\"--release\", type=int, default=None, help=\"EnsEMBL release to filter the databases\")\n    parser.add_argument(\"--db_regex\", default=\"\", help=\"Regular expression to match database names against\")\n    parser.add_argument_src_path(\"--db_list\", help=\"File with one database per line to load\")\n    # Add flags\n    parser.add_argument(\n        \"--brc_mode\",\n        action=\"store_true\",\n        help=\"Enable BRC mode, i.e. use organism_abbrev for species, component for division\",\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    return parser.parse_args(arg_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/meta_getter/","title":"meta_getter","text":""},{"location":"reference/ensembl/io/genomio/database/meta_getter/#ensembl.io.genomio.database.meta_getter","title":"<code>ensembl.io.genomio.database.meta_getter</code>","text":"<p>Connect to a core database and retrieve a meta_key:meta_value pair(s) and dump meta_key/value pairs to stdout / JSON.</p>"},{"location":"reference/ensembl/io/genomio/database/meta_getter/#ensembl.io.genomio.database.meta_getter.get_meta_values","title":"<code>get_meta_values(db_url, meta_keys)</code>","text":"<p>Returns a set of meta values based on set of 1 or more input DB meta_keys.</p> <p>Parameters:</p> Name Type Description Default <code>db_url</code> <code>URL</code> <p>Target core database URL.</p> required <code>meta_keys</code> <code>StrPath | list[str]</code> <p>File path with one meta key per line or list of meta keys.</p> required Source code in <code>src/python/ensembl/io/genomio/database/meta_getter.py</code> <pre><code>def get_meta_values(db_url: URL, meta_keys: StrPath | list[str]) -&gt; dict[str, str]:\n    \"\"\"Returns a set of meta values based on set of 1 or more input DB meta_keys.\n\n    Args:\n        db_url: Target core database URL.\n        meta_keys: File path with one meta key per line or list of meta keys.\n\n    \"\"\"\n    db_name = db_url.database\n    core_db = DBConnectionLite(db_url)\n    query_meta_keys = []\n    unpopulated_meta_keys = []\n    meta_values_located = {}\n    input_keys_count = 0\n    meta_populated = False\n\n    # Check input type and populated query list\n    if isinstance(meta_keys, PosixPath):\n        with Path(meta_keys).open(mode=\"r\", encoding=\"UTF-8\") as fh:\n            for line in fh.readlines():\n                meta_key = line.strip()\n                query_meta_keys.append(meta_key)\n    elif isinstance(meta_keys, list):\n        query_meta_keys = meta_keys\n\n    # Loop over input meta_key(s) and query DB\n    for meta_key in query_meta_keys:\n        input_keys_count += 1\n        meta_value = core_db.get_meta_value(f\"{meta_key}\")\n\n        if meta_value is not None:\n            meta_values_located[f\"{meta_key}\"] = meta_value\n        else:\n            unpopulated_meta_keys.append(f\"{meta_key}\")\n            logging.info(f\"Meta query returned no entry on meta_key: '{meta_key}'\")\n\n    # Now assess what meta info was recovered and dump to JSON\n    total_queries_located = len(meta_values_located)\n    if total_queries_located &gt;= 1:\n        meta_populated = True\n        if total_queries_located &lt; input_keys_count:\n            logging.info(f\"Missing meta_key(s)-&gt; {unpopulated_meta_keys}\")\n    else:\n        logging.warning(\"Zero input query meta_keys present/populated.\")\n\n    if meta_populated:\n        meta_values_located[\"database_name\"] = f\"{db_name}\"\n        print(json.dumps(meta_values_located, sort_keys=True, indent=2))\n        return meta_values_located\n    return {}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/meta_getter/#ensembl.io.genomio.database.meta_getter.main","title":"<code>main(arg_list=None)</code>","text":"<p>Main script entry-point.</p> <p>Parameters:</p> Name Type Description Default <code>arg_list</code> <code>list[str] | None</code> <p>Arguments to parse passing list to parse_args().</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/database/meta_getter.py</code> <pre><code>def main(arg_list: list[str] | None = None) -&gt; None:\n    \"\"\"Main script entry-point.\n\n    Args:\n        arg_list: Arguments to parse passing list to parse_args().\n    \"\"\"\n    args = parse_args(arg_list)\n    init_logging_with_args(args)\n\n    _ = get_meta_values(db_url=args.url, meta_keys=args.meta_keys_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/database/meta_getter/#ensembl.io.genomio.database.meta_getter.parse_args","title":"<code>parse_args(arg_list)</code>","text":"<p>Return a populated namespace with the arguments parsed from a list or from the command line.</p> <p>Parameters:</p> Name Type Description Default <code>arg_list</code> <code>list[str] | None</code> <p>List of arguments to parse. If <code>None</code>, grab them from the command line.</p> required Source code in <code>src/python/ensembl/io/genomio/database/meta_getter.py</code> <pre><code>def parse_args(arg_list: list[str] | None) -&gt; argparse.Namespace:\n    \"\"\"Return a populated namespace with the arguments parsed from a list or from the command line.\n\n    Args:\n        arg_list: List of arguments to parse. If `None`, grab them from the command line.\n\n    \"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_server_arguments(include_database=True, help=\"server url and core database\")\n    parser.add_argument_src_path(\n        \"--meta_keys_list\", help=\"Input File | List with &gt;=2 meta_keys to query target database.\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=False)\n    return parser.parse_args(arg_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/","title":"events","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events","title":"<code>ensembl.io.genomio.events</code>","text":"<p>Gene events handling module.</p>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.BRC4_START_DATE","title":"<code>BRC4_START_DATE = datetime(2020, 5, 1)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DictToIdsSet","title":"<code>DictToIdsSet = Dict[str, IdsSet]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdsSet","title":"<code>IdsSet = Set[str]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs","title":"<code>DumpStableIDs</code>","text":"<p>An processor that create events from pairs of ids and can print those events out.</p> <p>Attributes:</p> Name Type Description <code>server</code> <p>a core server set to a database, to retrieve the data from.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>class DumpStableIDs:\n    \"\"\"An processor that create events from pairs of ids and can print those events out.\n\n    Attributes:\n        server: a core server set to a database, to retrieve the data from.\n\n    \"\"\"\n\n    def __init__(self, session: Session) -&gt; None:\n        \"\"\"Create a processor for events\"\"\"\n        self.session = session\n\n    def get_history(self) -&gt; List:\n        \"\"\"Retrieve all events from a database.\n\n        Returns:\n            A list of all events.\n\n        \"\"\"\n\n        sessions = self.get_mapping_sessions()\n\n        events = []\n        for session in sessions:\n            logging.info(f\"Mapping session {session.new_release}\")\n            pairs = self.get_pairs(session.mapping_session_id)\n            session_events = self.make_events(pairs)\n            for event in session_events:\n                event.set_release(session.new_release)\n                event.set_date(session.created)\n            events += session_events\n\n        # Then analyse the pairs to make events\n        return events\n\n    def print_events(self, events: List[Event], output_file: Path) -&gt; None:\n        \"\"\"Print events in a format for BRC.\n\n        Args:\n            events: list of events for a given genome.\n            output_file: where the events will be printed.\n\n        \"\"\"\n        if not events:\n            logging.info(\"No events to print\")\n            return\n        with output_file.open(\"w\") as out_fh:\n            for event in events:\n                event_lines = event.brc_format_2()\n                for line in event_lines:\n                    out_fh.write(line + \"\\n\")\n\n    def get_mapping_sessions(self) -&gt; List[MappingSession]:\n        \"\"\"Retrieve the mapping sessions from the connected database.\n\n        Returns:\n            A list of sessions.\n\n        \"\"\"\n        map_sessions_stmt = select(MappingSession)\n        map_sessions = list(self.session.scalars(map_sessions_stmt).unique().all())\n        return map_sessions\n\n    def get_pairs(self, session_id: int) -&gt; List[Pair]:\n        \"\"\"Retrieve all pair of ids for a given session.\n\n        Args:\n            session_id: id of a session from the connected database.\n\n        Returns:\n            All pairs of IDs.\n\n        \"\"\"\n\n        id_events_stmt = (\n            select(StableIdEvent)\n            .where(\n                and_(\n                    (StableIdEvent.mapping_session_id == session_id),\n                    (StableIdEvent.id_type == \"gene\"),\n                    (\n                        or_(\n                            (StableIdEvent.old_stable_id.is_(None)),\n                            (StableIdEvent.new_stable_id.is_(None)),\n                            (StableIdEvent.old_stable_id != StableIdEvent.new_stable_id),\n                        )\n                    ),\n                )\n            )\n            .group_by(\n                StableIdEvent.old_stable_id, StableIdEvent.new_stable_id, StableIdEvent.mapping_session_id\n            )\n        )\n        pairs: List[Pair] = []\n        for row in self.session.scalars(id_events_stmt).unique().all():\n            pair = Pair(row.old_stable_id, row.new_stable_id)\n            pairs.append(pair)\n        return pairs\n\n    def make_events(self, pairs: List[Pair]) -&gt; List:\n        \"\"\"Given a list of pairs, create events.\n\n        Args:\n            pairs: list of Pair.\n\n        Return:\n            A list of events.\n\n        \"\"\"\n\n        from_list, to_list = self.get_pairs_from_to(pairs)\n\n        # Create events with those 2 dicts\n        events: List[Event] = []\n        for old_id, from_old_list in from_list.items():\n            if not old_id or old_id not in from_list:\n                continue\n            event = Event(set([old_id]), set(from_old_list))\n            (event, from_list, to_list) = self.extend_event(event, from_list, to_list)\n            event.add_pairs(pairs)\n            events.append(event)\n\n        # Remaining events should only be new genes\n        for new_id, to_new_list in to_list.items():\n            if not new_id:\n                continue\n            event = Event(set(to_new_list), set([new_id]))\n            event.add_pairs(pairs)\n            events.append(event)\n\n        stats = {}\n        for event in events:\n            name = event.get_name()\n            event.clean_pairs()\n            if name not in stats:\n                stats[name] = 1\n            else:\n                stats[name] += 1\n\n        for stat, value in stats.items():\n            logging.info(f\"\\t{stat} = {value}\")\n\n        return events\n\n    @staticmethod\n    def get_pairs_from_to(pairs: List[Pair]) -&gt; Tuple[DictToIdsSet, DictToIdsSet]:\n        \"\"\"\n        From a list of Pairs, extract a mapping of all ids from a given old id (from_list),\n        and a mapping of all ids to a given new id (to_list).\n\n        Args:\n            pairs: list of Pairs.\n\n        Return:\n             Tuple of 2 values:\n                from_list\n                to_list\n\n        \"\"\"\n        from_list: DictToIdsSet = {}\n        to_list: DictToIdsSet = {}\n        for pair in pairs:\n            old_id = pair.old_id\n            new_id = pair.new_id\n            if old_id is None:\n                old_id = \"\"\n            if new_id is None:\n                new_id = \"\"\n\n            if old_id in from_list:\n                from_list[old_id].add(new_id)\n            else:\n                from_list[old_id] = set([new_id])\n\n            if new_id in to_list:\n                to_list[new_id].add(old_id)\n            else:\n                to_list[new_id] = set([old_id])\n\n        # Remove empty elements\n        for from_id in from_list:\n            from_list[from_id] = Event.clean_set(from_list[from_id])\n        for to_id in to_list:\n            to_list[to_id] = Event.clean_set(to_list[to_id])\n\n        return from_list, to_list\n\n    def extend_event(\n        self, event: Event, from_list: DictToIdsSet, to_list: DictToIdsSet\n    ) -&gt; Tuple[Event, DictToIdsSet, DictToIdsSet]:\n        \"\"\"Given an event, aggregate ids in the 'from' and 'to' sets, to connect the whole group.\n\n        Args:\n            event: the event to extend.\n            from_list: A dict a the from ids, and their corresponding to ids.\n            to_list: A dict of the to ids, and their corresponding from ids.\n\n        Returns:\n            A tuple of the extended event, and the from_list and to_list from which the ids that\n            have been added to the event have been removed.\n\n        \"\"\"\n\n        extended = True\n\n        while extended:\n            extended = False\n\n            # Extend the group in the to ids\n            for to_id in event.to_set:\n                if to_id in to_list:\n                    to_from_ids: IdsSet = to_list[to_id]\n                    # Add to the from list?\n                    for to_from_id in to_from_ids:\n                        if to_from_id not in event.from_set:\n                            event.add_from(to_from_id)\n                            extended = True\n\n            # Extend the group in the from ids\n            for from_id in event.from_set:\n                if from_id in from_list:\n                    from_to_ids = from_list[from_id]\n                    # Add to the to list?\n                    for from_to_id in from_to_ids:\n                        if from_to_id not in event.to_set:\n                            event.add_to(from_to_id)\n                            extended = True\n\n        # Clean up\n        from_list = {from_id: from_list[from_id] for from_id in from_list if from_id not in event.from_set}\n        to_list = {to_id: to_list[to_id] for to_id in to_list if to_id not in event.to_set}\n\n        return (event, from_list, to_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs.session","title":"<code>session = session</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs.extend_event","title":"<code>extend_event(event, from_list, to_list)</code>","text":"<p>Given an event, aggregate ids in the 'from' and 'to' sets, to connect the whole group.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>the event to extend.</p> required <code>from_list</code> <code>DictToIdsSet</code> <p>A dict a the from ids, and their corresponding to ids.</p> required <code>to_list</code> <code>DictToIdsSet</code> <p>A dict of the to ids, and their corresponding from ids.</p> required <p>Returns:</p> Type Description <code>Event</code> <p>A tuple of the extended event, and the from_list and to_list from which the ids that</p> <code>DictToIdsSet</code> <p>have been added to the event have been removed.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def extend_event(\n    self, event: Event, from_list: DictToIdsSet, to_list: DictToIdsSet\n) -&gt; Tuple[Event, DictToIdsSet, DictToIdsSet]:\n    \"\"\"Given an event, aggregate ids in the 'from' and 'to' sets, to connect the whole group.\n\n    Args:\n        event: the event to extend.\n        from_list: A dict a the from ids, and their corresponding to ids.\n        to_list: A dict of the to ids, and their corresponding from ids.\n\n    Returns:\n        A tuple of the extended event, and the from_list and to_list from which the ids that\n        have been added to the event have been removed.\n\n    \"\"\"\n\n    extended = True\n\n    while extended:\n        extended = False\n\n        # Extend the group in the to ids\n        for to_id in event.to_set:\n            if to_id in to_list:\n                to_from_ids: IdsSet = to_list[to_id]\n                # Add to the from list?\n                for to_from_id in to_from_ids:\n                    if to_from_id not in event.from_set:\n                        event.add_from(to_from_id)\n                        extended = True\n\n        # Extend the group in the from ids\n        for from_id in event.from_set:\n            if from_id in from_list:\n                from_to_ids = from_list[from_id]\n                # Add to the to list?\n                for from_to_id in from_to_ids:\n                    if from_to_id not in event.to_set:\n                        event.add_to(from_to_id)\n                        extended = True\n\n    # Clean up\n    from_list = {from_id: from_list[from_id] for from_id in from_list if from_id not in event.from_set}\n    to_list = {to_id: to_list[to_id] for to_id in to_list if to_id not in event.to_set}\n\n    return (event, from_list, to_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs.get_history","title":"<code>get_history()</code>","text":"<p>Retrieve all events from a database.</p> <p>Returns:</p> Type Description <code>List</code> <p>A list of all events.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_history(self) -&gt; List:\n    \"\"\"Retrieve all events from a database.\n\n    Returns:\n        A list of all events.\n\n    \"\"\"\n\n    sessions = self.get_mapping_sessions()\n\n    events = []\n    for session in sessions:\n        logging.info(f\"Mapping session {session.new_release}\")\n        pairs = self.get_pairs(session.mapping_session_id)\n        session_events = self.make_events(pairs)\n        for event in session_events:\n            event.set_release(session.new_release)\n            event.set_date(session.created)\n        events += session_events\n\n    # Then analyse the pairs to make events\n    return events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs.get_mapping_sessions","title":"<code>get_mapping_sessions()</code>","text":"<p>Retrieve the mapping sessions from the connected database.</p> <p>Returns:</p> Type Description <code>List[MappingSession]</code> <p>A list of sessions.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_mapping_sessions(self) -&gt; List[MappingSession]:\n    \"\"\"Retrieve the mapping sessions from the connected database.\n\n    Returns:\n        A list of sessions.\n\n    \"\"\"\n    map_sessions_stmt = select(MappingSession)\n    map_sessions = list(self.session.scalars(map_sessions_stmt).unique().all())\n    return map_sessions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs.get_pairs","title":"<code>get_pairs(session_id)</code>","text":"<p>Retrieve all pair of ids for a given session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>int</code> <p>id of a session from the connected database.</p> required <p>Returns:</p> Type Description <code>List[Pair]</code> <p>All pairs of IDs.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_pairs(self, session_id: int) -&gt; List[Pair]:\n    \"\"\"Retrieve all pair of ids for a given session.\n\n    Args:\n        session_id: id of a session from the connected database.\n\n    Returns:\n        All pairs of IDs.\n\n    \"\"\"\n\n    id_events_stmt = (\n        select(StableIdEvent)\n        .where(\n            and_(\n                (StableIdEvent.mapping_session_id == session_id),\n                (StableIdEvent.id_type == \"gene\"),\n                (\n                    or_(\n                        (StableIdEvent.old_stable_id.is_(None)),\n                        (StableIdEvent.new_stable_id.is_(None)),\n                        (StableIdEvent.old_stable_id != StableIdEvent.new_stable_id),\n                    )\n                ),\n            )\n        )\n        .group_by(\n            StableIdEvent.old_stable_id, StableIdEvent.new_stable_id, StableIdEvent.mapping_session_id\n        )\n    )\n    pairs: List[Pair] = []\n    for row in self.session.scalars(id_events_stmt).unique().all():\n        pair = Pair(row.old_stable_id, row.new_stable_id)\n        pairs.append(pair)\n    return pairs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs.get_pairs_from_to","title":"<code>get_pairs_from_to(pairs)</code>  <code>staticmethod</code>","text":"<p>From a list of Pairs, extract a mapping of all ids from a given old id (from_list), and a mapping of all ids to a given new id (to_list).</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>List[Pair]</code> <p>list of Pairs.</p> required Return <p>Tuple of 2 values:    from_list    to_list</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>@staticmethod\ndef get_pairs_from_to(pairs: List[Pair]) -&gt; Tuple[DictToIdsSet, DictToIdsSet]:\n    \"\"\"\n    From a list of Pairs, extract a mapping of all ids from a given old id (from_list),\n    and a mapping of all ids to a given new id (to_list).\n\n    Args:\n        pairs: list of Pairs.\n\n    Return:\n         Tuple of 2 values:\n            from_list\n            to_list\n\n    \"\"\"\n    from_list: DictToIdsSet = {}\n    to_list: DictToIdsSet = {}\n    for pair in pairs:\n        old_id = pair.old_id\n        new_id = pair.new_id\n        if old_id is None:\n            old_id = \"\"\n        if new_id is None:\n            new_id = \"\"\n\n        if old_id in from_list:\n            from_list[old_id].add(new_id)\n        else:\n            from_list[old_id] = set([new_id])\n\n        if new_id in to_list:\n            to_list[new_id].add(old_id)\n        else:\n            to_list[new_id] = set([old_id])\n\n    # Remove empty elements\n    for from_id in from_list:\n        from_list[from_id] = Event.clean_set(from_list[from_id])\n    for to_id in to_list:\n        to_list[to_id] = Event.clean_set(to_list[to_id])\n\n    return from_list, to_list\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs.make_events","title":"<code>make_events(pairs)</code>","text":"<p>Given a list of pairs, create events.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>List[Pair]</code> <p>list of Pair.</p> required Return <p>A list of events.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def make_events(self, pairs: List[Pair]) -&gt; List:\n    \"\"\"Given a list of pairs, create events.\n\n    Args:\n        pairs: list of Pair.\n\n    Return:\n        A list of events.\n\n    \"\"\"\n\n    from_list, to_list = self.get_pairs_from_to(pairs)\n\n    # Create events with those 2 dicts\n    events: List[Event] = []\n    for old_id, from_old_list in from_list.items():\n        if not old_id or old_id not in from_list:\n            continue\n        event = Event(set([old_id]), set(from_old_list))\n        (event, from_list, to_list) = self.extend_event(event, from_list, to_list)\n        event.add_pairs(pairs)\n        events.append(event)\n\n    # Remaining events should only be new genes\n    for new_id, to_new_list in to_list.items():\n        if not new_id:\n            continue\n        event = Event(set(to_new_list), set([new_id]))\n        event.add_pairs(pairs)\n        events.append(event)\n\n    stats = {}\n    for event in events:\n        name = event.get_name()\n        event.clean_pairs()\n        if name not in stats:\n            stats[name] = 1\n        else:\n            stats[name] += 1\n\n    for stat, value in stats.items():\n        logging.info(f\"\\t{stat} = {value}\")\n\n    return events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.DumpStableIDs.print_events","title":"<code>print_events(events, output_file)</code>","text":"<p>Print events in a format for BRC.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>List[Event]</code> <p>list of events for a given genome.</p> required <code>output_file</code> <code>Path</code> <p>where the events will be printed.</p> required Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def print_events(self, events: List[Event], output_file: Path) -&gt; None:\n    \"\"\"Print events in a format for BRC.\n\n    Args:\n        events: list of events for a given genome.\n        output_file: where the events will be printed.\n\n    \"\"\"\n    if not events:\n        logging.info(\"No events to print\")\n        return\n    with output_file.open(\"w\") as out_fh:\n        for event in events:\n            event_lines = event.brc_format_2()\n            for line in event_lines:\n                out_fh.write(line + \"\\n\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event","title":"<code>Event</code>","text":"<p>Represents a stable id event from one gene set version to another one. Various events: - new genes - deleted genes - merged genes (several genes to one) - split genes (one gene to several) - mixed (several genes to several)</p> <p>Attributes:</p> Name Type Description <code>from_list</code> <p>List of genes the previous gene set.</p> <code>to_list</code> <p>List of genes in the new gene set.</p> <code>release</code> <p>New gene set release name.</p> <code>date</code> <p>Date of the new gene set.</p> <code>name</code> <p>Name of the event (will be updated automatically).</p> <code>pairs</code> <code>List[Pair]</code> <p>All pair of ids for this event.</p> <p>Any gene set before 2019-09 is dubbed pre-BRC4.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>class Event:\n    \"\"\"Represents a stable id event from one gene set version to another one. Various events:\n    - new genes\n    - deleted genes\n    - merged genes (several genes to one)\n    - split genes (one gene to several)\n    - mixed (several genes to several)\n\n    Attributes:\n        from_list: List of genes the previous gene set.\n        to_list: List of genes in the new gene set.\n        release: New gene set release name.\n        date: Date of the new gene set.\n        name: Name of the event (will be updated automatically).\n        pairs: All pair of ids for this event.\n\n    Any gene set before 2019-09 is dubbed pre-BRC4.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        from_list: Optional[Set[str]] = None,\n        to_list: Optional[Set[str]] = None,\n        release: Optional[str] = None,\n        date: Optional[datetime] = None,\n    ) -&gt; None:\n        \"\"\"Create a stable id event from a set of old_ids to a set of new_ids\"\"\"\n\n        if from_list is None:\n            from_list = set()\n        if to_list is None:\n            to_list = set()\n        self.from_set = self.clean_set(from_list)\n        self.to_set = self.clean_set(to_list)\n        self.release = release\n        self.date = date\n        self.name = \"\"\n        self.pairs: List[Pair] = []\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the stable id event\"\"\"\n\n        from_str = \",\".join(self.from_set)\n        to_str = \",\".join(self.to_set)\n        return f\"From {from_str} to {to_str} = {self.get_name()} in release {self.release}\"\n\n    def brc_format_1(self) -&gt; List[str]:\n        \"\"\"Returns a list events, one line per initial ID, in the following TSV format:\n        - old gene id\n        - event name\n        - release\n        - release date\n        - list of old gene ids in the event (comma-separated)\n        - list of new gene ids in the event (comma-separated)\n\n        \"\"\"\n        from_str = \",\".join(self.from_set)\n        to_str = \",\".join(self.to_set)\n        release = self.get_full_release()\n        if self.date:\n            date = self.date.strftime(\"%Y-%m\")\n        else:\n            date = \"no_date\"\n        name = self.get_name()\n        line_list = []\n        for identifier in self.from_set:\n            line = [\n                identifier,\n                name,\n                release,\n                date,\n            ]\n            if name in (\"merge\", \"split\", \"mixed\", \"change\"):\n                line.append(from_str)\n                line.append(to_str)\n            else:\n                line += [\"\", \"\"]\n            line_list.append(\"\\t\".join(line))\n\n        if self.get_name() == \"new\":\n            new_id = [self.to_set][0]\n            line = [new_id, name, release, date, \"\", \"\"]\n            line_list.append(\"\\t\".join(line))\n        return line_list\n\n    def brc_format_2(self) -&gt; List[str]:\n        \"\"\"Returns a list of combination of genes, one line per combination of old_id - new_ids, in the\n        following TSV format:\n        - old gene id\n        - new gene id\n        - event name\n        - release\n        - release date\n\n        \"\"\"\n        release = self.get_full_release()\n        if self.date:\n            date = self.date.strftime(\"%Y-%m\")\n        else:\n            date = \"no_date\"\n        name = self.get_name()\n        line_list = []\n\n        for pair in self.pairs:\n            line = [\n                pair.old_id,\n                pair.new_id,\n                name,\n                release,\n                date,\n            ]\n            line_list.append(\"\\t\".join(line))\n        return line_list\n\n    @staticmethod\n    def clean_set(this_list: Set) -&gt; Set:\n        \"\"\"Removes any empty elements from a list.\n\n        Args:\n            this_list: list of items, so of which can be empty/None.\n\n        Returns:\n            The cleaned list.\n\n        \"\"\"\n        return {identifier for identifier in this_list if identifier}\n\n    def add_from(self, from_id: str) -&gt; None:\n        \"\"\"Store an id in the from_set.\"\"\"\n        if from_id:\n            self.from_set.add(from_id)\n\n    def add_to(self, to_id: str) -&gt; None:\n        \"\"\"Store an id in the from_set.\"\"\"\n        if to_id:\n            self.to_set.add(to_id)\n\n    def set_release(self, release: str) -&gt; None:\n        \"\"\"Set the release name of the event\"\"\"\n        self.release = release\n\n    def set_date(self, date: datetime) -&gt; None:\n        \"\"\"Set the date of the release for this event\"\"\"\n        self.date = date\n\n    def add_pair(self, pair: Pair) -&gt; None:\n        \"\"\"Keeps a record of this pair.\n\n        Args:\n            pair: a Pair to record.\n\n        Raises:\n            ValueError: can't add an empty pair.\n\n        \"\"\"\n        if pair.is_empty():\n            raise ValueError(f\"Expected at least one value in the given pair {pair}\")\n        self.pairs.append(pair)\n\n    def get_full_release(self) -&gt; str:\n        \"\"\"Returns the expanded release name, pre-BRC4 or `BRC4 = build`.\"\"\"\n        release = self.release\n        date = self.date\n\n        if date and date &gt; BRC4_START_DATE:\n            release = f\"build {release}\"\n        else:\n            release = f\"pre-BRC4 {release}\"\n\n        return release\n\n    def _name_event(self) -&gt; None:\n        \"\"\"Identify the event name based on the old vs new id lists.\"\"\"\n        if not self.from_set and len(self.to_set) == 1:\n            self.name = \"new\"\n        elif not self.to_set and len(self.from_set) == 1:\n            self.name = \"deletion\"\n        elif len(self.from_set) == 1 and len(self.to_set) == 1:\n            self.name = \"change\"\n        elif len(self.from_set) == 1 and len(self.to_set) &gt; 1:\n            self.name = \"split\"\n        elif len(self.from_set) &gt; 1 and len(self.to_set) == 1:\n            self.name = \"merge\"\n        elif len(self.from_set) &gt; 1 and len(self.to_set) &gt; 1:\n            self.name = \"mixed\"\n        else:\n            raise UnsupportedEvent(f\"Event {self.from_set} to {self.to_set} is not supported\")\n\n    def clean_pairs(self) -&gt; None:\n        \"\"\"Remove the empty old pairs when the event is not 'new'.\"\"\"\n        if not self.name:\n            self._name_event()\n\n        if self.name != \"new\":\n            new_pairs = []\n            for pair in self.pairs:\n                if not pair.has_old_id():\n                    continue\n                new_pairs.append(pair)\n            self.pairs = new_pairs\n\n    def get_name(self) -&gt; str:\n        \"\"\"Retrieve the name for this event, update it beforehand.\"\"\"\n        self._name_event()\n        return self.name\n\n    def add_pairs(self, pairs: List[Pair]) -&gt; None:\n        \"\"\"Provided all the pairs, keep those that are used by this event.\n\n        Args:\n            pairs: list of Pair.\n\n        \"\"\"\n        for pair in pairs:\n            if (pair.has_old_id() and pair.old_id in self.from_set) or (\n                pair.has_new_id() and pair.new_id in self.to_set\n            ):\n                # Core db contains an empty line to signify that an old id has been removed\n                # in merge/split/mixed\n                name = self.get_name()\n                if (name != \"deletion\") and not pair.has_new_id():\n                    continue\n                self.add_pair(pair)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.date","title":"<code>date = date</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.from_set","title":"<code>from_set = self.clean_set(from_list)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.name","title":"<code>name = ''</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.pairs","title":"<code>pairs = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.release","title":"<code>release = release</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.to_set","title":"<code>to_set = self.clean_set(to_list)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.add_from","title":"<code>add_from(from_id)</code>","text":"<p>Store an id in the from_set.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def add_from(self, from_id: str) -&gt; None:\n    \"\"\"Store an id in the from_set.\"\"\"\n    if from_id:\n        self.from_set.add(from_id)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.add_pair","title":"<code>add_pair(pair)</code>","text":"<p>Keeps a record of this pair.</p> <p>Parameters:</p> Name Type Description Default <code>pair</code> <code>Pair</code> <p>a Pair to record.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>can't add an empty pair.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def add_pair(self, pair: Pair) -&gt; None:\n    \"\"\"Keeps a record of this pair.\n\n    Args:\n        pair: a Pair to record.\n\n    Raises:\n        ValueError: can't add an empty pair.\n\n    \"\"\"\n    if pair.is_empty():\n        raise ValueError(f\"Expected at least one value in the given pair {pair}\")\n    self.pairs.append(pair)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.add_pairs","title":"<code>add_pairs(pairs)</code>","text":"<p>Provided all the pairs, keep those that are used by this event.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>List[Pair]</code> <p>list of Pair.</p> required Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def add_pairs(self, pairs: List[Pair]) -&gt; None:\n    \"\"\"Provided all the pairs, keep those that are used by this event.\n\n    Args:\n        pairs: list of Pair.\n\n    \"\"\"\n    for pair in pairs:\n        if (pair.has_old_id() and pair.old_id in self.from_set) or (\n            pair.has_new_id() and pair.new_id in self.to_set\n        ):\n            # Core db contains an empty line to signify that an old id has been removed\n            # in merge/split/mixed\n            name = self.get_name()\n            if (name != \"deletion\") and not pair.has_new_id():\n                continue\n            self.add_pair(pair)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.add_to","title":"<code>add_to(to_id)</code>","text":"<p>Store an id in the from_set.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def add_to(self, to_id: str) -&gt; None:\n    \"\"\"Store an id in the from_set.\"\"\"\n    if to_id:\n        self.to_set.add(to_id)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.brc_format_1","title":"<code>brc_format_1()</code>","text":"<p>Returns a list events, one line per initial ID, in the following TSV format: - old gene id - event name - release - release date - list of old gene ids in the event (comma-separated) - list of new gene ids in the event (comma-separated)</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def brc_format_1(self) -&gt; List[str]:\n    \"\"\"Returns a list events, one line per initial ID, in the following TSV format:\n    - old gene id\n    - event name\n    - release\n    - release date\n    - list of old gene ids in the event (comma-separated)\n    - list of new gene ids in the event (comma-separated)\n\n    \"\"\"\n    from_str = \",\".join(self.from_set)\n    to_str = \",\".join(self.to_set)\n    release = self.get_full_release()\n    if self.date:\n        date = self.date.strftime(\"%Y-%m\")\n    else:\n        date = \"no_date\"\n    name = self.get_name()\n    line_list = []\n    for identifier in self.from_set:\n        line = [\n            identifier,\n            name,\n            release,\n            date,\n        ]\n        if name in (\"merge\", \"split\", \"mixed\", \"change\"):\n            line.append(from_str)\n            line.append(to_str)\n        else:\n            line += [\"\", \"\"]\n        line_list.append(\"\\t\".join(line))\n\n    if self.get_name() == \"new\":\n        new_id = [self.to_set][0]\n        line = [new_id, name, release, date, \"\", \"\"]\n        line_list.append(\"\\t\".join(line))\n    return line_list\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.brc_format_2","title":"<code>brc_format_2()</code>","text":"<p>Returns a list of combination of genes, one line per combination of old_id - new_ids, in the following TSV format: - old gene id - new gene id - event name - release - release date</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def brc_format_2(self) -&gt; List[str]:\n    \"\"\"Returns a list of combination of genes, one line per combination of old_id - new_ids, in the\n    following TSV format:\n    - old gene id\n    - new gene id\n    - event name\n    - release\n    - release date\n\n    \"\"\"\n    release = self.get_full_release()\n    if self.date:\n        date = self.date.strftime(\"%Y-%m\")\n    else:\n        date = \"no_date\"\n    name = self.get_name()\n    line_list = []\n\n    for pair in self.pairs:\n        line = [\n            pair.old_id,\n            pair.new_id,\n            name,\n            release,\n            date,\n        ]\n        line_list.append(\"\\t\".join(line))\n    return line_list\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.clean_pairs","title":"<code>clean_pairs()</code>","text":"<p>Remove the empty old pairs when the event is not 'new'.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def clean_pairs(self) -&gt; None:\n    \"\"\"Remove the empty old pairs when the event is not 'new'.\"\"\"\n    if not self.name:\n        self._name_event()\n\n    if self.name != \"new\":\n        new_pairs = []\n        for pair in self.pairs:\n            if not pair.has_old_id():\n                continue\n            new_pairs.append(pair)\n        self.pairs = new_pairs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.clean_set","title":"<code>clean_set(this_list)</code>  <code>staticmethod</code>","text":"<p>Removes any empty elements from a list.</p> <p>Parameters:</p> Name Type Description Default <code>this_list</code> <code>Set</code> <p>list of items, so of which can be empty/None.</p> required <p>Returns:</p> Type Description <code>Set</code> <p>The cleaned list.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>@staticmethod\ndef clean_set(this_list: Set) -&gt; Set:\n    \"\"\"Removes any empty elements from a list.\n\n    Args:\n        this_list: list of items, so of which can be empty/None.\n\n    Returns:\n        The cleaned list.\n\n    \"\"\"\n    return {identifier for identifier in this_list if identifier}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.get_full_release","title":"<code>get_full_release()</code>","text":"<p>Returns the expanded release name, pre-BRC4 or <code>BRC4 = build</code>.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_full_release(self) -&gt; str:\n    \"\"\"Returns the expanded release name, pre-BRC4 or `BRC4 = build`.\"\"\"\n    release = self.release\n    date = self.date\n\n    if date and date &gt; BRC4_START_DATE:\n        release = f\"build {release}\"\n    else:\n        release = f\"pre-BRC4 {release}\"\n\n    return release\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.get_name","title":"<code>get_name()</code>","text":"<p>Retrieve the name for this event, update it beforehand.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_name(self) -&gt; str:\n    \"\"\"Retrieve the name for this event, update it beforehand.\"\"\"\n    self._name_event()\n    return self.name\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.set_date","title":"<code>set_date(date)</code>","text":"<p>Set the date of the release for this event</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def set_date(self, date: datetime) -&gt; None:\n    \"\"\"Set the date of the release for this event\"\"\"\n    self.date = date\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Event.set_release","title":"<code>set_release(release)</code>","text":"<p>Set the release name of the event</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def set_release(self, release: str) -&gt; None:\n    \"\"\"Set the release name of the event\"\"\"\n    self.release = release\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.EventCollection","title":"<code>EventCollection</code>","text":"<p>Collection of events with loader/writer in various formats.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>class EventCollection:\n    \"\"\"Collection of events with loader/writer in various formats.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.events: List[IdEvent] = []\n\n    def load_events(self, input_file: PathLike) -&gt; None:\n        \"\"\"Load events from input file.\n        Expected tab file columns: old_id, new_id, event_name, release, release_date\n\n        \"\"\"\n        events: List[IdEvent] = []\n\n        with Path(input_file).open(\"r\") as events_fh:\n            for line in events_fh:\n                line.strip()\n                if line == \"\":\n                    continue\n                (from_id, to_id, event_name, release, release_date) = line.split(\"\\t\")\n                event = IdEvent(\n                    from_id=from_id, to_id=to_id, event=event_name, release=release, release_date=release_date\n                )\n                events.append(event)\n        self.events = events\n\n    def add_deletes(\n        self, genes: List[str], release_name: str = \"release_name\", release_date: str = \"release_date\"\n    ) -&gt; None:\n        \"\"\"Add deletion events from a list of deleted genes.\"\"\"\n        for gene_id in genes:\n            event = IdEvent(\n                from_id=gene_id, to_id=\"\", event=\"deletion\", release=release_name, release_date=release_date\n            )\n            self.events.append(event)\n\n    def load_events_from_gene_diff(\n        self, input_file: PathLike, release_name: str = \"release_name\", release_date: str = \"release_date\"\n    ) -&gt; None:\n        \"\"\"Load events from input file from gene_diff.\"\"\"\n        loaded_event = set()\n\n        with Path(input_file).open(\"r\") as events_fh:\n            for line in events_fh:\n                if line.startswith(\"//\") or line == \"\":\n                    continue\n                (_, event_string, _) = line.split(\"\\t\")\n                for pair in self._parse_gene_diff_event(event_string):\n                    (from_id, to_id, event_name) = pair\n                    if event_name == \"identical\":\n                        continue\n                    fingerprint = f\"{from_id} {to_id}\"\n                    if fingerprint in loaded_event:\n                        logging.debug(f\"Duplicated event, skipped: {fingerprint}\")\n                        continue\n                    loaded_event.add(fingerprint)\n                    event = IdEvent(\n                        from_id=from_id,\n                        to_id=to_id,\n                        event=event_name,\n                        release=release_name,\n                        release_date=release_date,\n                    )\n                    self.events.append(event)\n\n    def _parse_gene_diff_event(self, event_string: str) -&gt; Generator[Tuple[str, str, str], None, None]:\n        \"\"\"Gets all the pairs of IDs from an event string from gene diff.\"\"\"\n        event_symbol = {\n            \"~\": \"identical\",\n            \"=+\": \"iso_gain\",\n            \"=-\": \"iso_loss\",\n            \"=!\": \"broken\",\n            \"=\": \"changed\",\n            \"&gt;\": \"merge\",\n            \"&lt;\": \"split\",\n            \"+\": \"new\",\n        }\n        event_sep = r\"|\".join([symbol.replace(r\"+\", r\"\\+\") for symbol in event_symbol])\n        splitter = f\"({event_sep})\"\n        parts = re.split(splitter, event_string)\n        if len(parts) != 3:\n            logging.warning(f\"Wrong partition: from '{event_string}' to '{parts}'\")\n            return\n        [from_ids, sep, to_ids] = parts\n        event_name = event_symbol[sep]\n\n        # Identical gene: no need to keep in the history\n        for from_id in from_ids.split(\":\"):\n            for to_id in to_ids.split(\":\"):\n                yield (from_id, to_id, event_name)\n\n    def remap_to_ids(self, map_dict: Dict[str, str]) -&gt; None:\n        \"\"\"Using a mapping dict, remap the to_id of all events.\n\n        Raises:\n            ValueError: If there are events without map information.\n        \"\"\"\n\n        no_map = 0\n        for event in self.events:\n            if not event.to_id:\n                continue\n            if event.is_change():\n                event.to_id = event.from_id\n            elif event.to_id in map_dict:\n                event.to_id = map_dict[event.to_id]\n            else:\n                logging.info(f\"No map for to_id {event.to_id}\")\n                no_map += 1\n\n        if no_map:\n            raise ValueError(f\"No map for {no_map} event to_ids\")\n\n    def write_events_to_file(self, output_file: PathLike) -&gt; None:\n        \"\"\"Write the events to a file.\"\"\"\n        with Path(output_file).open(\"w\") as out_fh:\n            logging.info(f\"Write {len(self.events)} events to {output_file}\")\n            for event in self.events:\n                out_fh.write(f\"{event}\\n\")\n\n    def write_events_to_db(self, session: Session, update: bool = False) -&gt; None:\n        \"\"\"Insert the events in the core database.\n        A mapping session is created for each different 'release'.\n\n        \"\"\"\n        # First, create mapping_sessions based on the release\n        mappings: Dict[str, MapSession] = {}\n        for event in self.events:\n            release = event.release\n            if release not in mappings:\n                mappings[release] = MapSession(release, event.release_date)\n            mappings[release].add_event(event)\n\n        # Then, add the mapping, and the events for this mapping\n        for release, mapping in mappings.items():\n            if update:\n                logging.info(f\"Adding mapping for release {release} ({len(mapping.events)} events)\")\n                map_session = MappingSession(new_release=mapping.release, created=mapping.release_date)\n                session.add(map_session)\n                session.flush()\n                session.refresh(map_session)\n                for event in mapping.events:\n                    from_id: Optional[str] = event.from_id\n                    if from_id == \"\":\n                        from_id = None\n                    to_id: Optional[str] = event.to_id\n                    if to_id == \"\":\n                        to_id = None\n                    id_event = StableIdEvent(\n                        mapping_session_id=map_session.mapping_session_id,\n                        old_stable_id=from_id,\n                        new_stable_id=to_id,\n                        id_type=\"gene\",\n                        old_version=1,\n                        new_version=1,\n                    )\n                    session.add(id_event)\n                session.commit()\n            else:\n                logging.info(f\"Found mapping for release {release} ({len(mapping.events)} events)\")\n        if not update:\n            logging.info(\"Run your command again with '--update' to add them\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.EventCollection.events","title":"<code>events = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.EventCollection.add_deletes","title":"<code>add_deletes(genes, release_name='release_name', release_date='release_date')</code>","text":"<p>Add deletion events from a list of deleted genes.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def add_deletes(\n    self, genes: List[str], release_name: str = \"release_name\", release_date: str = \"release_date\"\n) -&gt; None:\n    \"\"\"Add deletion events from a list of deleted genes.\"\"\"\n    for gene_id in genes:\n        event = IdEvent(\n            from_id=gene_id, to_id=\"\", event=\"deletion\", release=release_name, release_date=release_date\n        )\n        self.events.append(event)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.EventCollection.load_events","title":"<code>load_events(input_file)</code>","text":"<p>Load events from input file. Expected tab file columns: old_id, new_id, event_name, release, release_date</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def load_events(self, input_file: PathLike) -&gt; None:\n    \"\"\"Load events from input file.\n    Expected tab file columns: old_id, new_id, event_name, release, release_date\n\n    \"\"\"\n    events: List[IdEvent] = []\n\n    with Path(input_file).open(\"r\") as events_fh:\n        for line in events_fh:\n            line.strip()\n            if line == \"\":\n                continue\n            (from_id, to_id, event_name, release, release_date) = line.split(\"\\t\")\n            event = IdEvent(\n                from_id=from_id, to_id=to_id, event=event_name, release=release, release_date=release_date\n            )\n            events.append(event)\n    self.events = events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.EventCollection.load_events_from_gene_diff","title":"<code>load_events_from_gene_diff(input_file, release_name='release_name', release_date='release_date')</code>","text":"<p>Load events from input file from gene_diff.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def load_events_from_gene_diff(\n    self, input_file: PathLike, release_name: str = \"release_name\", release_date: str = \"release_date\"\n) -&gt; None:\n    \"\"\"Load events from input file from gene_diff.\"\"\"\n    loaded_event = set()\n\n    with Path(input_file).open(\"r\") as events_fh:\n        for line in events_fh:\n            if line.startswith(\"//\") or line == \"\":\n                continue\n            (_, event_string, _) = line.split(\"\\t\")\n            for pair in self._parse_gene_diff_event(event_string):\n                (from_id, to_id, event_name) = pair\n                if event_name == \"identical\":\n                    continue\n                fingerprint = f\"{from_id} {to_id}\"\n                if fingerprint in loaded_event:\n                    logging.debug(f\"Duplicated event, skipped: {fingerprint}\")\n                    continue\n                loaded_event.add(fingerprint)\n                event = IdEvent(\n                    from_id=from_id,\n                    to_id=to_id,\n                    event=event_name,\n                    release=release_name,\n                    release_date=release_date,\n                )\n                self.events.append(event)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.EventCollection.remap_to_ids","title":"<code>remap_to_ids(map_dict)</code>","text":"<p>Using a mapping dict, remap the to_id of all events.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are events without map information.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def remap_to_ids(self, map_dict: Dict[str, str]) -&gt; None:\n    \"\"\"Using a mapping dict, remap the to_id of all events.\n\n    Raises:\n        ValueError: If there are events without map information.\n    \"\"\"\n\n    no_map = 0\n    for event in self.events:\n        if not event.to_id:\n            continue\n        if event.is_change():\n            event.to_id = event.from_id\n        elif event.to_id in map_dict:\n            event.to_id = map_dict[event.to_id]\n        else:\n            logging.info(f\"No map for to_id {event.to_id}\")\n            no_map += 1\n\n    if no_map:\n        raise ValueError(f\"No map for {no_map} event to_ids\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.EventCollection.write_events_to_db","title":"<code>write_events_to_db(session, update=False)</code>","text":"<p>Insert the events in the core database. A mapping session is created for each different 'release'.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def write_events_to_db(self, session: Session, update: bool = False) -&gt; None:\n    \"\"\"Insert the events in the core database.\n    A mapping session is created for each different 'release'.\n\n    \"\"\"\n    # First, create mapping_sessions based on the release\n    mappings: Dict[str, MapSession] = {}\n    for event in self.events:\n        release = event.release\n        if release not in mappings:\n            mappings[release] = MapSession(release, event.release_date)\n        mappings[release].add_event(event)\n\n    # Then, add the mapping, and the events for this mapping\n    for release, mapping in mappings.items():\n        if update:\n            logging.info(f\"Adding mapping for release {release} ({len(mapping.events)} events)\")\n            map_session = MappingSession(new_release=mapping.release, created=mapping.release_date)\n            session.add(map_session)\n            session.flush()\n            session.refresh(map_session)\n            for event in mapping.events:\n                from_id: Optional[str] = event.from_id\n                if from_id == \"\":\n                    from_id = None\n                to_id: Optional[str] = event.to_id\n                if to_id == \"\":\n                    to_id = None\n                id_event = StableIdEvent(\n                    mapping_session_id=map_session.mapping_session_id,\n                    old_stable_id=from_id,\n                    new_stable_id=to_id,\n                    id_type=\"gene\",\n                    old_version=1,\n                    new_version=1,\n                )\n                session.add(id_event)\n            session.commit()\n        else:\n            logging.info(f\"Found mapping for release {release} ({len(mapping.events)} events)\")\n    if not update:\n        logging.info(\"Run your command again with '--update' to add them\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.EventCollection.write_events_to_file","title":"<code>write_events_to_file(output_file)</code>","text":"<p>Write the events to a file.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def write_events_to_file(self, output_file: PathLike) -&gt; None:\n    \"\"\"Write the events to a file.\"\"\"\n    with Path(output_file).open(\"w\") as out_fh:\n        logging.info(f\"Write {len(self.events)} events to {output_file}\")\n        for event in self.events:\n            out_fh.write(f\"{event}\\n\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdEvent","title":"<code>IdEvent</code>  <code>dataclass</code>","text":"<p>Simple representation for the events from the input file</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>@dataclass\nclass IdEvent:\n    \"\"\"Simple representation for the events from the input file\"\"\"\n\n    from_id: str\n    to_id: str\n    event: str\n    release: str\n    release_date: str\n\n    def __str__(self) -&gt; str:\n        fields = [self.from_id, self.to_id, self.event, self.release, self.release_date]\n        return \"\\t\".join(fields)\n\n    def is_change(self) -&gt; bool:\n        \"\"\"If the event is an update of an existing gene.\"\"\"\n        changed_events = (\"iso_gain\", \"iso_loss\", \"broken\", \"changed\")\n        return self.event in changed_events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdEvent.event","title":"<code>event</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdEvent.from_id","title":"<code>from_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdEvent.release","title":"<code>release</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdEvent.release_date","title":"<code>release_date</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdEvent.to_id","title":"<code>to_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdEvent.is_change","title":"<code>is_change()</code>","text":"<p>If the event is an update of an existing gene.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def is_change(self) -&gt; bool:\n    \"\"\"If the event is an update of an existing gene.\"\"\"\n    changed_events = (\"iso_gain\", \"iso_loss\", \"broken\", \"changed\")\n    return self.event in changed_events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdsMapper","title":"<code>IdsMapper</code>","text":"<p>Simple mapper object, to cleanly get a mapping dict.</p> Source code in <code>src/python/ensembl/io/genomio/events/format.py</code> <pre><code>class IdsMapper:\n    \"\"\"Simple mapper object, to cleanly get a mapping dict.\"\"\"\n\n    def __init__(self, map_file: PathLike) -&gt; None:\n        self.map = self._load_mapping(Path(map_file))\n\n    def _load_mapping(self, map_file: Path) -&gt; Dict[str, str]:\n        \"\"\"Return a mapping in a simple dict from a tab file with 2 columns: from_id, to_id.\n\n        Args:\n            map_file: Tab file path.\n        \"\"\"\n        mapping = {}\n        with map_file.open(\"r\") as map_fh:\n            for line in map_fh:\n                if line == \"\":\n                    continue\n                items = line.split(\"\\t\")\n                if len(items) &lt; 2:\n                    raise ValueError(f\"Not 2 elements in {line}\")\n                (from_id, to_id) = items[0:2]\n                mapping[from_id] = to_id\n\n        return mapping\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.IdsMapper.map","title":"<code>map = self._load_mapping(Path(map_file))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.MapSession","title":"<code>MapSession</code>","text":"<p>Simple mapping_sessions representation from the input file</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>class MapSession:\n    \"\"\"Simple mapping_sessions representation from the input file\"\"\"\n\n    def __init__(self, release: str, release_date: str) -&gt; None:\n        self.release = release\n        self.release_date = release_date\n        self.events: List[IdEvent] = []\n\n    def add_event(self, event: IdEvent) -&gt; None:\n        \"\"\"Add an event to this mapping_session\"\"\"\n        self.events.append(event)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.MapSession.events","title":"<code>events = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.MapSession.release","title":"<code>release = release</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.MapSession.release_date","title":"<code>release_date = release_date</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.MapSession.add_event","title":"<code>add_event(event)</code>","text":"<p>Add an event to this mapping_session</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def add_event(self, event: IdEvent) -&gt; None:\n    \"\"\"Add an event to this mapping_session\"\"\"\n    self.events.append(event)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Pair","title":"<code>Pair</code>","text":"<p>Simple old_id - new_id pair representation</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>class Pair:\n    \"\"\"Simple old_id - new_id pair representation\"\"\"\n\n    def __init__(self, old_id: Optional[str], new_id: Optional[str]) -&gt; None:\n        \"\"\"Create a pair with an old_id and a new_id if provided\"\"\"\n\n        self.old_id = old_id if old_id is not None else \"\"\n        if new_id is not None:\n            self.new_id = new_id\n        else:\n            self.new_id = \"\"\n\n    def has_old_id(self) -&gt; bool:\n        \"\"\"Check if the pair has an old_id\"\"\"\n        return self.old_id != \"\"\n\n    def has_new_id(self) -&gt; bool:\n        \"\"\"Check if the pair has a new_id\"\"\"\n        return self.new_id != \"\"\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Test if the current pair has no id.\"\"\"\n\n        return not (self.has_old_id() or self.has_new_id())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Pair.new_id","title":"<code>new_id = new_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Pair.old_id","title":"<code>old_id = old_id if old_id is not None else ''</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Pair.has_new_id","title":"<code>has_new_id()</code>","text":"<p>Check if the pair has a new_id</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def has_new_id(self) -&gt; bool:\n    \"\"\"Check if the pair has a new_id\"\"\"\n    return self.new_id != \"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Pair.has_old_id","title":"<code>has_old_id()</code>","text":"<p>Check if the pair has an old_id</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def has_old_id(self) -&gt; bool:\n    \"\"\"Check if the pair has an old_id\"\"\"\n    return self.old_id != \"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.Pair.is_empty","title":"<code>is_empty()</code>","text":"<p>Test if the current pair has no id.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Test if the current pair has no id.\"\"\"\n\n    return not (self.has_old_id() or self.has_new_id())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.UnsupportedEvent","title":"<code>UnsupportedEvent</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>If an event is not supported</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>class UnsupportedEvent(ValueError):\n    \"\"\"If an event is not supported\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/#ensembl.io.genomio.events.load_list","title":"<code>load_list(list_file)</code>","text":"<p>Return a simple list from a file.</p> Source code in <code>src/python/ensembl/io/genomio/events/format.py</code> <pre><code>def load_list(list_file: Path) -&gt; List[str]:\n    \"\"\"Return a simple list from a file.\"\"\"\n    items = set()\n    empty_spaces = re.compile(r\"\\s+\")\n    with Path(list_file).open(\"r\") as map_fh:\n        for line in map_fh:\n            line = re.sub(empty_spaces, \"\", line)\n            if line == \"\":\n                continue\n            items.add(line)\n\n    return list(items)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/","title":"dump","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump","title":"<code>ensembl.io.genomio.events.dump</code>","text":"<p>Module to dump stable id events from an Ensembl Core database</p>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.BRC4_START_DATE","title":"<code>BRC4_START_DATE = datetime(2020, 5, 1)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DictToIdsSet","title":"<code>DictToIdsSet = Dict[str, IdsSet]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.IdsSet","title":"<code>IdsSet = Set[str]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs","title":"<code>DumpStableIDs</code>","text":"<p>An processor that create events from pairs of ids and can print those events out.</p> <p>Attributes:</p> Name Type Description <code>server</code> <p>a core server set to a database, to retrieve the data from.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>class DumpStableIDs:\n    \"\"\"An processor that create events from pairs of ids and can print those events out.\n\n    Attributes:\n        server: a core server set to a database, to retrieve the data from.\n\n    \"\"\"\n\n    def __init__(self, session: Session) -&gt; None:\n        \"\"\"Create a processor for events\"\"\"\n        self.session = session\n\n    def get_history(self) -&gt; List:\n        \"\"\"Retrieve all events from a database.\n\n        Returns:\n            A list of all events.\n\n        \"\"\"\n\n        sessions = self.get_mapping_sessions()\n\n        events = []\n        for session in sessions:\n            logging.info(f\"Mapping session {session.new_release}\")\n            pairs = self.get_pairs(session.mapping_session_id)\n            session_events = self.make_events(pairs)\n            for event in session_events:\n                event.set_release(session.new_release)\n                event.set_date(session.created)\n            events += session_events\n\n        # Then analyse the pairs to make events\n        return events\n\n    def print_events(self, events: List[Event], output_file: Path) -&gt; None:\n        \"\"\"Print events in a format for BRC.\n\n        Args:\n            events: list of events for a given genome.\n            output_file: where the events will be printed.\n\n        \"\"\"\n        if not events:\n            logging.info(\"No events to print\")\n            return\n        with output_file.open(\"w\") as out_fh:\n            for event in events:\n                event_lines = event.brc_format_2()\n                for line in event_lines:\n                    out_fh.write(line + \"\\n\")\n\n    def get_mapping_sessions(self) -&gt; List[MappingSession]:\n        \"\"\"Retrieve the mapping sessions from the connected database.\n\n        Returns:\n            A list of sessions.\n\n        \"\"\"\n        map_sessions_stmt = select(MappingSession)\n        map_sessions = list(self.session.scalars(map_sessions_stmt).unique().all())\n        return map_sessions\n\n    def get_pairs(self, session_id: int) -&gt; List[Pair]:\n        \"\"\"Retrieve all pair of ids for a given session.\n\n        Args:\n            session_id: id of a session from the connected database.\n\n        Returns:\n            All pairs of IDs.\n\n        \"\"\"\n\n        id_events_stmt = (\n            select(StableIdEvent)\n            .where(\n                and_(\n                    (StableIdEvent.mapping_session_id == session_id),\n                    (StableIdEvent.id_type == \"gene\"),\n                    (\n                        or_(\n                            (StableIdEvent.old_stable_id.is_(None)),\n                            (StableIdEvent.new_stable_id.is_(None)),\n                            (StableIdEvent.old_stable_id != StableIdEvent.new_stable_id),\n                        )\n                    ),\n                )\n            )\n            .group_by(\n                StableIdEvent.old_stable_id, StableIdEvent.new_stable_id, StableIdEvent.mapping_session_id\n            )\n        )\n        pairs: List[Pair] = []\n        for row in self.session.scalars(id_events_stmt).unique().all():\n            pair = Pair(row.old_stable_id, row.new_stable_id)\n            pairs.append(pair)\n        return pairs\n\n    def make_events(self, pairs: List[Pair]) -&gt; List:\n        \"\"\"Given a list of pairs, create events.\n\n        Args:\n            pairs: list of Pair.\n\n        Return:\n            A list of events.\n\n        \"\"\"\n\n        from_list, to_list = self.get_pairs_from_to(pairs)\n\n        # Create events with those 2 dicts\n        events: List[Event] = []\n        for old_id, from_old_list in from_list.items():\n            if not old_id or old_id not in from_list:\n                continue\n            event = Event(set([old_id]), set(from_old_list))\n            (event, from_list, to_list) = self.extend_event(event, from_list, to_list)\n            event.add_pairs(pairs)\n            events.append(event)\n\n        # Remaining events should only be new genes\n        for new_id, to_new_list in to_list.items():\n            if not new_id:\n                continue\n            event = Event(set(to_new_list), set([new_id]))\n            event.add_pairs(pairs)\n            events.append(event)\n\n        stats = {}\n        for event in events:\n            name = event.get_name()\n            event.clean_pairs()\n            if name not in stats:\n                stats[name] = 1\n            else:\n                stats[name] += 1\n\n        for stat, value in stats.items():\n            logging.info(f\"\\t{stat} = {value}\")\n\n        return events\n\n    @staticmethod\n    def get_pairs_from_to(pairs: List[Pair]) -&gt; Tuple[DictToIdsSet, DictToIdsSet]:\n        \"\"\"\n        From a list of Pairs, extract a mapping of all ids from a given old id (from_list),\n        and a mapping of all ids to a given new id (to_list).\n\n        Args:\n            pairs: list of Pairs.\n\n        Return:\n             Tuple of 2 values:\n                from_list\n                to_list\n\n        \"\"\"\n        from_list: DictToIdsSet = {}\n        to_list: DictToIdsSet = {}\n        for pair in pairs:\n            old_id = pair.old_id\n            new_id = pair.new_id\n            if old_id is None:\n                old_id = \"\"\n            if new_id is None:\n                new_id = \"\"\n\n            if old_id in from_list:\n                from_list[old_id].add(new_id)\n            else:\n                from_list[old_id] = set([new_id])\n\n            if new_id in to_list:\n                to_list[new_id].add(old_id)\n            else:\n                to_list[new_id] = set([old_id])\n\n        # Remove empty elements\n        for from_id in from_list:\n            from_list[from_id] = Event.clean_set(from_list[from_id])\n        for to_id in to_list:\n            to_list[to_id] = Event.clean_set(to_list[to_id])\n\n        return from_list, to_list\n\n    def extend_event(\n        self, event: Event, from_list: DictToIdsSet, to_list: DictToIdsSet\n    ) -&gt; Tuple[Event, DictToIdsSet, DictToIdsSet]:\n        \"\"\"Given an event, aggregate ids in the 'from' and 'to' sets, to connect the whole group.\n\n        Args:\n            event: the event to extend.\n            from_list: A dict a the from ids, and their corresponding to ids.\n            to_list: A dict of the to ids, and their corresponding from ids.\n\n        Returns:\n            A tuple of the extended event, and the from_list and to_list from which the ids that\n            have been added to the event have been removed.\n\n        \"\"\"\n\n        extended = True\n\n        while extended:\n            extended = False\n\n            # Extend the group in the to ids\n            for to_id in event.to_set:\n                if to_id in to_list:\n                    to_from_ids: IdsSet = to_list[to_id]\n                    # Add to the from list?\n                    for to_from_id in to_from_ids:\n                        if to_from_id not in event.from_set:\n                            event.add_from(to_from_id)\n                            extended = True\n\n            # Extend the group in the from ids\n            for from_id in event.from_set:\n                if from_id in from_list:\n                    from_to_ids = from_list[from_id]\n                    # Add to the to list?\n                    for from_to_id in from_to_ids:\n                        if from_to_id not in event.to_set:\n                            event.add_to(from_to_id)\n                            extended = True\n\n        # Clean up\n        from_list = {from_id: from_list[from_id] for from_id in from_list if from_id not in event.from_set}\n        to_list = {to_id: to_list[to_id] for to_id in to_list if to_id not in event.to_set}\n\n        return (event, from_list, to_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs.session","title":"<code>session = session</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs.extend_event","title":"<code>extend_event(event, from_list, to_list)</code>","text":"<p>Given an event, aggregate ids in the 'from' and 'to' sets, to connect the whole group.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>the event to extend.</p> required <code>from_list</code> <code>DictToIdsSet</code> <p>A dict a the from ids, and their corresponding to ids.</p> required <code>to_list</code> <code>DictToIdsSet</code> <p>A dict of the to ids, and their corresponding from ids.</p> required <p>Returns:</p> Type Description <code>Event</code> <p>A tuple of the extended event, and the from_list and to_list from which the ids that</p> <code>DictToIdsSet</code> <p>have been added to the event have been removed.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def extend_event(\n    self, event: Event, from_list: DictToIdsSet, to_list: DictToIdsSet\n) -&gt; Tuple[Event, DictToIdsSet, DictToIdsSet]:\n    \"\"\"Given an event, aggregate ids in the 'from' and 'to' sets, to connect the whole group.\n\n    Args:\n        event: the event to extend.\n        from_list: A dict a the from ids, and their corresponding to ids.\n        to_list: A dict of the to ids, and their corresponding from ids.\n\n    Returns:\n        A tuple of the extended event, and the from_list and to_list from which the ids that\n        have been added to the event have been removed.\n\n    \"\"\"\n\n    extended = True\n\n    while extended:\n        extended = False\n\n        # Extend the group in the to ids\n        for to_id in event.to_set:\n            if to_id in to_list:\n                to_from_ids: IdsSet = to_list[to_id]\n                # Add to the from list?\n                for to_from_id in to_from_ids:\n                    if to_from_id not in event.from_set:\n                        event.add_from(to_from_id)\n                        extended = True\n\n        # Extend the group in the from ids\n        for from_id in event.from_set:\n            if from_id in from_list:\n                from_to_ids = from_list[from_id]\n                # Add to the to list?\n                for from_to_id in from_to_ids:\n                    if from_to_id not in event.to_set:\n                        event.add_to(from_to_id)\n                        extended = True\n\n    # Clean up\n    from_list = {from_id: from_list[from_id] for from_id in from_list if from_id not in event.from_set}\n    to_list = {to_id: to_list[to_id] for to_id in to_list if to_id not in event.to_set}\n\n    return (event, from_list, to_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs.get_history","title":"<code>get_history()</code>","text":"<p>Retrieve all events from a database.</p> <p>Returns:</p> Type Description <code>List</code> <p>A list of all events.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_history(self) -&gt; List:\n    \"\"\"Retrieve all events from a database.\n\n    Returns:\n        A list of all events.\n\n    \"\"\"\n\n    sessions = self.get_mapping_sessions()\n\n    events = []\n    for session in sessions:\n        logging.info(f\"Mapping session {session.new_release}\")\n        pairs = self.get_pairs(session.mapping_session_id)\n        session_events = self.make_events(pairs)\n        for event in session_events:\n            event.set_release(session.new_release)\n            event.set_date(session.created)\n        events += session_events\n\n    # Then analyse the pairs to make events\n    return events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs.get_mapping_sessions","title":"<code>get_mapping_sessions()</code>","text":"<p>Retrieve the mapping sessions from the connected database.</p> <p>Returns:</p> Type Description <code>List[MappingSession]</code> <p>A list of sessions.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_mapping_sessions(self) -&gt; List[MappingSession]:\n    \"\"\"Retrieve the mapping sessions from the connected database.\n\n    Returns:\n        A list of sessions.\n\n    \"\"\"\n    map_sessions_stmt = select(MappingSession)\n    map_sessions = list(self.session.scalars(map_sessions_stmt).unique().all())\n    return map_sessions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs.get_pairs","title":"<code>get_pairs(session_id)</code>","text":"<p>Retrieve all pair of ids for a given session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>int</code> <p>id of a session from the connected database.</p> required <p>Returns:</p> Type Description <code>List[Pair]</code> <p>All pairs of IDs.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_pairs(self, session_id: int) -&gt; List[Pair]:\n    \"\"\"Retrieve all pair of ids for a given session.\n\n    Args:\n        session_id: id of a session from the connected database.\n\n    Returns:\n        All pairs of IDs.\n\n    \"\"\"\n\n    id_events_stmt = (\n        select(StableIdEvent)\n        .where(\n            and_(\n                (StableIdEvent.mapping_session_id == session_id),\n                (StableIdEvent.id_type == \"gene\"),\n                (\n                    or_(\n                        (StableIdEvent.old_stable_id.is_(None)),\n                        (StableIdEvent.new_stable_id.is_(None)),\n                        (StableIdEvent.old_stable_id != StableIdEvent.new_stable_id),\n                    )\n                ),\n            )\n        )\n        .group_by(\n            StableIdEvent.old_stable_id, StableIdEvent.new_stable_id, StableIdEvent.mapping_session_id\n        )\n    )\n    pairs: List[Pair] = []\n    for row in self.session.scalars(id_events_stmt).unique().all():\n        pair = Pair(row.old_stable_id, row.new_stable_id)\n        pairs.append(pair)\n    return pairs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs.get_pairs_from_to","title":"<code>get_pairs_from_to(pairs)</code>  <code>staticmethod</code>","text":"<p>From a list of Pairs, extract a mapping of all ids from a given old id (from_list), and a mapping of all ids to a given new id (to_list).</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>List[Pair]</code> <p>list of Pairs.</p> required Return <p>Tuple of 2 values:    from_list    to_list</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>@staticmethod\ndef get_pairs_from_to(pairs: List[Pair]) -&gt; Tuple[DictToIdsSet, DictToIdsSet]:\n    \"\"\"\n    From a list of Pairs, extract a mapping of all ids from a given old id (from_list),\n    and a mapping of all ids to a given new id (to_list).\n\n    Args:\n        pairs: list of Pairs.\n\n    Return:\n         Tuple of 2 values:\n            from_list\n            to_list\n\n    \"\"\"\n    from_list: DictToIdsSet = {}\n    to_list: DictToIdsSet = {}\n    for pair in pairs:\n        old_id = pair.old_id\n        new_id = pair.new_id\n        if old_id is None:\n            old_id = \"\"\n        if new_id is None:\n            new_id = \"\"\n\n        if old_id in from_list:\n            from_list[old_id].add(new_id)\n        else:\n            from_list[old_id] = set([new_id])\n\n        if new_id in to_list:\n            to_list[new_id].add(old_id)\n        else:\n            to_list[new_id] = set([old_id])\n\n    # Remove empty elements\n    for from_id in from_list:\n        from_list[from_id] = Event.clean_set(from_list[from_id])\n    for to_id in to_list:\n        to_list[to_id] = Event.clean_set(to_list[to_id])\n\n    return from_list, to_list\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs.make_events","title":"<code>make_events(pairs)</code>","text":"<p>Given a list of pairs, create events.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>List[Pair]</code> <p>list of Pair.</p> required Return <p>A list of events.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def make_events(self, pairs: List[Pair]) -&gt; List:\n    \"\"\"Given a list of pairs, create events.\n\n    Args:\n        pairs: list of Pair.\n\n    Return:\n        A list of events.\n\n    \"\"\"\n\n    from_list, to_list = self.get_pairs_from_to(pairs)\n\n    # Create events with those 2 dicts\n    events: List[Event] = []\n    for old_id, from_old_list in from_list.items():\n        if not old_id or old_id not in from_list:\n            continue\n        event = Event(set([old_id]), set(from_old_list))\n        (event, from_list, to_list) = self.extend_event(event, from_list, to_list)\n        event.add_pairs(pairs)\n        events.append(event)\n\n    # Remaining events should only be new genes\n    for new_id, to_new_list in to_list.items():\n        if not new_id:\n            continue\n        event = Event(set(to_new_list), set([new_id]))\n        event.add_pairs(pairs)\n        events.append(event)\n\n    stats = {}\n    for event in events:\n        name = event.get_name()\n        event.clean_pairs()\n        if name not in stats:\n            stats[name] = 1\n        else:\n            stats[name] += 1\n\n    for stat, value in stats.items():\n        logging.info(f\"\\t{stat} = {value}\")\n\n    return events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.DumpStableIDs.print_events","title":"<code>print_events(events, output_file)</code>","text":"<p>Print events in a format for BRC.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>List[Event]</code> <p>list of events for a given genome.</p> required <code>output_file</code> <code>Path</code> <p>where the events will be printed.</p> required Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def print_events(self, events: List[Event], output_file: Path) -&gt; None:\n    \"\"\"Print events in a format for BRC.\n\n    Args:\n        events: list of events for a given genome.\n        output_file: where the events will be printed.\n\n    \"\"\"\n    if not events:\n        logging.info(\"No events to print\")\n        return\n    with output_file.open(\"w\") as out_fh:\n        for event in events:\n            event_lines = event.brc_format_2()\n            for line in event_lines:\n                out_fh.write(line + \"\\n\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event","title":"<code>Event</code>","text":"<p>Represents a stable id event from one gene set version to another one. Various events: - new genes - deleted genes - merged genes (several genes to one) - split genes (one gene to several) - mixed (several genes to several)</p> <p>Attributes:</p> Name Type Description <code>from_list</code> <p>List of genes the previous gene set.</p> <code>to_list</code> <p>List of genes in the new gene set.</p> <code>release</code> <p>New gene set release name.</p> <code>date</code> <p>Date of the new gene set.</p> <code>name</code> <p>Name of the event (will be updated automatically).</p> <code>pairs</code> <code>List[Pair]</code> <p>All pair of ids for this event.</p> <p>Any gene set before 2019-09 is dubbed pre-BRC4.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>class Event:\n    \"\"\"Represents a stable id event from one gene set version to another one. Various events:\n    - new genes\n    - deleted genes\n    - merged genes (several genes to one)\n    - split genes (one gene to several)\n    - mixed (several genes to several)\n\n    Attributes:\n        from_list: List of genes the previous gene set.\n        to_list: List of genes in the new gene set.\n        release: New gene set release name.\n        date: Date of the new gene set.\n        name: Name of the event (will be updated automatically).\n        pairs: All pair of ids for this event.\n\n    Any gene set before 2019-09 is dubbed pre-BRC4.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        from_list: Optional[Set[str]] = None,\n        to_list: Optional[Set[str]] = None,\n        release: Optional[str] = None,\n        date: Optional[datetime] = None,\n    ) -&gt; None:\n        \"\"\"Create a stable id event from a set of old_ids to a set of new_ids\"\"\"\n\n        if from_list is None:\n            from_list = set()\n        if to_list is None:\n            to_list = set()\n        self.from_set = self.clean_set(from_list)\n        self.to_set = self.clean_set(to_list)\n        self.release = release\n        self.date = date\n        self.name = \"\"\n        self.pairs: List[Pair] = []\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the stable id event\"\"\"\n\n        from_str = \",\".join(self.from_set)\n        to_str = \",\".join(self.to_set)\n        return f\"From {from_str} to {to_str} = {self.get_name()} in release {self.release}\"\n\n    def brc_format_1(self) -&gt; List[str]:\n        \"\"\"Returns a list events, one line per initial ID, in the following TSV format:\n        - old gene id\n        - event name\n        - release\n        - release date\n        - list of old gene ids in the event (comma-separated)\n        - list of new gene ids in the event (comma-separated)\n\n        \"\"\"\n        from_str = \",\".join(self.from_set)\n        to_str = \",\".join(self.to_set)\n        release = self.get_full_release()\n        if self.date:\n            date = self.date.strftime(\"%Y-%m\")\n        else:\n            date = \"no_date\"\n        name = self.get_name()\n        line_list = []\n        for identifier in self.from_set:\n            line = [\n                identifier,\n                name,\n                release,\n                date,\n            ]\n            if name in (\"merge\", \"split\", \"mixed\", \"change\"):\n                line.append(from_str)\n                line.append(to_str)\n            else:\n                line += [\"\", \"\"]\n            line_list.append(\"\\t\".join(line))\n\n        if self.get_name() == \"new\":\n            new_id = [self.to_set][0]\n            line = [new_id, name, release, date, \"\", \"\"]\n            line_list.append(\"\\t\".join(line))\n        return line_list\n\n    def brc_format_2(self) -&gt; List[str]:\n        \"\"\"Returns a list of combination of genes, one line per combination of old_id - new_ids, in the\n        following TSV format:\n        - old gene id\n        - new gene id\n        - event name\n        - release\n        - release date\n\n        \"\"\"\n        release = self.get_full_release()\n        if self.date:\n            date = self.date.strftime(\"%Y-%m\")\n        else:\n            date = \"no_date\"\n        name = self.get_name()\n        line_list = []\n\n        for pair in self.pairs:\n            line = [\n                pair.old_id,\n                pair.new_id,\n                name,\n                release,\n                date,\n            ]\n            line_list.append(\"\\t\".join(line))\n        return line_list\n\n    @staticmethod\n    def clean_set(this_list: Set) -&gt; Set:\n        \"\"\"Removes any empty elements from a list.\n\n        Args:\n            this_list: list of items, so of which can be empty/None.\n\n        Returns:\n            The cleaned list.\n\n        \"\"\"\n        return {identifier for identifier in this_list if identifier}\n\n    def add_from(self, from_id: str) -&gt; None:\n        \"\"\"Store an id in the from_set.\"\"\"\n        if from_id:\n            self.from_set.add(from_id)\n\n    def add_to(self, to_id: str) -&gt; None:\n        \"\"\"Store an id in the from_set.\"\"\"\n        if to_id:\n            self.to_set.add(to_id)\n\n    def set_release(self, release: str) -&gt; None:\n        \"\"\"Set the release name of the event\"\"\"\n        self.release = release\n\n    def set_date(self, date: datetime) -&gt; None:\n        \"\"\"Set the date of the release for this event\"\"\"\n        self.date = date\n\n    def add_pair(self, pair: Pair) -&gt; None:\n        \"\"\"Keeps a record of this pair.\n\n        Args:\n            pair: a Pair to record.\n\n        Raises:\n            ValueError: can't add an empty pair.\n\n        \"\"\"\n        if pair.is_empty():\n            raise ValueError(f\"Expected at least one value in the given pair {pair}\")\n        self.pairs.append(pair)\n\n    def get_full_release(self) -&gt; str:\n        \"\"\"Returns the expanded release name, pre-BRC4 or `BRC4 = build`.\"\"\"\n        release = self.release\n        date = self.date\n\n        if date and date &gt; BRC4_START_DATE:\n            release = f\"build {release}\"\n        else:\n            release = f\"pre-BRC4 {release}\"\n\n        return release\n\n    def _name_event(self) -&gt; None:\n        \"\"\"Identify the event name based on the old vs new id lists.\"\"\"\n        if not self.from_set and len(self.to_set) == 1:\n            self.name = \"new\"\n        elif not self.to_set and len(self.from_set) == 1:\n            self.name = \"deletion\"\n        elif len(self.from_set) == 1 and len(self.to_set) == 1:\n            self.name = \"change\"\n        elif len(self.from_set) == 1 and len(self.to_set) &gt; 1:\n            self.name = \"split\"\n        elif len(self.from_set) &gt; 1 and len(self.to_set) == 1:\n            self.name = \"merge\"\n        elif len(self.from_set) &gt; 1 and len(self.to_set) &gt; 1:\n            self.name = \"mixed\"\n        else:\n            raise UnsupportedEvent(f\"Event {self.from_set} to {self.to_set} is not supported\")\n\n    def clean_pairs(self) -&gt; None:\n        \"\"\"Remove the empty old pairs when the event is not 'new'.\"\"\"\n        if not self.name:\n            self._name_event()\n\n        if self.name != \"new\":\n            new_pairs = []\n            for pair in self.pairs:\n                if not pair.has_old_id():\n                    continue\n                new_pairs.append(pair)\n            self.pairs = new_pairs\n\n    def get_name(self) -&gt; str:\n        \"\"\"Retrieve the name for this event, update it beforehand.\"\"\"\n        self._name_event()\n        return self.name\n\n    def add_pairs(self, pairs: List[Pair]) -&gt; None:\n        \"\"\"Provided all the pairs, keep those that are used by this event.\n\n        Args:\n            pairs: list of Pair.\n\n        \"\"\"\n        for pair in pairs:\n            if (pair.has_old_id() and pair.old_id in self.from_set) or (\n                pair.has_new_id() and pair.new_id in self.to_set\n            ):\n                # Core db contains an empty line to signify that an old id has been removed\n                # in merge/split/mixed\n                name = self.get_name()\n                if (name != \"deletion\") and not pair.has_new_id():\n                    continue\n                self.add_pair(pair)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.date","title":"<code>date = date</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.from_set","title":"<code>from_set = self.clean_set(from_list)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.name","title":"<code>name = ''</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.pairs","title":"<code>pairs = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.release","title":"<code>release = release</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.to_set","title":"<code>to_set = self.clean_set(to_list)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.add_from","title":"<code>add_from(from_id)</code>","text":"<p>Store an id in the from_set.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def add_from(self, from_id: str) -&gt; None:\n    \"\"\"Store an id in the from_set.\"\"\"\n    if from_id:\n        self.from_set.add(from_id)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.add_pair","title":"<code>add_pair(pair)</code>","text":"<p>Keeps a record of this pair.</p> <p>Parameters:</p> Name Type Description Default <code>pair</code> <code>Pair</code> <p>a Pair to record.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>can't add an empty pair.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def add_pair(self, pair: Pair) -&gt; None:\n    \"\"\"Keeps a record of this pair.\n\n    Args:\n        pair: a Pair to record.\n\n    Raises:\n        ValueError: can't add an empty pair.\n\n    \"\"\"\n    if pair.is_empty():\n        raise ValueError(f\"Expected at least one value in the given pair {pair}\")\n    self.pairs.append(pair)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.add_pairs","title":"<code>add_pairs(pairs)</code>","text":"<p>Provided all the pairs, keep those that are used by this event.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>List[Pair]</code> <p>list of Pair.</p> required Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def add_pairs(self, pairs: List[Pair]) -&gt; None:\n    \"\"\"Provided all the pairs, keep those that are used by this event.\n\n    Args:\n        pairs: list of Pair.\n\n    \"\"\"\n    for pair in pairs:\n        if (pair.has_old_id() and pair.old_id in self.from_set) or (\n            pair.has_new_id() and pair.new_id in self.to_set\n        ):\n            # Core db contains an empty line to signify that an old id has been removed\n            # in merge/split/mixed\n            name = self.get_name()\n            if (name != \"deletion\") and not pair.has_new_id():\n                continue\n            self.add_pair(pair)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.add_to","title":"<code>add_to(to_id)</code>","text":"<p>Store an id in the from_set.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def add_to(self, to_id: str) -&gt; None:\n    \"\"\"Store an id in the from_set.\"\"\"\n    if to_id:\n        self.to_set.add(to_id)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.brc_format_1","title":"<code>brc_format_1()</code>","text":"<p>Returns a list events, one line per initial ID, in the following TSV format: - old gene id - event name - release - release date - list of old gene ids in the event (comma-separated) - list of new gene ids in the event (comma-separated)</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def brc_format_1(self) -&gt; List[str]:\n    \"\"\"Returns a list events, one line per initial ID, in the following TSV format:\n    - old gene id\n    - event name\n    - release\n    - release date\n    - list of old gene ids in the event (comma-separated)\n    - list of new gene ids in the event (comma-separated)\n\n    \"\"\"\n    from_str = \",\".join(self.from_set)\n    to_str = \",\".join(self.to_set)\n    release = self.get_full_release()\n    if self.date:\n        date = self.date.strftime(\"%Y-%m\")\n    else:\n        date = \"no_date\"\n    name = self.get_name()\n    line_list = []\n    for identifier in self.from_set:\n        line = [\n            identifier,\n            name,\n            release,\n            date,\n        ]\n        if name in (\"merge\", \"split\", \"mixed\", \"change\"):\n            line.append(from_str)\n            line.append(to_str)\n        else:\n            line += [\"\", \"\"]\n        line_list.append(\"\\t\".join(line))\n\n    if self.get_name() == \"new\":\n        new_id = [self.to_set][0]\n        line = [new_id, name, release, date, \"\", \"\"]\n        line_list.append(\"\\t\".join(line))\n    return line_list\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.brc_format_2","title":"<code>brc_format_2()</code>","text":"<p>Returns a list of combination of genes, one line per combination of old_id - new_ids, in the following TSV format: - old gene id - new gene id - event name - release - release date</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def brc_format_2(self) -&gt; List[str]:\n    \"\"\"Returns a list of combination of genes, one line per combination of old_id - new_ids, in the\n    following TSV format:\n    - old gene id\n    - new gene id\n    - event name\n    - release\n    - release date\n\n    \"\"\"\n    release = self.get_full_release()\n    if self.date:\n        date = self.date.strftime(\"%Y-%m\")\n    else:\n        date = \"no_date\"\n    name = self.get_name()\n    line_list = []\n\n    for pair in self.pairs:\n        line = [\n            pair.old_id,\n            pair.new_id,\n            name,\n            release,\n            date,\n        ]\n        line_list.append(\"\\t\".join(line))\n    return line_list\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.clean_pairs","title":"<code>clean_pairs()</code>","text":"<p>Remove the empty old pairs when the event is not 'new'.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def clean_pairs(self) -&gt; None:\n    \"\"\"Remove the empty old pairs when the event is not 'new'.\"\"\"\n    if not self.name:\n        self._name_event()\n\n    if self.name != \"new\":\n        new_pairs = []\n        for pair in self.pairs:\n            if not pair.has_old_id():\n                continue\n            new_pairs.append(pair)\n        self.pairs = new_pairs\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.clean_set","title":"<code>clean_set(this_list)</code>  <code>staticmethod</code>","text":"<p>Removes any empty elements from a list.</p> <p>Parameters:</p> Name Type Description Default <code>this_list</code> <code>Set</code> <p>list of items, so of which can be empty/None.</p> required <p>Returns:</p> Type Description <code>Set</code> <p>The cleaned list.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>@staticmethod\ndef clean_set(this_list: Set) -&gt; Set:\n    \"\"\"Removes any empty elements from a list.\n\n    Args:\n        this_list: list of items, so of which can be empty/None.\n\n    Returns:\n        The cleaned list.\n\n    \"\"\"\n    return {identifier for identifier in this_list if identifier}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.get_full_release","title":"<code>get_full_release()</code>","text":"<p>Returns the expanded release name, pre-BRC4 or <code>BRC4 = build</code>.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_full_release(self) -&gt; str:\n    \"\"\"Returns the expanded release name, pre-BRC4 or `BRC4 = build`.\"\"\"\n    release = self.release\n    date = self.date\n\n    if date and date &gt; BRC4_START_DATE:\n        release = f\"build {release}\"\n    else:\n        release = f\"pre-BRC4 {release}\"\n\n    return release\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.get_name","title":"<code>get_name()</code>","text":"<p>Retrieve the name for this event, update it beforehand.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def get_name(self) -&gt; str:\n    \"\"\"Retrieve the name for this event, update it beforehand.\"\"\"\n    self._name_event()\n    return self.name\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.set_date","title":"<code>set_date(date)</code>","text":"<p>Set the date of the release for this event</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def set_date(self, date: datetime) -&gt; None:\n    \"\"\"Set the date of the release for this event\"\"\"\n    self.date = date\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Event.set_release","title":"<code>set_release(release)</code>","text":"<p>Set the release name of the event</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def set_release(self, release: str) -&gt; None:\n    \"\"\"Set the release name of the event\"\"\"\n    self.release = release\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Pair","title":"<code>Pair</code>","text":"<p>Simple old_id - new_id pair representation</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>class Pair:\n    \"\"\"Simple old_id - new_id pair representation\"\"\"\n\n    def __init__(self, old_id: Optional[str], new_id: Optional[str]) -&gt; None:\n        \"\"\"Create a pair with an old_id and a new_id if provided\"\"\"\n\n        self.old_id = old_id if old_id is not None else \"\"\n        if new_id is not None:\n            self.new_id = new_id\n        else:\n            self.new_id = \"\"\n\n    def has_old_id(self) -&gt; bool:\n        \"\"\"Check if the pair has an old_id\"\"\"\n        return self.old_id != \"\"\n\n    def has_new_id(self) -&gt; bool:\n        \"\"\"Check if the pair has a new_id\"\"\"\n        return self.new_id != \"\"\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Test if the current pair has no id.\"\"\"\n\n        return not (self.has_old_id() or self.has_new_id())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Pair.new_id","title":"<code>new_id = new_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Pair.old_id","title":"<code>old_id = old_id if old_id is not None else ''</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Pair.has_new_id","title":"<code>has_new_id()</code>","text":"<p>Check if the pair has a new_id</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def has_new_id(self) -&gt; bool:\n    \"\"\"Check if the pair has a new_id\"\"\"\n    return self.new_id != \"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Pair.has_old_id","title":"<code>has_old_id()</code>","text":"<p>Check if the pair has an old_id</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def has_old_id(self) -&gt; bool:\n    \"\"\"Check if the pair has an old_id\"\"\"\n    return self.old_id != \"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.Pair.is_empty","title":"<code>is_empty()</code>","text":"<p>Test if the current pair has no id.</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Test if the current pair has no id.\"\"\"\n\n    return not (self.has_old_id() or self.has_new_id())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.UnsupportedEvent","title":"<code>UnsupportedEvent</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>If an event is not supported</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>class UnsupportedEvent(ValueError):\n    \"\"\"If an event is not supported\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/dump/#ensembl.io.genomio.events.dump.main","title":"<code>main()</code>","text":"<p>Main entrypoint</p> Source code in <code>src/python/ensembl/io/genomio/events/dump.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entrypoint\"\"\"\n    parser = ArgumentParser(\n        description=\"Dump the stable ID events from the information available in a core database.\"\n    )\n    parser.add_server_arguments(include_database=True)\n    parser.add_argument_dst_path(\"--output_file\", required=True, help=\"Output file\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    dbc = DBConnectionLite(args.url)\n    with dbc.session_scope() as session:\n        dumper = DumpStableIDs(session)\n    events = dumper.get_history()\n    dumper.print_events(events, args.output_file)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/format/","title":"format","text":""},{"location":"reference/ensembl/io/genomio/events/format/#ensembl.io.genomio.events.format","title":"<code>ensembl.io.genomio.events.format</code>","text":"<p>Module to map stable ids in a file, given a mapping.</p>"},{"location":"reference/ensembl/io/genomio/events/format/#ensembl.io.genomio.events.format.IdsMapper","title":"<code>IdsMapper</code>","text":"<p>Simple mapper object, to cleanly get a mapping dict.</p> Source code in <code>src/python/ensembl/io/genomio/events/format.py</code> <pre><code>class IdsMapper:\n    \"\"\"Simple mapper object, to cleanly get a mapping dict.\"\"\"\n\n    def __init__(self, map_file: PathLike) -&gt; None:\n        self.map = self._load_mapping(Path(map_file))\n\n    def _load_mapping(self, map_file: Path) -&gt; Dict[str, str]:\n        \"\"\"Return a mapping in a simple dict from a tab file with 2 columns: from_id, to_id.\n\n        Args:\n            map_file: Tab file path.\n        \"\"\"\n        mapping = {}\n        with map_file.open(\"r\") as map_fh:\n            for line in map_fh:\n                if line == \"\":\n                    continue\n                items = line.split(\"\\t\")\n                if len(items) &lt; 2:\n                    raise ValueError(f\"Not 2 elements in {line}\")\n                (from_id, to_id) = items[0:2]\n                mapping[from_id] = to_id\n\n        return mapping\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/format/#ensembl.io.genomio.events.format.IdsMapper.map","title":"<code>map = self._load_mapping(Path(map_file))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/format/#ensembl.io.genomio.events.format.load_list","title":"<code>load_list(list_file)</code>","text":"<p>Return a simple list from a file.</p> Source code in <code>src/python/ensembl/io/genomio/events/format.py</code> <pre><code>def load_list(list_file: Path) -&gt; List[str]:\n    \"\"\"Return a simple list from a file.\"\"\"\n    items = set()\n    empty_spaces = re.compile(r\"\\s+\")\n    with Path(list_file).open(\"r\") as map_fh:\n        for line in map_fh:\n            line = re.sub(empty_spaces, \"\", line)\n            if line == \"\":\n                continue\n            items.add(line)\n\n    return list(items)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/format/#ensembl.io.genomio.events.format.main","title":"<code>main()</code>","text":"<p>Main entrypoint</p> Source code in <code>src/python/ensembl/io/genomio/events/format.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entrypoint\"\"\"\n    parser = ArgumentParser(description=\"Map stable IDs in a file and produce an events file.\")\n    parser.add_argument_src_path(\"--input_file\", required=True, help=\"Input file from gene_diff\")\n    parser.add_argument_src_path(\n        \"--deletes_file\", required=True, help=\"Deleted genes file (apart from the deletes from the gene diff)\"\n    )\n    parser.add_argument_src_path(\n        \"--map_file\", required=True, help=\"Mapping tab file with 2 columns: old_id, new_id\"\n    )\n    parser.add_argument(\"--release_name\", required=True, metavar=\"NAME\", help=\"Release name for all events\")\n    parser.add_argument(\"--release_date\", required=True, metavar=\"DATE\", help=\"Release date for all events\")\n    parser.add_argument_dst_path(\"--output_file\", required=True, help=\"Output formatted event file\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    events = EventCollection()\n    deleted_genes = load_list(args.deletes_file)\n    events.add_deletes(deleted_genes, args.release_name, args.release_date)\n    events.load_events_from_gene_diff(args.input_file, args.release_name, args.release_date)\n    mapper = IdsMapper(args.map_file)\n    events.remap_to_ids(mapper.map)\n    events.write_events_to_file(args.output_file)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/","title":"load","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load","title":"<code>ensembl.io.genomio.events.load</code>","text":"<p>Provided a file with events, load them in a core database.</p> <p>cf the load_events functions for the events tab file format.</p>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.EventCollection","title":"<code>EventCollection</code>","text":"<p>Collection of events with loader/writer in various formats.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>class EventCollection:\n    \"\"\"Collection of events with loader/writer in various formats.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.events: List[IdEvent] = []\n\n    def load_events(self, input_file: PathLike) -&gt; None:\n        \"\"\"Load events from input file.\n        Expected tab file columns: old_id, new_id, event_name, release, release_date\n\n        \"\"\"\n        events: List[IdEvent] = []\n\n        with Path(input_file).open(\"r\") as events_fh:\n            for line in events_fh:\n                line.strip()\n                if line == \"\":\n                    continue\n                (from_id, to_id, event_name, release, release_date) = line.split(\"\\t\")\n                event = IdEvent(\n                    from_id=from_id, to_id=to_id, event=event_name, release=release, release_date=release_date\n                )\n                events.append(event)\n        self.events = events\n\n    def add_deletes(\n        self, genes: List[str], release_name: str = \"release_name\", release_date: str = \"release_date\"\n    ) -&gt; None:\n        \"\"\"Add deletion events from a list of deleted genes.\"\"\"\n        for gene_id in genes:\n            event = IdEvent(\n                from_id=gene_id, to_id=\"\", event=\"deletion\", release=release_name, release_date=release_date\n            )\n            self.events.append(event)\n\n    def load_events_from_gene_diff(\n        self, input_file: PathLike, release_name: str = \"release_name\", release_date: str = \"release_date\"\n    ) -&gt; None:\n        \"\"\"Load events from input file from gene_diff.\"\"\"\n        loaded_event = set()\n\n        with Path(input_file).open(\"r\") as events_fh:\n            for line in events_fh:\n                if line.startswith(\"//\") or line == \"\":\n                    continue\n                (_, event_string, _) = line.split(\"\\t\")\n                for pair in self._parse_gene_diff_event(event_string):\n                    (from_id, to_id, event_name) = pair\n                    if event_name == \"identical\":\n                        continue\n                    fingerprint = f\"{from_id} {to_id}\"\n                    if fingerprint in loaded_event:\n                        logging.debug(f\"Duplicated event, skipped: {fingerprint}\")\n                        continue\n                    loaded_event.add(fingerprint)\n                    event = IdEvent(\n                        from_id=from_id,\n                        to_id=to_id,\n                        event=event_name,\n                        release=release_name,\n                        release_date=release_date,\n                    )\n                    self.events.append(event)\n\n    def _parse_gene_diff_event(self, event_string: str) -&gt; Generator[Tuple[str, str, str], None, None]:\n        \"\"\"Gets all the pairs of IDs from an event string from gene diff.\"\"\"\n        event_symbol = {\n            \"~\": \"identical\",\n            \"=+\": \"iso_gain\",\n            \"=-\": \"iso_loss\",\n            \"=!\": \"broken\",\n            \"=\": \"changed\",\n            \"&gt;\": \"merge\",\n            \"&lt;\": \"split\",\n            \"+\": \"new\",\n        }\n        event_sep = r\"|\".join([symbol.replace(r\"+\", r\"\\+\") for symbol in event_symbol])\n        splitter = f\"({event_sep})\"\n        parts = re.split(splitter, event_string)\n        if len(parts) != 3:\n            logging.warning(f\"Wrong partition: from '{event_string}' to '{parts}'\")\n            return\n        [from_ids, sep, to_ids] = parts\n        event_name = event_symbol[sep]\n\n        # Identical gene: no need to keep in the history\n        for from_id in from_ids.split(\":\"):\n            for to_id in to_ids.split(\":\"):\n                yield (from_id, to_id, event_name)\n\n    def remap_to_ids(self, map_dict: Dict[str, str]) -&gt; None:\n        \"\"\"Using a mapping dict, remap the to_id of all events.\n\n        Raises:\n            ValueError: If there are events without map information.\n        \"\"\"\n\n        no_map = 0\n        for event in self.events:\n            if not event.to_id:\n                continue\n            if event.is_change():\n                event.to_id = event.from_id\n            elif event.to_id in map_dict:\n                event.to_id = map_dict[event.to_id]\n            else:\n                logging.info(f\"No map for to_id {event.to_id}\")\n                no_map += 1\n\n        if no_map:\n            raise ValueError(f\"No map for {no_map} event to_ids\")\n\n    def write_events_to_file(self, output_file: PathLike) -&gt; None:\n        \"\"\"Write the events to a file.\"\"\"\n        with Path(output_file).open(\"w\") as out_fh:\n            logging.info(f\"Write {len(self.events)} events to {output_file}\")\n            for event in self.events:\n                out_fh.write(f\"{event}\\n\")\n\n    def write_events_to_db(self, session: Session, update: bool = False) -&gt; None:\n        \"\"\"Insert the events in the core database.\n        A mapping session is created for each different 'release'.\n\n        \"\"\"\n        # First, create mapping_sessions based on the release\n        mappings: Dict[str, MapSession] = {}\n        for event in self.events:\n            release = event.release\n            if release not in mappings:\n                mappings[release] = MapSession(release, event.release_date)\n            mappings[release].add_event(event)\n\n        # Then, add the mapping, and the events for this mapping\n        for release, mapping in mappings.items():\n            if update:\n                logging.info(f\"Adding mapping for release {release} ({len(mapping.events)} events)\")\n                map_session = MappingSession(new_release=mapping.release, created=mapping.release_date)\n                session.add(map_session)\n                session.flush()\n                session.refresh(map_session)\n                for event in mapping.events:\n                    from_id: Optional[str] = event.from_id\n                    if from_id == \"\":\n                        from_id = None\n                    to_id: Optional[str] = event.to_id\n                    if to_id == \"\":\n                        to_id = None\n                    id_event = StableIdEvent(\n                        mapping_session_id=map_session.mapping_session_id,\n                        old_stable_id=from_id,\n                        new_stable_id=to_id,\n                        id_type=\"gene\",\n                        old_version=1,\n                        new_version=1,\n                    )\n                    session.add(id_event)\n                session.commit()\n            else:\n                logging.info(f\"Found mapping for release {release} ({len(mapping.events)} events)\")\n        if not update:\n            logging.info(\"Run your command again with '--update' to add them\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.EventCollection.events","title":"<code>events = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.EventCollection.add_deletes","title":"<code>add_deletes(genes, release_name='release_name', release_date='release_date')</code>","text":"<p>Add deletion events from a list of deleted genes.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def add_deletes(\n    self, genes: List[str], release_name: str = \"release_name\", release_date: str = \"release_date\"\n) -&gt; None:\n    \"\"\"Add deletion events from a list of deleted genes.\"\"\"\n    for gene_id in genes:\n        event = IdEvent(\n            from_id=gene_id, to_id=\"\", event=\"deletion\", release=release_name, release_date=release_date\n        )\n        self.events.append(event)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.EventCollection.load_events","title":"<code>load_events(input_file)</code>","text":"<p>Load events from input file. Expected tab file columns: old_id, new_id, event_name, release, release_date</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def load_events(self, input_file: PathLike) -&gt; None:\n    \"\"\"Load events from input file.\n    Expected tab file columns: old_id, new_id, event_name, release, release_date\n\n    \"\"\"\n    events: List[IdEvent] = []\n\n    with Path(input_file).open(\"r\") as events_fh:\n        for line in events_fh:\n            line.strip()\n            if line == \"\":\n                continue\n            (from_id, to_id, event_name, release, release_date) = line.split(\"\\t\")\n            event = IdEvent(\n                from_id=from_id, to_id=to_id, event=event_name, release=release, release_date=release_date\n            )\n            events.append(event)\n    self.events = events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.EventCollection.load_events_from_gene_diff","title":"<code>load_events_from_gene_diff(input_file, release_name='release_name', release_date='release_date')</code>","text":"<p>Load events from input file from gene_diff.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def load_events_from_gene_diff(\n    self, input_file: PathLike, release_name: str = \"release_name\", release_date: str = \"release_date\"\n) -&gt; None:\n    \"\"\"Load events from input file from gene_diff.\"\"\"\n    loaded_event = set()\n\n    with Path(input_file).open(\"r\") as events_fh:\n        for line in events_fh:\n            if line.startswith(\"//\") or line == \"\":\n                continue\n            (_, event_string, _) = line.split(\"\\t\")\n            for pair in self._parse_gene_diff_event(event_string):\n                (from_id, to_id, event_name) = pair\n                if event_name == \"identical\":\n                    continue\n                fingerprint = f\"{from_id} {to_id}\"\n                if fingerprint in loaded_event:\n                    logging.debug(f\"Duplicated event, skipped: {fingerprint}\")\n                    continue\n                loaded_event.add(fingerprint)\n                event = IdEvent(\n                    from_id=from_id,\n                    to_id=to_id,\n                    event=event_name,\n                    release=release_name,\n                    release_date=release_date,\n                )\n                self.events.append(event)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.EventCollection.remap_to_ids","title":"<code>remap_to_ids(map_dict)</code>","text":"<p>Using a mapping dict, remap the to_id of all events.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are events without map information.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def remap_to_ids(self, map_dict: Dict[str, str]) -&gt; None:\n    \"\"\"Using a mapping dict, remap the to_id of all events.\n\n    Raises:\n        ValueError: If there are events without map information.\n    \"\"\"\n\n    no_map = 0\n    for event in self.events:\n        if not event.to_id:\n            continue\n        if event.is_change():\n            event.to_id = event.from_id\n        elif event.to_id in map_dict:\n            event.to_id = map_dict[event.to_id]\n        else:\n            logging.info(f\"No map for to_id {event.to_id}\")\n            no_map += 1\n\n    if no_map:\n        raise ValueError(f\"No map for {no_map} event to_ids\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.EventCollection.write_events_to_db","title":"<code>write_events_to_db(session, update=False)</code>","text":"<p>Insert the events in the core database. A mapping session is created for each different 'release'.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def write_events_to_db(self, session: Session, update: bool = False) -&gt; None:\n    \"\"\"Insert the events in the core database.\n    A mapping session is created for each different 'release'.\n\n    \"\"\"\n    # First, create mapping_sessions based on the release\n    mappings: Dict[str, MapSession] = {}\n    for event in self.events:\n        release = event.release\n        if release not in mappings:\n            mappings[release] = MapSession(release, event.release_date)\n        mappings[release].add_event(event)\n\n    # Then, add the mapping, and the events for this mapping\n    for release, mapping in mappings.items():\n        if update:\n            logging.info(f\"Adding mapping for release {release} ({len(mapping.events)} events)\")\n            map_session = MappingSession(new_release=mapping.release, created=mapping.release_date)\n            session.add(map_session)\n            session.flush()\n            session.refresh(map_session)\n            for event in mapping.events:\n                from_id: Optional[str] = event.from_id\n                if from_id == \"\":\n                    from_id = None\n                to_id: Optional[str] = event.to_id\n                if to_id == \"\":\n                    to_id = None\n                id_event = StableIdEvent(\n                    mapping_session_id=map_session.mapping_session_id,\n                    old_stable_id=from_id,\n                    new_stable_id=to_id,\n                    id_type=\"gene\",\n                    old_version=1,\n                    new_version=1,\n                )\n                session.add(id_event)\n            session.commit()\n        else:\n            logging.info(f\"Found mapping for release {release} ({len(mapping.events)} events)\")\n    if not update:\n        logging.info(\"Run your command again with '--update' to add them\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.EventCollection.write_events_to_file","title":"<code>write_events_to_file(output_file)</code>","text":"<p>Write the events to a file.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def write_events_to_file(self, output_file: PathLike) -&gt; None:\n    \"\"\"Write the events to a file.\"\"\"\n    with Path(output_file).open(\"w\") as out_fh:\n        logging.info(f\"Write {len(self.events)} events to {output_file}\")\n        for event in self.events:\n            out_fh.write(f\"{event}\\n\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.IdEvent","title":"<code>IdEvent</code>  <code>dataclass</code>","text":"<p>Simple representation for the events from the input file</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>@dataclass\nclass IdEvent:\n    \"\"\"Simple representation for the events from the input file\"\"\"\n\n    from_id: str\n    to_id: str\n    event: str\n    release: str\n    release_date: str\n\n    def __str__(self) -&gt; str:\n        fields = [self.from_id, self.to_id, self.event, self.release, self.release_date]\n        return \"\\t\".join(fields)\n\n    def is_change(self) -&gt; bool:\n        \"\"\"If the event is an update of an existing gene.\"\"\"\n        changed_events = (\"iso_gain\", \"iso_loss\", \"broken\", \"changed\")\n        return self.event in changed_events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.IdEvent.event","title":"<code>event</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.IdEvent.from_id","title":"<code>from_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.IdEvent.release","title":"<code>release</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.IdEvent.release_date","title":"<code>release_date</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.IdEvent.to_id","title":"<code>to_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.IdEvent.is_change","title":"<code>is_change()</code>","text":"<p>If the event is an update of an existing gene.</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def is_change(self) -&gt; bool:\n    \"\"\"If the event is an update of an existing gene.\"\"\"\n    changed_events = (\"iso_gain\", \"iso_loss\", \"broken\", \"changed\")\n    return self.event in changed_events\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.MapSession","title":"<code>MapSession</code>","text":"<p>Simple mapping_sessions representation from the input file</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>class MapSession:\n    \"\"\"Simple mapping_sessions representation from the input file\"\"\"\n\n    def __init__(self, release: str, release_date: str) -&gt; None:\n        self.release = release\n        self.release_date = release_date\n        self.events: List[IdEvent] = []\n\n    def add_event(self, event: IdEvent) -&gt; None:\n        \"\"\"Add an event to this mapping_session\"\"\"\n        self.events.append(event)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.MapSession.events","title":"<code>events = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.MapSession.release","title":"<code>release = release</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.MapSession.release_date","title":"<code>release_date = release_date</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.MapSession.add_event","title":"<code>add_event(event)</code>","text":"<p>Add an event to this mapping_session</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def add_event(self, event: IdEvent) -&gt; None:\n    \"\"\"Add an event to this mapping_session\"\"\"\n    self.events.append(event)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/events/load/#ensembl.io.genomio.events.load.main","title":"<code>main()</code>","text":"<p>Main entrypoint</p> Source code in <code>src/python/ensembl/io/genomio/events/load.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entrypoint\"\"\"\n    parser = ArgumentParser(description=\"Load the events in the input file into a core database.\")\n    parser.add_server_arguments(include_database=True)\n    parser.add_argument_src_path(\n        \"--input_file\",\n        required=True,\n        help=(\n            \"Input TSV file with events in the format exported by the dumper: old_id, new_id, event_name, \"\n            \"release, date\"\n        ),\n    )\n    parser.add_argument(\"--update\", action=\"store_true\", help=\"Make changes to the database\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    # Start\n    dbc = DBConnectionLite(args.url)\n    collection = EventCollection()\n    collection.load_events(args.input_file)\n\n    with dbc.session_scope() as session:\n        collection.write_events_to_db(session, args.update)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/external_db/","title":"external_db","text":""},{"location":"reference/ensembl/io/genomio/external_db/#ensembl.io.genomio.external_db","title":"<code>ensembl.io.genomio.external_db</code>","text":"<p>External DB map module.</p>"},{"location":"reference/ensembl/io/genomio/external_db/#ensembl.io.genomio.external_db.DEFAULT_EXTERNAL_DB_MAP","title":"<code>DEFAULT_EXTERNAL_DB_MAP = default_map_path</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/external_db/#ensembl.io.genomio.external_db.MapFormatError","title":"<code>MapFormatError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Error when parsing the db map file.</p> Source code in <code>src/python/ensembl/io/genomio/external_db/db_map.py</code> <pre><code>class MapFormatError(ValueError):\n    \"\"\"Error when parsing the db map file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/external_db/#ensembl.io.genomio.external_db.get_external_db_map","title":"<code>get_external_db_map(map_file)</code>","text":"<p>Get an external_db map from a tab file without header.</p> <p>Empty lines and comments (lines starting with #) are ignored. The first 2 columns are expected to be the main name, and the alternative name. Any other columns after that are ignored.</p> <p>Parameters:</p> Name Type Description Default <code>map_file</code> <code>Path</code> <p>Path to a file with external DB mapping.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dict with keys as alternate names, and values as standard name.</p> Source code in <code>src/python/ensembl/io/genomio/external_db/db_map.py</code> <pre><code>def get_external_db_map(map_file: Path) -&gt; dict[str, str]:\n    \"\"\"Get an external_db map from a tab file without header.\n\n    Empty lines and comments (lines starting with #) are ignored.\n    The first 2 columns are expected to be the main name, and the alternative name. Any other columns\n    after that are ignored.\n\n    Args:\n        map_file: Path to a file with external DB mapping.\n\n    Returns:\n        Dict with keys as alternate names, and values as standard name.\n\n    \"\"\"\n    db_map: dict[str, str] = {}\n    with map_file.open(\"r\") as map_fh:\n        for line in map_fh:\n            line = line.rstrip()\n            if line.startswith(\"#\") or line.startswith(\" \") or line == \"\":\n                continue\n            parts = line.split(\"\\t\")\n            if len(parts) &lt; 2:\n                raise MapFormatError(f\"External db file is not formatted correctly for: {line}\")\n            (main_name, alt_name) = parts[0:2]\n            db_map[alt_name] = main_name\n    return db_map\n</code></pre>"},{"location":"reference/ensembl/io/genomio/external_db/db_map/","title":"db_map","text":""},{"location":"reference/ensembl/io/genomio/external_db/db_map/#ensembl.io.genomio.external_db.db_map","title":"<code>ensembl.io.genomio.external_db.db_map</code>","text":"<p>Get a mapping for external db names.</p>"},{"location":"reference/ensembl/io/genomio/external_db/db_map/#ensembl.io.genomio.external_db.db_map.DEFAULT_EXTERNAL_DB_MAP","title":"<code>DEFAULT_EXTERNAL_DB_MAP = default_map_path</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/external_db/db_map/#ensembl.io.genomio.external_db.db_map.default_map_res","title":"<code>default_map_res = files('ensembl.io.genomio.data.external_db_map').joinpath('default.txt')</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/external_db/db_map/#ensembl.io.genomio.external_db.db_map.MapFormatError","title":"<code>MapFormatError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Error when parsing the db map file.</p> Source code in <code>src/python/ensembl/io/genomio/external_db/db_map.py</code> <pre><code>class MapFormatError(ValueError):\n    \"\"\"Error when parsing the db map file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/external_db/db_map/#ensembl.io.genomio.external_db.db_map.get_external_db_map","title":"<code>get_external_db_map(map_file)</code>","text":"<p>Get an external_db map from a tab file without header.</p> <p>Empty lines and comments (lines starting with #) are ignored. The first 2 columns are expected to be the main name, and the alternative name. Any other columns after that are ignored.</p> <p>Parameters:</p> Name Type Description Default <code>map_file</code> <code>Path</code> <p>Path to a file with external DB mapping.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dict with keys as alternate names, and values as standard name.</p> Source code in <code>src/python/ensembl/io/genomio/external_db/db_map.py</code> <pre><code>def get_external_db_map(map_file: Path) -&gt; dict[str, str]:\n    \"\"\"Get an external_db map from a tab file without header.\n\n    Empty lines and comments (lines starting with #) are ignored.\n    The first 2 columns are expected to be the main name, and the alternative name. Any other columns\n    after that are ignored.\n\n    Args:\n        map_file: Path to a file with external DB mapping.\n\n    Returns:\n        Dict with keys as alternate names, and values as standard name.\n\n    \"\"\"\n    db_map: dict[str, str] = {}\n    with map_file.open(\"r\") as map_fh:\n        for line in map_fh:\n            line = line.rstrip()\n            if line.startswith(\"#\") or line.startswith(\" \") or line == \"\":\n                continue\n            parts = line.split(\"\\t\")\n            if len(parts) &lt; 2:\n                raise MapFormatError(f\"External db file is not formatted correctly for: {line}\")\n            (main_name, alt_name) = parts[0:2]\n            db_map[alt_name] = main_name\n    return db_map\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/","title":"fasta","text":""},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta","title":"<code>ensembl.io.genomio.fasta</code>","text":"<p>Fasta files processing module.</p>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta","title":"<code>CompareFasta</code>","text":"<p>Read and compare the FASTA sequences.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>class CompareFasta:\n    \"\"\"Read and compare the FASTA sequences.\"\"\"\n\n    def __init__(self, fasta_ext: Path, fasta_core: Path, output_dir: Path) -&gt; None:\n        \"\"\"\n        Initialize the `CompareFasta` with input fasta files and output directory.\n\n        Args:\n            fasta_ext: Path to INSDC fasta file.\n            fasta_core: Path to core db fasta file.\n            output_dir: Directory where comparison logs will be stored.\n\n        \"\"\"\n        self.fasta_ext = Path(fasta_ext)\n        self.fasta_core = Path(fasta_core)\n        self.output_dir = Path(output_dir)\n        self.comp: list[str] = []\n\n    def compare_seqs(self) -&gt; None:\n        \"\"\"Compare two FASTA files for common, unique, and differing sequences.\n        Use `write_results()` to generate a report.\n        \"\"\"\n        seq_ext = self.read_fasta(self.fasta_ext)\n        seq_core = self.read_fasta(self.fasta_core)\n\n        # Compare sequences\n        seq_ext_dict = self.build_seq_dict(seq_ext)\n        seq_core_dict = self.build_seq_dict(seq_core)\n\n        # Compare number of sequences\n        if len(seq_ext) != len(seq_core):\n            self.comp.append(\n                \"WARNING: Different number of sequences: \"\n                f\"fasta_ext [ n = {len(seq_ext)} ] -Vs- fasta_core [ n = {len(seq_core)} ]\"\n            )\n            logging.warning(\"Different number of sequences: fasta_ext compared to fasta_core\")\n\n        common = self.find_common_groups(seq_ext_dict, seq_core_dict)\n\n        # Sequences that are not common\n        only1 = {seq: group for seq, group in seq_ext_dict.items() if not seq in seq_core_dict}\n\n        only2 = {seq: group for seq, group in seq_core_dict.items() if not seq in seq_ext_dict}\n\n        if only1:\n            self.comp.append(f\"Sequences only in Fasta_1: {', '.join([str(ids) for ids in only1.values()])}\")\n        if only2:\n            self.comp.append(f\"Sequences only in Fasta_2: {', '.join([str(ids) for ids in only2.values()])}\")\n\n        if common:\n            self.comp.append(f\"Common ids: {', '.join([str(common_ids) for common_ids in common.items()])}\")\n\n        # Check for sequences with extra Ns\n        if only1 and only2:\n            self.compare_seq_for_Ns(only1, only2)\n\n        # Write results to file\n        self.write_results()\n\n    def read_fasta(self, fasta_path: Path) -&gt; dict[str, str]:\n        \"\"\"Reads a FASTA file and returns a dictionary mapping sequence IDs to sequences.\n\n        Args:\n            fasta_path: Path to the FASTA file. Supports gzipped files.\n\n        Returns:\n            A dictionary where keys are sequence IDs and values are sequences with all non-CGTA\n                characters replaced by \"N\".\n        \"\"\"\n        logging.info(f\"Read fasta file {fasta_path}\")\n        sequences = {}\n        with open_gz_file(fasta_path) as fasta_fh:\n            for rec in SeqIO.parse(fasta_fh, \"fasta\"):\n                name = rec.id\n                sequences[name] = re.sub(r\"[^CGTA]\", \"N\", str(rec.seq.upper()))\n        return sequences\n\n    def build_seq_dict(self, seqs: dict[str, str]) -&gt; dict[str, SeqGroup]:\n        \"\"\"Builds a dictionary of unique sequences and their associated IDs, accounting for duplicates.\n\n        Args:\n            seqs: A dictionary where keys are sequence IDs and values are sequences.\n\n        Returns:\n            A dictionary where keys are unique sequences and values are `SeqGroup` objects that\n                group sequence IDs sharing the same sequence.\n        \"\"\"\n        seqs_dict: dict[str, SeqGroup] = {}\n        for name, seq in seqs.items():\n            if seq in seqs_dict:\n                seqs_dict[seq].add_id(name)\n            else:\n                seqs_dict[seq] = SeqGroup(name)\n\n        return seqs_dict\n\n    def find_common_groups(\n        self, seq_ext_dict: dict[str, SeqGroup], seq_core_dict: dict[str, SeqGroup]\n    ) -&gt; dict[str, str]:\n        \"\"\"Find common sequences between two dictionaries and group them.\n\n        Args:\n            seq_ext_dict: Dictionary of sequences from the first dataset.\n            seq_core_dict: Dictionary of sequences from the second dataset.\n\n        Returns:\n            A dictionary of common sequence mappings and a list of comparison results.\n\n        \"\"\"\n        common = {}\n\n        for seq1, group1 in seq_ext_dict.items():\n            if seq1 in seq_core_dict:\n                group2 = seq_core_dict[seq1]\n                # Check that the 2 groups have the same number of sequences\n                if group1.count == group2.count:\n                    if group1.count == 1:\n                        common[group1.ids[0]] = group2.ids[0]\n                    else:\n                        self.comp.append(f\"Matched 2 identical groups of sequences: {group1} and {group2}\")\n                        # Map each ID in group1 to a possible group2 ID\n                        possible_id2 = \" OR \".join(group2.ids)\n                        common.update({id1: possible_id2 for id1 in group1.ids})\n                else:\n                    self.comp.append(\n                        \"Matched 2 different groups of sequences\"\n                        f\" ({group1.count} vs {group2.count}): {group1} and {group2}\"\n                    )\n\n        return common\n\n    def write_results(self) -&gt; None:\n        \"\"\"Write the comparison results to a file in the output directory.\"\"\"\n        output_file = self.output_dir / \"compare.log\"\n        observed_compare = set()\n\n        logging.info(f\"Writing results to {output_file}\")\n        with open(output_file, \"w\") as out_fh:\n            for line in self.comp:\n                if line not in observed_compare:\n                    observed_compare.add(line)\n                    out_fh.write(str(line) + \"\\n\")\n\n    def compare_seq_for_Ns(self, only1: dict[str, SeqGroup], only2: dict[str, SeqGroup]) -&gt; None:\n        \"\"\"Compare sequences in `only1` and `only2` for differences in `N` content and length.\n\n        Args:\n            only1: Sequences unique to the first dataset, mapping sequence to group/identifier.\n            only2: Sequences unique to the second dataset, mapping sequence to group/identifier.\n\n        \"\"\"\n        # sequences which have extra N at the end\n        for seq_1, name1 in only1.items():\n            len1 = len(seq_1)\n            seq1_N = seq_1.count(\"N\")\n\n            for seq_2, name2 in only2.items():\n                len2 = len(seq_2)\n                seq2_N = seq_2.count(\"N\")\n\n                if abs(seq1_N - seq2_N) == abs(len1 - len2):\n                    self.comp.append(f\"Please check extra Ns added in the accessions {name1} and {name2}\")\n                else:\n                    self.comp.append(\n                        f\"ALERT INSERTIONS at the end or diff assembly level {name1} and {name2}\"\n                    )\n\n                if len1 == len2:\n                    if seq2_N &gt; seq1_N:\n                        self.comp.append(f\"your fasta_core has more Ns, check {name1} and {name2}\")\n                    else:\n                        self.comp.append(f\"sequences have the same length, check {name1} and {name2}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.comp","title":"<code>comp = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.fasta_core","title":"<code>fasta_core = Path(fasta_core)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.fasta_ext","title":"<code>fasta_ext = Path(fasta_ext)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.output_dir","title":"<code>output_dir = Path(output_dir)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.build_seq_dict","title":"<code>build_seq_dict(seqs)</code>","text":"<p>Builds a dictionary of unique sequences and their associated IDs, accounting for duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>seqs</code> <code>dict[str, str]</code> <p>A dictionary where keys are sequence IDs and values are sequences.</p> required <p>Returns:</p> Type Description <code>dict[str, SeqGroup]</code> <p>A dictionary where keys are unique sequences and values are <code>SeqGroup</code> objects that group sequence IDs sharing the same sequence.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def build_seq_dict(self, seqs: dict[str, str]) -&gt; dict[str, SeqGroup]:\n    \"\"\"Builds a dictionary of unique sequences and their associated IDs, accounting for duplicates.\n\n    Args:\n        seqs: A dictionary where keys are sequence IDs and values are sequences.\n\n    Returns:\n        A dictionary where keys are unique sequences and values are `SeqGroup` objects that\n            group sequence IDs sharing the same sequence.\n    \"\"\"\n    seqs_dict: dict[str, SeqGroup] = {}\n    for name, seq in seqs.items():\n        if seq in seqs_dict:\n            seqs_dict[seq].add_id(name)\n        else:\n            seqs_dict[seq] = SeqGroup(name)\n\n    return seqs_dict\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.compare_seq_for_Ns","title":"<code>compare_seq_for_Ns(only1, only2)</code>","text":"<p>Compare sequences in <code>only1</code> and <code>only2</code> for differences in <code>N</code> content and length.</p> <p>Parameters:</p> Name Type Description Default <code>only1</code> <code>dict[str, SeqGroup]</code> <p>Sequences unique to the first dataset, mapping sequence to group/identifier.</p> required <code>only2</code> <code>dict[str, SeqGroup]</code> <p>Sequences unique to the second dataset, mapping sequence to group/identifier.</p> required Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def compare_seq_for_Ns(self, only1: dict[str, SeqGroup], only2: dict[str, SeqGroup]) -&gt; None:\n    \"\"\"Compare sequences in `only1` and `only2` for differences in `N` content and length.\n\n    Args:\n        only1: Sequences unique to the first dataset, mapping sequence to group/identifier.\n        only2: Sequences unique to the second dataset, mapping sequence to group/identifier.\n\n    \"\"\"\n    # sequences which have extra N at the end\n    for seq_1, name1 in only1.items():\n        len1 = len(seq_1)\n        seq1_N = seq_1.count(\"N\")\n\n        for seq_2, name2 in only2.items():\n            len2 = len(seq_2)\n            seq2_N = seq_2.count(\"N\")\n\n            if abs(seq1_N - seq2_N) == abs(len1 - len2):\n                self.comp.append(f\"Please check extra Ns added in the accessions {name1} and {name2}\")\n            else:\n                self.comp.append(\n                    f\"ALERT INSERTIONS at the end or diff assembly level {name1} and {name2}\"\n                )\n\n            if len1 == len2:\n                if seq2_N &gt; seq1_N:\n                    self.comp.append(f\"your fasta_core has more Ns, check {name1} and {name2}\")\n                else:\n                    self.comp.append(f\"sequences have the same length, check {name1} and {name2}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.compare_seqs","title":"<code>compare_seqs()</code>","text":"<p>Compare two FASTA files for common, unique, and differing sequences. Use <code>write_results()</code> to generate a report.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def compare_seqs(self) -&gt; None:\n    \"\"\"Compare two FASTA files for common, unique, and differing sequences.\n    Use `write_results()` to generate a report.\n    \"\"\"\n    seq_ext = self.read_fasta(self.fasta_ext)\n    seq_core = self.read_fasta(self.fasta_core)\n\n    # Compare sequences\n    seq_ext_dict = self.build_seq_dict(seq_ext)\n    seq_core_dict = self.build_seq_dict(seq_core)\n\n    # Compare number of sequences\n    if len(seq_ext) != len(seq_core):\n        self.comp.append(\n            \"WARNING: Different number of sequences: \"\n            f\"fasta_ext [ n = {len(seq_ext)} ] -Vs- fasta_core [ n = {len(seq_core)} ]\"\n        )\n        logging.warning(\"Different number of sequences: fasta_ext compared to fasta_core\")\n\n    common = self.find_common_groups(seq_ext_dict, seq_core_dict)\n\n    # Sequences that are not common\n    only1 = {seq: group for seq, group in seq_ext_dict.items() if not seq in seq_core_dict}\n\n    only2 = {seq: group for seq, group in seq_core_dict.items() if not seq in seq_ext_dict}\n\n    if only1:\n        self.comp.append(f\"Sequences only in Fasta_1: {', '.join([str(ids) for ids in only1.values()])}\")\n    if only2:\n        self.comp.append(f\"Sequences only in Fasta_2: {', '.join([str(ids) for ids in only2.values()])}\")\n\n    if common:\n        self.comp.append(f\"Common ids: {', '.join([str(common_ids) for common_ids in common.items()])}\")\n\n    # Check for sequences with extra Ns\n    if only1 and only2:\n        self.compare_seq_for_Ns(only1, only2)\n\n    # Write results to file\n    self.write_results()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.find_common_groups","title":"<code>find_common_groups(seq_ext_dict, seq_core_dict)</code>","text":"<p>Find common sequences between two dictionaries and group them.</p> <p>Parameters:</p> Name Type Description Default <code>seq_ext_dict</code> <code>dict[str, SeqGroup]</code> <p>Dictionary of sequences from the first dataset.</p> required <code>seq_core_dict</code> <code>dict[str, SeqGroup]</code> <p>Dictionary of sequences from the second dataset.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>A dictionary of common sequence mappings and a list of comparison results.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def find_common_groups(\n    self, seq_ext_dict: dict[str, SeqGroup], seq_core_dict: dict[str, SeqGroup]\n) -&gt; dict[str, str]:\n    \"\"\"Find common sequences between two dictionaries and group them.\n\n    Args:\n        seq_ext_dict: Dictionary of sequences from the first dataset.\n        seq_core_dict: Dictionary of sequences from the second dataset.\n\n    Returns:\n        A dictionary of common sequence mappings and a list of comparison results.\n\n    \"\"\"\n    common = {}\n\n    for seq1, group1 in seq_ext_dict.items():\n        if seq1 in seq_core_dict:\n            group2 = seq_core_dict[seq1]\n            # Check that the 2 groups have the same number of sequences\n            if group1.count == group2.count:\n                if group1.count == 1:\n                    common[group1.ids[0]] = group2.ids[0]\n                else:\n                    self.comp.append(f\"Matched 2 identical groups of sequences: {group1} and {group2}\")\n                    # Map each ID in group1 to a possible group2 ID\n                    possible_id2 = \" OR \".join(group2.ids)\n                    common.update({id1: possible_id2 for id1 in group1.ids})\n            else:\n                self.comp.append(\n                    \"Matched 2 different groups of sequences\"\n                    f\" ({group1.count} vs {group2.count}): {group1} and {group2}\"\n                )\n\n    return common\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.read_fasta","title":"<code>read_fasta(fasta_path)</code>","text":"<p>Reads a FASTA file and returns a dictionary mapping sequence IDs to sequences.</p> <p>Parameters:</p> Name Type Description Default <code>fasta_path</code> <code>Path</code> <p>Path to the FASTA file. Supports gzipped files.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>A dictionary where keys are sequence IDs and values are sequences with all non-CGTA characters replaced by \"N\".</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def read_fasta(self, fasta_path: Path) -&gt; dict[str, str]:\n    \"\"\"Reads a FASTA file and returns a dictionary mapping sequence IDs to sequences.\n\n    Args:\n        fasta_path: Path to the FASTA file. Supports gzipped files.\n\n    Returns:\n        A dictionary where keys are sequence IDs and values are sequences with all non-CGTA\n            characters replaced by \"N\".\n    \"\"\"\n    logging.info(f\"Read fasta file {fasta_path}\")\n    sequences = {}\n    with open_gz_file(fasta_path) as fasta_fh:\n        for rec in SeqIO.parse(fasta_fh, \"fasta\"):\n            name = rec.id\n            sequences[name] = re.sub(r\"[^CGTA]\", \"N\", str(rec.seq.upper()))\n    return sequences\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.CompareFasta.write_results","title":"<code>write_results()</code>","text":"<p>Write the comparison results to a file in the output directory.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def write_results(self) -&gt; None:\n    \"\"\"Write the comparison results to a file in the output directory.\"\"\"\n    output_file = self.output_dir / \"compare.log\"\n    observed_compare = set()\n\n    logging.info(f\"Writing results to {output_file}\")\n    with open(output_file, \"w\") as out_fh:\n        for line in self.comp:\n            if line not in observed_compare:\n                observed_compare.add(line)\n                out_fh.write(str(line) + \"\\n\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.FastaParserError","title":"<code>FastaParserError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error while parsing a FASTA file.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/process.py</code> <pre><code>class FastaParserError(Exception):\n    \"\"\"Error while parsing a FASTA file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.SeqGroup","title":"<code>SeqGroup</code>","text":"<p>Represents a group of sequence identifiers and maintains a count of them.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>class SeqGroup:\n    \"\"\"Represents a group of sequence identifiers and maintains a count of them.\"\"\"\n\n    def __init__(self, identifier: str | None = None) -&gt; None:\n        \"\"\"Initializes a `SeqGroup` instance.\n\n        Args:\n            identifier: The first identifier to add to the group. If `None`, adds \"None\" as the identifier.\n\n        \"\"\"\n        self.ids: list[str] = [str(identifier)]\n        self.count = 1\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a comma-separated string of sequence identifiers.\"\"\"\n        return \", \".join(self.ids)\n\n    def add_id(self, identifier: str | None = None) -&gt; None:\n        \"\"\"Add a new identifier to the group and updates the count.\n\n        Args:\n            identifier: The identifier to add. If `None`, \"None\" is added instead.\n\n        \"\"\"\n        self.ids.append(str(identifier))\n        self.count += 1\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.SeqGroup.count","title":"<code>count = 1</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.SeqGroup.ids","title":"<code>ids = [str(identifier)]</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.SeqGroup.add_id","title":"<code>add_id(identifier=None)</code>","text":"<p>Add a new identifier to the group and updates the count.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | None</code> <p>The identifier to add. If <code>None</code>, \"None\" is added instead.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def add_id(self, identifier: str | None = None) -&gt; None:\n    \"\"\"Add a new identifier to the group and updates the count.\n\n    Args:\n        identifier: The identifier to add. If `None`, \"None\" is added instead.\n\n    \"\"\"\n    self.ids.append(str(identifier))\n    self.count += 1\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.check_chunk_size_and_tolerance","title":"<code>check_chunk_size_and_tolerance(chunk_size, chunk_tolerance, error_f=_on_value_error)</code>","text":"<p>Check the chunk size and the tolerance are positive and chunk size is not too small</p> <p>Parameters:</p> Name Type Description Default <code>chunk_size</code> <code>int</code> <p>Chunk size to check</p> required <code>chunk_tolerance</code> <code>int</code> <p>Chunk tolerance to check</p> required Dies <p>If checks failed dies with <code>parser.error</code></p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def check_chunk_size_and_tolerance(\n    chunk_size: int,\n    chunk_tolerance: int,\n    error_f: Callable[[str], None] = _on_value_error,\n) -&gt; None:\n    \"\"\"Check the chunk size and the tolerance are positive and chunk size is not too small\n\n    Args:\n        chunk_size: Chunk size to check\n        chunk_tolerance: Chunk tolerance to check\n\n    Dies:\n        If checks failed dies with `parser.error`\n    \"\"\"\n    if chunk_size &lt; 50_000:\n        error_f(f\"wrong '--chunk_size' value: '{chunk_size}'. should be greater then 50_000. exiting...\")\n    if chunk_tolerance &lt; 0:\n        error_f(f\"wrong '--chunk_tolerance' value: '{chunk_tolerance}'. can't be less then 0. exiting...\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.chunk_fasta","title":"<code>chunk_fasta(input_fasta_file, chunk_size, chunk_size_tolerated, out_file_name, individual_file_prefix, *, agp_output_file=None, n_sequence_len=0, chunk_sfx='ens_chunk', append_offset_to_chunk_name=None)</code>","text":"<p>Open <code>input_fasta_file</code> and split into a smaller chunks based on stretches of \"N\"s and then based on chunk_size_tolerated and store either to the <code>out_file_name</code> if no <code>individual_file_prefix</code> is provided or store each individual chunk to a file starting with non-empty <code>individual_file_prefix</code>.</p> <p>Parameters:</p> Name Type Description Default <code>input_fasta_file</code> <code>str</code> <p>Input FASTA</p> required <code>chunk_size</code> <code>int</code> <p>Size of the chunks to split into.</p> required <code>chunk_size_tolerated</code> <code>int</code> <p>If more flexibility allowed, use this as the maximum size of a chunk.</p> required <code>out_file_name</code> <code>str</code> <p>Output FASTA to store the chunks into if no <code>individual_file_prefix</code> is provided.</p> required <code>individual_file_prefix</code> <code>Optional[Path]</code> <p>A file path prefix including dirs and filenames part to use as a     first part of the chunk file name.</p> required <code>agp_output_file</code> <code>Optional[str]</code> <p>Output AGP file to store the map for the chunking procedure if present and non-empty.</p> <code>None</code> <code>n_sequence_len</code> <code>int</code> <p>Length of the stretch of <code>N</code>s to split at; not slitting on <code>N</code>s if 0.</p> <code>0</code> <code>chunk_sfx</code> <code>str</code> <p>A string to put between the original sequence name and the chunk suffix.</p> <code>'ens_chunk'</code> <code>append_offset_to_chunk_name</code> <code>Optional[bool]</code> <p>Append 0-based offset in the form of <code>_off_{offset}</code> to the chunk name.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def chunk_fasta(\n    input_fasta_file: str,\n    chunk_size: int,\n    chunk_size_tolerated: int,\n    out_file_name: str,\n    individual_file_prefix: Optional[Path],\n    *,\n    agp_output_file: Optional[str] = None,\n    n_sequence_len: int = 0,\n    chunk_sfx: str = \"ens_chunk\",\n    append_offset_to_chunk_name: Optional[bool] = None,\n) -&gt; None:\n    \"\"\"Open `input_fasta_file` and split into a smaller chunks based on\n    stretches of \"N\"s and then based on chunk_size_tolerated and store either to\n    the `out_file_name` if no `individual_file_prefix` is provided or\n    store each individual chunk to a file starting with non-empty `individual_file_prefix`.\n\n    Args:\n        input_fasta_file: Input FASTA\n        chunk_size: Size of the chunks to split into.\n        chunk_size_tolerated: If more flexibility allowed, use this as the maximum size of a chunk.\n        out_file_name: Output FASTA to store the chunks into if no `individual_file_prefix` is provided.\n        individual_file_prefix: A file path prefix including dirs and filenames part to use as a\n                first part of the chunk file name.\n        agp_output_file: Output AGP file to store the map for the chunking procedure if present and non-empty.\n        n_sequence_len: Length of the stretch of `N`s to split at; not slitting on `N`s if 0.\n        chunk_sfx: A string to put between the original sequence name and the chunk suffix.\n        append_offset_to_chunk_name: Append 0-based offset in the form of `_off_{offset}` to the chunk name.\n    \"\"\"\n\n    # process input fasta\n    with open_gz_file(input_fasta_file) as fasta:\n        logging.info(\n            f\"splitting sequences from '{input_fasta_file}', chunk size {chunk_size:_}, \\\n                splitting on {n_sequence_len} Ns (0 -- disabled)\"\n        )\n        # do not open a joined file if you plan to open many individual ones\n        with (\n            individual_file_prefix\n            and nullcontext(None)\n            or open(out_file_name, \"wt\", encoding=\"utf-8\") as out_file_joined\n        ):\n            agp_lines = chunk_fasta_stream(\n                fasta,\n                chunk_size,\n                chunk_size_tolerated,\n                out_file_joined,\n                individual_file_prefix,\n                n_sequence_len=n_sequence_len,\n                chunk_sfx=chunk_sfx,\n                append_offset_to_chunk_name=append_offset_to_chunk_name,\n            )\n\n        # dump AGP\n        if agp_output_file:\n            with open(agp_output_file, \"w\", encoding=\"utf-8\") as agp_out:\n                agp_out.write(\"\\n\".join(agp_lines) + \"\\n\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.chunk_fasta_stream","title":"<code>chunk_fasta_stream(input_fasta, chunk_size, chunk_size_tolerated, output_fasta, individual_file_prefix, *, n_sequence_len=0, chunk_sfx='ens_chunk', append_offset_to_chunk_name=None, open_individual=_individual_file_opener)</code>","text":"<p>Split input TextIOWrapper stream with fasta into a smaller chunks based on stretches of \"N\"s and then based on chunk_size_tolerated and store either to the output_fasta stream (if valid) or to the files created by invocation of the <code>open_individual</code> callable.</p> <p>Parameters:</p> Name Type Description Default <code>input_fasta</code> <code>TextIOWrapper</code> <p>Input FASTA as the TextIOWrapper stream.</p> required <code>chunk_size</code> <code>int</code> <p>Size of the chunks to split into.</p> required <code>chunk_size_tolerated</code> <code>int</code> <p>If more flexibility allowed, use this as the maximum size of a chunk.</p> required <code>output_fasta</code> <code>Optional[TextIOWrapper] | nullcontext[Any]</code> <p>Output FASTA TextIOWrapper stream to store the chunks into,     if none or False, <code>open_individual</code> is used (see below).</p> required <code>individual_file_prefix</code> <code>Optional[Path]</code> <p>A file path prefix including dirs and filenames part to use as a     first part of the chunk file name.</p> required <code>n_sequence_len</code> <code>int</code> <p>Length of the stretch of <code>N</code>s to split at; not slitting on <code>N</code>s if 0.</p> <code>0</code> <code>chunk_sfx</code> <code>str</code> <p>A string to put between the original sequence name and the chunk suffix.</p> <code>'ens_chunk'</code> <code>append_offset_to_chunk_name</code> <code>Optional[bool]</code> <p>A flag to append 0-based offset (<code>_off_{offset}</code>) to the chunk name.</p> <code>None</code> <code>open_individual</code> <code>Callable[[str], ContextManager[Any]]</code> <p>A callable taking filename as an input to generate the output file for     individual contig if out_put FASTA is <code>false</code> of <code>None</code>, folders should be preexisting.</p> <code>_individual_file_opener</code> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def chunk_fasta_stream(\n    input_fasta: TextIOWrapper,\n    chunk_size: int,\n    chunk_size_tolerated: int,\n    output_fasta: Optional[TextIOWrapper] | nullcontext[Any],\n    individual_file_prefix: Optional[Path],\n    *,\n    n_sequence_len: int = 0,\n    chunk_sfx: str = \"ens_chunk\",\n    append_offset_to_chunk_name: Optional[bool] = None,\n    open_individual: Callable[[str], ContextManager[Any]] = _individual_file_opener,\n) -&gt; list[str]:\n    \"\"\"Split input TextIOWrapper stream with fasta into a smaller chunks based on\n    stretches of \"N\"s and then based on chunk_size_tolerated and store either to\n    the output_fasta stream (if valid) or to the files created by\n    invocation of the `open_individual` callable.\n\n    Args:\n        input_fasta: Input FASTA as the TextIOWrapper stream.\n        chunk_size: Size of the chunks to split into.\n        chunk_size_tolerated: If more flexibility allowed, use this as the maximum size of a chunk.\n        output_fasta: Output FASTA TextIOWrapper stream to store the chunks into,\n                if none or False, `open_individual` is used (see below).\n        individual_file_prefix: A file path prefix including dirs and filenames part to use as a\n                first part of the chunk file name.\n        n_sequence_len: Length of the stretch of `N`s to split at; not slitting on `N`s if 0.\n        chunk_sfx: A string to put between the original sequence name and the chunk suffix.\n        append_offset_to_chunk_name: A flag to append 0-based offset (`_off_{offset}`) to the chunk name.\n        open_individual: A callable taking filename as an input to generate the output file for\n                individual contig if out_put FASTA is `false` of `None`, folders should be preexisting.\n    \"\"\"\n\n    chunk_size_tolerated = max(chunk_size, chunk_size_tolerated)\n    # output agp_lines list\n    agp_lines = []\n\n    # make sure not used for n_seq &lt;= 0\n    n_split_regex = None\n    if n_sequence_len &gt; 0:\n        pattern = f\"(N{{{n_sequence_len},}})\"\n        n_split_regex = re.compile(pattern)\n\n    # process stream\n    fasta_parser = SeqIO.parse(input_fasta, \"fasta\")\n    for rec_count, rec in enumerate(fasta_parser, start=1):\n        rec_name = str(rec.name)\n\n        ends = split_seq_by_n(str(rec.seq), n_split_regex)\n        ends = split_seq_by_chunk_size(ends, chunk_size, chunk_size_tolerated)\n\n        offset = 0\n        for chunk, chunk_end in enumerate(ends, start=1):\n            chunk_name = f\"{rec_name}_{chunk_sfx}_{chunk:03d}\"\n            chunk_file_name = \"\"\n            if individual_file_prefix:\n                chunk_file_name = f\"{individual_file_prefix}.{rec_count:03d}.{chunk:03d}.fa\"\n            if append_offset_to_chunk_name:\n                chunk_name += f\"_off_{offset}\"\n\n            rec_from = offset + 1\n            rec_to = chunk_end\n            chunk_len = chunk_end - offset\n\n            # form agp lines\n            agp_line = f\"{rec_name}\\t{rec_from}\\t{rec_to}\\t{chunk}\\tW\\t{chunk_name}\\t1\\t{chunk_len}\\t+\"\n            agp_lines.append(agp_line)\n\n            # use agp lines as fasta description\n            agp_line = agp_line.replace(\"\\t\", \" \")\n            logging.info(f\"Dumping {chunk_name} AGP {agp_line}\")\n\n            # get slice and put it out\n            tmp_record = SeqRecord(\n                Seq(rec.seq[offset:chunk_end]),\n                id=chunk_name,\n                description=f\"AGP {agp_line}\",\n                name=\"\",\n            )\n\n            # if user specified chunks -- store each chunk in an individual output file\n            with output_fasta and nullcontext(output_fasta) or open_individual(chunk_file_name) as out_file:\n                out_file.write(tmp_record.format(\"fasta\"))  # type: ignore[union-attr]\n\n            del tmp_record\n            offset = chunk_end\n\n    return agp_lines\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.get_peptides_to_exclude","title":"<code>get_peptides_to_exclude(genbank_path, seqr_to_exclude)</code>","text":"<p>Extract peptide IDs from a genbank file that are in a given list of seq regions</p> Source code in <code>src/python/ensembl/io/genomio/fasta/process.py</code> <pre><code>def get_peptides_to_exclude(genbank_path: PathLike, seqr_to_exclude: Set[str]) -&gt; Set[str]:\n    \"\"\"\n    Extract peptide IDs from a genbank file that are in a given list of seq regions\n    \"\"\"\n    peptides_to_exclude: Set[str] = set()\n    with open_gz_file(genbank_path) as in_genbank:\n        for record in SeqIO.parse(in_genbank, \"genbank\"):\n            if record.id in seqr_to_exclude:\n                logging.info(f\"Skip sequence {record.id}\")\n                for feat in record.features:\n                    if feat.type == \"CDS\":\n                        if \"protein_id\" in feat.qualifiers:\n                            feat_id = feat.qualifiers[\"protein_id\"]\n                            peptides_to_exclude.add(feat_id[0])\n                        else:\n                            raise FastaParserError(f\"Peptide without peptide ID ${feat}\")\n    return peptides_to_exclude\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.get_tolerated_size","title":"<code>get_tolerated_size(size, tolerance)</code>","text":"<p>Calculate max tolerated size of the chunk based on initial size and percent of allowed deviation.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Base chunk size</p> required <code>tolerance</code> <code>int</code> <p>Percent of allowed deviance as integer.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Maximum tolerated chunk size.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def get_tolerated_size(size: int, tolerance: int) -&gt; int:\n    \"\"\"Calculate max tolerated size of the chunk based on initial size and percent of allowed deviation.\n\n    Args:\n        size: Base chunk size\n        tolerance: Percent of allowed deviance as integer.\n\n    Returns:\n        Maximum tolerated chunk size.\n    \"\"\"\n    tolerance = max(tolerance, 0)\n\n    tolerated_size = size\n    tolerated_size += size * tolerance // 100\n    return tolerated_size\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.prep_fasta_data","title":"<code>prep_fasta_data(fasta_infile, genbank_infile, fasta_outfile, peptide_mode=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>fasta_file</code> <p>Input FASTA file - DNA / Protein</p> required <code>genbank_infile</code> <code>Optional[PathLike]</code> <p>Input GenBank GBFF file (Optional)</p> required <code>fasta_outfile</code> <code>PathLike</code> <p>Output FASTA sequence file.</p> required <code>peptide_mode</code> <code>bool</code> <p>Process proteins instead of DNA</p> <code>False</code> Source code in <code>src/python/ensembl/io/genomio/fasta/process.py</code> <pre><code>def prep_fasta_data(\n    fasta_infile: PathLike,\n    genbank_infile: Optional[PathLike],\n    fasta_outfile: PathLike,\n    peptide_mode: bool = False,\n) -&gt; None:\n    \"\"\"\n    Args:\n        fasta_file: Input FASTA file - DNA / Protein\n        genbank_infile: Input GenBank GBFF file (Optional)\n        fasta_outfile: Output FASTA sequence file.\n        peptide_mode: Process proteins instead of DNA\n    \"\"\"\n    file_path = Path(fasta_infile)\n\n    to_exclude = set()\n    seqr_to_exclude = set(exclude_seq_regions)\n    if peptide_mode:\n        if genbank_infile is not None:\n            genbank_path = Path(genbank_infile)\n            to_exclude = get_peptides_to_exclude(genbank_path, seqr_to_exclude)\n    else:\n        to_exclude = seqr_to_exclude\n\n    # Copy and filter\n    records = []\n\n    # Final path\n    with open_gz_file(file_path) as in_fasta:\n        for record in SeqIO.parse(in_fasta, \"fasta\"):\n            if record.id in to_exclude:\n                logging.info(f\"Skip record ${record.id}\")\n            else:\n                records.append(record)\n    with Path(fasta_outfile).open(\"w\") as out_fasta:\n        SeqIO.write(records, out_fasta, \"fasta\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.prepare_out_dir_for_individuals","title":"<code>prepare_out_dir_for_individuals(dir_name, file_part)</code>","text":"<p>Creates <code>dir_name</code> (including upstream dirs) and returns its paths with the <code>file_part</code> appended.</p> <p>Parameters:</p> Name Type Description Default <code>dir_name</code> <code>Path</code> <p>Directory to create.</p> required <code>file_part</code> <code>str</code> <p>File part to append.</p> required <p>Returns:</p> Type Description <code>Optional[Path]</code> <p><code>dir_name</code> with appended <code>file_part</code>.</p> Throws <p>exception if not able to create directory.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def prepare_out_dir_for_individuals(dir_name: Path, file_part: str) -&gt; Optional[Path]:\n    \"\"\"Creates `dir_name` (including upstream dirs) and returns its paths with the `file_part` appended.\n\n    Args:\n        dir_name: Directory to create.\n        file_part: File part to append.\n\n    Returns:\n        `dir_name` with appended `file_part`.\n\n    Throws:\n        exception if not able to create directory.\n    \"\"\"\n    file_prefix = None\n    if dir_name:\n        dir_name.mkdir(parents=True, exist_ok=True)\n        file_prefix = Path(dir_name, file_part)\n    return file_prefix\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.split_seq_by_chunk_size","title":"<code>split_seq_by_chunk_size(ends, chunk_size, tolerated_size=None)</code>","text":"<p>Split list of end coordinates, to form chunks not longer then chunk_size.</p> <p>Parameters:</p> Name Type Description Default <code>ends</code> <code>list[int]</code> <p>List of one or more chunk(s) to split a sequence.</p> required <code>chunk_size</code> <code>int</code> <p>Size of chunks to split a sequence into.</p> required <code>tolerated_size</code> <code>Optional[int]</code> <p>Threshold to use instead of <code>chunk_size</code> to determine when to split a sequence.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>List with open coordinates of the chunks ends (or with only a single sequence length).</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def split_seq_by_chunk_size(\n    ends: list[int], chunk_size: int, tolerated_size: Optional[int] = None\n) -&gt; list[int]:\n    \"\"\"Split list of end coordinates, to form chunks not longer then\n    chunk_size.\n\n    Args:\n        ends: List of one or more chunk(s) to split a sequence.\n        chunk_size: Size of chunks to split a sequence into.\n        tolerated_size: Threshold to use instead of `chunk_size` to determine when to split a sequence.\n\n    Returns:\n        List with open coordinates of the chunks ends (or with only a single sequence length).\n    \"\"\"\n    if not ends or chunk_size &lt; 1:\n        return ends\n\n    if tolerated_size is None or tolerated_size &lt; chunk_size:\n        tolerated_size = chunk_size\n    result = []\n    offset = 0\n    for chunk_end in ends:\n        chunk_len = chunk_end - offset\n        if chunk_len &gt; tolerated_size:\n            # exclude starts, as they are 0 or pushed as previous chunk_ends\n            result += list(range(offset, chunk_end, chunk_size))[1:]\n        result.append(chunk_end)\n        offset = chunk_end\n    return result\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/#ensembl.io.genomio.fasta.split_seq_by_n","title":"<code>split_seq_by_n(seq, split_pattern)</code>","text":"<p>Split a string into chunks at the positions where the pattern is found. <code>N</code>s (pattern) are appended to the chunk on the left.</p> <p>The end point of each chunk will correspond to the end of the matching part.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>str</code> <p>Sequence to be split into chunks.</p> required <code>split_pattern</code> <code>Optional[Pattern]</code> <p>Pattern to search in the sequence.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>List with open coordinates of the chunks ends (or with only a single sequence length).</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def split_seq_by_n(seq: str, split_pattern: Optional[re.Pattern]) -&gt; list[int]:\n    \"\"\"Split a string into chunks at the positions where the\n    pattern is found. `N`s (pattern) are appended to the chunk on the left.\n\n    The end point of each chunk will correspond to the end\n    of the matching part.\n\n    Args:\n        seq: Sequence to be split into chunks.\n        split_pattern: Pattern to search in the sequence.\n\n    Returns:\n        List with open coordinates of the chunks ends (or with only a single sequence length).\n    \"\"\"\n    seq_len = len(seq)\n    if not split_pattern:\n        return [seq_len]\n    split_points = [m.end() for m in split_pattern.finditer(seq)]\n    if not split_points or split_points[-1] != seq_len:\n        split_points.append(seq_len)\n    return split_points\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/","title":"chunk","text":""},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk","title":"<code>ensembl.io.genomio.fasta.chunk</code>","text":"<p>Split a set of nucleotide sequence(s) (.fasta, .gz) into smaller chunks.</p>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk.check_chunk_size_and_tolerance","title":"<code>check_chunk_size_and_tolerance(chunk_size, chunk_tolerance, error_f=_on_value_error)</code>","text":"<p>Check the chunk size and the tolerance are positive and chunk size is not too small</p> <p>Parameters:</p> Name Type Description Default <code>chunk_size</code> <code>int</code> <p>Chunk size to check</p> required <code>chunk_tolerance</code> <code>int</code> <p>Chunk tolerance to check</p> required Dies <p>If checks failed dies with <code>parser.error</code></p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def check_chunk_size_and_tolerance(\n    chunk_size: int,\n    chunk_tolerance: int,\n    error_f: Callable[[str], None] = _on_value_error,\n) -&gt; None:\n    \"\"\"Check the chunk size and the tolerance are positive and chunk size is not too small\n\n    Args:\n        chunk_size: Chunk size to check\n        chunk_tolerance: Chunk tolerance to check\n\n    Dies:\n        If checks failed dies with `parser.error`\n    \"\"\"\n    if chunk_size &lt; 50_000:\n        error_f(f\"wrong '--chunk_size' value: '{chunk_size}'. should be greater then 50_000. exiting...\")\n    if chunk_tolerance &lt; 0:\n        error_f(f\"wrong '--chunk_tolerance' value: '{chunk_tolerance}'. can't be less then 0. exiting...\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk.chunk_fasta","title":"<code>chunk_fasta(input_fasta_file, chunk_size, chunk_size_tolerated, out_file_name, individual_file_prefix, *, agp_output_file=None, n_sequence_len=0, chunk_sfx='ens_chunk', append_offset_to_chunk_name=None)</code>","text":"<p>Open <code>input_fasta_file</code> and split into a smaller chunks based on stretches of \"N\"s and then based on chunk_size_tolerated and store either to the <code>out_file_name</code> if no <code>individual_file_prefix</code> is provided or store each individual chunk to a file starting with non-empty <code>individual_file_prefix</code>.</p> <p>Parameters:</p> Name Type Description Default <code>input_fasta_file</code> <code>str</code> <p>Input FASTA</p> required <code>chunk_size</code> <code>int</code> <p>Size of the chunks to split into.</p> required <code>chunk_size_tolerated</code> <code>int</code> <p>If more flexibility allowed, use this as the maximum size of a chunk.</p> required <code>out_file_name</code> <code>str</code> <p>Output FASTA to store the chunks into if no <code>individual_file_prefix</code> is provided.</p> required <code>individual_file_prefix</code> <code>Optional[Path]</code> <p>A file path prefix including dirs and filenames part to use as a     first part of the chunk file name.</p> required <code>agp_output_file</code> <code>Optional[str]</code> <p>Output AGP file to store the map for the chunking procedure if present and non-empty.</p> <code>None</code> <code>n_sequence_len</code> <code>int</code> <p>Length of the stretch of <code>N</code>s to split at; not slitting on <code>N</code>s if 0.</p> <code>0</code> <code>chunk_sfx</code> <code>str</code> <p>A string to put between the original sequence name and the chunk suffix.</p> <code>'ens_chunk'</code> <code>append_offset_to_chunk_name</code> <code>Optional[bool]</code> <p>Append 0-based offset in the form of <code>_off_{offset}</code> to the chunk name.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def chunk_fasta(\n    input_fasta_file: str,\n    chunk_size: int,\n    chunk_size_tolerated: int,\n    out_file_name: str,\n    individual_file_prefix: Optional[Path],\n    *,\n    agp_output_file: Optional[str] = None,\n    n_sequence_len: int = 0,\n    chunk_sfx: str = \"ens_chunk\",\n    append_offset_to_chunk_name: Optional[bool] = None,\n) -&gt; None:\n    \"\"\"Open `input_fasta_file` and split into a smaller chunks based on\n    stretches of \"N\"s and then based on chunk_size_tolerated and store either to\n    the `out_file_name` if no `individual_file_prefix` is provided or\n    store each individual chunk to a file starting with non-empty `individual_file_prefix`.\n\n    Args:\n        input_fasta_file: Input FASTA\n        chunk_size: Size of the chunks to split into.\n        chunk_size_tolerated: If more flexibility allowed, use this as the maximum size of a chunk.\n        out_file_name: Output FASTA to store the chunks into if no `individual_file_prefix` is provided.\n        individual_file_prefix: A file path prefix including dirs and filenames part to use as a\n                first part of the chunk file name.\n        agp_output_file: Output AGP file to store the map for the chunking procedure if present and non-empty.\n        n_sequence_len: Length of the stretch of `N`s to split at; not slitting on `N`s if 0.\n        chunk_sfx: A string to put between the original sequence name and the chunk suffix.\n        append_offset_to_chunk_name: Append 0-based offset in the form of `_off_{offset}` to the chunk name.\n    \"\"\"\n\n    # process input fasta\n    with open_gz_file(input_fasta_file) as fasta:\n        logging.info(\n            f\"splitting sequences from '{input_fasta_file}', chunk size {chunk_size:_}, \\\n                splitting on {n_sequence_len} Ns (0 -- disabled)\"\n        )\n        # do not open a joined file if you plan to open many individual ones\n        with (\n            individual_file_prefix\n            and nullcontext(None)\n            or open(out_file_name, \"wt\", encoding=\"utf-8\") as out_file_joined\n        ):\n            agp_lines = chunk_fasta_stream(\n                fasta,\n                chunk_size,\n                chunk_size_tolerated,\n                out_file_joined,\n                individual_file_prefix,\n                n_sequence_len=n_sequence_len,\n                chunk_sfx=chunk_sfx,\n                append_offset_to_chunk_name=append_offset_to_chunk_name,\n            )\n\n        # dump AGP\n        if agp_output_file:\n            with open(agp_output_file, \"w\", encoding=\"utf-8\") as agp_out:\n                agp_out.write(\"\\n\".join(agp_lines) + \"\\n\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk.chunk_fasta_stream","title":"<code>chunk_fasta_stream(input_fasta, chunk_size, chunk_size_tolerated, output_fasta, individual_file_prefix, *, n_sequence_len=0, chunk_sfx='ens_chunk', append_offset_to_chunk_name=None, open_individual=_individual_file_opener)</code>","text":"<p>Split input TextIOWrapper stream with fasta into a smaller chunks based on stretches of \"N\"s and then based on chunk_size_tolerated and store either to the output_fasta stream (if valid) or to the files created by invocation of the <code>open_individual</code> callable.</p> <p>Parameters:</p> Name Type Description Default <code>input_fasta</code> <code>TextIOWrapper</code> <p>Input FASTA as the TextIOWrapper stream.</p> required <code>chunk_size</code> <code>int</code> <p>Size of the chunks to split into.</p> required <code>chunk_size_tolerated</code> <code>int</code> <p>If more flexibility allowed, use this as the maximum size of a chunk.</p> required <code>output_fasta</code> <code>Optional[TextIOWrapper] | nullcontext[Any]</code> <p>Output FASTA TextIOWrapper stream to store the chunks into,     if none or False, <code>open_individual</code> is used (see below).</p> required <code>individual_file_prefix</code> <code>Optional[Path]</code> <p>A file path prefix including dirs and filenames part to use as a     first part of the chunk file name.</p> required <code>n_sequence_len</code> <code>int</code> <p>Length of the stretch of <code>N</code>s to split at; not slitting on <code>N</code>s if 0.</p> <code>0</code> <code>chunk_sfx</code> <code>str</code> <p>A string to put between the original sequence name and the chunk suffix.</p> <code>'ens_chunk'</code> <code>append_offset_to_chunk_name</code> <code>Optional[bool]</code> <p>A flag to append 0-based offset (<code>_off_{offset}</code>) to the chunk name.</p> <code>None</code> <code>open_individual</code> <code>Callable[[str], ContextManager[Any]]</code> <p>A callable taking filename as an input to generate the output file for     individual contig if out_put FASTA is <code>false</code> of <code>None</code>, folders should be preexisting.</p> <code>_individual_file_opener</code> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def chunk_fasta_stream(\n    input_fasta: TextIOWrapper,\n    chunk_size: int,\n    chunk_size_tolerated: int,\n    output_fasta: Optional[TextIOWrapper] | nullcontext[Any],\n    individual_file_prefix: Optional[Path],\n    *,\n    n_sequence_len: int = 0,\n    chunk_sfx: str = \"ens_chunk\",\n    append_offset_to_chunk_name: Optional[bool] = None,\n    open_individual: Callable[[str], ContextManager[Any]] = _individual_file_opener,\n) -&gt; list[str]:\n    \"\"\"Split input TextIOWrapper stream with fasta into a smaller chunks based on\n    stretches of \"N\"s and then based on chunk_size_tolerated and store either to\n    the output_fasta stream (if valid) or to the files created by\n    invocation of the `open_individual` callable.\n\n    Args:\n        input_fasta: Input FASTA as the TextIOWrapper stream.\n        chunk_size: Size of the chunks to split into.\n        chunk_size_tolerated: If more flexibility allowed, use this as the maximum size of a chunk.\n        output_fasta: Output FASTA TextIOWrapper stream to store the chunks into,\n                if none or False, `open_individual` is used (see below).\n        individual_file_prefix: A file path prefix including dirs and filenames part to use as a\n                first part of the chunk file name.\n        n_sequence_len: Length of the stretch of `N`s to split at; not slitting on `N`s if 0.\n        chunk_sfx: A string to put between the original sequence name and the chunk suffix.\n        append_offset_to_chunk_name: A flag to append 0-based offset (`_off_{offset}`) to the chunk name.\n        open_individual: A callable taking filename as an input to generate the output file for\n                individual contig if out_put FASTA is `false` of `None`, folders should be preexisting.\n    \"\"\"\n\n    chunk_size_tolerated = max(chunk_size, chunk_size_tolerated)\n    # output agp_lines list\n    agp_lines = []\n\n    # make sure not used for n_seq &lt;= 0\n    n_split_regex = None\n    if n_sequence_len &gt; 0:\n        pattern = f\"(N{{{n_sequence_len},}})\"\n        n_split_regex = re.compile(pattern)\n\n    # process stream\n    fasta_parser = SeqIO.parse(input_fasta, \"fasta\")\n    for rec_count, rec in enumerate(fasta_parser, start=1):\n        rec_name = str(rec.name)\n\n        ends = split_seq_by_n(str(rec.seq), n_split_regex)\n        ends = split_seq_by_chunk_size(ends, chunk_size, chunk_size_tolerated)\n\n        offset = 0\n        for chunk, chunk_end in enumerate(ends, start=1):\n            chunk_name = f\"{rec_name}_{chunk_sfx}_{chunk:03d}\"\n            chunk_file_name = \"\"\n            if individual_file_prefix:\n                chunk_file_name = f\"{individual_file_prefix}.{rec_count:03d}.{chunk:03d}.fa\"\n            if append_offset_to_chunk_name:\n                chunk_name += f\"_off_{offset}\"\n\n            rec_from = offset + 1\n            rec_to = chunk_end\n            chunk_len = chunk_end - offset\n\n            # form agp lines\n            agp_line = f\"{rec_name}\\t{rec_from}\\t{rec_to}\\t{chunk}\\tW\\t{chunk_name}\\t1\\t{chunk_len}\\t+\"\n            agp_lines.append(agp_line)\n\n            # use agp lines as fasta description\n            agp_line = agp_line.replace(\"\\t\", \" \")\n            logging.info(f\"Dumping {chunk_name} AGP {agp_line}\")\n\n            # get slice and put it out\n            tmp_record = SeqRecord(\n                Seq(rec.seq[offset:chunk_end]),\n                id=chunk_name,\n                description=f\"AGP {agp_line}\",\n                name=\"\",\n            )\n\n            # if user specified chunks -- store each chunk in an individual output file\n            with output_fasta and nullcontext(output_fasta) or open_individual(chunk_file_name) as out_file:\n                out_file.write(tmp_record.format(\"fasta\"))  # type: ignore[union-attr]\n\n            del tmp_record\n            offset = chunk_end\n\n    return agp_lines\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk.get_tolerated_size","title":"<code>get_tolerated_size(size, tolerance)</code>","text":"<p>Calculate max tolerated size of the chunk based on initial size and percent of allowed deviation.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Base chunk size</p> required <code>tolerance</code> <code>int</code> <p>Percent of allowed deviance as integer.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Maximum tolerated chunk size.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def get_tolerated_size(size: int, tolerance: int) -&gt; int:\n    \"\"\"Calculate max tolerated size of the chunk based on initial size and percent of allowed deviation.\n\n    Args:\n        size: Base chunk size\n        tolerance: Percent of allowed deviance as integer.\n\n    Returns:\n        Maximum tolerated chunk size.\n    \"\"\"\n    tolerance = max(tolerance, 0)\n\n    tolerated_size = size\n    tolerated_size += size * tolerance // 100\n    return tolerated_size\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk.main","title":"<code>main()</code>","text":"<p>Module entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module entry-point.\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument_src_path(\n        \"--fasta_dna\",\n        required=True,\n        metavar=\"input[.fa | .gz]\",\n        help=\"Raw or compressed (.gz) FASTA file with DNA sequences to be split\",\n    )\n    parser.add_argument(\n        \"--out\",\n        required=False,\n        default=\"chunks.fna\",\n        help=\"Chunks output file\",\n    )\n    parser.add_argument(\n        \"--individual_out_dir\",\n        required=False,\n        default=None,\n        type=Path,\n        help=\"Output directory for writing files with individual chunks to. \\\n            If provided,`--out` value used as a filename prefix\",\n    )\n    parser.add_argument_dst_path(\n        \"--agp_output_file\",\n        required=False,\n        default=None,\n        help=\"AGP file with chunks to contigs mapping.\",\n    )\n    parser.add_argument(\n        \"--chunk_size\",\n        required=False,\n        default=100_000_000,\n        metavar=\"100_000_000\",\n        type=int,\n        help=\"Maximum chunk size (should be greater then 50k).\",\n    )\n    parser.add_argument(\n        \"--chunk_sfx\",\n        required=False,\n        default=\"ens_chunk\",\n        type=str,\n        help=\"Added to contig ID before chunk number.\",\n    )\n    parser.add_argument(\n        \"--chunk_tolerance\",\n        required=False,\n        default=0,\n        type=int,\n        help=\"Chunk size tolerance percentage. If the to-be-written chunk is longer \\\n            than the defined chunk size by less than the specified tolerance percentage,\\\n            it will not be split.\",\n    )\n    parser.add_argument(\n        \"--n_seq\",\n        required=False,\n        default=0,\n        type=int,\n        help=\"Split into chunks at positions of at least this number of N characters.\",\n    )\n    parser.add_argument(\n        \"--add_offset\",\n        required=False,\n        action=\"store_true\",\n        help=\"Append zero-based offset to chunk name ('_off_{offset}').\",\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    check_chunk_size_and_tolerance(args.chunk_size, args.chunk_tolerance, error_f=parser.error)\n\n    chunk_size_tolerated = get_tolerated_size(args.chunk_size, args.chunk_tolerance)\n\n    file_prefix = prepare_out_dir_for_individuals(args.individual_out_dir, args.out or args.fasta_dna)\n\n    chunk_fasta(\n        args.fasta_dna,\n        args.chunk_size,\n        chunk_size_tolerated,\n        args.out,\n        individual_file_prefix=file_prefix,\n        agp_output_file=args.agp_output_file,\n        n_sequence_len=args.n_seq,\n        chunk_sfx=args.chunk_sfx,\n        append_offset_to_chunk_name=args.add_offset,\n    )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk.prepare_out_dir_for_individuals","title":"<code>prepare_out_dir_for_individuals(dir_name, file_part)</code>","text":"<p>Creates <code>dir_name</code> (including upstream dirs) and returns its paths with the <code>file_part</code> appended.</p> <p>Parameters:</p> Name Type Description Default <code>dir_name</code> <code>Path</code> <p>Directory to create.</p> required <code>file_part</code> <code>str</code> <p>File part to append.</p> required <p>Returns:</p> Type Description <code>Optional[Path]</code> <p><code>dir_name</code> with appended <code>file_part</code>.</p> Throws <p>exception if not able to create directory.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def prepare_out_dir_for_individuals(dir_name: Path, file_part: str) -&gt; Optional[Path]:\n    \"\"\"Creates `dir_name` (including upstream dirs) and returns its paths with the `file_part` appended.\n\n    Args:\n        dir_name: Directory to create.\n        file_part: File part to append.\n\n    Returns:\n        `dir_name` with appended `file_part`.\n\n    Throws:\n        exception if not able to create directory.\n    \"\"\"\n    file_prefix = None\n    if dir_name:\n        dir_name.mkdir(parents=True, exist_ok=True)\n        file_prefix = Path(dir_name, file_part)\n    return file_prefix\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk.split_seq_by_chunk_size","title":"<code>split_seq_by_chunk_size(ends, chunk_size, tolerated_size=None)</code>","text":"<p>Split list of end coordinates, to form chunks not longer then chunk_size.</p> <p>Parameters:</p> Name Type Description Default <code>ends</code> <code>list[int]</code> <p>List of one or more chunk(s) to split a sequence.</p> required <code>chunk_size</code> <code>int</code> <p>Size of chunks to split a sequence into.</p> required <code>tolerated_size</code> <code>Optional[int]</code> <p>Threshold to use instead of <code>chunk_size</code> to determine when to split a sequence.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>List with open coordinates of the chunks ends (or with only a single sequence length).</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def split_seq_by_chunk_size(\n    ends: list[int], chunk_size: int, tolerated_size: Optional[int] = None\n) -&gt; list[int]:\n    \"\"\"Split list of end coordinates, to form chunks not longer then\n    chunk_size.\n\n    Args:\n        ends: List of one or more chunk(s) to split a sequence.\n        chunk_size: Size of chunks to split a sequence into.\n        tolerated_size: Threshold to use instead of `chunk_size` to determine when to split a sequence.\n\n    Returns:\n        List with open coordinates of the chunks ends (or with only a single sequence length).\n    \"\"\"\n    if not ends or chunk_size &lt; 1:\n        return ends\n\n    if tolerated_size is None or tolerated_size &lt; chunk_size:\n        tolerated_size = chunk_size\n    result = []\n    offset = 0\n    for chunk_end in ends:\n        chunk_len = chunk_end - offset\n        if chunk_len &gt; tolerated_size:\n            # exclude starts, as they are 0 or pushed as previous chunk_ends\n            result += list(range(offset, chunk_end, chunk_size))[1:]\n        result.append(chunk_end)\n        offset = chunk_end\n    return result\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/chunk/#ensembl.io.genomio.fasta.chunk.split_seq_by_n","title":"<code>split_seq_by_n(seq, split_pattern)</code>","text":"<p>Split a string into chunks at the positions where the pattern is found. <code>N</code>s (pattern) are appended to the chunk on the left.</p> <p>The end point of each chunk will correspond to the end of the matching part.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>str</code> <p>Sequence to be split into chunks.</p> required <code>split_pattern</code> <code>Optional[Pattern]</code> <p>Pattern to search in the sequence.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>List with open coordinates of the chunks ends (or with only a single sequence length).</p> Source code in <code>src/python/ensembl/io/genomio/fasta/chunk.py</code> <pre><code>def split_seq_by_n(seq: str, split_pattern: Optional[re.Pattern]) -&gt; list[int]:\n    \"\"\"Split a string into chunks at the positions where the\n    pattern is found. `N`s (pattern) are appended to the chunk on the left.\n\n    The end point of each chunk will correspond to the end\n    of the matching part.\n\n    Args:\n        seq: Sequence to be split into chunks.\n        split_pattern: Pattern to search in the sequence.\n\n    Returns:\n        List with open coordinates of the chunks ends (or with only a single sequence length).\n    \"\"\"\n    seq_len = len(seq)\n    if not split_pattern:\n        return [seq_len]\n    split_points = [m.end() for m in split_pattern.finditer(seq)]\n    if not split_points or split_points[-1] != seq_len:\n        split_points.append(seq_len)\n    return split_points\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/","title":"compare","text":""},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare","title":"<code>ensembl.io.genomio.fasta.compare</code>","text":"<p>Compares the INSDC and core fasta files based on md5sum and ids.</p>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta","title":"<code>CompareFasta</code>","text":"<p>Read and compare the FASTA sequences.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>class CompareFasta:\n    \"\"\"Read and compare the FASTA sequences.\"\"\"\n\n    def __init__(self, fasta_ext: Path, fasta_core: Path, output_dir: Path) -&gt; None:\n        \"\"\"\n        Initialize the `CompareFasta` with input fasta files and output directory.\n\n        Args:\n            fasta_ext: Path to INSDC fasta file.\n            fasta_core: Path to core db fasta file.\n            output_dir: Directory where comparison logs will be stored.\n\n        \"\"\"\n        self.fasta_ext = Path(fasta_ext)\n        self.fasta_core = Path(fasta_core)\n        self.output_dir = Path(output_dir)\n        self.comp: list[str] = []\n\n    def compare_seqs(self) -&gt; None:\n        \"\"\"Compare two FASTA files for common, unique, and differing sequences.\n        Use `write_results()` to generate a report.\n        \"\"\"\n        seq_ext = self.read_fasta(self.fasta_ext)\n        seq_core = self.read_fasta(self.fasta_core)\n\n        # Compare sequences\n        seq_ext_dict = self.build_seq_dict(seq_ext)\n        seq_core_dict = self.build_seq_dict(seq_core)\n\n        # Compare number of sequences\n        if len(seq_ext) != len(seq_core):\n            self.comp.append(\n                \"WARNING: Different number of sequences: \"\n                f\"fasta_ext [ n = {len(seq_ext)} ] -Vs- fasta_core [ n = {len(seq_core)} ]\"\n            )\n            logging.warning(\"Different number of sequences: fasta_ext compared to fasta_core\")\n\n        common = self.find_common_groups(seq_ext_dict, seq_core_dict)\n\n        # Sequences that are not common\n        only1 = {seq: group for seq, group in seq_ext_dict.items() if not seq in seq_core_dict}\n\n        only2 = {seq: group for seq, group in seq_core_dict.items() if not seq in seq_ext_dict}\n\n        if only1:\n            self.comp.append(f\"Sequences only in Fasta_1: {', '.join([str(ids) for ids in only1.values()])}\")\n        if only2:\n            self.comp.append(f\"Sequences only in Fasta_2: {', '.join([str(ids) for ids in only2.values()])}\")\n\n        if common:\n            self.comp.append(f\"Common ids: {', '.join([str(common_ids) for common_ids in common.items()])}\")\n\n        # Check for sequences with extra Ns\n        if only1 and only2:\n            self.compare_seq_for_Ns(only1, only2)\n\n        # Write results to file\n        self.write_results()\n\n    def read_fasta(self, fasta_path: Path) -&gt; dict[str, str]:\n        \"\"\"Reads a FASTA file and returns a dictionary mapping sequence IDs to sequences.\n\n        Args:\n            fasta_path: Path to the FASTA file. Supports gzipped files.\n\n        Returns:\n            A dictionary where keys are sequence IDs and values are sequences with all non-CGTA\n                characters replaced by \"N\".\n        \"\"\"\n        logging.info(f\"Read fasta file {fasta_path}\")\n        sequences = {}\n        with open_gz_file(fasta_path) as fasta_fh:\n            for rec in SeqIO.parse(fasta_fh, \"fasta\"):\n                name = rec.id\n                sequences[name] = re.sub(r\"[^CGTA]\", \"N\", str(rec.seq.upper()))\n        return sequences\n\n    def build_seq_dict(self, seqs: dict[str, str]) -&gt; dict[str, SeqGroup]:\n        \"\"\"Builds a dictionary of unique sequences and their associated IDs, accounting for duplicates.\n\n        Args:\n            seqs: A dictionary where keys are sequence IDs and values are sequences.\n\n        Returns:\n            A dictionary where keys are unique sequences and values are `SeqGroup` objects that\n                group sequence IDs sharing the same sequence.\n        \"\"\"\n        seqs_dict: dict[str, SeqGroup] = {}\n        for name, seq in seqs.items():\n            if seq in seqs_dict:\n                seqs_dict[seq].add_id(name)\n            else:\n                seqs_dict[seq] = SeqGroup(name)\n\n        return seqs_dict\n\n    def find_common_groups(\n        self, seq_ext_dict: dict[str, SeqGroup], seq_core_dict: dict[str, SeqGroup]\n    ) -&gt; dict[str, str]:\n        \"\"\"Find common sequences between two dictionaries and group them.\n\n        Args:\n            seq_ext_dict: Dictionary of sequences from the first dataset.\n            seq_core_dict: Dictionary of sequences from the second dataset.\n\n        Returns:\n            A dictionary of common sequence mappings and a list of comparison results.\n\n        \"\"\"\n        common = {}\n\n        for seq1, group1 in seq_ext_dict.items():\n            if seq1 in seq_core_dict:\n                group2 = seq_core_dict[seq1]\n                # Check that the 2 groups have the same number of sequences\n                if group1.count == group2.count:\n                    if group1.count == 1:\n                        common[group1.ids[0]] = group2.ids[0]\n                    else:\n                        self.comp.append(f\"Matched 2 identical groups of sequences: {group1} and {group2}\")\n                        # Map each ID in group1 to a possible group2 ID\n                        possible_id2 = \" OR \".join(group2.ids)\n                        common.update({id1: possible_id2 for id1 in group1.ids})\n                else:\n                    self.comp.append(\n                        \"Matched 2 different groups of sequences\"\n                        f\" ({group1.count} vs {group2.count}): {group1} and {group2}\"\n                    )\n\n        return common\n\n    def write_results(self) -&gt; None:\n        \"\"\"Write the comparison results to a file in the output directory.\"\"\"\n        output_file = self.output_dir / \"compare.log\"\n        observed_compare = set()\n\n        logging.info(f\"Writing results to {output_file}\")\n        with open(output_file, \"w\") as out_fh:\n            for line in self.comp:\n                if line not in observed_compare:\n                    observed_compare.add(line)\n                    out_fh.write(str(line) + \"\\n\")\n\n    def compare_seq_for_Ns(self, only1: dict[str, SeqGroup], only2: dict[str, SeqGroup]) -&gt; None:\n        \"\"\"Compare sequences in `only1` and `only2` for differences in `N` content and length.\n\n        Args:\n            only1: Sequences unique to the first dataset, mapping sequence to group/identifier.\n            only2: Sequences unique to the second dataset, mapping sequence to group/identifier.\n\n        \"\"\"\n        # sequences which have extra N at the end\n        for seq_1, name1 in only1.items():\n            len1 = len(seq_1)\n            seq1_N = seq_1.count(\"N\")\n\n            for seq_2, name2 in only2.items():\n                len2 = len(seq_2)\n                seq2_N = seq_2.count(\"N\")\n\n                if abs(seq1_N - seq2_N) == abs(len1 - len2):\n                    self.comp.append(f\"Please check extra Ns added in the accessions {name1} and {name2}\")\n                else:\n                    self.comp.append(\n                        f\"ALERT INSERTIONS at the end or diff assembly level {name1} and {name2}\"\n                    )\n\n                if len1 == len2:\n                    if seq2_N &gt; seq1_N:\n                        self.comp.append(f\"your fasta_core has more Ns, check {name1} and {name2}\")\n                    else:\n                        self.comp.append(f\"sequences have the same length, check {name1} and {name2}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.comp","title":"<code>comp = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.fasta_core","title":"<code>fasta_core = Path(fasta_core)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.fasta_ext","title":"<code>fasta_ext = Path(fasta_ext)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.output_dir","title":"<code>output_dir = Path(output_dir)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.build_seq_dict","title":"<code>build_seq_dict(seqs)</code>","text":"<p>Builds a dictionary of unique sequences and their associated IDs, accounting for duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>seqs</code> <code>dict[str, str]</code> <p>A dictionary where keys are sequence IDs and values are sequences.</p> required <p>Returns:</p> Type Description <code>dict[str, SeqGroup]</code> <p>A dictionary where keys are unique sequences and values are <code>SeqGroup</code> objects that group sequence IDs sharing the same sequence.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def build_seq_dict(self, seqs: dict[str, str]) -&gt; dict[str, SeqGroup]:\n    \"\"\"Builds a dictionary of unique sequences and their associated IDs, accounting for duplicates.\n\n    Args:\n        seqs: A dictionary where keys are sequence IDs and values are sequences.\n\n    Returns:\n        A dictionary where keys are unique sequences and values are `SeqGroup` objects that\n            group sequence IDs sharing the same sequence.\n    \"\"\"\n    seqs_dict: dict[str, SeqGroup] = {}\n    for name, seq in seqs.items():\n        if seq in seqs_dict:\n            seqs_dict[seq].add_id(name)\n        else:\n            seqs_dict[seq] = SeqGroup(name)\n\n    return seqs_dict\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.compare_seq_for_Ns","title":"<code>compare_seq_for_Ns(only1, only2)</code>","text":"<p>Compare sequences in <code>only1</code> and <code>only2</code> for differences in <code>N</code> content and length.</p> <p>Parameters:</p> Name Type Description Default <code>only1</code> <code>dict[str, SeqGroup]</code> <p>Sequences unique to the first dataset, mapping sequence to group/identifier.</p> required <code>only2</code> <code>dict[str, SeqGroup]</code> <p>Sequences unique to the second dataset, mapping sequence to group/identifier.</p> required Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def compare_seq_for_Ns(self, only1: dict[str, SeqGroup], only2: dict[str, SeqGroup]) -&gt; None:\n    \"\"\"Compare sequences in `only1` and `only2` for differences in `N` content and length.\n\n    Args:\n        only1: Sequences unique to the first dataset, mapping sequence to group/identifier.\n        only2: Sequences unique to the second dataset, mapping sequence to group/identifier.\n\n    \"\"\"\n    # sequences which have extra N at the end\n    for seq_1, name1 in only1.items():\n        len1 = len(seq_1)\n        seq1_N = seq_1.count(\"N\")\n\n        for seq_2, name2 in only2.items():\n            len2 = len(seq_2)\n            seq2_N = seq_2.count(\"N\")\n\n            if abs(seq1_N - seq2_N) == abs(len1 - len2):\n                self.comp.append(f\"Please check extra Ns added in the accessions {name1} and {name2}\")\n            else:\n                self.comp.append(\n                    f\"ALERT INSERTIONS at the end or diff assembly level {name1} and {name2}\"\n                )\n\n            if len1 == len2:\n                if seq2_N &gt; seq1_N:\n                    self.comp.append(f\"your fasta_core has more Ns, check {name1} and {name2}\")\n                else:\n                    self.comp.append(f\"sequences have the same length, check {name1} and {name2}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.compare_seqs","title":"<code>compare_seqs()</code>","text":"<p>Compare two FASTA files for common, unique, and differing sequences. Use <code>write_results()</code> to generate a report.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def compare_seqs(self) -&gt; None:\n    \"\"\"Compare two FASTA files for common, unique, and differing sequences.\n    Use `write_results()` to generate a report.\n    \"\"\"\n    seq_ext = self.read_fasta(self.fasta_ext)\n    seq_core = self.read_fasta(self.fasta_core)\n\n    # Compare sequences\n    seq_ext_dict = self.build_seq_dict(seq_ext)\n    seq_core_dict = self.build_seq_dict(seq_core)\n\n    # Compare number of sequences\n    if len(seq_ext) != len(seq_core):\n        self.comp.append(\n            \"WARNING: Different number of sequences: \"\n            f\"fasta_ext [ n = {len(seq_ext)} ] -Vs- fasta_core [ n = {len(seq_core)} ]\"\n        )\n        logging.warning(\"Different number of sequences: fasta_ext compared to fasta_core\")\n\n    common = self.find_common_groups(seq_ext_dict, seq_core_dict)\n\n    # Sequences that are not common\n    only1 = {seq: group for seq, group in seq_ext_dict.items() if not seq in seq_core_dict}\n\n    only2 = {seq: group for seq, group in seq_core_dict.items() if not seq in seq_ext_dict}\n\n    if only1:\n        self.comp.append(f\"Sequences only in Fasta_1: {', '.join([str(ids) for ids in only1.values()])}\")\n    if only2:\n        self.comp.append(f\"Sequences only in Fasta_2: {', '.join([str(ids) for ids in only2.values()])}\")\n\n    if common:\n        self.comp.append(f\"Common ids: {', '.join([str(common_ids) for common_ids in common.items()])}\")\n\n    # Check for sequences with extra Ns\n    if only1 and only2:\n        self.compare_seq_for_Ns(only1, only2)\n\n    # Write results to file\n    self.write_results()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.find_common_groups","title":"<code>find_common_groups(seq_ext_dict, seq_core_dict)</code>","text":"<p>Find common sequences between two dictionaries and group them.</p> <p>Parameters:</p> Name Type Description Default <code>seq_ext_dict</code> <code>dict[str, SeqGroup]</code> <p>Dictionary of sequences from the first dataset.</p> required <code>seq_core_dict</code> <code>dict[str, SeqGroup]</code> <p>Dictionary of sequences from the second dataset.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>A dictionary of common sequence mappings and a list of comparison results.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def find_common_groups(\n    self, seq_ext_dict: dict[str, SeqGroup], seq_core_dict: dict[str, SeqGroup]\n) -&gt; dict[str, str]:\n    \"\"\"Find common sequences between two dictionaries and group them.\n\n    Args:\n        seq_ext_dict: Dictionary of sequences from the first dataset.\n        seq_core_dict: Dictionary of sequences from the second dataset.\n\n    Returns:\n        A dictionary of common sequence mappings and a list of comparison results.\n\n    \"\"\"\n    common = {}\n\n    for seq1, group1 in seq_ext_dict.items():\n        if seq1 in seq_core_dict:\n            group2 = seq_core_dict[seq1]\n            # Check that the 2 groups have the same number of sequences\n            if group1.count == group2.count:\n                if group1.count == 1:\n                    common[group1.ids[0]] = group2.ids[0]\n                else:\n                    self.comp.append(f\"Matched 2 identical groups of sequences: {group1} and {group2}\")\n                    # Map each ID in group1 to a possible group2 ID\n                    possible_id2 = \" OR \".join(group2.ids)\n                    common.update({id1: possible_id2 for id1 in group1.ids})\n            else:\n                self.comp.append(\n                    \"Matched 2 different groups of sequences\"\n                    f\" ({group1.count} vs {group2.count}): {group1} and {group2}\"\n                )\n\n    return common\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.read_fasta","title":"<code>read_fasta(fasta_path)</code>","text":"<p>Reads a FASTA file and returns a dictionary mapping sequence IDs to sequences.</p> <p>Parameters:</p> Name Type Description Default <code>fasta_path</code> <code>Path</code> <p>Path to the FASTA file. Supports gzipped files.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>A dictionary where keys are sequence IDs and values are sequences with all non-CGTA characters replaced by \"N\".</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def read_fasta(self, fasta_path: Path) -&gt; dict[str, str]:\n    \"\"\"Reads a FASTA file and returns a dictionary mapping sequence IDs to sequences.\n\n    Args:\n        fasta_path: Path to the FASTA file. Supports gzipped files.\n\n    Returns:\n        A dictionary where keys are sequence IDs and values are sequences with all non-CGTA\n            characters replaced by \"N\".\n    \"\"\"\n    logging.info(f\"Read fasta file {fasta_path}\")\n    sequences = {}\n    with open_gz_file(fasta_path) as fasta_fh:\n        for rec in SeqIO.parse(fasta_fh, \"fasta\"):\n            name = rec.id\n            sequences[name] = re.sub(r\"[^CGTA]\", \"N\", str(rec.seq.upper()))\n    return sequences\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.CompareFasta.write_results","title":"<code>write_results()</code>","text":"<p>Write the comparison results to a file in the output directory.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def write_results(self) -&gt; None:\n    \"\"\"Write the comparison results to a file in the output directory.\"\"\"\n    output_file = self.output_dir / \"compare.log\"\n    observed_compare = set()\n\n    logging.info(f\"Writing results to {output_file}\")\n    with open(output_file, \"w\") as out_fh:\n        for line in self.comp:\n            if line not in observed_compare:\n                observed_compare.add(line)\n                out_fh.write(str(line) + \"\\n\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.SeqGroup","title":"<code>SeqGroup</code>","text":"<p>Represents a group of sequence identifiers and maintains a count of them.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>class SeqGroup:\n    \"\"\"Represents a group of sequence identifiers and maintains a count of them.\"\"\"\n\n    def __init__(self, identifier: str | None = None) -&gt; None:\n        \"\"\"Initializes a `SeqGroup` instance.\n\n        Args:\n            identifier: The first identifier to add to the group. If `None`, adds \"None\" as the identifier.\n\n        \"\"\"\n        self.ids: list[str] = [str(identifier)]\n        self.count = 1\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a comma-separated string of sequence identifiers.\"\"\"\n        return \", \".join(self.ids)\n\n    def add_id(self, identifier: str | None = None) -&gt; None:\n        \"\"\"Add a new identifier to the group and updates the count.\n\n        Args:\n            identifier: The identifier to add. If `None`, \"None\" is added instead.\n\n        \"\"\"\n        self.ids.append(str(identifier))\n        self.count += 1\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.SeqGroup.count","title":"<code>count = 1</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.SeqGroup.ids","title":"<code>ids = [str(identifier)]</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.SeqGroup.add_id","title":"<code>add_id(identifier=None)</code>","text":"<p>Add a new identifier to the group and updates the count.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | None</code> <p>The identifier to add. If <code>None</code>, \"None\" is added instead.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def add_id(self, identifier: str | None = None) -&gt; None:\n    \"\"\"Add a new identifier to the group and updates the count.\n\n    Args:\n        identifier: The identifier to add. If `None`, \"None\" is added instead.\n\n    \"\"\"\n    self.ids.append(str(identifier))\n    self.count += 1\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.main","title":"<code>main(arg_list=None)</code>","text":"<p>Main script entry-point.</p> <p>Parameters:</p> Name Type Description Default <code>arg_list</code> <code>list[str] | None</code> <p>Parsed arguments as an <code>argparse.Namespace</code> object.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def main(arg_list: list[str] | None = None) -&gt; None:\n    \"\"\"Main script entry-point.\n\n    Args:\n        arg_list: Parsed arguments as an `argparse.Namespace` object.\n\n    \"\"\"\n    args = parse_args(arg_list)\n    init_logging_with_args(args)\n    compare_initialise = CompareFasta(args.fasta_ext, args.fasta_core, args.output_dir)\n    # Perform the comparison explicitly\n    compare_initialise.compare_seqs()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/compare/#ensembl.io.genomio.fasta.compare.parse_args","title":"<code>parse_args(arg_list)</code>","text":"<p>Return a populated namespace with the arguments parsed from a list or from the command line.</p> <p>Parameters:</p> Name Type Description Default <code>arg_list</code> <code>list[str] | None</code> <p>List of arguments to parse. If <code>None</code>, grab them from the command line.</p> required Source code in <code>src/python/ensembl/io/genomio/fasta/compare.py</code> <pre><code>def parse_args(arg_list: list[str] | None) -&gt; argparse.Namespace:\n    \"\"\"Return a populated namespace with the arguments parsed from a list or from the command line.\n\n    Args:\n        arg_list: List of arguments to parse. If `None`, grab them from the command line.\n\n    \"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_argument_src_path(\"--fasta_ext\", required=True, help=\"Path to external fasta file\")\n    parser.add_argument_src_path(\n        \"--fasta_core\", required=True, help=\"Query FASTA file to compare against external file.\"\n    )\n    parser.add_argument_dst_path(\n        \"--output_dir\",\n        default=Path.cwd(),\n        help=\"Directory to store the comparison report.\",\n    )\n    # Add flags\n    parser.add_argument(\n        \"--compare_seq_region\",\n        action=\"store_true\",\n        help=\"Enable compare seq_region mode, i.e. use seq_region for sequence comparison\",\n    )\n    parser.add_log_arguments()\n    return parser.parse_args(arg_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/process/","title":"process","text":""},{"location":"reference/ensembl/io/genomio/fasta/process/#ensembl.io.genomio.fasta.process","title":"<code>ensembl.io.genomio.fasta.process</code>","text":"<p>Takes a FASTA file (DNA or peptide), cleans it up and optionally excludes some IDs.</p>"},{"location":"reference/ensembl/io/genomio/fasta/process/#ensembl.io.genomio.fasta.process.exclude_seq_regions","title":"<code>exclude_seq_regions = []</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/fasta/process/#ensembl.io.genomio.fasta.process.FastaParserError","title":"<code>FastaParserError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error while parsing a FASTA file.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/process.py</code> <pre><code>class FastaParserError(Exception):\n    \"\"\"Error while parsing a FASTA file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/process/#ensembl.io.genomio.fasta.process.get_peptides_to_exclude","title":"<code>get_peptides_to_exclude(genbank_path, seqr_to_exclude)</code>","text":"<p>Extract peptide IDs from a genbank file that are in a given list of seq regions</p> Source code in <code>src/python/ensembl/io/genomio/fasta/process.py</code> <pre><code>def get_peptides_to_exclude(genbank_path: PathLike, seqr_to_exclude: Set[str]) -&gt; Set[str]:\n    \"\"\"\n    Extract peptide IDs from a genbank file that are in a given list of seq regions\n    \"\"\"\n    peptides_to_exclude: Set[str] = set()\n    with open_gz_file(genbank_path) as in_genbank:\n        for record in SeqIO.parse(in_genbank, \"genbank\"):\n            if record.id in seqr_to_exclude:\n                logging.info(f\"Skip sequence {record.id}\")\n                for feat in record.features:\n                    if feat.type == \"CDS\":\n                        if \"protein_id\" in feat.qualifiers:\n                            feat_id = feat.qualifiers[\"protein_id\"]\n                            peptides_to_exclude.add(feat_id[0])\n                        else:\n                            raise FastaParserError(f\"Peptide without peptide ID ${feat}\")\n    return peptides_to_exclude\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/process/#ensembl.io.genomio.fasta.process.main","title":"<code>main()</code>","text":"<p>Module's entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/fasta/process.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module's entry-point.\"\"\"\n    parser = ArgumentParser(description=\"Clean-up a given FASTA file to remove unwanted elements.\")\n    parser.add_argument_src_path(\"--fasta_infile\", required=True, help=\"Input FASTA file - DNA / Protein\")\n    parser.add_argument_src_path(\"--genbank_infile\", help=\"Input GenBank GBFF file\")\n    parser.add_argument_dst_path(\"--fasta_outfile\", required=True, help=\"Output FASTA file\")\n    parser.add_argument(\"--peptide_mode\", action=\"store_true\", help=\"Process proteins instead of DNA\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    prep_fasta_data(\n        fasta_infile=args.fasta_infile,\n        genbank_infile=args.genbank_infile,\n        fasta_outfile=args.fasta_outfile,\n        peptide_mode=args.peptide_mode,\n    )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/fasta/process/#ensembl.io.genomio.fasta.process.prep_fasta_data","title":"<code>prep_fasta_data(fasta_infile, genbank_infile, fasta_outfile, peptide_mode=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>fasta_file</code> <p>Input FASTA file - DNA / Protein</p> required <code>genbank_infile</code> <code>Optional[PathLike]</code> <p>Input GenBank GBFF file (Optional)</p> required <code>fasta_outfile</code> <code>PathLike</code> <p>Output FASTA sequence file.</p> required <code>peptide_mode</code> <code>bool</code> <p>Process proteins instead of DNA</p> <code>False</code> Source code in <code>src/python/ensembl/io/genomio/fasta/process.py</code> <pre><code>def prep_fasta_data(\n    fasta_infile: PathLike,\n    genbank_infile: Optional[PathLike],\n    fasta_outfile: PathLike,\n    peptide_mode: bool = False,\n) -&gt; None:\n    \"\"\"\n    Args:\n        fasta_file: Input FASTA file - DNA / Protein\n        genbank_infile: Input GenBank GBFF file (Optional)\n        fasta_outfile: Output FASTA sequence file.\n        peptide_mode: Process proteins instead of DNA\n    \"\"\"\n    file_path = Path(fasta_infile)\n\n    to_exclude = set()\n    seqr_to_exclude = set(exclude_seq_regions)\n    if peptide_mode:\n        if genbank_infile is not None:\n            genbank_path = Path(genbank_infile)\n            to_exclude = get_peptides_to_exclude(genbank_path, seqr_to_exclude)\n    else:\n        to_exclude = seqr_to_exclude\n\n    # Copy and filter\n    records = []\n\n    # Final path\n    with open_gz_file(file_path) as in_fasta:\n        for record in SeqIO.parse(in_fasta, \"fasta\"):\n            if record.id in to_exclude:\n                logging.info(f\"Skip record ${record.id}\")\n            else:\n                records.append(record)\n    with Path(fasta_outfile).open(\"w\") as out_fasta:\n        SeqIO.write(records, out_fasta, \"fasta\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/","title":"genbank","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank","title":"<code>ensembl.io.genomio.genbank</code>","text":"<p>GenBank fetching and data manipulation module.</p>"},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.DownloadError","title":"<code>DownloadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>In case a download failed.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/download.py</code> <pre><code>class DownloadError(Exception):\n    \"\"\"In case a download failed.\"\"\"\n\n    def __init__(self, msg: str) -&gt; None:\n        self.msg = msg\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.DownloadError.msg","title":"<code>msg = msg</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator","title":"<code>FormattedFilesGenerator</code>","text":"<p>Contains a parser to load data from a file, and output a set of files that follow our schema for input into a core database</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>class FormattedFilesGenerator:\n    \"\"\"\n    Contains a parser to load data from a file, and output a set of files that follow our schema\n    for input into a core database\n    \"\"\"\n\n    locations = {\n        \"mitochondrion\": \"mitochondrial_chromosome\",\n        \"apicoplast\": \"apicoplast_chromosome\",\n        \"chloroplast\": \"chloroplast_chromosome\",\n        \"chromoplast\": \"chromoplast_chromosome\",\n        \"cyanelle\": \"cyanelle_chromosome\",\n        \"leucoplast\": \"leucoplast_chromosome\",\n    }\n\n    allowed_feat_types = [\n        \"gene\",\n        \"transcript\",\n        \"tRNA\",\n        \"rRNA\",\n        \"CDS\",\n    ]\n\n    def __init__(self, prod_name: str, gb_file: PathLike, prefix: str, out_dir: PathLike) -&gt; None:\n        self.prefix = prefix\n        self.seq_records: List[SeqRecord] = []\n        self.prod_name = prod_name\n        self.gb_file = gb_file\n\n        # Output the gff3 file\n        self.files = GenomeFiles(Path(out_dir))\n\n    def parse_genbank(self, gb_file: PathLike) -&gt; None:\n        \"\"\"\n        Load records metadata from a Genbank file\n\n        Args:\n            gb_file: Path to downloaded genbank file\n        \"\"\"\n        organella = self._get_organella(gb_file)\n        logging.debug(f\"Organella loaded: {organella}\")\n\n        with open(gb_file, \"r\") as gbh:\n            for record in SeqIO.parse(gbh, \"genbank\"):\n                # We don't want the record description (especially for the fasta file)\n                record.description = \"\"\n                record.organelle = None\n                if record.id in organella:\n                    record.annotations[\"organelle\"] = organella[record.id]\n                self.seq_records.append(record)\n\n        if len(self.seq_records) &gt;= 1:\n            self.format_write_record()\n        else:\n            logging.warning(\"No records are found in gb_file\")\n\n    def format_write_record(self) -&gt; None:\n        \"\"\"\n        Generate the prepared files from genbank record\n        \"\"\"\n        self._format_genome_data()\n        self._format_write_genes_gff()\n        self._format_write_seq_json()\n        self._write_fasta_dna()\n\n    def _get_organella(self, gb_file: PathLike) -&gt; Dict[str, str]:\n        \"\"\"\n        Retrieve the organelle from the genbank file, using the specific GenBank object,\n        because SeqIO does not support this field\n\n        Args:\n            gb_file: path to genbank file\n        \"\"\"\n        organella = {}\n        with open(gb_file, \"r\") as gbh:\n            for record in GenBank.parse(gbh):\n                accession = record.version\n                for q in record.features[0].qualifiers:\n                    if q.key == \"/organelle=\":\n                        organelle = q.value.replace('\"', \"\")\n                        organella[accession] = organelle\n        return organella\n\n    def _write_fasta_dna(self) -&gt; None:\n        \"\"\"\n        Generate a DNA fasta file with all the sequences in the record\n        \"\"\"\n        logging.debug(f\"Write {len(self.seq_records)} DNA sequences to {self.files['fasta_dna']}\")\n        with open(self.files[\"fasta_dna\"], \"w\") as fasta_fh:\n            SeqIO.write(self.seq_records, fasta_fh, \"fasta\")\n\n    def _format_write_genes_gff(self) -&gt; None:\n        \"\"\"\n        Extract gene models from the record, and write a GFF and peptide fasta file.\n        Raise GBParseError If the IDs in all the records are not unique.\n        \"\"\"\n        peptides: List[SeqRecord] = []\n        gff_records: List[SeqRecord] = []\n        all_ids: List[str] = []\n\n        for record in self.seq_records:\n            new_record, rec_ids, rec_peptides = self._parse_record(record)\n            if new_record.features:\n                gff_records.append(new_record)\n            all_ids += rec_ids\n            peptides += rec_peptides\n\n        if gff_records:\n            self._write_genes_gff(gff_records)\n\n        if peptides:\n            self._write_pep_fasta(peptides)\n\n        logging.debug(\"Check that IDs are unique\")\n        count = dict(Counter(all_ids))\n        num_duplicates = 0\n        for key in count:\n            if count[key] &gt; 1:\n                num_duplicates += 1\n                logging.warning(f\"ID {key} is duplicated {count[key]} times\")\n        if num_duplicates &gt; 0:\n            raise GBParseError(f\"Some {num_duplicates} IDs are duplicated\")\n\n    def _write_genes_gff(self, gff_records: List[SeqRecord]) -&gt; None:\n        \"\"\"\n        Generate gene_models.gff file with the parsed gff_features\n\n        Args:\n            gff_records: List of records with features extracted from the record\n        \"\"\"\n        logging.debug(f\"Write {len(gff_records)} gene records to {self.files['gene_models']}\")\n        with self.files[\"gene_models\"].open(\"w\") as gff_fh:\n            GFF.write(gff_records, gff_fh)\n\n    def _write_pep_fasta(self, peptides: List[SeqRecord]) -&gt; None:\n        \"\"\"\n        Generate a peptide fasta file with the protein ids and sequence\n\n        Args:\n            peptides: List of extracted peptide features as records\n        \"\"\"\n        logging.debug(f\"Write {len(peptides)} peptide sequences to {self.files['fasta_pep']}\")\n        with self.files[\"fasta_pep\"].open(\"w\") as fasta_fh:\n            SeqIO.write(peptides, fasta_fh, \"fasta\")\n\n    def _parse_record(self, record: SeqRecord) -&gt; Tuple[SeqRecord, List[str], List[SeqRecord]]:\n        \"\"\"\n        Parse a gene feature from the genbank file\n        Args:\n            gene_feat: Gene feature to parse\n            gene_name: Gene name associated with the gene feature\n        \"\"\"\n        all_ids: List[str] = []\n        peptides: List[SeqRecord] = []\n        feats: Dict[str, SeqFeature] = {}\n\n        for feat in record.features:\n            # Silently skip any unsupported feature type\n            if feat.type not in self.allowed_feat_types:\n                continue\n\n            # Create a clean clone of the feature\n            gff_qualifiers = feat.qualifiers\n            gff_feat = SeqFeature(\n                location=feat.location,\n                type=feat.type,\n                qualifiers=gff_qualifiers,\n            )\n            # Only Genes should have a name: use either attribute gene or locus_tag\n            gene_name = gff_qualifiers.get(\"gene\", [None])[0]\n            if gene_name is None:\n                gene_name = gff_qualifiers.get(\"locus_tag\", [None])[0]\n\n            # Parse this gene\n            if gene_name is not None:\n                gene_feats, gene_ids, gene_peptides = self._parse_gene_feat(gff_feat, gene_name)\n                peptides += gene_peptides\n                feats = {**feats, **gene_feats}\n                all_ids += gene_ids\n\n            # No gene ID: parse if it is a tRNA or rRNA\n            elif gff_feat.type in (\"tRNA\", \"rRNA\"):\n                rna_feats, rna_ids = self._parse_rna_feat(gff_feat)\n                feats = {**feats, **rna_feats}\n                all_ids += rna_ids\n\n            # Any other case? Fail here and check if we should support it, or add it to unsupported list\n            else:\n                raise GBParseError(f\"No ID for allowed feature: {feat}\")\n\n        new_record = SeqRecord(record.seq, record.id)\n        new_record.features = list(feats.values())\n        return new_record, all_ids, peptides\n\n    def _parse_gene_feat(\n        self, gene_feat: SeqFeature, gene_name: str\n    ) -&gt; Tuple[Dict[str, SeqFeature], List[str], List[SeqRecord]]:\n        \"\"\"\n        Parse a gene feature from the genbank file\n\n        Args:\n            gene_feat: Gene feature to parse\n            gene_name: Gene name associated with the gene feature\n        \"\"\"\n\n        gene_id = self.prefix + gene_name\n        gene_qualifiers = gene_feat.qualifiers\n        new_feats: Dict[str, Any] = {}\n        peptides: List[SeqRecord] = []\n        all_ids: List[str] = []\n\n        if gene_feat.type == \"gene\":\n            if \"pseudo\" in gene_qualifiers:\n                gene_feat.type = \"pseudogene\"\n            gene_feat.qualifiers[\"ID\"] = gene_id\n            gene_feat.qualifiers[\"Name\"] = gene_name\n            if \"gene\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"gene\"]\n            if \"locus_tag\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"locus_tag\"]\n            new_feats[str(gene_id)] = gene_feat\n            all_ids.append(str(gene_id))\n\n        if gene_feat.type in (\"tRNA\", \"rRNA\"):\n            tr_id = gene_id + \"_t1\"\n            gene_feat.qualifiers[\"ID\"] = tr_id\n            gene_feat.qualifiers[\"Parent\"] = gene_id\n            if \"gene\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"gene\"]\n            if \"locus_tag\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"locus_tag\"]\n            new_feats[str(tr_id)] = gene_feat\n            all_ids.append(str(tr_id))\n\n        if gene_feat.type == \"CDS\":\n            if \"pseudo\" in gene_qualifiers:\n                gene_feat.type = \"exon\"\n            cds_id = gene_id + \"_p1\"\n            tr_id = gene_id + \"_t1\"\n            gene_feat.qualifiers[\"ID\"] = cds_id\n            gene_feat.qualifiers[\"Parent\"] = tr_id\n            if \"gene\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"gene\"]\n            if \"locus_tag\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"locus_tag\"]\n\n            # Add fasta to pep fasta file\n            if \"translation\" in gene_qualifiers:\n                new_pep_record = SeqRecord(Seq(gene_qualifiers[\"translation\"][0]), id=cds_id)\n                peptides.append(new_pep_record)\n\n            # Also create a parent transcript for this translation\n            tr_qualifiers = {\"ID\": tr_id, \"Name\": gene_name, \"Parent\": gene_id}\n            gff_tr = SeqFeature(\n                location=gene_feat.location,\n                type=\"mRNA\",\n                qualifiers=tr_qualifiers,\n            )\n            new_feats[str(tr_id)] = gff_tr\n            new_feats[str(cds_id)] = gene_feat\n            all_ids.append(str(tr_id))\n            all_ids.append(str(cds_id))\n\n        return new_feats, all_ids, peptides\n\n    def _parse_rna_feat(self, rna_feat: SeqFeature) -&gt; Tuple[Dict[str, SeqFeature], List[str]]:\n        \"\"\"\n        Parse an RNA feature\n\n        Args:\n            gene_feat: list of RNA features found in the record\n        \"\"\"\n        new_feats: Dict[str, Any] = {}\n        all_ids: List[str] = []\n\n        gff_qualifiers = rna_feat.qualifiers\n        feat_name = gff_qualifiers[\"product\"][0]\n        gene_id = self.prefix + feat_name\n\n        parts = gene_id.split(\" \")\n        if len(parts) &gt; 2:\n            logging.info(f\"Shortening gene_id to {parts[0]}\")\n            gene_id = parts[0]\n        gene_id = self._uniquify_id(gene_id, all_ids)\n\n        feat_id = gene_id + \"_t1\"\n        rna_feat.qualifiers[\"ID\"] = feat_id\n        rna_feat.qualifiers[\"Name\"] = feat_name\n        rna_feat.qualifiers[\"Parent\"] = gene_id\n\n        # Also create a parent gene for this transcript\n        gene_qualifiers = {\n            \"ID\": gene_id,\n            \"Name\": feat_name,\n        }\n        gff_gene = SeqFeature(\n            location=rna_feat.location,\n            type=\"gene\",\n            qualifiers=gene_qualifiers,\n        )\n        new_feats[str(gene_id)] = gff_gene\n        new_feats[str(feat_id)] = rna_feat\n        all_ids.append(str(gene_id))\n        all_ids.append(str(feat_id))\n\n        return new_feats, all_ids\n\n    def _uniquify_id(self, gene_id: str, all_ids: List[str]) -&gt; str:\n        \"\"\"\n        Ensure the gene id used is unique,\n        and append a number otherwise, starting at 2\n\n        Args:\n            all_ids: list of all the feature ids\n            gene_id: ids assigned to gene\n        \"\"\"\n\n        new_id = gene_id\n        num = 1\n        while new_id in all_ids:\n            num += 1\n            new_id = f\"{gene_id}_{num}\"\n        if gene_id != new_id:\n            logging.info(f\"Make gene id unique: {gene_id} -&gt; {new_id}\")\n\n        return new_id\n\n    def _format_write_seq_json(self) -&gt; None:\n        \"\"\"\n        Add the sequence metadata to seq_json based on ensembl requirements\n        \"\"\"\n        json_array = []\n        for seq in self.seq_records:\n            codon_table = self._get_codon_table(seq)\n            if codon_table is None:\n                logging.warning(\n                    (\n                        \"No codon table found. Make sure to change the codon table number in \"\n                        f\"{self.files['seq_region']} manually if it is not the standard codon table.\"\n                    )\n                )\n                codon_table = 1\n            else:\n                codon_table = int(codon_table)\n\n            seq_obj: Dict[str, Any] = {\n                \"name\": seq.id,\n                \"coord_system_level\": \"chromosome\",\n                \"circular\": (seq.annotations[\"topology\"] == \"circular\"),\n                \"codon_table\": codon_table,\n                \"length\": len(seq.seq),  # type: ignore[arg-type]\n            }\n            if \"organelle\" in seq.annotations:\n                seq_obj[\"location\"] = self._prepare_location(str(seq.annotations[\"organelle\"]))\n                if not codon_table:\n                    logging.warning(\n                        (\n                            f\"'{seq.annotations['organelle']}' is an organelle: \"\n                            \"make sure to change the codon table number \"\n                            f\"in {self.files['seq_region']} manually if it is not the standard codon table\"\n                        )\n                    )\n\n            # Additional attributes for Ensembl\n            seq_obj[\"added_sequence\"] = {\n                \"accession\": seq.id,\n                \"assembly_provider\": {\n                    \"name\": \"GenBank\",\n                    \"url\": \"https://www.ncbi.nlm.nih.gov/genbank\",\n                },\n            }\n            json_array.append(seq_obj)\n            self._write_seq_region_json(json_array)\n\n    def _write_seq_region_json(self, json_array: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"\n        Generate seq_region.json file with metadata for the sequence\n\n        Args:\n            json_array: List of extracted sequence with metadata\n        \"\"\"\n        logging.debug(f\"Write {len(json_array)} seq_region to {self.files['seq_region']}\")\n        with open(self.files[\"seq_region\"], \"w\") as seq_fh:\n            seq_fh.write(json.dumps(json_array, indent=4))\n\n    def _get_codon_table(self, seq: SeqRecord) -&gt; Optional[int]:\n        \"\"\"\n        Look at the CDS features to see if they have a codon table\n\n        Args:\n            seq: SeqRecord in the genbank file\n        \"\"\"\n        for feat in seq.features:\n            if feat.type == \"CDS\":\n                qualifiers = feat.qualifiers\n                if \"transl_table\" in qualifiers:\n                    return qualifiers[\"transl_table\"][0]\n                return None\n        return None\n\n    def _prepare_location(self, organelle: str) -&gt; str:\n        \"\"\"\n        Given an organelle name, returns the SO term corresponding to its location\n\n        Args:\n            organelle: SeqRecord with organelle\n        \"\"\"\n        if organelle in self.locations:\n            return self.locations[organelle]\n        raise UnsupportedData(f\"Unknown organelle: {organelle}\")\n\n    def _format_genome_data(self) -&gt; None:\n        \"\"\"\n        Write a draft for the genome json file\n        Only the production_name is needed, but the rest of the fields need to be given\n        for the validation of the json file\n        \"\"\"\n        prod_name = self.prod_name\n        genome_data: Dict[str, Dict[str, Any]] = {\n            \"species\": {\n                \"production_name\": prod_name,\n                \"taxonomy_id\": 0,\n            },\n            \"assembly\": {\"accession\": \"GCA_000000000\", \"version\": 1},\n            \"added_seq\": {},\n        }\n\n        if not genome_data[\"species\"][\"production_name\"]:\n            logging.warning(\n                f\"Please add the relevant production_name for this genome in {self.files['genome']}\"\n            )\n\n        ids = [seq.id for seq in self.seq_records]\n        genome_data[\"added_seq\"][\"region_name\"] = ids\n        self._write_genome_json(genome_data)\n\n    def _write_genome_json(self, genome_data: Dict[str, Any]) -&gt; None:\n        \"\"\"\n        Generate genome.json file with metadata for the assembly\n\n        Args:\n            genome_data: Dict of metadata for assembly\n        \"\"\"\n        logging.debug(f\"Write assembly metadata to {self.files['genome']}\")\n        with open(self.files[\"genome\"], \"w\") as genome_fh:\n            genome_fh.write(json.dumps(genome_data, indent=4))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.allowed_feat_types","title":"<code>allowed_feat_types = ['gene', 'transcript', 'tRNA', 'rRNA', 'CDS']</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.files","title":"<code>files = GenomeFiles(Path(out_dir))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.gb_file","title":"<code>gb_file = gb_file</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.locations","title":"<code>locations = {'mitochondrion': 'mitochondrial_chromosome', 'apicoplast': 'apicoplast_chromosome', 'chloroplast': 'chloroplast_chromosome', 'chromoplast': 'chromoplast_chromosome', 'cyanelle': 'cyanelle_chromosome', 'leucoplast': 'leucoplast_chromosome'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.prefix","title":"<code>prefix = prefix</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.prod_name","title":"<code>prod_name = prod_name</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.seq_records","title":"<code>seq_records = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.format_write_record","title":"<code>format_write_record()</code>","text":"<p>Generate the prepared files from genbank record</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>def format_write_record(self) -&gt; None:\n    \"\"\"\n    Generate the prepared files from genbank record\n    \"\"\"\n    self._format_genome_data()\n    self._format_write_genes_gff()\n    self._format_write_seq_json()\n    self._write_fasta_dna()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.FormattedFilesGenerator.parse_genbank","title":"<code>parse_genbank(gb_file)</code>","text":"<p>Load records metadata from a Genbank file</p> <p>Parameters:</p> Name Type Description Default <code>gb_file</code> <code>PathLike</code> <p>Path to downloaded genbank file</p> required Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>def parse_genbank(self, gb_file: PathLike) -&gt; None:\n    \"\"\"\n    Load records metadata from a Genbank file\n\n    Args:\n        gb_file: Path to downloaded genbank file\n    \"\"\"\n    organella = self._get_organella(gb_file)\n    logging.debug(f\"Organella loaded: {organella}\")\n\n    with open(gb_file, \"r\") as gbh:\n        for record in SeqIO.parse(gbh, \"genbank\"):\n            # We don't want the record description (especially for the fasta file)\n            record.description = \"\"\n            record.organelle = None\n            if record.id in organella:\n                record.annotations[\"organelle\"] = organella[record.id]\n            self.seq_records.append(record)\n\n    if len(self.seq_records) &gt;= 1:\n        self.format_write_record()\n    else:\n        logging.warning(\"No records are found in gb_file\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.GBParseError","title":"<code>GBParseError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error when parsing the Genbank file.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>class GBParseError(Exception):\n    \"\"\"Error when parsing the Genbank file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.GenomeFiles","title":"<code>GenomeFiles</code>","text":"<p>               Bases: <code>dict</code></p> <p>Store the representation of the genome files created.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>class GenomeFiles(dict):\n    \"\"\"\n    Store the representation of the genome files created.\n    \"\"\"\n\n    def __init__(self, out_dir: PathLike) -&gt; None:\n        super().__init__()\n        out_dir = Path(out_dir)\n        self[\"genome\"] = out_dir / \"genome.json\"\n        self[\"seq_region\"] = out_dir / \"seq_region.json\"\n        self[\"fasta_dna\"] = out_dir / \"dna.fasta\"\n        self[\"fasta_pep\"] = out_dir / \"pep.fasta\"\n        self[\"gene_models\"] = out_dir / \"genes.gff\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.UnsupportedData","title":"<code>UnsupportedData</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When an expected data is not supported by the current parser.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>class UnsupportedData(Exception):\n    \"\"\"When an expected data is not supported by the current parser.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/#ensembl.io.genomio.genbank.download_genbank","title":"<code>download_genbank(accession, output_file)</code>","text":"<p>Given a GenBank accession, download the corresponding file in GenBank format.</p> <p>Uses NCBI Entrez service to fetch the data.</p> <p>Parameters:</p> Name Type Description Default <code>accession</code> <code>str</code> <p>INSDC Genbank record accession.</p> required <code>output_file</code> <code>PathLike</code> <p>Path to the downloaded record in Genbank format.</p> required <p>Raises:</p> Type Description <code>DownloadError</code> <p>If the download fails.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/download.py</code> <pre><code>def download_genbank(accession: str, output_file: PathLike) -&gt; None:\n    \"\"\"Given a GenBank accession, download the corresponding file in GenBank format.\n\n    Uses NCBI Entrez service to fetch the data.\n\n    Args:\n        accession: INSDC Genbank record accession.\n        output_file: Path to the downloaded record in Genbank format.\n\n    Raises:\n        DownloadError: If the download fails.\n\n    \"\"\"\n\n    # Get the list of assemblies for this accession\n    entrez_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n    entrez_params = {\n        \"db\": \"nuccore\",\n        \"rettype\": \"gbwithparts\",\n        \"retmode\": \"text\",\n    }\n    entrez_params[\"id\"] = accession\n    logging.debug(f\"Getting file from {entrez_url} with params {entrez_params}\")\n    result = requests.get(entrez_url, params=entrez_params, timeout=60)\n    if result and result.status_code == 200:\n        with Path(output_file).open(\"wb\") as gbff:\n            gbff.write(result.content)\n        logging.info(f\"GenBank file written to {output_file}\")\n        return\n    raise DownloadError(f\"Could not download the genbank ({accession}) file: {result}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/download/","title":"download","text":""},{"location":"reference/ensembl/io/genomio/genbank/download/#ensembl.io.genomio.genbank.download","title":"<code>ensembl.io.genomio.genbank.download</code>","text":"<p>Download a Genbank file from NCBI from an accession.</p>"},{"location":"reference/ensembl/io/genomio/genbank/download/#ensembl.io.genomio.genbank.download.DownloadError","title":"<code>DownloadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>In case a download failed.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/download.py</code> <pre><code>class DownloadError(Exception):\n    \"\"\"In case a download failed.\"\"\"\n\n    def __init__(self, msg: str) -&gt; None:\n        self.msg = msg\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/download/#ensembl.io.genomio.genbank.download.DownloadError.msg","title":"<code>msg = msg</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/download/#ensembl.io.genomio.genbank.download.download_genbank","title":"<code>download_genbank(accession, output_file)</code>","text":"<p>Given a GenBank accession, download the corresponding file in GenBank format.</p> <p>Uses NCBI Entrez service to fetch the data.</p> <p>Parameters:</p> Name Type Description Default <code>accession</code> <code>str</code> <p>INSDC Genbank record accession.</p> required <code>output_file</code> <code>PathLike</code> <p>Path to the downloaded record in Genbank format.</p> required <p>Raises:</p> Type Description <code>DownloadError</code> <p>If the download fails.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/download.py</code> <pre><code>def download_genbank(accession: str, output_file: PathLike) -&gt; None:\n    \"\"\"Given a GenBank accession, download the corresponding file in GenBank format.\n\n    Uses NCBI Entrez service to fetch the data.\n\n    Args:\n        accession: INSDC Genbank record accession.\n        output_file: Path to the downloaded record in Genbank format.\n\n    Raises:\n        DownloadError: If the download fails.\n\n    \"\"\"\n\n    # Get the list of assemblies for this accession\n    entrez_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n    entrez_params = {\n        \"db\": \"nuccore\",\n        \"rettype\": \"gbwithparts\",\n        \"retmode\": \"text\",\n    }\n    entrez_params[\"id\"] = accession\n    logging.debug(f\"Getting file from {entrez_url} with params {entrez_params}\")\n    result = requests.get(entrez_url, params=entrez_params, timeout=60)\n    if result and result.status_code == 200:\n        with Path(output_file).open(\"wb\") as gbff:\n            gbff.write(result.content)\n        logging.info(f\"GenBank file written to {output_file}\")\n        return\n    raise DownloadError(f\"Could not download the genbank ({accession}) file: {result}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/download/#ensembl.io.genomio.genbank.download.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/download.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(description=\"Download a sequence from GenBank.\")\n    parser.add_argument(\"--accession\", required=True, help=\"Sequence accession\")\n    parser.add_argument_dst_path(\"--output_file\", required=True, help=\"Output GenBank file\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    download_genbank(accession=args.accession, output_file=args.output_file)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/extract_data/","title":"extract_data","text":""},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data","title":"<code>ensembl.io.genomio.genbank.extract_data</code>","text":"<p>Parse a Genbank file and creates cleaned up files from it: - DNA fasta - Peptide fasta - Gene models GFF3 - seq_regions json - genome metadata json</p> <p>Raises:</p> Type Description <code>GBParseError</code> <p>If the structure of the gb file cannot be parsed.</p> <code>UnsupportedData</code> <p>If some data is not as expected.</p> <p>Returns:</p> Name Type Description <code>json_output</code> <p>json file with a dict that contains all genome files created.</p>"},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator","title":"<code>FormattedFilesGenerator</code>","text":"<p>Contains a parser to load data from a file, and output a set of files that follow our schema for input into a core database</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>class FormattedFilesGenerator:\n    \"\"\"\n    Contains a parser to load data from a file, and output a set of files that follow our schema\n    for input into a core database\n    \"\"\"\n\n    locations = {\n        \"mitochondrion\": \"mitochondrial_chromosome\",\n        \"apicoplast\": \"apicoplast_chromosome\",\n        \"chloroplast\": \"chloroplast_chromosome\",\n        \"chromoplast\": \"chromoplast_chromosome\",\n        \"cyanelle\": \"cyanelle_chromosome\",\n        \"leucoplast\": \"leucoplast_chromosome\",\n    }\n\n    allowed_feat_types = [\n        \"gene\",\n        \"transcript\",\n        \"tRNA\",\n        \"rRNA\",\n        \"CDS\",\n    ]\n\n    def __init__(self, prod_name: str, gb_file: PathLike, prefix: str, out_dir: PathLike) -&gt; None:\n        self.prefix = prefix\n        self.seq_records: List[SeqRecord] = []\n        self.prod_name = prod_name\n        self.gb_file = gb_file\n\n        # Output the gff3 file\n        self.files = GenomeFiles(Path(out_dir))\n\n    def parse_genbank(self, gb_file: PathLike) -&gt; None:\n        \"\"\"\n        Load records metadata from a Genbank file\n\n        Args:\n            gb_file: Path to downloaded genbank file\n        \"\"\"\n        organella = self._get_organella(gb_file)\n        logging.debug(f\"Organella loaded: {organella}\")\n\n        with open(gb_file, \"r\") as gbh:\n            for record in SeqIO.parse(gbh, \"genbank\"):\n                # We don't want the record description (especially for the fasta file)\n                record.description = \"\"\n                record.organelle = None\n                if record.id in organella:\n                    record.annotations[\"organelle\"] = organella[record.id]\n                self.seq_records.append(record)\n\n        if len(self.seq_records) &gt;= 1:\n            self.format_write_record()\n        else:\n            logging.warning(\"No records are found in gb_file\")\n\n    def format_write_record(self) -&gt; None:\n        \"\"\"\n        Generate the prepared files from genbank record\n        \"\"\"\n        self._format_genome_data()\n        self._format_write_genes_gff()\n        self._format_write_seq_json()\n        self._write_fasta_dna()\n\n    def _get_organella(self, gb_file: PathLike) -&gt; Dict[str, str]:\n        \"\"\"\n        Retrieve the organelle from the genbank file, using the specific GenBank object,\n        because SeqIO does not support this field\n\n        Args:\n            gb_file: path to genbank file\n        \"\"\"\n        organella = {}\n        with open(gb_file, \"r\") as gbh:\n            for record in GenBank.parse(gbh):\n                accession = record.version\n                for q in record.features[0].qualifiers:\n                    if q.key == \"/organelle=\":\n                        organelle = q.value.replace('\"', \"\")\n                        organella[accession] = organelle\n        return organella\n\n    def _write_fasta_dna(self) -&gt; None:\n        \"\"\"\n        Generate a DNA fasta file with all the sequences in the record\n        \"\"\"\n        logging.debug(f\"Write {len(self.seq_records)} DNA sequences to {self.files['fasta_dna']}\")\n        with open(self.files[\"fasta_dna\"], \"w\") as fasta_fh:\n            SeqIO.write(self.seq_records, fasta_fh, \"fasta\")\n\n    def _format_write_genes_gff(self) -&gt; None:\n        \"\"\"\n        Extract gene models from the record, and write a GFF and peptide fasta file.\n        Raise GBParseError If the IDs in all the records are not unique.\n        \"\"\"\n        peptides: List[SeqRecord] = []\n        gff_records: List[SeqRecord] = []\n        all_ids: List[str] = []\n\n        for record in self.seq_records:\n            new_record, rec_ids, rec_peptides = self._parse_record(record)\n            if new_record.features:\n                gff_records.append(new_record)\n            all_ids += rec_ids\n            peptides += rec_peptides\n\n        if gff_records:\n            self._write_genes_gff(gff_records)\n\n        if peptides:\n            self._write_pep_fasta(peptides)\n\n        logging.debug(\"Check that IDs are unique\")\n        count = dict(Counter(all_ids))\n        num_duplicates = 0\n        for key in count:\n            if count[key] &gt; 1:\n                num_duplicates += 1\n                logging.warning(f\"ID {key} is duplicated {count[key]} times\")\n        if num_duplicates &gt; 0:\n            raise GBParseError(f\"Some {num_duplicates} IDs are duplicated\")\n\n    def _write_genes_gff(self, gff_records: List[SeqRecord]) -&gt; None:\n        \"\"\"\n        Generate gene_models.gff file with the parsed gff_features\n\n        Args:\n            gff_records: List of records with features extracted from the record\n        \"\"\"\n        logging.debug(f\"Write {len(gff_records)} gene records to {self.files['gene_models']}\")\n        with self.files[\"gene_models\"].open(\"w\") as gff_fh:\n            GFF.write(gff_records, gff_fh)\n\n    def _write_pep_fasta(self, peptides: List[SeqRecord]) -&gt; None:\n        \"\"\"\n        Generate a peptide fasta file with the protein ids and sequence\n\n        Args:\n            peptides: List of extracted peptide features as records\n        \"\"\"\n        logging.debug(f\"Write {len(peptides)} peptide sequences to {self.files['fasta_pep']}\")\n        with self.files[\"fasta_pep\"].open(\"w\") as fasta_fh:\n            SeqIO.write(peptides, fasta_fh, \"fasta\")\n\n    def _parse_record(self, record: SeqRecord) -&gt; Tuple[SeqRecord, List[str], List[SeqRecord]]:\n        \"\"\"\n        Parse a gene feature from the genbank file\n        Args:\n            gene_feat: Gene feature to parse\n            gene_name: Gene name associated with the gene feature\n        \"\"\"\n        all_ids: List[str] = []\n        peptides: List[SeqRecord] = []\n        feats: Dict[str, SeqFeature] = {}\n\n        for feat in record.features:\n            # Silently skip any unsupported feature type\n            if feat.type not in self.allowed_feat_types:\n                continue\n\n            # Create a clean clone of the feature\n            gff_qualifiers = feat.qualifiers\n            gff_feat = SeqFeature(\n                location=feat.location,\n                type=feat.type,\n                qualifiers=gff_qualifiers,\n            )\n            # Only Genes should have a name: use either attribute gene or locus_tag\n            gene_name = gff_qualifiers.get(\"gene\", [None])[0]\n            if gene_name is None:\n                gene_name = gff_qualifiers.get(\"locus_tag\", [None])[0]\n\n            # Parse this gene\n            if gene_name is not None:\n                gene_feats, gene_ids, gene_peptides = self._parse_gene_feat(gff_feat, gene_name)\n                peptides += gene_peptides\n                feats = {**feats, **gene_feats}\n                all_ids += gene_ids\n\n            # No gene ID: parse if it is a tRNA or rRNA\n            elif gff_feat.type in (\"tRNA\", \"rRNA\"):\n                rna_feats, rna_ids = self._parse_rna_feat(gff_feat)\n                feats = {**feats, **rna_feats}\n                all_ids += rna_ids\n\n            # Any other case? Fail here and check if we should support it, or add it to unsupported list\n            else:\n                raise GBParseError(f\"No ID for allowed feature: {feat}\")\n\n        new_record = SeqRecord(record.seq, record.id)\n        new_record.features = list(feats.values())\n        return new_record, all_ids, peptides\n\n    def _parse_gene_feat(\n        self, gene_feat: SeqFeature, gene_name: str\n    ) -&gt; Tuple[Dict[str, SeqFeature], List[str], List[SeqRecord]]:\n        \"\"\"\n        Parse a gene feature from the genbank file\n\n        Args:\n            gene_feat: Gene feature to parse\n            gene_name: Gene name associated with the gene feature\n        \"\"\"\n\n        gene_id = self.prefix + gene_name\n        gene_qualifiers = gene_feat.qualifiers\n        new_feats: Dict[str, Any] = {}\n        peptides: List[SeqRecord] = []\n        all_ids: List[str] = []\n\n        if gene_feat.type == \"gene\":\n            if \"pseudo\" in gene_qualifiers:\n                gene_feat.type = \"pseudogene\"\n            gene_feat.qualifiers[\"ID\"] = gene_id\n            gene_feat.qualifiers[\"Name\"] = gene_name\n            if \"gene\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"gene\"]\n            if \"locus_tag\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"locus_tag\"]\n            new_feats[str(gene_id)] = gene_feat\n            all_ids.append(str(gene_id))\n\n        if gene_feat.type in (\"tRNA\", \"rRNA\"):\n            tr_id = gene_id + \"_t1\"\n            gene_feat.qualifiers[\"ID\"] = tr_id\n            gene_feat.qualifiers[\"Parent\"] = gene_id\n            if \"gene\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"gene\"]\n            if \"locus_tag\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"locus_tag\"]\n            new_feats[str(tr_id)] = gene_feat\n            all_ids.append(str(tr_id))\n\n        if gene_feat.type == \"CDS\":\n            if \"pseudo\" in gene_qualifiers:\n                gene_feat.type = \"exon\"\n            cds_id = gene_id + \"_p1\"\n            tr_id = gene_id + \"_t1\"\n            gene_feat.qualifiers[\"ID\"] = cds_id\n            gene_feat.qualifiers[\"Parent\"] = tr_id\n            if \"gene\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"gene\"]\n            if \"locus_tag\" in gene_feat.qualifiers:\n                del gene_feat.qualifiers[\"locus_tag\"]\n\n            # Add fasta to pep fasta file\n            if \"translation\" in gene_qualifiers:\n                new_pep_record = SeqRecord(Seq(gene_qualifiers[\"translation\"][0]), id=cds_id)\n                peptides.append(new_pep_record)\n\n            # Also create a parent transcript for this translation\n            tr_qualifiers = {\"ID\": tr_id, \"Name\": gene_name, \"Parent\": gene_id}\n            gff_tr = SeqFeature(\n                location=gene_feat.location,\n                type=\"mRNA\",\n                qualifiers=tr_qualifiers,\n            )\n            new_feats[str(tr_id)] = gff_tr\n            new_feats[str(cds_id)] = gene_feat\n            all_ids.append(str(tr_id))\n            all_ids.append(str(cds_id))\n\n        return new_feats, all_ids, peptides\n\n    def _parse_rna_feat(self, rna_feat: SeqFeature) -&gt; Tuple[Dict[str, SeqFeature], List[str]]:\n        \"\"\"\n        Parse an RNA feature\n\n        Args:\n            gene_feat: list of RNA features found in the record\n        \"\"\"\n        new_feats: Dict[str, Any] = {}\n        all_ids: List[str] = []\n\n        gff_qualifiers = rna_feat.qualifiers\n        feat_name = gff_qualifiers[\"product\"][0]\n        gene_id = self.prefix + feat_name\n\n        parts = gene_id.split(\" \")\n        if len(parts) &gt; 2:\n            logging.info(f\"Shortening gene_id to {parts[0]}\")\n            gene_id = parts[0]\n        gene_id = self._uniquify_id(gene_id, all_ids)\n\n        feat_id = gene_id + \"_t1\"\n        rna_feat.qualifiers[\"ID\"] = feat_id\n        rna_feat.qualifiers[\"Name\"] = feat_name\n        rna_feat.qualifiers[\"Parent\"] = gene_id\n\n        # Also create a parent gene for this transcript\n        gene_qualifiers = {\n            \"ID\": gene_id,\n            \"Name\": feat_name,\n        }\n        gff_gene = SeqFeature(\n            location=rna_feat.location,\n            type=\"gene\",\n            qualifiers=gene_qualifiers,\n        )\n        new_feats[str(gene_id)] = gff_gene\n        new_feats[str(feat_id)] = rna_feat\n        all_ids.append(str(gene_id))\n        all_ids.append(str(feat_id))\n\n        return new_feats, all_ids\n\n    def _uniquify_id(self, gene_id: str, all_ids: List[str]) -&gt; str:\n        \"\"\"\n        Ensure the gene id used is unique,\n        and append a number otherwise, starting at 2\n\n        Args:\n            all_ids: list of all the feature ids\n            gene_id: ids assigned to gene\n        \"\"\"\n\n        new_id = gene_id\n        num = 1\n        while new_id in all_ids:\n            num += 1\n            new_id = f\"{gene_id}_{num}\"\n        if gene_id != new_id:\n            logging.info(f\"Make gene id unique: {gene_id} -&gt; {new_id}\")\n\n        return new_id\n\n    def _format_write_seq_json(self) -&gt; None:\n        \"\"\"\n        Add the sequence metadata to seq_json based on ensembl requirements\n        \"\"\"\n        json_array = []\n        for seq in self.seq_records:\n            codon_table = self._get_codon_table(seq)\n            if codon_table is None:\n                logging.warning(\n                    (\n                        \"No codon table found. Make sure to change the codon table number in \"\n                        f\"{self.files['seq_region']} manually if it is not the standard codon table.\"\n                    )\n                )\n                codon_table = 1\n            else:\n                codon_table = int(codon_table)\n\n            seq_obj: Dict[str, Any] = {\n                \"name\": seq.id,\n                \"coord_system_level\": \"chromosome\",\n                \"circular\": (seq.annotations[\"topology\"] == \"circular\"),\n                \"codon_table\": codon_table,\n                \"length\": len(seq.seq),  # type: ignore[arg-type]\n            }\n            if \"organelle\" in seq.annotations:\n                seq_obj[\"location\"] = self._prepare_location(str(seq.annotations[\"organelle\"]))\n                if not codon_table:\n                    logging.warning(\n                        (\n                            f\"'{seq.annotations['organelle']}' is an organelle: \"\n                            \"make sure to change the codon table number \"\n                            f\"in {self.files['seq_region']} manually if it is not the standard codon table\"\n                        )\n                    )\n\n            # Additional attributes for Ensembl\n            seq_obj[\"added_sequence\"] = {\n                \"accession\": seq.id,\n                \"assembly_provider\": {\n                    \"name\": \"GenBank\",\n                    \"url\": \"https://www.ncbi.nlm.nih.gov/genbank\",\n                },\n            }\n            json_array.append(seq_obj)\n            self._write_seq_region_json(json_array)\n\n    def _write_seq_region_json(self, json_array: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"\n        Generate seq_region.json file with metadata for the sequence\n\n        Args:\n            json_array: List of extracted sequence with metadata\n        \"\"\"\n        logging.debug(f\"Write {len(json_array)} seq_region to {self.files['seq_region']}\")\n        with open(self.files[\"seq_region\"], \"w\") as seq_fh:\n            seq_fh.write(json.dumps(json_array, indent=4))\n\n    def _get_codon_table(self, seq: SeqRecord) -&gt; Optional[int]:\n        \"\"\"\n        Look at the CDS features to see if they have a codon table\n\n        Args:\n            seq: SeqRecord in the genbank file\n        \"\"\"\n        for feat in seq.features:\n            if feat.type == \"CDS\":\n                qualifiers = feat.qualifiers\n                if \"transl_table\" in qualifiers:\n                    return qualifiers[\"transl_table\"][0]\n                return None\n        return None\n\n    def _prepare_location(self, organelle: str) -&gt; str:\n        \"\"\"\n        Given an organelle name, returns the SO term corresponding to its location\n\n        Args:\n            organelle: SeqRecord with organelle\n        \"\"\"\n        if organelle in self.locations:\n            return self.locations[organelle]\n        raise UnsupportedData(f\"Unknown organelle: {organelle}\")\n\n    def _format_genome_data(self) -&gt; None:\n        \"\"\"\n        Write a draft for the genome json file\n        Only the production_name is needed, but the rest of the fields need to be given\n        for the validation of the json file\n        \"\"\"\n        prod_name = self.prod_name\n        genome_data: Dict[str, Dict[str, Any]] = {\n            \"species\": {\n                \"production_name\": prod_name,\n                \"taxonomy_id\": 0,\n            },\n            \"assembly\": {\"accession\": \"GCA_000000000\", \"version\": 1},\n            \"added_seq\": {},\n        }\n\n        if not genome_data[\"species\"][\"production_name\"]:\n            logging.warning(\n                f\"Please add the relevant production_name for this genome in {self.files['genome']}\"\n            )\n\n        ids = [seq.id for seq in self.seq_records]\n        genome_data[\"added_seq\"][\"region_name\"] = ids\n        self._write_genome_json(genome_data)\n\n    def _write_genome_json(self, genome_data: Dict[str, Any]) -&gt; None:\n        \"\"\"\n        Generate genome.json file with metadata for the assembly\n\n        Args:\n            genome_data: Dict of metadata for assembly\n        \"\"\"\n        logging.debug(f\"Write assembly metadata to {self.files['genome']}\")\n        with open(self.files[\"genome\"], \"w\") as genome_fh:\n            genome_fh.write(json.dumps(genome_data, indent=4))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.allowed_feat_types","title":"<code>allowed_feat_types = ['gene', 'transcript', 'tRNA', 'rRNA', 'CDS']</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.files","title":"<code>files = GenomeFiles(Path(out_dir))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.gb_file","title":"<code>gb_file = gb_file</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.locations","title":"<code>locations = {'mitochondrion': 'mitochondrial_chromosome', 'apicoplast': 'apicoplast_chromosome', 'chloroplast': 'chloroplast_chromosome', 'chromoplast': 'chromoplast_chromosome', 'cyanelle': 'cyanelle_chromosome', 'leucoplast': 'leucoplast_chromosome'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.prefix","title":"<code>prefix = prefix</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.prod_name","title":"<code>prod_name = prod_name</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.seq_records","title":"<code>seq_records = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.format_write_record","title":"<code>format_write_record()</code>","text":"<p>Generate the prepared files from genbank record</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>def format_write_record(self) -&gt; None:\n    \"\"\"\n    Generate the prepared files from genbank record\n    \"\"\"\n    self._format_genome_data()\n    self._format_write_genes_gff()\n    self._format_write_seq_json()\n    self._write_fasta_dna()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.FormattedFilesGenerator.parse_genbank","title":"<code>parse_genbank(gb_file)</code>","text":"<p>Load records metadata from a Genbank file</p> <p>Parameters:</p> Name Type Description Default <code>gb_file</code> <code>PathLike</code> <p>Path to downloaded genbank file</p> required Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>def parse_genbank(self, gb_file: PathLike) -&gt; None:\n    \"\"\"\n    Load records metadata from a Genbank file\n\n    Args:\n        gb_file: Path to downloaded genbank file\n    \"\"\"\n    organella = self._get_organella(gb_file)\n    logging.debug(f\"Organella loaded: {organella}\")\n\n    with open(gb_file, \"r\") as gbh:\n        for record in SeqIO.parse(gbh, \"genbank\"):\n            # We don't want the record description (especially for the fasta file)\n            record.description = \"\"\n            record.organelle = None\n            if record.id in organella:\n                record.annotations[\"organelle\"] = organella[record.id]\n            self.seq_records.append(record)\n\n    if len(self.seq_records) &gt;= 1:\n        self.format_write_record()\n    else:\n        logging.warning(\"No records are found in gb_file\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.GBParseError","title":"<code>GBParseError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error when parsing the Genbank file.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>class GBParseError(Exception):\n    \"\"\"Error when parsing the Genbank file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.GenomeFiles","title":"<code>GenomeFiles</code>","text":"<p>               Bases: <code>dict</code></p> <p>Store the representation of the genome files created.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>class GenomeFiles(dict):\n    \"\"\"\n    Store the representation of the genome files created.\n    \"\"\"\n\n    def __init__(self, out_dir: PathLike) -&gt; None:\n        super().__init__()\n        out_dir = Path(out_dir)\n        self[\"genome\"] = out_dir / \"genome.json\"\n        self[\"seq_region\"] = out_dir / \"seq_region.json\"\n        self[\"fasta_dna\"] = out_dir / \"dna.fasta\"\n        self[\"fasta_pep\"] = out_dir / \"pep.fasta\"\n        self[\"gene_models\"] = out_dir / \"genes.gff\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.UnsupportedData","title":"<code>UnsupportedData</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When an expected data is not supported by the current parser.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>class UnsupportedData(Exception):\n    \"\"\"When an expected data is not supported by the current parser.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genbank/extract_data/#ensembl.io.genomio.genbank.extract_data.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/genbank/extract_data.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(description=\"Parse a GenBank file and create cleaned up files from it.\")\n    parser.add_argument_src_path(\"--gb_file\", required=True, help=\"sequence accession file\")\n    parser.add_argument(\"--prefix\", required=True, help=\"prefix to add to every feature ID\")\n    parser.add_argument(\"--prod_name\", required=True, help=\"production name for the species\")\n    parser.add_argument_dst_path(\n        \"--out_dir\", default=Path.cwd(), help=\"output folder where the generated files will be stored\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    gb_extractor = FormattedFilesGenerator(\n        prefix=args.prefix, prod_name=args.prod_name, gb_file=args.gb_file, out_dir=args.out_dir\n    )\n    gb_extractor.parse_genbank(args.gb_file)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/","title":"genome_metadata","text":""},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata","title":"<code>ensembl.io.genomio.genome_metadata</code>","text":"<p>Genome metadata handling module.</p>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.PROVIDER_DATA","title":"<code>PROVIDER_DATA = {'GenBank': {'assembly': {'provider_name': 'GenBank', 'provider_url': 'https://www.ncbi.nlm.nih.gov/datasets/genome'}, 'annotation': {'provider_name': 'GenBank', 'provider_url': 'https://www.ncbi.nlm.nih.gov/datasets/genome'}}, 'RefSeq': {'assembly': {'provider_name': 'RefSeq', 'provider_url': 'https://www.ncbi.nlm.nih.gov/datasets/genome'}, 'annotation': {'provider_name': 'RefSeq', 'provider_url': 'https://www.ncbi.nlm.nih.gov/datasets/genome'}}}</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.MetadataError","title":"<code>MetadataError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a metadata value is not expected.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>class MetadataError(Exception):\n    \"\"\"When a metadata value is not expected.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.MissingNodeError","title":"<code>MissingNodeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a taxon XML node cannot be found.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>class MissingNodeError(Exception):\n    \"\"\"When a taxon XML node cannot be found.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.add_assembly_version","title":"<code>add_assembly_version(genome_data)</code>","text":"<p>Adds version number to the genome's assembly information if one is not present already.</p> <p>Parameters:</p> Name Type Description Default <code>genome_data</code> <code>Dict</code> <p>Genome information of assembly, accession and annotation.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def add_assembly_version(genome_data: Dict) -&gt; None:\n    \"\"\"Adds version number to the genome's assembly information if one is not present already.\n\n    Args:\n        genome_data: Genome information of assembly, accession and annotation.\n    \"\"\"\n    assembly = genome_data[\"assembly\"]\n    if \"version\" not in assembly:\n        accession = assembly[\"accession\"]\n        version = accession.partition(\".\")[2]\n        if version:\n            assembly[\"version\"] = int(version)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.add_genebuild_metadata","title":"<code>add_genebuild_metadata(genome_data)</code>","text":"<p>Adds genebuild metadata to genome information if not present already.</p> <p>The default convention is to use the current date as <code>\"version\"</code> and <code>\"start_date\"</code>.</p> <p>Parameters:</p> Name Type Description Default <code>genome_data</code> <code>Dict</code> <p>Genome information of assembly, accession and annotation.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def add_genebuild_metadata(genome_data: Dict) -&gt; None:\n    \"\"\"Adds genebuild metadata to genome information if not present already.\n\n    The default convention is to use the current date as `\"version\"` and `\"start_date\"`.\n\n    Args:\n        genome_data: Genome information of assembly, accession and annotation.\n    \"\"\"\n    genebuild = genome_data.setdefault(\"genebuild\", {})\n    current_date = datetime.date.today().isoformat()\n    if \"version\" not in genebuild:\n        genebuild[\"version\"] = current_date\n    if \"start_date\" not in genebuild:\n        genebuild[\"start_date\"] = current_date\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.add_provider","title":"<code>add_provider(genome_metadata, ncbi_data)</code>","text":"<p>Updates the genome metadata adding provider information for assembly and gene models.</p> <p>Assembly provider metadata will only be added if it is missing, i.e. neither <code>\"provider_name\"</code> or <code>\"provider_url\"</code> are present. The gene model metadata will only be added if <code>gff3_file</code> is provided.</p> <p>Parameters:</p> Name Type Description Default <code>genome_data</code> <p>Genome information of assembly, accession and annotation.</p> required <code>ncbi_data</code> <code>Dict</code> <p>Report data from NCBI datasets.</p> required <p>Raises:</p> Type Description <code>MetadataError</code> <p>If accession's format in genome metadata does not match with a known provider.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def add_provider(genome_metadata: Dict, ncbi_data: Dict) -&gt; None:\n    \"\"\"Updates the genome metadata adding provider information for assembly and gene models.\n\n    Assembly provider metadata will only be added if it is missing, i.e. neither `\"provider_name\"` or\n    `\"provider_url\"` are present. The gene model metadata will only be added if `gff3_file` is provided.\n\n    Args:\n        genome_data: Genome information of assembly, accession and annotation.\n        ncbi_data: Report data from NCBI datasets.\n\n    Raises:\n        MetadataError: If accession's format in genome metadata does not match with a known provider.\n    \"\"\"\n    # Get accession provider\n    accession = genome_metadata[\"assembly\"][\"accession\"]\n    if accession.startswith(\"GCF\"):\n        provider = PROVIDER_DATA[\"RefSeq\"]\n    elif accession.startswith(\"GCA\"):\n        provider = PROVIDER_DATA[\"GenBank\"]\n    else:\n        raise MetadataError(f\"Accession does not look like an INSDC or RefSeq accession: {accession}\")\n\n    # Add assembly provider (if missing)\n    assembly = genome_metadata[\"assembly\"]\n    if (\"provider_name\" not in assembly) and (\"provider_url\" not in assembly):\n        assembly[\"provider_name\"] = provider[\"assembly\"][\"provider_name\"]\n        assembly[\"provider_url\"] = f'{provider[\"assembly\"][\"provider_url\"]}/{accession}'\n\n    # Add annotation provider if there are gene models\n    if \"annotation_info\" in ncbi_data:\n        annotation = genome_metadata.setdefault(\"annotation\", {})\n        if (\"provider_name\" not in annotation) and (\"provider_url\" not in annotation):\n            annotation[\"provider_name\"] = provider[\"annotation\"][\"provider_name\"]\n            annotation[\"provider_url\"] = f'{provider[\"annotation\"][\"provider_url\"]}/{accession}'\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.add_species_metadata","title":"<code>add_species_metadata(genome_metadata, ncbi_data)</code>","text":"<p>Adds taxonomy ID, scientific name and strain (if present) from the NCBI dataset report.</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <code>Dict</code> <p>Genome information of assembly, accession and annotation.</p> required <code>ncbi_data</code> <code>Dict</code> <p>Report data from NCBI datasets.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def add_species_metadata(genome_metadata: Dict, ncbi_data: Dict) -&gt; None:\n    \"\"\"Adds taxonomy ID, scientific name and strain (if present) from the NCBI dataset report.\n\n    Args:\n        genome_metadata: Genome information of assembly, accession and annotation.\n        ncbi_data: Report data from NCBI datasets.\n\n    \"\"\"\n    species = genome_metadata.setdefault(\"species\", {})\n    try:\n        organism = ncbi_data[\"organism\"]\n    except KeyError:\n        return\n\n    if \"tax_id\" in organism:\n        species.setdefault(\"taxonomy_id\", organism[\"tax_id\"])\n    if \"organism_name\" in organism:\n        species.setdefault(\"scientific_name\", organism[\"organism_name\"])\n\n    try:\n        species.setdefault(\"strain\", organism[\"infraspecific_names\"][\"strain\"])\n    except KeyError:\n        pass\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.amend_genome_metadata","title":"<code>amend_genome_metadata(genome_infile, genome_outfile, report_file=None, genbank_file=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>genome_infile</code> <code>PathLike</code> <p>Genome metadata following the <code>src/python/ensembl/io/genomio/data/schemas/genome.json</code>.</p> required <code>genome_outfile</code> <code>PathLike</code> <p>Amended genome metadata file.</p> required <code>report_file</code> <code>Optional[PathLike]</code> <p>INSDC/RefSeq sequences report file.</p> <code>None</code> <code>genbank_file</code> <code>Optional[PathLike]</code> <p>INSDC/RefSeq GBFF file.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def amend_genome_metadata(\n    genome_infile: PathLike,\n    genome_outfile: PathLike,\n    report_file: Optional[PathLike] = None,\n    genbank_file: Optional[PathLike] = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        genome_infile: Genome metadata following the `src/python/ensembl/io/genomio/data/schemas/genome.json`.\n        genome_outfile: Amended genome metadata file.\n        report_file: INSDC/RefSeq sequences report file.\n        genbank_file: INSDC/RefSeq GBFF file.\n    \"\"\"\n    genome_metadata = get_json(genome_infile)\n    # Get additional sequences in the assembly but not in the data\n    if report_file:\n        genbank_path = Path(genbank_file) if genbank_file else None\n        additions = get_additions(report_file, genbank_path)\n        if additions:\n            genome_metadata[\"added_seq\"] = {\"region_name\": additions}\n    # Print out the file\n    genome_outfile = Path(genome_outfile)\n    print_json(genome_outfile, genome_metadata)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.check_assembly_version","title":"<code>check_assembly_version(genome_metadata)</code>","text":"<p>Updates the assembly version of the genome metadata provided.</p> <p>If <code>version</code> meta key is not and integer or it is not available, the assembly accession's version will be used instead.</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <code>dict[str, Any]</code> <p>Nested metadata key values from the core metadata table.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>version</code> and the assembly accession's version are not integers or are missing.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def check_assembly_version(genome_metadata: dict[str, Any]) -&gt; None:\n    \"\"\"Updates the assembly version of the genome metadata provided.\n\n    If `version` meta key is not and integer or it is not available, the assembly accession's version\n    will be used instead.\n\n    Args:\n        genome_metadata: Nested metadata key values from the core metadata table.\n\n    Raises:\n        ValueError: If both `version` and the assembly accession's version are not integers or are missing.\n    \"\"\"\n    assembly = genome_metadata[\"assembly\"]\n    version = assembly.get(\"version\")\n    # Check the version is an integer\n    try:\n        assembly[\"version\"] = int(version)\n    except (ValueError, TypeError) as exc:\n        # Get the version from the assembly accession\n        accession = assembly[\"accession\"]\n        version = accession.partition(\".\")[2]\n        try:\n            assembly[\"version\"] = int(version)\n        except ValueError:\n            raise ValueError(f\"Assembly version is not an integer in {assembly}\") from exc\n        logging.info(f\"Assembly version [v{version}] obtained from assembly accession ({accession}).\")\n    else:\n        logging.info(f'Located version [v{assembly[\"version\"]}] info from meta data.')\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.check_genebuild_version","title":"<code>check_genebuild_version(genome_metadata)</code>","text":"<p>Updates the genebuild version (if not present) from the genebuild ID, removing the latter.</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <code>dict[str, Any]</code> <p>Nested metadata key values from the core metadata table.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is no genebuild version or ID available.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def check_genebuild_version(genome_metadata: dict[str, Any]) -&gt; None:\n    \"\"\"Updates the genebuild version (if not present) from the genebuild ID, removing the latter.\n\n    Args:\n        genome_metadata: Nested metadata key values from the core metadata table.\n\n    Raises:\n        ValueError: If there is no genebuild version or ID available.\n    \"\"\"\n    try:\n        genebuild = genome_metadata[\"genebuild\"]\n    except KeyError:\n        return\n    if \"version\" not in genebuild:\n        try:\n            genebuild_id = genebuild[\"id\"]\n        except KeyError:\n            # pylint: disable=raise-missing-from\n            raise ValueError(\"No genebuild version or ID found\")\n        genome_metadata[\"genebuild\"][\"version\"] = str(genebuild_id)\n    # Drop genebuild ID since there is a genebuild version\n    genome_metadata[\"genebuild\"].pop(\"id\", None)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.filter_genome_meta","title":"<code>filter_genome_meta(genome_metadata, metafilter, meta_update)</code>","text":"<p>Returns a filtered metadata dictionary with only the predefined keys in METADATA_FILTER.</p> <p>Also converts to expected data types (to follow the genome JSON schema).</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <code>dict[str, Any]</code> <p>Nested metadata key values from the core metadata table.</p> required <code>metafilter</code> <code>dict | None</code> <p>Input JSON containing subset of meta table values to filter on.</p> required <code>meta_update</code> <code>bool</code> <p>Deactivates additional meta updating.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def filter_genome_meta(\n    genome_metadata: dict[str, Any], metafilter: dict | None, meta_update: bool\n) -&gt; dict[str, Any]:\n    \"\"\"Returns a filtered metadata dictionary with only the predefined keys in METADATA_FILTER.\n\n    Also converts to expected data types (to follow the genome JSON schema).\n\n    Args:\n        genome_metadata: Nested metadata key values from the core metadata table.\n        metafilter: Input JSON containing subset of meta table values to filter on.\n        meta_update: Deactivates additional meta updating.\n\n    \"\"\"\n    filtered_metadata: dict[str, Any] = {}\n\n    if metafilter:\n        metadata_filter: dict[str, dict[str, type]] = metafilter\n    else:\n        metadata_filter = DEFAULT_FILTER\n\n    for key, subfilter in metadata_filter.items():\n        if key in genome_metadata:\n            filtered_metadata[key] = {}\n            for subkey, value_type in subfilter.items():\n                if isinstance(value_type, str):\n                    value_type = type(value_type)\n                if isinstance(value_type, int):\n                    value_type = type(value_type)\n                if subkey in genome_metadata[key]:\n                    value = genome_metadata[key][subkey]\n                    if isinstance(value, list):\n                        value = [value_type(x) for x in value]\n                    else:\n                        value = value_type(value)\n                    filtered_metadata[key][subkey] = value\n\n    # Optional assembly and genebuild based filtering:\n    if meta_update:\n        # Check assembly and genebuild versions\n        check_assembly_refseq(filtered_metadata)\n        check_assembly_version(filtered_metadata)\n        check_genebuild_version(filtered_metadata)\n\n    return filtered_metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.get_additions","title":"<code>get_additions(report_path, gbff_path)</code>","text":"<p>Returns all <code>seq_regions</code> that are mentioned in the report but that are not in the data.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>PathLike</code> <p>Path to the report file.</p> required <code>gbff_path</code> <code>Optional[PathLike]</code> <p>Path to the GBFF file.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def get_additions(report_path: PathLike, gbff_path: Optional[PathLike]) -&gt; List[str]:\n    \"\"\"Returns all `seq_regions` that are mentioned in the report but that are not in the data.\n\n    Args:\n        report_path: Path to the report file.\n        gbff_path: Path to the GBFF file.\n    \"\"\"\n    gbff_regions = set(get_gbff_regions(gbff_path))\n    report_regions = get_report_regions_names(report_path)\n    additions = []\n    for seq_region_name in report_regions:\n        (genbank_seq_name, refseq_seq_name) = seq_region_name\n        if genbank_seq_name not in gbff_regions and refseq_seq_name not in gbff_regions:\n            if refseq_seq_name:\n                additions.append(refseq_seq_name)\n            else:\n                additions.append(genbank_seq_name)\n    additions = sorted(additions)\n    return additions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.get_gbff_regions","title":"<code>get_gbff_regions(gbff_path)</code>","text":"<p>Returns the <code>seq_region</code> data from a GBFF file.</p> <p>Parameters:</p> Name Type Description Default <code>gbff_path</code> <code>Optional[PathLike]</code> <p>GBFF file path to use.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def get_gbff_regions(gbff_path: Optional[PathLike]) -&gt; List[str]:\n    \"\"\"Returns the `seq_region` data from a GBFF file.\n\n    Args:\n        gbff_path: GBFF file path to use.\n    \"\"\"\n    seq_regions = []\n    if gbff_path:\n        with open_gz_file(gbff_path) as gbff_file:\n            for record in SeqIO.parse(gbff_file, \"genbank\"):\n                record_id = re.sub(_VERSION_END, \"\", record.id)\n                seq_regions.append(record_id)\n    return seq_regions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.get_genome_metadata","title":"<code>get_genome_metadata(session, db_name)</code>","text":"<p>Returns the meta table content from the core database in a nested dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session for the current core.</p> required <code>db_name</code> <code>str | None</code> <p>Target database name</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def get_genome_metadata(session: Session, db_name: str | None) -&gt; dict[str, Any]:\n    \"\"\"Returns the meta table content from the core database in a nested dictionary.\n\n    Args:\n        session: Session for the current core.\n        db_name: Target database name\n    \"\"\"\n    genome_metadata: dict[str, Any] = {}\n\n    meta_statement = select(Meta)\n    for row in session.execute(meta_statement).unique().all():\n        meta_key = row[0].meta_key\n        meta_value = row[0].meta_value\n        (main_key, _, subkey) = meta_key.partition(\".\")\n        # Use empty string as subkey when no \".\" found to simplify dictionary creation\n        if main_key in genome_metadata:\n            if subkey in genome_metadata[main_key]:\n                genome_metadata[main_key][subkey].append(meta_value)\n            else:\n                genome_metadata[main_key][subkey] = [meta_value]\n        else:\n            genome_metadata[main_key] = {subkey: [meta_value]}\n\n    if db_name:\n        genome_metadata[\"database\"] = {\"name\": f\"{db_name}\"}\n\n    # Parse genome metadata to simplify dictionary and check data consistency\n    for main_key, subkeys_dict in genome_metadata.items():\n        # Replace single-value lists by the value itself\n        for subkey, value in subkeys_dict.items():\n            if len(value) == 1:\n                subkeys_dict[subkey] = value[0]\n        # Remove nested dictionary if it only has \"\" as key, passing its value to the main key\n        if \"\" in subkeys_dict:\n            if len(subkeys_dict) == 1:\n                genome_metadata[main_key] = subkeys_dict.pop(\"\")\n            else:\n                raise ValueError(f\"Unexpected meta keys for '{main_key}': {', '.join(subkeys_dict.keys())}\")\n    return genome_metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.get_report_regions_names","title":"<code>get_report_regions_names(report_path)</code>","text":"<p>Returns a list of GenBank-RefSeq <code>seq_region</code> names from the assembly report file.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>PathLike</code> <p>Path to the assembly report file from INSDC/RefSeq.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def get_report_regions_names(report_path: PathLike) -&gt; List[Tuple[str, str]]:\n    \"\"\"Returns a list of GenBank-RefSeq `seq_region` names from the assembly report file.\n\n    Args:\n        report_path: Path to the assembly report file from INSDC/RefSeq.\n    \"\"\"\n    # Get the report in a CSV format, easier to manipulate\n    report_csv, _ = _report_to_csv(report_path)\n    # Feed the CSV string to the CSV reader\n    reader = csv.DictReader(report_csv.splitlines(), delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n    # Create the seq_regions\n    seq_regions = []\n    for row in reader:\n        refseq_name = row[\"RefSeq-Accn\"]\n        genbank_name = row[\"GenBank-Accn\"]\n        if refseq_name == \"na\":\n            refseq_name = \"\"\n        if genbank_name == \"na\":\n            genbank_name = \"\"\n        refseq_name = re.sub(_VERSION_END, \"\", refseq_name)\n        genbank_name = re.sub(_VERSION_END, \"\", genbank_name)\n        seq_regions.append((genbank_name, refseq_name))\n    return seq_regions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.metadata_dump_setup","title":"<code>metadata_dump_setup(db_url, input_filter, meta_update, append_db)</code>","text":"<p>Setup main stages of genome meta dump from user input arguments provided. Args:     db_url: Target core database URL.     input_filter: Input JSON containing subset of meta table values to filter on.     no_update: Deactivate additional meta updating.     append_db: Append target core database name to output JSON.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def metadata_dump_setup(\n    db_url: URL, input_filter: StrPath | None, meta_update: bool, append_db: bool\n) -&gt; dict[str, Any]:\n    \"\"\"Setup main stages of genome meta dump from user input arguments provided.\n    Args:\n        db_url: Target core database URL.\n        input_filter: Input JSON containing subset of meta table values to filter on.\n        no_update: Deactivate additional meta updating.\n        append_db: Append target core database name to output JSON.\n\n    \"\"\"\n    dbc = DBConnectionLite(db_url)\n    db_name = None\n    meta_filter = {}\n    if append_db:\n        db_name = db_url.database\n\n    if input_filter:\n        unconverted_json = get_json(input_filter)\n        meta_filter = convert_dict(unconverted_json)\n\n    with dbc.session_scope() as session:\n        genome_meta = get_genome_metadata(session, db_name)\n        genome_meta = filter_genome_meta(genome_meta, meta_filter, meta_update)\n\n    return genome_meta\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/#ensembl.io.genomio.genome_metadata.prepare_genome_metadata","title":"<code>prepare_genome_metadata(input_file, output_file, ncbi_meta)</code>","text":"<p>Updates the genome metadata JSON file with additional information.</p> <p>In particular, more information is added about the provider, the assembly and its gene build version, and the taxonomy.</p> <p>Parameters:</p> Name Type Description Default <code>input_file</code> <code>PathLike</code> <p>Path to JSON file with genome metadata.</p> required <code>output_file</code> <code>PathLike</code> <p>Output directory where to generate the final <code>genome.json</code> file.</p> required <code>ncbi_meta</code> <code>PathLike</code> <p>JSON file from NCBI datasets.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def prepare_genome_metadata(\n    input_file: PathLike,\n    output_file: PathLike,\n    ncbi_meta: PathLike,\n) -&gt; None:\n    \"\"\"Updates the genome metadata JSON file with additional information.\n\n    In particular, more information is added about the provider, the assembly and its gene build version,\n    and the taxonomy.\n\n    Args:\n        input_file: Path to JSON file with genome metadata.\n        output_file: Output directory where to generate the final `genome.json` file.\n        ncbi_meta: JSON file from NCBI datasets.\n\n    \"\"\"\n    genome_data = get_json(input_file)\n    ncbi_data = {}\n    if ncbi_meta:\n        ncbi_data = get_json(ncbi_meta)[\"reports\"][0]\n\n    # Amend any missing metadata\n    add_provider(genome_data, ncbi_data)\n    add_assembly_version(genome_data)\n    add_genebuild_metadata(genome_data)\n    add_species_metadata(genome_data, ncbi_data)\n    # Dump updated genome metadata\n    print_json(output_file, genome_data)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/","title":"dump","text":""},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump","title":"<code>ensembl.io.genomio.genome_metadata.dump</code>","text":"<p>Generates a JSON file representing the genome metadata from a core database.</p>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.DEFAULT_FILTER","title":"<code>DEFAULT_FILTER = {'database': {'name': str}, 'added_seq': {'region_name': str}, 'annotation': {'provider_name': str, 'provider_url': str}, 'assembly': {'accession': str, 'date': str, 'name': str, 'provider_name': str, 'provider_url': str, 'version': int}, 'BRC4': {'organism_abbrev': str, 'component': str}, 'genebuild': {'id': str, 'method': str, 'method_display': str, 'start_date': str, 'version': str}, 'species': {'alias': str, 'annotation_source': str, 'display_name': str, 'division': str, 'production_name': str, 'scientific_name': str, 'strain': str, 'taxonomy_id': int}}</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.check_assembly_refseq","title":"<code>check_assembly_refseq(gmeta_out)</code>","text":"<p>Update the GCA accession to use GCF if it is from RefSeq.</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <p>Nested metadata key values from the core metadata table.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def check_assembly_refseq(gmeta_out: dict[str, Any]) -&gt; None:\n    \"\"\"Update the GCA accession to use GCF if it is from RefSeq.\n\n    Args:\n        genome_metadata: Nested metadata key values from the core metadata table.\n    \"\"\"\n    assembly = gmeta_out.get(\"assembly\", {})\n    if assembly.get(\"provider_name\"):\n        if assembly[\"provider_name\"] == \"RefSeq\":\n            assembly[\"accession\"] = assembly[\"accession\"].replace(\"GCA\", \"GCF\")\n            logging.info(\"GCA accession updated to RefSeq GFC accession.\")\n        else:\n            logging.info(f\"Meta check 'assembly is RefSeq': Asm provider = {assembly['provider_name']}\")\n    else:\n        logging.debug(\n            \"Meta filter update to RefSeq accession not done: user meta filter missing: \\\n            'assembly.provider_name'\"\n        )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.check_assembly_version","title":"<code>check_assembly_version(genome_metadata)</code>","text":"<p>Updates the assembly version of the genome metadata provided.</p> <p>If <code>version</code> meta key is not and integer or it is not available, the assembly accession's version will be used instead.</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <code>dict[str, Any]</code> <p>Nested metadata key values from the core metadata table.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>version</code> and the assembly accession's version are not integers or are missing.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def check_assembly_version(genome_metadata: dict[str, Any]) -&gt; None:\n    \"\"\"Updates the assembly version of the genome metadata provided.\n\n    If `version` meta key is not and integer or it is not available, the assembly accession's version\n    will be used instead.\n\n    Args:\n        genome_metadata: Nested metadata key values from the core metadata table.\n\n    Raises:\n        ValueError: If both `version` and the assembly accession's version are not integers or are missing.\n    \"\"\"\n    assembly = genome_metadata[\"assembly\"]\n    version = assembly.get(\"version\")\n    # Check the version is an integer\n    try:\n        assembly[\"version\"] = int(version)\n    except (ValueError, TypeError) as exc:\n        # Get the version from the assembly accession\n        accession = assembly[\"accession\"]\n        version = accession.partition(\".\")[2]\n        try:\n            assembly[\"version\"] = int(version)\n        except ValueError:\n            raise ValueError(f\"Assembly version is not an integer in {assembly}\") from exc\n        logging.info(f\"Assembly version [v{version}] obtained from assembly accession ({accession}).\")\n    else:\n        logging.info(f'Located version [v{assembly[\"version\"]}] info from meta data.')\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.check_genebuild_version","title":"<code>check_genebuild_version(genome_metadata)</code>","text":"<p>Updates the genebuild version (if not present) from the genebuild ID, removing the latter.</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <code>dict[str, Any]</code> <p>Nested metadata key values from the core metadata table.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is no genebuild version or ID available.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def check_genebuild_version(genome_metadata: dict[str, Any]) -&gt; None:\n    \"\"\"Updates the genebuild version (if not present) from the genebuild ID, removing the latter.\n\n    Args:\n        genome_metadata: Nested metadata key values from the core metadata table.\n\n    Raises:\n        ValueError: If there is no genebuild version or ID available.\n    \"\"\"\n    try:\n        genebuild = genome_metadata[\"genebuild\"]\n    except KeyError:\n        return\n    if \"version\" not in genebuild:\n        try:\n            genebuild_id = genebuild[\"id\"]\n        except KeyError:\n            # pylint: disable=raise-missing-from\n            raise ValueError(\"No genebuild version or ID found\")\n        genome_metadata[\"genebuild\"][\"version\"] = str(genebuild_id)\n    # Drop genebuild ID since there is a genebuild version\n    genome_metadata[\"genebuild\"].pop(\"id\", None)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.convert_dict","title":"<code>convert_dict(meta_dict)</code>","text":"<p>Converts text JSON to add type properties from string</p> <p>Parameters:</p> Name Type Description Default <code>meta_dict</code> <code>dict</code> <p>User meta dictionary with literal string typing to be converted.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def convert_dict(meta_dict: dict) -&gt; dict:\n    \"\"\"Converts text JSON to add type properties from string\n\n    Args:\n        meta_dict: User meta dictionary with literal string typing to be converted.\n    \"\"\"\n    new_dict = meta_dict.copy()\n    for key, value in meta_dict.items():\n        if isinstance(value, dict):\n            new_dict[key] = convert_dict(value)\n        else:\n            new_dict[key] = locate(value)\n    return new_dict\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.filter_genome_meta","title":"<code>filter_genome_meta(genome_metadata, metafilter, meta_update)</code>","text":"<p>Returns a filtered metadata dictionary with only the predefined keys in METADATA_FILTER.</p> <p>Also converts to expected data types (to follow the genome JSON schema).</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <code>dict[str, Any]</code> <p>Nested metadata key values from the core metadata table.</p> required <code>metafilter</code> <code>dict | None</code> <p>Input JSON containing subset of meta table values to filter on.</p> required <code>meta_update</code> <code>bool</code> <p>Deactivates additional meta updating.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def filter_genome_meta(\n    genome_metadata: dict[str, Any], metafilter: dict | None, meta_update: bool\n) -&gt; dict[str, Any]:\n    \"\"\"Returns a filtered metadata dictionary with only the predefined keys in METADATA_FILTER.\n\n    Also converts to expected data types (to follow the genome JSON schema).\n\n    Args:\n        genome_metadata: Nested metadata key values from the core metadata table.\n        metafilter: Input JSON containing subset of meta table values to filter on.\n        meta_update: Deactivates additional meta updating.\n\n    \"\"\"\n    filtered_metadata: dict[str, Any] = {}\n\n    if metafilter:\n        metadata_filter: dict[str, dict[str, type]] = metafilter\n    else:\n        metadata_filter = DEFAULT_FILTER\n\n    for key, subfilter in metadata_filter.items():\n        if key in genome_metadata:\n            filtered_metadata[key] = {}\n            for subkey, value_type in subfilter.items():\n                if isinstance(value_type, str):\n                    value_type = type(value_type)\n                if isinstance(value_type, int):\n                    value_type = type(value_type)\n                if subkey in genome_metadata[key]:\n                    value = genome_metadata[key][subkey]\n                    if isinstance(value, list):\n                        value = [value_type(x) for x in value]\n                    else:\n                        value = value_type(value)\n                    filtered_metadata[key][subkey] = value\n\n    # Optional assembly and genebuild based filtering:\n    if meta_update:\n        # Check assembly and genebuild versions\n        check_assembly_refseq(filtered_metadata)\n        check_assembly_version(filtered_metadata)\n        check_genebuild_version(filtered_metadata)\n\n    return filtered_metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.get_genome_metadata","title":"<code>get_genome_metadata(session, db_name)</code>","text":"<p>Returns the meta table content from the core database in a nested dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session for the current core.</p> required <code>db_name</code> <code>str | None</code> <p>Target database name</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def get_genome_metadata(session: Session, db_name: str | None) -&gt; dict[str, Any]:\n    \"\"\"Returns the meta table content from the core database in a nested dictionary.\n\n    Args:\n        session: Session for the current core.\n        db_name: Target database name\n    \"\"\"\n    genome_metadata: dict[str, Any] = {}\n\n    meta_statement = select(Meta)\n    for row in session.execute(meta_statement).unique().all():\n        meta_key = row[0].meta_key\n        meta_value = row[0].meta_value\n        (main_key, _, subkey) = meta_key.partition(\".\")\n        # Use empty string as subkey when no \".\" found to simplify dictionary creation\n        if main_key in genome_metadata:\n            if subkey in genome_metadata[main_key]:\n                genome_metadata[main_key][subkey].append(meta_value)\n            else:\n                genome_metadata[main_key][subkey] = [meta_value]\n        else:\n            genome_metadata[main_key] = {subkey: [meta_value]}\n\n    if db_name:\n        genome_metadata[\"database\"] = {\"name\": f\"{db_name}\"}\n\n    # Parse genome metadata to simplify dictionary and check data consistency\n    for main_key, subkeys_dict in genome_metadata.items():\n        # Replace single-value lists by the value itself\n        for subkey, value in subkeys_dict.items():\n            if len(value) == 1:\n                subkeys_dict[subkey] = value[0]\n        # Remove nested dictionary if it only has \"\" as key, passing its value to the main key\n        if \"\" in subkeys_dict:\n            if len(subkeys_dict) == 1:\n                genome_metadata[main_key] = subkeys_dict.pop(\"\")\n            else:\n                raise ValueError(f\"Unexpected meta keys for '{main_key}': {', '.join(subkeys_dict.keys())}\")\n    return genome_metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.main","title":"<code>main(arg_list=None)</code>","text":"<p>Main script entry-point.</p> <p>Parameters:</p> Name Type Description Default <code>arg_list</code> <code>list[str] | None</code> <p>Arguments to parse passing list to parse_args().</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def main(arg_list: list[str] | None = None) -&gt; None:\n    \"\"\"Main script entry-point.\n\n    Args:\n        arg_list: Arguments to parse passing list to parse_args().\n    \"\"\"\n    args = parse_args(arg_list)\n    init_logging_with_args(args)\n\n    genome_meta = metadata_dump_setup(\n        db_url=args.url, input_filter=args.metafilter, meta_update=args.meta_update, append_db=args.append_db\n    )\n\n    print(json.dumps(genome_meta, indent=2, sort_keys=True))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.metadata_dump_setup","title":"<code>metadata_dump_setup(db_url, input_filter, meta_update, append_db)</code>","text":"<p>Setup main stages of genome meta dump from user input arguments provided. Args:     db_url: Target core database URL.     input_filter: Input JSON containing subset of meta table values to filter on.     no_update: Deactivate additional meta updating.     append_db: Append target core database name to output JSON.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def metadata_dump_setup(\n    db_url: URL, input_filter: StrPath | None, meta_update: bool, append_db: bool\n) -&gt; dict[str, Any]:\n    \"\"\"Setup main stages of genome meta dump from user input arguments provided.\n    Args:\n        db_url: Target core database URL.\n        input_filter: Input JSON containing subset of meta table values to filter on.\n        no_update: Deactivate additional meta updating.\n        append_db: Append target core database name to output JSON.\n\n    \"\"\"\n    dbc = DBConnectionLite(db_url)\n    db_name = None\n    meta_filter = {}\n    if append_db:\n        db_name = db_url.database\n\n    if input_filter:\n        unconverted_json = get_json(input_filter)\n        meta_filter = convert_dict(unconverted_json)\n\n    with dbc.session_scope() as session:\n        genome_meta = get_genome_metadata(session, db_name)\n        genome_meta = filter_genome_meta(genome_meta, meta_filter, meta_update)\n\n    return genome_meta\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/dump/#ensembl.io.genomio.genome_metadata.dump.parse_args","title":"<code>parse_args(arg_list)</code>","text":"<p>Return a populated namespace with the arguments parsed from a list or from the command line.</p> <p>Parameters:</p> Name Type Description Default <code>arg_list</code> <code>list[str] | None</code> <p>List of arguments to parse. If <code>None</code>, grab them from the command line.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/dump.py</code> <pre><code>def parse_args(arg_list: list[str] | None) -&gt; argparse.Namespace:\n    \"\"\"Return a populated namespace with the arguments parsed from a list or from the command line.\n\n    Args:\n        arg_list: List of arguments to parse. If `None`, grab them from the command line.\n\n    \"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_server_arguments(include_database=True, help=\"server url and core database\")\n    parser.add_argument_src_path(\n        \"--metafilter\", default=None, help=\"JSON file of nested meta_key:meta_value to filter dump output.\"\n    )\n    parser.add_argument(\n        \"--meta_update\",\n        action=\"store_true\",\n        help=\"Perform assembly and genebuild 'version' metadata checks &amp; update if needed.\",\n    )\n    parser.add_argument(\"--append_db\", action=\"store_true\", help=\"Append core database name to output JSON.\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    return parser.parse_args(arg_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/extend/","title":"extend","text":""},{"location":"reference/ensembl/io/genomio/genome_metadata/extend/#ensembl.io.genomio.genome_metadata.extend","title":"<code>ensembl.io.genomio.genome_metadata.extend</code>","text":"<p>Update a genome metadata file to include additional sequence regions (e.g. MT chromosome).</p>"},{"location":"reference/ensembl/io/genomio/genome_metadata/extend/#ensembl.io.genomio.genome_metadata.extend.amend_genome_metadata","title":"<code>amend_genome_metadata(genome_infile, genome_outfile, report_file=None, genbank_file=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>genome_infile</code> <code>PathLike</code> <p>Genome metadata following the <code>src/python/ensembl/io/genomio/data/schemas/genome.json</code>.</p> required <code>genome_outfile</code> <code>PathLike</code> <p>Amended genome metadata file.</p> required <code>report_file</code> <code>Optional[PathLike]</code> <p>INSDC/RefSeq sequences report file.</p> <code>None</code> <code>genbank_file</code> <code>Optional[PathLike]</code> <p>INSDC/RefSeq GBFF file.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def amend_genome_metadata(\n    genome_infile: PathLike,\n    genome_outfile: PathLike,\n    report_file: Optional[PathLike] = None,\n    genbank_file: Optional[PathLike] = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        genome_infile: Genome metadata following the `src/python/ensembl/io/genomio/data/schemas/genome.json`.\n        genome_outfile: Amended genome metadata file.\n        report_file: INSDC/RefSeq sequences report file.\n        genbank_file: INSDC/RefSeq GBFF file.\n    \"\"\"\n    genome_metadata = get_json(genome_infile)\n    # Get additional sequences in the assembly but not in the data\n    if report_file:\n        genbank_path = Path(genbank_file) if genbank_file else None\n        additions = get_additions(report_file, genbank_path)\n        if additions:\n            genome_metadata[\"added_seq\"] = {\"region_name\": additions}\n    # Print out the file\n    genome_outfile = Path(genome_outfile)\n    print_json(genome_outfile, genome_metadata)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/extend/#ensembl.io.genomio.genome_metadata.extend.get_additions","title":"<code>get_additions(report_path, gbff_path)</code>","text":"<p>Returns all <code>seq_regions</code> that are mentioned in the report but that are not in the data.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>PathLike</code> <p>Path to the report file.</p> required <code>gbff_path</code> <code>Optional[PathLike]</code> <p>Path to the GBFF file.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def get_additions(report_path: PathLike, gbff_path: Optional[PathLike]) -&gt; List[str]:\n    \"\"\"Returns all `seq_regions` that are mentioned in the report but that are not in the data.\n\n    Args:\n        report_path: Path to the report file.\n        gbff_path: Path to the GBFF file.\n    \"\"\"\n    gbff_regions = set(get_gbff_regions(gbff_path))\n    report_regions = get_report_regions_names(report_path)\n    additions = []\n    for seq_region_name in report_regions:\n        (genbank_seq_name, refseq_seq_name) = seq_region_name\n        if genbank_seq_name not in gbff_regions and refseq_seq_name not in gbff_regions:\n            if refseq_seq_name:\n                additions.append(refseq_seq_name)\n            else:\n                additions.append(genbank_seq_name)\n    additions = sorted(additions)\n    return additions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/extend/#ensembl.io.genomio.genome_metadata.extend.get_gbff_regions","title":"<code>get_gbff_regions(gbff_path)</code>","text":"<p>Returns the <code>seq_region</code> data from a GBFF file.</p> <p>Parameters:</p> Name Type Description Default <code>gbff_path</code> <code>Optional[PathLike]</code> <p>GBFF file path to use.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def get_gbff_regions(gbff_path: Optional[PathLike]) -&gt; List[str]:\n    \"\"\"Returns the `seq_region` data from a GBFF file.\n\n    Args:\n        gbff_path: GBFF file path to use.\n    \"\"\"\n    seq_regions = []\n    if gbff_path:\n        with open_gz_file(gbff_path) as gbff_file:\n            for record in SeqIO.parse(gbff_file, \"genbank\"):\n                record_id = re.sub(_VERSION_END, \"\", record.id)\n                seq_regions.append(record_id)\n    return seq_regions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/extend/#ensembl.io.genomio.genome_metadata.extend.get_report_regions_names","title":"<code>get_report_regions_names(report_path)</code>","text":"<p>Returns a list of GenBank-RefSeq <code>seq_region</code> names from the assembly report file.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>PathLike</code> <p>Path to the assembly report file from INSDC/RefSeq.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def get_report_regions_names(report_path: PathLike) -&gt; List[Tuple[str, str]]:\n    \"\"\"Returns a list of GenBank-RefSeq `seq_region` names from the assembly report file.\n\n    Args:\n        report_path: Path to the assembly report file from INSDC/RefSeq.\n    \"\"\"\n    # Get the report in a CSV format, easier to manipulate\n    report_csv, _ = _report_to_csv(report_path)\n    # Feed the CSV string to the CSV reader\n    reader = csv.DictReader(report_csv.splitlines(), delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n    # Create the seq_regions\n    seq_regions = []\n    for row in reader:\n        refseq_name = row[\"RefSeq-Accn\"]\n        genbank_name = row[\"GenBank-Accn\"]\n        if refseq_name == \"na\":\n            refseq_name = \"\"\n        if genbank_name == \"na\":\n            genbank_name = \"\"\n        refseq_name = re.sub(_VERSION_END, \"\", refseq_name)\n        genbank_name = re.sub(_VERSION_END, \"\", genbank_name)\n        seq_regions.append((genbank_name, refseq_name))\n    return seq_regions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/extend/#ensembl.io.genomio.genome_metadata.extend.main","title":"<code>main()</code>","text":"<p>Module's entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/extend.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module's entry-point.\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument_src_path(\n        \"--genome_infile\",\n        required=True,\n        help=\"Input genome metadata file (following src/python/ensembl/io/genomio/data/schemas/genome.json)\",\n    )\n    parser.add_argument_dst_path(\n        \"--genome_outfile\", required=True, help=\"Path to the new amended genome metadata file\"\n    )\n    parser.add_argument_src_path(\"--report_file\", help=\"INSDC/RefSeq sequences report file\")\n    parser.add_argument_src_path(\"--genbank_file\", help=\"INSDC/RefSeq GBFF file\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    amend_genome_metadata(\n        genome_infile=args.genome_infile,\n        genome_outfile=args.genome_outfile,\n        report_file=args.report_file,\n        genbank_file=args.genbank_file,\n    )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/","title":"prepare","text":""},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare","title":"<code>ensembl.io.genomio.genome_metadata.prepare</code>","text":"<p>Expand the genome metadata file adding information about the provider, taxonomy, and assembly and gene build versions.</p>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.PROVIDER_DATA","title":"<code>PROVIDER_DATA = {'GenBank': {'assembly': {'provider_name': 'GenBank', 'provider_url': 'https://www.ncbi.nlm.nih.gov/datasets/genome'}, 'annotation': {'provider_name': 'GenBank', 'provider_url': 'https://www.ncbi.nlm.nih.gov/datasets/genome'}}, 'RefSeq': {'assembly': {'provider_name': 'RefSeq', 'provider_url': 'https://www.ncbi.nlm.nih.gov/datasets/genome'}, 'annotation': {'provider_name': 'RefSeq', 'provider_url': 'https://www.ncbi.nlm.nih.gov/datasets/genome'}}}</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.MetadataError","title":"<code>MetadataError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a metadata value is not expected.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>class MetadataError(Exception):\n    \"\"\"When a metadata value is not expected.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.MissingNodeError","title":"<code>MissingNodeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a taxon XML node cannot be found.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>class MissingNodeError(Exception):\n    \"\"\"When a taxon XML node cannot be found.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.add_assembly_version","title":"<code>add_assembly_version(genome_data)</code>","text":"<p>Adds version number to the genome's assembly information if one is not present already.</p> <p>Parameters:</p> Name Type Description Default <code>genome_data</code> <code>Dict</code> <p>Genome information of assembly, accession and annotation.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def add_assembly_version(genome_data: Dict) -&gt; None:\n    \"\"\"Adds version number to the genome's assembly information if one is not present already.\n\n    Args:\n        genome_data: Genome information of assembly, accession and annotation.\n    \"\"\"\n    assembly = genome_data[\"assembly\"]\n    if \"version\" not in assembly:\n        accession = assembly[\"accession\"]\n        version = accession.partition(\".\")[2]\n        if version:\n            assembly[\"version\"] = int(version)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.add_genebuild_metadata","title":"<code>add_genebuild_metadata(genome_data)</code>","text":"<p>Adds genebuild metadata to genome information if not present already.</p> <p>The default convention is to use the current date as <code>\"version\"</code> and <code>\"start_date\"</code>.</p> <p>Parameters:</p> Name Type Description Default <code>genome_data</code> <code>Dict</code> <p>Genome information of assembly, accession and annotation.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def add_genebuild_metadata(genome_data: Dict) -&gt; None:\n    \"\"\"Adds genebuild metadata to genome information if not present already.\n\n    The default convention is to use the current date as `\"version\"` and `\"start_date\"`.\n\n    Args:\n        genome_data: Genome information of assembly, accession and annotation.\n    \"\"\"\n    genebuild = genome_data.setdefault(\"genebuild\", {})\n    current_date = datetime.date.today().isoformat()\n    if \"version\" not in genebuild:\n        genebuild[\"version\"] = current_date\n    if \"start_date\" not in genebuild:\n        genebuild[\"start_date\"] = current_date\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.add_provider","title":"<code>add_provider(genome_metadata, ncbi_data)</code>","text":"<p>Updates the genome metadata adding provider information for assembly and gene models.</p> <p>Assembly provider metadata will only be added if it is missing, i.e. neither <code>\"provider_name\"</code> or <code>\"provider_url\"</code> are present. The gene model metadata will only be added if <code>gff3_file</code> is provided.</p> <p>Parameters:</p> Name Type Description Default <code>genome_data</code> <p>Genome information of assembly, accession and annotation.</p> required <code>ncbi_data</code> <code>Dict</code> <p>Report data from NCBI datasets.</p> required <p>Raises:</p> Type Description <code>MetadataError</code> <p>If accession's format in genome metadata does not match with a known provider.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def add_provider(genome_metadata: Dict, ncbi_data: Dict) -&gt; None:\n    \"\"\"Updates the genome metadata adding provider information for assembly and gene models.\n\n    Assembly provider metadata will only be added if it is missing, i.e. neither `\"provider_name\"` or\n    `\"provider_url\"` are present. The gene model metadata will only be added if `gff3_file` is provided.\n\n    Args:\n        genome_data: Genome information of assembly, accession and annotation.\n        ncbi_data: Report data from NCBI datasets.\n\n    Raises:\n        MetadataError: If accession's format in genome metadata does not match with a known provider.\n    \"\"\"\n    # Get accession provider\n    accession = genome_metadata[\"assembly\"][\"accession\"]\n    if accession.startswith(\"GCF\"):\n        provider = PROVIDER_DATA[\"RefSeq\"]\n    elif accession.startswith(\"GCA\"):\n        provider = PROVIDER_DATA[\"GenBank\"]\n    else:\n        raise MetadataError(f\"Accession does not look like an INSDC or RefSeq accession: {accession}\")\n\n    # Add assembly provider (if missing)\n    assembly = genome_metadata[\"assembly\"]\n    if (\"provider_name\" not in assembly) and (\"provider_url\" not in assembly):\n        assembly[\"provider_name\"] = provider[\"assembly\"][\"provider_name\"]\n        assembly[\"provider_url\"] = f'{provider[\"assembly\"][\"provider_url\"]}/{accession}'\n\n    # Add annotation provider if there are gene models\n    if \"annotation_info\" in ncbi_data:\n        annotation = genome_metadata.setdefault(\"annotation\", {})\n        if (\"provider_name\" not in annotation) and (\"provider_url\" not in annotation):\n            annotation[\"provider_name\"] = provider[\"annotation\"][\"provider_name\"]\n            annotation[\"provider_url\"] = f'{provider[\"annotation\"][\"provider_url\"]}/{accession}'\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.add_species_metadata","title":"<code>add_species_metadata(genome_metadata, ncbi_data)</code>","text":"<p>Adds taxonomy ID, scientific name and strain (if present) from the NCBI dataset report.</p> <p>Parameters:</p> Name Type Description Default <code>genome_metadata</code> <code>Dict</code> <p>Genome information of assembly, accession and annotation.</p> required <code>ncbi_data</code> <code>Dict</code> <p>Report data from NCBI datasets.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def add_species_metadata(genome_metadata: Dict, ncbi_data: Dict) -&gt; None:\n    \"\"\"Adds taxonomy ID, scientific name and strain (if present) from the NCBI dataset report.\n\n    Args:\n        genome_metadata: Genome information of assembly, accession and annotation.\n        ncbi_data: Report data from NCBI datasets.\n\n    \"\"\"\n    species = genome_metadata.setdefault(\"species\", {})\n    try:\n        organism = ncbi_data[\"organism\"]\n    except KeyError:\n        return\n\n    if \"tax_id\" in organism:\n        species.setdefault(\"taxonomy_id\", organism[\"tax_id\"])\n    if \"organism_name\" in organism:\n        species.setdefault(\"scientific_name\", organism[\"organism_name\"])\n\n    try:\n        species.setdefault(\"strain\", organism[\"infraspecific_names\"][\"strain\"])\n    except KeyError:\n        pass\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.main","title":"<code>main()</code>","text":"<p>Module's entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module's entry-point.\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument_src_path(\"--input_file\", required=True, help=\"Genome metadata JSON file\")\n    parser.add_argument_dst_path(\n        \"--output_file\", required=True, help=\"Output path for the new genome metadata file\"\n    )\n    parser.add_argument_src_path(\n        \"--ncbi_meta\", required=True, help=\"JSON file from NCBI datasets for this genome.\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    prepare_genome_metadata(\n        input_file=args.input_file, output_file=args.output_file, ncbi_meta=args.ncbi_meta\n    )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_metadata/prepare/#ensembl.io.genomio.genome_metadata.prepare.prepare_genome_metadata","title":"<code>prepare_genome_metadata(input_file, output_file, ncbi_meta)</code>","text":"<p>Updates the genome metadata JSON file with additional information.</p> <p>In particular, more information is added about the provider, the assembly and its gene build version, and the taxonomy.</p> <p>Parameters:</p> Name Type Description Default <code>input_file</code> <code>PathLike</code> <p>Path to JSON file with genome metadata.</p> required <code>output_file</code> <code>PathLike</code> <p>Output directory where to generate the final <code>genome.json</code> file.</p> required <code>ncbi_meta</code> <code>PathLike</code> <p>JSON file from NCBI datasets.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_metadata/prepare.py</code> <pre><code>def prepare_genome_metadata(\n    input_file: PathLike,\n    output_file: PathLike,\n    ncbi_meta: PathLike,\n) -&gt; None:\n    \"\"\"Updates the genome metadata JSON file with additional information.\n\n    In particular, more information is added about the provider, the assembly and its gene build version,\n    and the taxonomy.\n\n    Args:\n        input_file: Path to JSON file with genome metadata.\n        output_file: Output directory where to generate the final `genome.json` file.\n        ncbi_meta: JSON file from NCBI datasets.\n\n    \"\"\"\n    genome_data = get_json(input_file)\n    ncbi_data = {}\n    if ncbi_meta:\n        ncbi_data = get_json(ncbi_meta)[\"reports\"][0]\n\n    # Amend any missing metadata\n    add_provider(genome_data, ncbi_data)\n    add_assembly_version(genome_data)\n    add_genebuild_metadata(genome_data)\n    add_species_metadata(genome_data, ncbi_data)\n    # Dump updated genome metadata\n    print_json(output_file, genome_data)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/","title":"genome_stats","text":""},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats","title":"<code>ensembl.io.genomio.genome_stats</code>","text":"<p>Genome statistics handling module.</p>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.StatsGenerator","title":"<code>StatsGenerator</code>  <code>dataclass</code>","text":"<p>Interface to extract genome stats from a core database.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>@dataclass\nclass StatsGenerator:\n    \"\"\"Interface to extract genome stats from a core database.\"\"\"\n\n    session: Session\n\n    def get_assembly_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Returns a dict of stats about the assembly.\"\"\"\n        stats = {\n            \"coord_system\": self.get_attrib_counts(\"coord_system_tag\"),\n            \"locations\": self.get_attrib_counts(\"sequence_location\"),\n            \"codon_table\": self.get_attrib_counts(\"codon_table\"),\n        }\n        # Special: rename supercontigs to scaffolds for homogeneity\n        StatsGenerator._fix_scaffolds(stats)\n        return stats\n\n    @staticmethod\n    def _fix_scaffolds(stats: Dict[str, Any]) -&gt; None:\n        \"\"\"Renames supercontigs to scaffolds in the provided stats.\n\n        If scaffolds are present already, nothing is done.\n\n        Args:\n            stats: Statistics dictionary.\n\n        \"\"\"\n        coords = stats.get(\"coord_system\", {})\n        if \"supercontig\" in coords and \"scaffold\" not in coords:\n            coords[\"scaffold\"] = coords[\"supercontig\"]\n            del coords[\"supercontig\"]\n\n    def get_attrib_counts(self, code: str) -&gt; Dict[str, Any]:\n        \"\"\"Returns a dict of count for each value counted with the attrib_type code provided.\n\n        Args:\n            code: Ensembl database attrib_type code.\n\n        \"\"\"\n        seqs_st = (\n            select(SeqRegionAttrib.value, func.count())  # pylint: disable=not-callable\n            .join(AttribType)\n            .filter(AttribType.code == code)\n            .group_by(SeqRegionAttrib.value)\n        )\n        attributes = {}\n        for row in self.session.execute(seqs_st):\n            (attribute_name, count) = row\n            attributes[attribute_name] = count\n        return attributes\n\n    def get_annotation_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Returns a dict of stats about the coordinate systems (number of biotypes, etc.).\"\"\"\n        stats = {\n            \"genes\": self.get_feature_stats(Gene),\n            \"transcripts\": self.get_feature_stats(Transcript),\n        }\n        return stats\n\n    def get_biotypes(self, table: Any) -&gt; Dict[str, int]:\n        \"\"\"Returns a dict of stats about the feature biotypes.\"\"\"\n        # pylint: disable-next=not-callable\n        seqs_st = select(table.biotype, func.count()).group_by(table.biotype)\n        biotypes = {}\n        for row in self.session.execute(seqs_st):\n            (biotype, count) = row\n            biotypes[biotype] = count\n        return biotypes\n\n    def get_feature_stats(self, table: Any) -&gt; Dict[str, int]:\n        \"\"\"Returns a dict of stats about a given feature.\"\"\"\n        session = self.session\n        totals_st = select(func.count()).select_from(table)  # pylint: disable=not-callable\n        (total,) = session.execute(totals_st).one()\n        # pylint: disable-next=singleton-comparison,not-callable\n        no_desc_st = select(func.count()).filter(table.description.is_(None))\n        (no_desc,) = session.execute(no_desc_st).one()\n        # pylint: disable-next=not-callable\n        xref_desc_st = select(func.count()).where(table.description.like(\"%[Source:%\"))\n        (xref_desc,) = session.execute(xref_desc_st).one()\n        left_over = total - no_desc - xref_desc\n        feat_stats = {\n            \"total\": total,\n            \"biotypes\": self.get_biotypes(table),\n            \"description\": {\n                \"empty\": no_desc,\n                \"source_xref\": xref_desc,\n                \"normal\": left_over,\n            },\n        }\n        return feat_stats\n\n    def get_genome_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Returns a dict of stats about the assembly and annotation.\"\"\"\n        genome_stats = {\n            \"assembly_stats\": self.get_assembly_stats(),\n            \"annotation_stats\": self.get_annotation_stats(),\n        }\n        return genome_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.StatsGenerator.session","title":"<code>session</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.StatsGenerator.get_annotation_stats","title":"<code>get_annotation_stats()</code>","text":"<p>Returns a dict of stats about the coordinate systems (number of biotypes, etc.).</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_annotation_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns a dict of stats about the coordinate systems (number of biotypes, etc.).\"\"\"\n    stats = {\n        \"genes\": self.get_feature_stats(Gene),\n        \"transcripts\": self.get_feature_stats(Transcript),\n    }\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.StatsGenerator.get_assembly_stats","title":"<code>get_assembly_stats()</code>","text":"<p>Returns a dict of stats about the assembly.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_assembly_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns a dict of stats about the assembly.\"\"\"\n    stats = {\n        \"coord_system\": self.get_attrib_counts(\"coord_system_tag\"),\n        \"locations\": self.get_attrib_counts(\"sequence_location\"),\n        \"codon_table\": self.get_attrib_counts(\"codon_table\"),\n    }\n    # Special: rename supercontigs to scaffolds for homogeneity\n    StatsGenerator._fix_scaffolds(stats)\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.StatsGenerator.get_attrib_counts","title":"<code>get_attrib_counts(code)</code>","text":"<p>Returns a dict of count for each value counted with the attrib_type code provided.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>Ensembl database attrib_type code.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_attrib_counts(self, code: str) -&gt; Dict[str, Any]:\n    \"\"\"Returns a dict of count for each value counted with the attrib_type code provided.\n\n    Args:\n        code: Ensembl database attrib_type code.\n\n    \"\"\"\n    seqs_st = (\n        select(SeqRegionAttrib.value, func.count())  # pylint: disable=not-callable\n        .join(AttribType)\n        .filter(AttribType.code == code)\n        .group_by(SeqRegionAttrib.value)\n    )\n    attributes = {}\n    for row in self.session.execute(seqs_st):\n        (attribute_name, count) = row\n        attributes[attribute_name] = count\n    return attributes\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.StatsGenerator.get_biotypes","title":"<code>get_biotypes(table)</code>","text":"<p>Returns a dict of stats about the feature biotypes.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_biotypes(self, table: Any) -&gt; Dict[str, int]:\n    \"\"\"Returns a dict of stats about the feature biotypes.\"\"\"\n    # pylint: disable-next=not-callable\n    seqs_st = select(table.biotype, func.count()).group_by(table.biotype)\n    biotypes = {}\n    for row in self.session.execute(seqs_st):\n        (biotype, count) = row\n        biotypes[biotype] = count\n    return biotypes\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.StatsGenerator.get_feature_stats","title":"<code>get_feature_stats(table)</code>","text":"<p>Returns a dict of stats about a given feature.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_feature_stats(self, table: Any) -&gt; Dict[str, int]:\n    \"\"\"Returns a dict of stats about a given feature.\"\"\"\n    session = self.session\n    totals_st = select(func.count()).select_from(table)  # pylint: disable=not-callable\n    (total,) = session.execute(totals_st).one()\n    # pylint: disable-next=singleton-comparison,not-callable\n    no_desc_st = select(func.count()).filter(table.description.is_(None))\n    (no_desc,) = session.execute(no_desc_st).one()\n    # pylint: disable-next=not-callable\n    xref_desc_st = select(func.count()).where(table.description.like(\"%[Source:%\"))\n    (xref_desc,) = session.execute(xref_desc_st).one()\n    left_over = total - no_desc - xref_desc\n    feat_stats = {\n        \"total\": total,\n        \"biotypes\": self.get_biotypes(table),\n        \"description\": {\n            \"empty\": no_desc,\n            \"source_xref\": xref_desc,\n            \"normal\": left_over,\n        },\n    }\n    return feat_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.StatsGenerator.get_genome_stats","title":"<code>get_genome_stats()</code>","text":"<p>Returns a dict of stats about the assembly and annotation.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_genome_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns a dict of stats about the assembly and annotation.\"\"\"\n    genome_stats = {\n        \"assembly_stats\": self.get_assembly_stats(),\n        \"annotation_stats\": self.get_annotation_stats(),\n    }\n    return genome_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.compare_annotation","title":"<code>compare_annotation(ncbi, core)</code>","text":"<p>Extracts the annotation statistics and returns the comparison between both sources.</p> Annotation statistics compared <ul> <li>protein_coding</li> <li>pseudogene (all pseudogene biotypes)</li> <li>other (number of misc_RNA)</li> <li>total</li> </ul> <p>Parameters:</p> Name Type Description Default <code>ncbi</code> <code>Dict[str, Any]</code> <p>NCBI dataset annotation statistics.</p> required <code>core</code> <code>Dict[str, Any]</code> <p>Core database annotation statistics.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>The common statistics with their value and the statistics with different value, including NCBI'</p> <code>Dict[str, Dict]</code> <p>and core database's values as well as their difference (<code>core_value - ncbi_value</code>).</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def compare_annotation(ncbi: Dict[str, Any], core: Dict[str, Any]) -&gt; Dict[str, Dict]:\n    \"\"\"Extracts the annotation statistics and returns the comparison between both sources.\n\n    Annotation statistics compared:\n        - protein_coding\n        - pseudogene (all pseudogene biotypes)\n        - other (number of misc_RNA)\n        - total\n\n    Args:\n        ncbi: NCBI dataset annotation statistics.\n        core: Core database annotation statistics.\n\n    Returns:\n        The common statistics with their value and the statistics with different value, including NCBI'\n        and core database's values as well as their difference (`core_value - ncbi_value`).\n\n    \"\"\"\n    ncbi_counts = {\n        \"protein_coding\": ncbi.get(\"protein_coding\", 0),\n        \"pseudogene\": ncbi.get(\"pseudogene\", 0),\n        \"total_genes\": ncbi.get(\"total\", 0),\n        \"other\": ncbi.get(\"other\", 0),\n    }\n\n    # Prepare core database counts to be comparable\n    core_biotypes = core.get(\"genes\", {}).get(\"biotypes\", {})\n\n    # Add all pseudogenes\n    num_pseudogenes = 0\n    for name, num in core_biotypes.items():\n        if re.match(\".*pseudogen.*\", name):\n            num_pseudogenes += num\n\n    # Other genes such as misc_mRNA\n    num_others = core_biotypes.get(\"misc_RNA\", 0)\n\n    core_counts = {\n        \"protein_coding\": core_biotypes.get(\"protein_coding\", 0),\n        \"pseudogene\": num_pseudogenes,\n        \"total_genes\": core.get(\"genes\", {}).get(\"total\", 0),\n        \"other\": num_others,\n    }\n\n    return stats_dict_cmp(ncbi_counts, core_counts)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.compare_assembly","title":"<code>compare_assembly(ncbi, core)</code>","text":"<p>Extracts the assembly statistics and returns the comparison between both sources.</p> <p>The assembly statistics compared are the number of: organella, chromosomes, scaffolds and contigs. The last one is only included if NCBI's assembly is contig level.</p> <p>Parameters:</p> Name Type Description Default <code>ncbi</code> <code>Dict[str, Any]</code> <p>NCBI dataset assembly statistics.</p> required <code>core</code> <code>Dict[str, Any]</code> <p>Core database assembly statistics.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>The common statistics with their value and the statistics with different value, including NCBI'</p> <code>Dict[str, Dict]</code> <p>and core database's values as well as their difference (<code>core_value - ncbi_value</code>).</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def compare_assembly(ncbi: Dict[str, Any], core: Dict[str, Any]) -&gt; Dict[str, Dict]:\n    \"\"\"Extracts the assembly statistics and returns the comparison between both sources.\n\n    The assembly statistics compared are the number of: organella, chromosomes, scaffolds and contigs.\n    The last one is only included if NCBI's assembly is contig level.\n\n    Args:\n        ncbi: NCBI dataset assembly statistics.\n        core: Core database assembly statistics.\n\n    Returns:\n        The common statistics with their value and the statistics with different value, including NCBI'\n        and core database's values as well as their difference (`core_value - ncbi_value`).\n\n    \"\"\"\n    # Prepare counts to be comparable to the NCBI stats\n    ncbi_main = ncbi.get(\"assembly_stats\", {})\n    ncbi_info = ncbi.get(\"assembly_info\", {})\n    ncbi_organella = ncbi.get(\"organelle_info\", [])\n\n    # First count the organella\n    core_num_organella = 0\n    for loc, loc_count in core.get(\"locations\", {}).items():\n        if loc != \"nuclear_chromosome\":\n            core_num_organella += loc_count\n\n    # Our core stats count Organella chromosomes, sanity check here\n    core_chr = core.get(\"coord_system\", {}).get(\"chromosome\", 0)\n    core_adjusted_chrs = 0\n    if core_chr:\n        core_adjusted_chrs = core_chr - core_num_organella\n\n    # Number of scaffolds from our core\n    core_num_scaffolds = core.get(\"coord_system\", {}).get(\"scaffold\", 0)\n\n    # NCBI includes the chromosomes in its scaffold count\n    core_adjusted_scaffolds = core_num_scaffolds + core_adjusted_chrs\n\n    # Compile the counts\n    ncbi_counts = {\n        \"num_organella\": len(ncbi_organella),\n        \"num_chromosomes\": ncbi_main.get(\"total_number_of_chromosomes\", 0),\n        \"num_scaffolds\": ncbi_main.get(\"number_of_scaffolds\", 0),\n        \"num_contigs\": ncbi_main.get(\"number_of_contigs\", 0),\n    }\n    core_counts = {\n        \"num_organella\": core_num_organella,\n        \"num_chromosomes\": core_adjusted_chrs,\n        \"num_scaffolds\": core_adjusted_scaffolds,\n        \"num_contigs\": core.get(\"coord_system\", {}).get(\"contig\", 0),\n    }\n\n    # Only compare contigs if there are any in NCBI\n    if ncbi_info.get(\"assembly_level\") != \"Contig\":\n        del ncbi_counts[\"num_contigs\"]\n        del core_counts[\"num_contigs\"]\n\n    return stats_dict_cmp(ncbi_counts, core_counts)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.compare_stats","title":"<code>compare_stats(ncbi, core)</code>","text":"<p>Compares the genome statistics between an NCBI dataset and a core database.</p> <p>Parameters:</p> Name Type Description Default <code>ncbi</code> <code>Dict[str, Any]</code> <p>NCBI dataset genome statistics.</p> required <code>core</code> <code>Dict[str, Any]</code> <p>Core database genome statistics.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>The common statistics with their value and the statistics with different value, including NCBI'</p> <code>Dict[str, Dict]</code> <p>and core database's values as well as their difference (<code>core_value - ncbi_value</code>), for the</p> <code>Dict[str, Dict]</code> <p>assembly and annotation (if present in one of the sources) under \"assembly_diff\" and</p> <code>Dict[str, Dict]</code> <p>\"annotation_diff\" keys, respectively.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def compare_stats(ncbi: Dict[str, Any], core: Dict[str, Any]) -&gt; Dict[str, Dict]:\n    \"\"\"Compares the genome statistics between an NCBI dataset and a core database.\n\n    Args:\n        ncbi: NCBI dataset genome statistics.\n        core: Core database genome statistics.\n\n    Returns:\n        The common statistics with their value and the statistics with different value, including NCBI'\n        and core database's values as well as their difference (`core_value - ncbi_value`), for the\n        assembly and annotation (if present in one of the sources) under \"assembly_diff\" and\n        \"annotation_diff\" keys, respectively.\n\n    \"\"\"\n    ncbi_annotation_stats = ncbi.get(\"annotation_info\", {}).get(\"stats\", {}).get(\"gene_counts\", {})\n    core_assembly_stats = core.get(\"assembly_stats\", {})\n    core_annotation_stats = core.get(\"annotation_stats\", {})\n\n    comp: Dict[str, Dict] = {\n        \"assembly_diff\": compare_assembly(ncbi, core_assembly_stats),\n    }\n    if core_annotation_stats or ncbi_annotation_stats:\n        comp[\"annotation_diff\"] = compare_annotation(ncbi_annotation_stats, core_annotation_stats)\n    return comp\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.compare_stats_files","title":"<code>compare_stats_files(ncbi_file, core_file)</code>","text":"<p>Compares the genome statistics between an NCBI dataset and a core database.</p> <p>Parameters:</p> Name Type Description Default <code>ncbi_file</code> <code>PathLike</code> <p>NCBI dataset genome statistics JSON file.</p> required <code>core_file</code> <code>PathLike</code> <p>Core database genome statistics JSON file.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>The common statistics with their value and the statistics with different value, including NCBI'</p> <code>Dict[str, Dict]</code> <p>and core database's values as well as their difference (<code>core_value - ncbi_value</code>), for the</p> <code>Dict[str, Dict]</code> <p>assembly and annotation (if present in one of the sources) under \"assembly_diff\" and</p> <code>Dict[str, Dict]</code> <p>\"annotation_diff\" keys, respectively.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def compare_stats_files(ncbi_file: PathLike, core_file: PathLike) -&gt; Dict[str, Dict]:\n    \"\"\"Compares the genome statistics between an NCBI dataset and a core database.\n\n    Args:\n        ncbi_file: NCBI dataset genome statistics JSON file.\n        core_file: Core database genome statistics JSON file.\n\n    Returns:\n        The common statistics with their value and the statistics with different value, including NCBI'\n        and core database's values as well as their difference (`core_value - ncbi_value`), for the\n        assembly and annotation (if present in one of the sources) under \"assembly_diff\" and\n        \"annotation_diff\" keys, respectively.\n\n    \"\"\"\n    ncbi_stats = {}\n    ncbi_stats = get_json(ncbi_file)[\"reports\"][0]\n    core_stats = get_json(core_file)\n    all_stats = compare_stats(ncbi_stats, core_stats)\n    return all_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/#ensembl.io.genomio.genome_stats.stats_dict_cmp","title":"<code>stats_dict_cmp(ncbi, core)</code>","text":"<p>Compares both dictionaries and returns the similar and different elements between both.</p> <p>The method assumes both dictionaries have the same set of keys. A key would be considered the same if its value in both dictionaries is the same, but will only be included in the returned dictionary if that value is different than 0.</p> <p>Parameters:</p> Name Type Description Default <code>ncbi</code> <code>Dict[str, int]</code> <p>NCBI dataset statistics in key-value pairs.</p> required <code>core</code> <code>Dict[str, int]</code> <p>Core database statistics in key-value pairs.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>A dictionary with 2 keys:</p> <code>Dict[str, Dict]</code> <ul> <li>\"same\": Pairs of key - value for those entries equal in both dictionaries.</li> </ul> <code>Dict[str, Dict]</code> <ul> <li>\"different\": Keys that differ, with values for \"ncbi\", \"core\", and \"diff\", i.e. their difference represented as <code>core_value - ncbi_value</code>.</li> </ul> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def stats_dict_cmp(ncbi: Dict[str, int], core: Dict[str, int]) -&gt; Dict[str, Dict]:\n    \"\"\"Compares both dictionaries and returns the similar and different elements between both.\n\n    The method assumes both dictionaries have the same set of keys. A key would be considered the\n    same if its value in both dictionaries is the same, but will only be included in the returned\n    dictionary if that value is different than 0.\n\n    Args:\n        ncbi: NCBI dataset statistics in key-value pairs.\n        core: Core database statistics in key-value pairs.\n\n    Returns:\n        A dictionary with 2 keys:\n        - \"same\": Pairs of key - value for those entries equal in both dictionaries.\n        - \"different\": Keys that differ, with values for \"ncbi\", \"core\", and \"diff\", i.e. their\n            difference represented as `core_value - ncbi_value`.\n\n    \"\"\"\n    diff = {}\n    same = {}\n    for key, ncbi_count in ncbi.items():\n        core_count = core[key]\n        if ncbi_count == core_count:\n            if ncbi_count != 0:\n                same[key] = ncbi_count\n        else:\n            diff[key] = {\"ncbi\": ncbi_count, \"core\": core_count, \"diff\": core_count - ncbi_count}\n    comparison: Dict[str, Dict] = {}\n    if same:\n        comparison[\"same\"] = same\n    if diff:\n        comparison[\"different\"] = diff\n    return comparison\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/compare/","title":"compare","text":""},{"location":"reference/ensembl/io/genomio/genome_stats/compare/#ensembl.io.genomio.genome_stats.compare","title":"<code>ensembl.io.genomio.genome_stats.compare</code>","text":"<p>Tool set to compare genome statistic between NCBI datasets and Ensembl's core databases.</p>"},{"location":"reference/ensembl/io/genomio/genome_stats/compare/#ensembl.io.genomio.genome_stats.compare.compare_annotation","title":"<code>compare_annotation(ncbi, core)</code>","text":"<p>Extracts the annotation statistics and returns the comparison between both sources.</p> Annotation statistics compared <ul> <li>protein_coding</li> <li>pseudogene (all pseudogene biotypes)</li> <li>other (number of misc_RNA)</li> <li>total</li> </ul> <p>Parameters:</p> Name Type Description Default <code>ncbi</code> <code>Dict[str, Any]</code> <p>NCBI dataset annotation statistics.</p> required <code>core</code> <code>Dict[str, Any]</code> <p>Core database annotation statistics.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>The common statistics with their value and the statistics with different value, including NCBI'</p> <code>Dict[str, Dict]</code> <p>and core database's values as well as their difference (<code>core_value - ncbi_value</code>).</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def compare_annotation(ncbi: Dict[str, Any], core: Dict[str, Any]) -&gt; Dict[str, Dict]:\n    \"\"\"Extracts the annotation statistics and returns the comparison between both sources.\n\n    Annotation statistics compared:\n        - protein_coding\n        - pseudogene (all pseudogene biotypes)\n        - other (number of misc_RNA)\n        - total\n\n    Args:\n        ncbi: NCBI dataset annotation statistics.\n        core: Core database annotation statistics.\n\n    Returns:\n        The common statistics with their value and the statistics with different value, including NCBI'\n        and core database's values as well as their difference (`core_value - ncbi_value`).\n\n    \"\"\"\n    ncbi_counts = {\n        \"protein_coding\": ncbi.get(\"protein_coding\", 0),\n        \"pseudogene\": ncbi.get(\"pseudogene\", 0),\n        \"total_genes\": ncbi.get(\"total\", 0),\n        \"other\": ncbi.get(\"other\", 0),\n    }\n\n    # Prepare core database counts to be comparable\n    core_biotypes = core.get(\"genes\", {}).get(\"biotypes\", {})\n\n    # Add all pseudogenes\n    num_pseudogenes = 0\n    for name, num in core_biotypes.items():\n        if re.match(\".*pseudogen.*\", name):\n            num_pseudogenes += num\n\n    # Other genes such as misc_mRNA\n    num_others = core_biotypes.get(\"misc_RNA\", 0)\n\n    core_counts = {\n        \"protein_coding\": core_biotypes.get(\"protein_coding\", 0),\n        \"pseudogene\": num_pseudogenes,\n        \"total_genes\": core.get(\"genes\", {}).get(\"total\", 0),\n        \"other\": num_others,\n    }\n\n    return stats_dict_cmp(ncbi_counts, core_counts)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/compare/#ensembl.io.genomio.genome_stats.compare.compare_assembly","title":"<code>compare_assembly(ncbi, core)</code>","text":"<p>Extracts the assembly statistics and returns the comparison between both sources.</p> <p>The assembly statistics compared are the number of: organella, chromosomes, scaffolds and contigs. The last one is only included if NCBI's assembly is contig level.</p> <p>Parameters:</p> Name Type Description Default <code>ncbi</code> <code>Dict[str, Any]</code> <p>NCBI dataset assembly statistics.</p> required <code>core</code> <code>Dict[str, Any]</code> <p>Core database assembly statistics.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>The common statistics with their value and the statistics with different value, including NCBI'</p> <code>Dict[str, Dict]</code> <p>and core database's values as well as their difference (<code>core_value - ncbi_value</code>).</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def compare_assembly(ncbi: Dict[str, Any], core: Dict[str, Any]) -&gt; Dict[str, Dict]:\n    \"\"\"Extracts the assembly statistics and returns the comparison between both sources.\n\n    The assembly statistics compared are the number of: organella, chromosomes, scaffolds and contigs.\n    The last one is only included if NCBI's assembly is contig level.\n\n    Args:\n        ncbi: NCBI dataset assembly statistics.\n        core: Core database assembly statistics.\n\n    Returns:\n        The common statistics with their value and the statistics with different value, including NCBI'\n        and core database's values as well as their difference (`core_value - ncbi_value`).\n\n    \"\"\"\n    # Prepare counts to be comparable to the NCBI stats\n    ncbi_main = ncbi.get(\"assembly_stats\", {})\n    ncbi_info = ncbi.get(\"assembly_info\", {})\n    ncbi_organella = ncbi.get(\"organelle_info\", [])\n\n    # First count the organella\n    core_num_organella = 0\n    for loc, loc_count in core.get(\"locations\", {}).items():\n        if loc != \"nuclear_chromosome\":\n            core_num_organella += loc_count\n\n    # Our core stats count Organella chromosomes, sanity check here\n    core_chr = core.get(\"coord_system\", {}).get(\"chromosome\", 0)\n    core_adjusted_chrs = 0\n    if core_chr:\n        core_adjusted_chrs = core_chr - core_num_organella\n\n    # Number of scaffolds from our core\n    core_num_scaffolds = core.get(\"coord_system\", {}).get(\"scaffold\", 0)\n\n    # NCBI includes the chromosomes in its scaffold count\n    core_adjusted_scaffolds = core_num_scaffolds + core_adjusted_chrs\n\n    # Compile the counts\n    ncbi_counts = {\n        \"num_organella\": len(ncbi_organella),\n        \"num_chromosomes\": ncbi_main.get(\"total_number_of_chromosomes\", 0),\n        \"num_scaffolds\": ncbi_main.get(\"number_of_scaffolds\", 0),\n        \"num_contigs\": ncbi_main.get(\"number_of_contigs\", 0),\n    }\n    core_counts = {\n        \"num_organella\": core_num_organella,\n        \"num_chromosomes\": core_adjusted_chrs,\n        \"num_scaffolds\": core_adjusted_scaffolds,\n        \"num_contigs\": core.get(\"coord_system\", {}).get(\"contig\", 0),\n    }\n\n    # Only compare contigs if there are any in NCBI\n    if ncbi_info.get(\"assembly_level\") != \"Contig\":\n        del ncbi_counts[\"num_contigs\"]\n        del core_counts[\"num_contigs\"]\n\n    return stats_dict_cmp(ncbi_counts, core_counts)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/compare/#ensembl.io.genomio.genome_stats.compare.compare_stats","title":"<code>compare_stats(ncbi, core)</code>","text":"<p>Compares the genome statistics between an NCBI dataset and a core database.</p> <p>Parameters:</p> Name Type Description Default <code>ncbi</code> <code>Dict[str, Any]</code> <p>NCBI dataset genome statistics.</p> required <code>core</code> <code>Dict[str, Any]</code> <p>Core database genome statistics.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>The common statistics with their value and the statistics with different value, including NCBI'</p> <code>Dict[str, Dict]</code> <p>and core database's values as well as their difference (<code>core_value - ncbi_value</code>), for the</p> <code>Dict[str, Dict]</code> <p>assembly and annotation (if present in one of the sources) under \"assembly_diff\" and</p> <code>Dict[str, Dict]</code> <p>\"annotation_diff\" keys, respectively.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def compare_stats(ncbi: Dict[str, Any], core: Dict[str, Any]) -&gt; Dict[str, Dict]:\n    \"\"\"Compares the genome statistics between an NCBI dataset and a core database.\n\n    Args:\n        ncbi: NCBI dataset genome statistics.\n        core: Core database genome statistics.\n\n    Returns:\n        The common statistics with their value and the statistics with different value, including NCBI'\n        and core database's values as well as their difference (`core_value - ncbi_value`), for the\n        assembly and annotation (if present in one of the sources) under \"assembly_diff\" and\n        \"annotation_diff\" keys, respectively.\n\n    \"\"\"\n    ncbi_annotation_stats = ncbi.get(\"annotation_info\", {}).get(\"stats\", {}).get(\"gene_counts\", {})\n    core_assembly_stats = core.get(\"assembly_stats\", {})\n    core_annotation_stats = core.get(\"annotation_stats\", {})\n\n    comp: Dict[str, Dict] = {\n        \"assembly_diff\": compare_assembly(ncbi, core_assembly_stats),\n    }\n    if core_annotation_stats or ncbi_annotation_stats:\n        comp[\"annotation_diff\"] = compare_annotation(ncbi_annotation_stats, core_annotation_stats)\n    return comp\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/compare/#ensembl.io.genomio.genome_stats.compare.compare_stats_files","title":"<code>compare_stats_files(ncbi_file, core_file)</code>","text":"<p>Compares the genome statistics between an NCBI dataset and a core database.</p> <p>Parameters:</p> Name Type Description Default <code>ncbi_file</code> <code>PathLike</code> <p>NCBI dataset genome statistics JSON file.</p> required <code>core_file</code> <code>PathLike</code> <p>Core database genome statistics JSON file.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>The common statistics with their value and the statistics with different value, including NCBI'</p> <code>Dict[str, Dict]</code> <p>and core database's values as well as their difference (<code>core_value - ncbi_value</code>), for the</p> <code>Dict[str, Dict]</code> <p>assembly and annotation (if present in one of the sources) under \"assembly_diff\" and</p> <code>Dict[str, Dict]</code> <p>\"annotation_diff\" keys, respectively.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def compare_stats_files(ncbi_file: PathLike, core_file: PathLike) -&gt; Dict[str, Dict]:\n    \"\"\"Compares the genome statistics between an NCBI dataset and a core database.\n\n    Args:\n        ncbi_file: NCBI dataset genome statistics JSON file.\n        core_file: Core database genome statistics JSON file.\n\n    Returns:\n        The common statistics with their value and the statistics with different value, including NCBI'\n        and core database's values as well as their difference (`core_value - ncbi_value`), for the\n        assembly and annotation (if present in one of the sources) under \"assembly_diff\" and\n        \"annotation_diff\" keys, respectively.\n\n    \"\"\"\n    ncbi_stats = {}\n    ncbi_stats = get_json(ncbi_file)[\"reports\"][0]\n    core_stats = get_json(core_file)\n    all_stats = compare_stats(ncbi_stats, core_stats)\n    return all_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/compare/#ensembl.io.genomio.genome_stats.compare.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(\n        description=\"Compares the genome statistics between an NCBI dataset and a core database.\"\n    )\n    parser.add_argument_src_path(\"--ncbi_stats\", required=True, help=\"NCBI dataset stats JSON file\")\n    parser.add_argument_src_path(\"--core_stats\", required=True, help=\"core database stats JSON file\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n\n    # Configure and initialise logging\n    init_logging_with_args(args)\n\n    report = compare_stats_files(args.ncbi_stats, args.core_stats)\n    print(json.dumps(report, indent=2, sort_keys=True))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/compare/#ensembl.io.genomio.genome_stats.compare.stats_dict_cmp","title":"<code>stats_dict_cmp(ncbi, core)</code>","text":"<p>Compares both dictionaries and returns the similar and different elements between both.</p> <p>The method assumes both dictionaries have the same set of keys. A key would be considered the same if its value in both dictionaries is the same, but will only be included in the returned dictionary if that value is different than 0.</p> <p>Parameters:</p> Name Type Description Default <code>ncbi</code> <code>Dict[str, int]</code> <p>NCBI dataset statistics in key-value pairs.</p> required <code>core</code> <code>Dict[str, int]</code> <p>Core database statistics in key-value pairs.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>A dictionary with 2 keys:</p> <code>Dict[str, Dict]</code> <ul> <li>\"same\": Pairs of key - value for those entries equal in both dictionaries.</li> </ul> <code>Dict[str, Dict]</code> <ul> <li>\"different\": Keys that differ, with values for \"ncbi\", \"core\", and \"diff\", i.e. their difference represented as <code>core_value - ncbi_value</code>.</li> </ul> Source code in <code>src/python/ensembl/io/genomio/genome_stats/compare.py</code> <pre><code>def stats_dict_cmp(ncbi: Dict[str, int], core: Dict[str, int]) -&gt; Dict[str, Dict]:\n    \"\"\"Compares both dictionaries and returns the similar and different elements between both.\n\n    The method assumes both dictionaries have the same set of keys. A key would be considered the\n    same if its value in both dictionaries is the same, but will only be included in the returned\n    dictionary if that value is different than 0.\n\n    Args:\n        ncbi: NCBI dataset statistics in key-value pairs.\n        core: Core database statistics in key-value pairs.\n\n    Returns:\n        A dictionary with 2 keys:\n        - \"same\": Pairs of key - value for those entries equal in both dictionaries.\n        - \"different\": Keys that differ, with values for \"ncbi\", \"core\", and \"diff\", i.e. their\n            difference represented as `core_value - ncbi_value`.\n\n    \"\"\"\n    diff = {}\n    same = {}\n    for key, ncbi_count in ncbi.items():\n        core_count = core[key]\n        if ncbi_count == core_count:\n            if ncbi_count != 0:\n                same[key] = ncbi_count\n        else:\n            diff[key] = {\"ncbi\": ncbi_count, \"core\": core_count, \"diff\": core_count - ncbi_count}\n    comparison: Dict[str, Dict] = {}\n    if same:\n        comparison[\"same\"] = same\n    if diff:\n        comparison[\"different\"] = diff\n    return comparison\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/","title":"dump","text":""},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump","title":"<code>ensembl.io.genomio.genome_stats.dump</code>","text":"<p>Generates a JSON representation of the genome stats (assembly and annotation) from a core database.</p>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.StatsGenerator","title":"<code>StatsGenerator</code>  <code>dataclass</code>","text":"<p>Interface to extract genome stats from a core database.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>@dataclass\nclass StatsGenerator:\n    \"\"\"Interface to extract genome stats from a core database.\"\"\"\n\n    session: Session\n\n    def get_assembly_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Returns a dict of stats about the assembly.\"\"\"\n        stats = {\n            \"coord_system\": self.get_attrib_counts(\"coord_system_tag\"),\n            \"locations\": self.get_attrib_counts(\"sequence_location\"),\n            \"codon_table\": self.get_attrib_counts(\"codon_table\"),\n        }\n        # Special: rename supercontigs to scaffolds for homogeneity\n        StatsGenerator._fix_scaffolds(stats)\n        return stats\n\n    @staticmethod\n    def _fix_scaffolds(stats: Dict[str, Any]) -&gt; None:\n        \"\"\"Renames supercontigs to scaffolds in the provided stats.\n\n        If scaffolds are present already, nothing is done.\n\n        Args:\n            stats: Statistics dictionary.\n\n        \"\"\"\n        coords = stats.get(\"coord_system\", {})\n        if \"supercontig\" in coords and \"scaffold\" not in coords:\n            coords[\"scaffold\"] = coords[\"supercontig\"]\n            del coords[\"supercontig\"]\n\n    def get_attrib_counts(self, code: str) -&gt; Dict[str, Any]:\n        \"\"\"Returns a dict of count for each value counted with the attrib_type code provided.\n\n        Args:\n            code: Ensembl database attrib_type code.\n\n        \"\"\"\n        seqs_st = (\n            select(SeqRegionAttrib.value, func.count())  # pylint: disable=not-callable\n            .join(AttribType)\n            .filter(AttribType.code == code)\n            .group_by(SeqRegionAttrib.value)\n        )\n        attributes = {}\n        for row in self.session.execute(seqs_st):\n            (attribute_name, count) = row\n            attributes[attribute_name] = count\n        return attributes\n\n    def get_annotation_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Returns a dict of stats about the coordinate systems (number of biotypes, etc.).\"\"\"\n        stats = {\n            \"genes\": self.get_feature_stats(Gene),\n            \"transcripts\": self.get_feature_stats(Transcript),\n        }\n        return stats\n\n    def get_biotypes(self, table: Any) -&gt; Dict[str, int]:\n        \"\"\"Returns a dict of stats about the feature biotypes.\"\"\"\n        # pylint: disable-next=not-callable\n        seqs_st = select(table.biotype, func.count()).group_by(table.biotype)\n        biotypes = {}\n        for row in self.session.execute(seqs_st):\n            (biotype, count) = row\n            biotypes[biotype] = count\n        return biotypes\n\n    def get_feature_stats(self, table: Any) -&gt; Dict[str, int]:\n        \"\"\"Returns a dict of stats about a given feature.\"\"\"\n        session = self.session\n        totals_st = select(func.count()).select_from(table)  # pylint: disable=not-callable\n        (total,) = session.execute(totals_st).one()\n        # pylint: disable-next=singleton-comparison,not-callable\n        no_desc_st = select(func.count()).filter(table.description.is_(None))\n        (no_desc,) = session.execute(no_desc_st).one()\n        # pylint: disable-next=not-callable\n        xref_desc_st = select(func.count()).where(table.description.like(\"%[Source:%\"))\n        (xref_desc,) = session.execute(xref_desc_st).one()\n        left_over = total - no_desc - xref_desc\n        feat_stats = {\n            \"total\": total,\n            \"biotypes\": self.get_biotypes(table),\n            \"description\": {\n                \"empty\": no_desc,\n                \"source_xref\": xref_desc,\n                \"normal\": left_over,\n            },\n        }\n        return feat_stats\n\n    def get_genome_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Returns a dict of stats about the assembly and annotation.\"\"\"\n        genome_stats = {\n            \"assembly_stats\": self.get_assembly_stats(),\n            \"annotation_stats\": self.get_annotation_stats(),\n        }\n        return genome_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.StatsGenerator.session","title":"<code>session</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.StatsGenerator.get_annotation_stats","title":"<code>get_annotation_stats()</code>","text":"<p>Returns a dict of stats about the coordinate systems (number of biotypes, etc.).</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_annotation_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns a dict of stats about the coordinate systems (number of biotypes, etc.).\"\"\"\n    stats = {\n        \"genes\": self.get_feature_stats(Gene),\n        \"transcripts\": self.get_feature_stats(Transcript),\n    }\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.StatsGenerator.get_assembly_stats","title":"<code>get_assembly_stats()</code>","text":"<p>Returns a dict of stats about the assembly.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_assembly_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns a dict of stats about the assembly.\"\"\"\n    stats = {\n        \"coord_system\": self.get_attrib_counts(\"coord_system_tag\"),\n        \"locations\": self.get_attrib_counts(\"sequence_location\"),\n        \"codon_table\": self.get_attrib_counts(\"codon_table\"),\n    }\n    # Special: rename supercontigs to scaffolds for homogeneity\n    StatsGenerator._fix_scaffolds(stats)\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.StatsGenerator.get_attrib_counts","title":"<code>get_attrib_counts(code)</code>","text":"<p>Returns a dict of count for each value counted with the attrib_type code provided.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>Ensembl database attrib_type code.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_attrib_counts(self, code: str) -&gt; Dict[str, Any]:\n    \"\"\"Returns a dict of count for each value counted with the attrib_type code provided.\n\n    Args:\n        code: Ensembl database attrib_type code.\n\n    \"\"\"\n    seqs_st = (\n        select(SeqRegionAttrib.value, func.count())  # pylint: disable=not-callable\n        .join(AttribType)\n        .filter(AttribType.code == code)\n        .group_by(SeqRegionAttrib.value)\n    )\n    attributes = {}\n    for row in self.session.execute(seqs_st):\n        (attribute_name, count) = row\n        attributes[attribute_name] = count\n    return attributes\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.StatsGenerator.get_biotypes","title":"<code>get_biotypes(table)</code>","text":"<p>Returns a dict of stats about the feature biotypes.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_biotypes(self, table: Any) -&gt; Dict[str, int]:\n    \"\"\"Returns a dict of stats about the feature biotypes.\"\"\"\n    # pylint: disable-next=not-callable\n    seqs_st = select(table.biotype, func.count()).group_by(table.biotype)\n    biotypes = {}\n    for row in self.session.execute(seqs_st):\n        (biotype, count) = row\n        biotypes[biotype] = count\n    return biotypes\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.StatsGenerator.get_feature_stats","title":"<code>get_feature_stats(table)</code>","text":"<p>Returns a dict of stats about a given feature.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_feature_stats(self, table: Any) -&gt; Dict[str, int]:\n    \"\"\"Returns a dict of stats about a given feature.\"\"\"\n    session = self.session\n    totals_st = select(func.count()).select_from(table)  # pylint: disable=not-callable\n    (total,) = session.execute(totals_st).one()\n    # pylint: disable-next=singleton-comparison,not-callable\n    no_desc_st = select(func.count()).filter(table.description.is_(None))\n    (no_desc,) = session.execute(no_desc_st).one()\n    # pylint: disable-next=not-callable\n    xref_desc_st = select(func.count()).where(table.description.like(\"%[Source:%\"))\n    (xref_desc,) = session.execute(xref_desc_st).one()\n    left_over = total - no_desc - xref_desc\n    feat_stats = {\n        \"total\": total,\n        \"biotypes\": self.get_biotypes(table),\n        \"description\": {\n            \"empty\": no_desc,\n            \"source_xref\": xref_desc,\n            \"normal\": left_over,\n        },\n    }\n    return feat_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.StatsGenerator.get_genome_stats","title":"<code>get_genome_stats()</code>","text":"<p>Returns a dict of stats about the assembly and annotation.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def get_genome_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns a dict of stats about the assembly and annotation.\"\"\"\n    genome_stats = {\n        \"assembly_stats\": self.get_assembly_stats(),\n        \"annotation_stats\": self.get_annotation_stats(),\n    }\n    return genome_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.dump_genome_stats","title":"<code>dump_genome_stats(url)</code>","text":"<p>Returns JSON object containing the genome stats (assembly and annotation) of the given core database.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>StrURL</code> <p>Core database URL.</p> required Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def dump_genome_stats(url: StrURL) -&gt; Dict[str, Any]:\n    \"\"\"Returns JSON object containing the genome stats (assembly and annotation) of the given core database.\n\n    Args:\n        url: Core database URL.\n\n    \"\"\"\n    dbc = DBConnectionLite(url)\n    with dbc.session_scope() as session:\n        generator = StatsGenerator(session)\n        genome_stats = generator.get_genome_stats()\n        return genome_stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/genome_stats/dump/#ensembl.io.genomio.genome_stats.dump.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/genome_stats/dump.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_server_arguments(include_database=True)\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    genome_stats = dump_genome_stats(args.url)\n    print(json.dumps(genome_stats, indent=2, sort_keys=True))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/","title":"gff3","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3","title":"<code>ensembl.io.genomio.gff3</code>","text":"<p>GFF3 files processing module.</p>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.Annotation","title":"<code>Annotation = Dict[str, Any]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.AnnotationError","title":"<code>AnnotationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>If anything wrong happens when recording annotations.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>class AnnotationError(Exception):\n    \"\"\"If anything wrong happens when recording annotations.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser","title":"<code>ArgumentParser</code>","text":"<p>               Bases: <code>ArgumentParser</code></p> <p>Extends <code>argparse.ArgumentParser</code> with additional methods and functionality.</p> <p>The default behaviour of the help text will be to display the default values on every non-required argument, i.e. optional arguments with <code>required=False</code>.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>class ArgumentParser(argparse.ArgumentParser):\n    \"\"\"Extends `argparse.ArgumentParser` with additional methods and functionality.\n\n    The default behaviour of the help text will be to display the default values on every non-required\n    argument, i.e. optional arguments with `required=False`.\n\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Extends the base class to include the information about default argument values by default.\"\"\"\n        super().__init__(*args, **kwargs)\n        self.formatter_class = argparse.ArgumentDefaultsHelpFormatter\n\n    def _validate_src_path(self, src_path: StrPath) -&gt; Path:\n        \"\"\"Returns the path if exists and it is readable, raises an error through the parser otherwise.\n\n        Args:\n            src_path: File or directory path to check.\n\n        \"\"\"\n        src_path = Path(src_path)\n        if not src_path.exists():\n            self.error(f\"'{src_path}' not found\")\n        elif not os.access(src_path, os.R_OK):\n            self.error(f\"'{src_path}' not readable\")\n        return src_path\n\n    def _validate_dst_path(self, dst_path: StrPath, exists_ok: bool = False) -&gt; Path:\n        \"\"\"Returns the path if it is writable, raises an error through the parser otherwise.\n\n        Args:\n            dst_path: File or directory path to check.\n            exists_ok: Do not raise an error during parsing if the destination path already exists.\n\n        \"\"\"\n        dst_path = Path(dst_path)\n        if dst_path.exists():\n            if os.access(dst_path, os.W_OK):\n                if exists_ok:\n                    return dst_path\n                self.error(f\"'{dst_path}' already exists\")\n            else:\n                self.error(f\"'{dst_path}' is not writable\")\n        # Check if the first parent directory that exists is writable\n        for parent_path in dst_path.parents:\n            if parent_path.exists():\n                if not os.access(parent_path, os.W_OK):\n                    self.error(f\"'{dst_path}' is not writable\")\n                break\n        return dst_path\n\n    def _validate_number(\n        self,\n        value: str,\n        value_type: Callable[[str], int | float],\n        min_value: int | float | None,\n        max_value: int | float | None,\n    ) -&gt; int | float:\n        \"\"\"Returns the numeric value if it is of the expected type and it is within the specified range.\n\n        Args:\n            value: String representation of numeric value to check.\n            value_type: Expected type of the numeric value.\n            min_value: Minimum value constrain. If `None`, no minimum value constrain.\n            max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n        \"\"\"\n        # Check if the string representation can be converted to the expected type\n        try:\n            result = value_type(value)\n        except (TypeError, ValueError):\n            self.error(f\"invalid {value_type.__name__} value: {value}\")\n        # Check if numeric value is within range\n        if (min_value is not None) and (result &lt; min_value):\n            self.error(f\"{value} is lower than minimum value ({min_value})\")\n        if (max_value is not None) and (result &gt; max_value):\n            self.error(f\"{value} is greater than maximum value ({max_value})\")\n        return result\n\n    def add_argument(self, *args: Any, **kwargs: Any) -&gt; None:  # type: ignore[override]\n        \"\"\"Extends the parent function by excluding the default value in the help text when not provided.\n\n        Only applied to required arguments without a default value, i.e. positional arguments or optional\n        arguments with `required=True`.\n\n        \"\"\"\n        if kwargs.get(\"required\", False):\n            kwargs.setdefault(\"default\", argparse.SUPPRESS)\n        super().add_argument(*args, **kwargs)\n\n    def add_argument_src_path(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `pathlib.Path` argument, checking if it exists and it is readable at parsing time.\n\n        If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"PATH\")\n        kwargs[\"type\"] = self._validate_src_path\n        self.add_argument(*args, **kwargs)\n\n    def add_argument_dst_path(self, *args: Any, exists_ok: bool = True, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `pathlib.Path` argument, checking if it is writable at parsing time.\n\n        If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.\n\n        Args:\n            exists_ok: Do not raise an error if the destination path already exists.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"PATH\")\n        kwargs[\"type\"] = lambda x: self._validate_dst_path(x, exists_ok)\n        self.add_argument(*args, **kwargs)\n\n    def add_argument_url(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `sqlalchemy.engine.URL` argument.\n\n        If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"URI\")\n        kwargs[\"type\"] = make_url\n        self.add_argument(*args, **kwargs)\n\n    # pylint: disable=redefined-builtin\n    def add_numeric_argument(\n        self,\n        *args: Any,\n        type: Callable[[str], int | float] = float,\n        min_value: int | float | None = None,\n        max_value: int | float | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Adds a numeric argument with constrains on its type and its minimum or maximum value.\n\n        Note that the default value (if defined) is not checked unless the argument is an optional argument\n        and no value is provided in the command line.\n\n        Args:\n            type: Type to convert the argument value to when parsing.\n            min_value: Minimum value constrain. If `None`, no minimum value constrain.\n            max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n        \"\"\"\n        # If both minimum and maximum values are defined, ensure min_value &lt;= max_value\n        if (min_value is not None) and (max_value is not None) and (min_value &gt; max_value):\n            raise ArgumentError(\"minimum value is greater than maximum value\")\n        # Add lambda function to check numeric constrains when parsing argument\n        kwargs[\"type\"] = lambda x: self._validate_number(x, type, min_value, max_value)\n        self.add_argument(*args, **kwargs)\n\n    # pylint: disable=redefined-builtin\n    def add_server_arguments(\n        self, prefix: str = \"\", include_database: bool = False, help: str | None = None\n    ) -&gt; None:\n        \"\"\"Adds the usual set of arguments needed to connect to a server, i.e. `--host`, `--port`, `--user`\n        and `--password` (optional).\n\n        Note that the parser will assume this is a MySQL server.\n\n        Args:\n            prefix: Prefix to add the each argument, e.g. if prefix is `src_`, the arguments will be\n                `--src_host`, etc.\n            include_database: Include `--database` argument.\n            help: Description message to include for this set of arguments.\n\n        \"\"\"\n        group = self.add_argument_group(f\"{prefix}server connection arguments\", description=help)\n        group.add_argument(\n            f\"--{prefix}host\", required=True, metavar=\"HOST\", default=argparse.SUPPRESS, help=\"host name\"\n        )\n        group.add_argument(\n            f\"--{prefix}port\",\n            required=True,\n            type=int,\n            metavar=\"PORT\",\n            default=argparse.SUPPRESS,\n            help=\"port number\",\n        )\n        group.add_argument(\n            f\"--{prefix}user\", required=True, metavar=\"USER\", default=argparse.SUPPRESS, help=\"user name\"\n        )\n        group.add_argument(f\"--{prefix}password\", metavar=\"PWD\", help=\"host password\")\n        if include_database:\n            group.add_argument(\n                f\"--{prefix}database\",\n                required=True,\n                metavar=\"NAME\",\n                default=argparse.SUPPRESS,\n                help=\"database name\",\n            )\n\n    def add_log_arguments(self, add_log_file: bool = False) -&gt; None:\n        \"\"\"Adds the usual set of arguments required to set and initialise a logging system.\n\n        The current set includes a mutually exclusive group for the default logging level: `--verbose`,\n        `--debug`, `--quiet` or `--log LEVEL`.\n\n        Args:\n            add_log_file: Add arguments to allow storing messages into a file, i.e. `--log_file` and\n                `--log_file_level`.\n\n        \"\"\"\n        # Define the list of log levels available\n        log_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n        # NOTE: from 3.11 this list can be changed to: logging.getLevelNamesMapping().keys()\n        # Create logging arguments group\n        group = self.add_argument_group(\"logging arguments\")\n        # Add 3 mutually exclusive options to set the logging level\n        subgroup = group.add_mutually_exclusive_group()\n        subgroup.add_argument(\n            \"-v\",\n            \"--verbose\",\n            action=\"store_const\",\n            const=\"INFO\",\n            dest=\"log_level\",\n            help=\"verbose mode, i.e. 'INFO' log level\",\n        )\n        subgroup.add_argument(\n            \"--debug\",\n            action=\"store_const\",\n            const=\"DEBUG\",\n            dest=\"log_level\",\n            help=\"debugging mode, i.e. 'DEBUG' log level\",\n        )\n        subgroup.add_argument(\n            \"--quiet\",\n            action=\"store_const\",\n            const=\"CRITICAL\",\n            dest=\"log_level\",\n            help=\"quiet mode, i.e. 'CRITICAL' log level\",\n        )\n        subgroup.add_argument(\n            \"--log\",\n            choices=log_levels,\n            type=str.upper,\n            default=\"WARNING\",\n            metavar=\"LEVEL\",\n            dest=\"log_level\",\n            help=\"level of the events to track: %(choices)s\",\n        )\n        subgroup.set_defaults(log_level=\"WARNING\")\n        if add_log_file:\n            # Add log file-related arguments\n            group.add_argument(\n                \"--log_file\",\n                type=lambda x: self._validate_dst_path(x, exists_ok=True),\n                metavar=\"PATH\",\n                default=None,\n                help=\"log file path\",\n            )\n            group.add_argument(\n                \"--log_file_level\",\n                choices=log_levels,\n                type=str.upper,\n                default=\"DEBUG\",\n                metavar=\"LEVEL\",\n                help=\"level of the events to track in the log file: %(choices)s\",\n            )\n\n    def parse_args(self, *args: Any, **kwargs: Any) -&gt; argparse.Namespace:  # type: ignore[override]\n        \"\"\"Extends the parent function by adding a new URL argument for every server group added.\n\n        The type of this new argument will be `sqlalchemy.engine.URL`. It also logs all the parsed\n        arguments for debugging purposes when logging arguments have been added.\n\n        \"\"\"\n        arguments = super().parse_args(*args, **kwargs)\n        # Build and add an sqlalchemy.engine.URL object for every server group added\n        pattern = re.compile(r\"([\\w-]*)host$\")\n        server_prefixes = [x.group(1) for x in map(pattern.match, vars(arguments)) if x]\n        for prefix in server_prefixes:\n            # Raise an error rather than overwriting when the URL argument is already present\n            if f\"{prefix}url\" in arguments:\n                self.error(f\"argument '{prefix}url' is already present\")\n            try:\n                server_url = URL.create(\n                    \"mysql\",\n                    getattr(arguments, f\"{prefix}user\"),\n                    getattr(arguments, f\"{prefix}password\"),\n                    getattr(arguments, f\"{prefix}host\"),\n                    getattr(arguments, f\"{prefix}port\"),\n                    getattr(arguments, f\"{prefix}database\", None),\n                )\n            except AttributeError:\n                # Not a database server host argument\n                continue\n            setattr(arguments, f\"{prefix}url\", server_url)\n        return arguments\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.formatter_class","title":"<code>formatter_class = argparse.ArgumentDefaultsHelpFormatter</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.add_argument","title":"<code>add_argument(*args, **kwargs)</code>","text":"<p>Extends the parent function by excluding the default value in the help text when not provided.</p> <p>Only applied to required arguments without a default value, i.e. positional arguments or optional arguments with <code>required=True</code>.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument(self, *args: Any, **kwargs: Any) -&gt; None:  # type: ignore[override]\n    \"\"\"Extends the parent function by excluding the default value in the help text when not provided.\n\n    Only applied to required arguments without a default value, i.e. positional arguments or optional\n    arguments with `required=True`.\n\n    \"\"\"\n    if kwargs.get(\"required\", False):\n        kwargs.setdefault(\"default\", argparse.SUPPRESS)\n    super().add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.add_argument_dst_path","title":"<code>add_argument_dst_path(*args, exists_ok=True, **kwargs)</code>","text":"<p>Adds <code>pathlib.Path</code> argument, checking if it is writable at parsing time.</p> <p>If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.</p> <p>Parameters:</p> Name Type Description Default <code>exists_ok</code> <code>bool</code> <p>Do not raise an error if the destination path already exists.</p> <code>True</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_dst_path(self, *args: Any, exists_ok: bool = True, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `pathlib.Path` argument, checking if it is writable at parsing time.\n\n    If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.\n\n    Args:\n        exists_ok: Do not raise an error if the destination path already exists.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"PATH\")\n    kwargs[\"type\"] = lambda x: self._validate_dst_path(x, exists_ok)\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.add_argument_src_path","title":"<code>add_argument_src_path(*args, **kwargs)</code>","text":"<p>Adds <code>pathlib.Path</code> argument, checking if it exists and it is readable at parsing time.</p> <p>If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_src_path(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `pathlib.Path` argument, checking if it exists and it is readable at parsing time.\n\n    If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"PATH\")\n    kwargs[\"type\"] = self._validate_src_path\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.add_argument_url","title":"<code>add_argument_url(*args, **kwargs)</code>","text":"<p>Adds <code>sqlalchemy.engine.URL</code> argument.</p> <p>If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_url(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `sqlalchemy.engine.URL` argument.\n\n    If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"URI\")\n    kwargs[\"type\"] = make_url\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.add_log_arguments","title":"<code>add_log_arguments(add_log_file=False)</code>","text":"<p>Adds the usual set of arguments required to set and initialise a logging system.</p> <p>The current set includes a mutually exclusive group for the default logging level: <code>--verbose</code>, <code>--debug</code>, <code>--quiet</code> or <code>--log LEVEL</code>.</p> <p>Parameters:</p> Name Type Description Default <code>add_log_file</code> <code>bool</code> <p>Add arguments to allow storing messages into a file, i.e. <code>--log_file</code> and <code>--log_file_level</code>.</p> <code>False</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_log_arguments(self, add_log_file: bool = False) -&gt; None:\n    \"\"\"Adds the usual set of arguments required to set and initialise a logging system.\n\n    The current set includes a mutually exclusive group for the default logging level: `--verbose`,\n    `--debug`, `--quiet` or `--log LEVEL`.\n\n    Args:\n        add_log_file: Add arguments to allow storing messages into a file, i.e. `--log_file` and\n            `--log_file_level`.\n\n    \"\"\"\n    # Define the list of log levels available\n    log_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n    # NOTE: from 3.11 this list can be changed to: logging.getLevelNamesMapping().keys()\n    # Create logging arguments group\n    group = self.add_argument_group(\"logging arguments\")\n    # Add 3 mutually exclusive options to set the logging level\n    subgroup = group.add_mutually_exclusive_group()\n    subgroup.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_const\",\n        const=\"INFO\",\n        dest=\"log_level\",\n        help=\"verbose mode, i.e. 'INFO' log level\",\n    )\n    subgroup.add_argument(\n        \"--debug\",\n        action=\"store_const\",\n        const=\"DEBUG\",\n        dest=\"log_level\",\n        help=\"debugging mode, i.e. 'DEBUG' log level\",\n    )\n    subgroup.add_argument(\n        \"--quiet\",\n        action=\"store_const\",\n        const=\"CRITICAL\",\n        dest=\"log_level\",\n        help=\"quiet mode, i.e. 'CRITICAL' log level\",\n    )\n    subgroup.add_argument(\n        \"--log\",\n        choices=log_levels,\n        type=str.upper,\n        default=\"WARNING\",\n        metavar=\"LEVEL\",\n        dest=\"log_level\",\n        help=\"level of the events to track: %(choices)s\",\n    )\n    subgroup.set_defaults(log_level=\"WARNING\")\n    if add_log_file:\n        # Add log file-related arguments\n        group.add_argument(\n            \"--log_file\",\n            type=lambda x: self._validate_dst_path(x, exists_ok=True),\n            metavar=\"PATH\",\n            default=None,\n            help=\"log file path\",\n        )\n        group.add_argument(\n            \"--log_file_level\",\n            choices=log_levels,\n            type=str.upper,\n            default=\"DEBUG\",\n            metavar=\"LEVEL\",\n            help=\"level of the events to track in the log file: %(choices)s\",\n        )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.add_numeric_argument","title":"<code>add_numeric_argument(*args, type=float, min_value=None, max_value=None, **kwargs)</code>","text":"<p>Adds a numeric argument with constrains on its type and its minimum or maximum value.</p> <p>Note that the default value (if defined) is not checked unless the argument is an optional argument and no value is provided in the command line.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Callable[[str], int | float]</code> <p>Type to convert the argument value to when parsing.</p> <code>float</code> <code>min_value</code> <code>int | float | None</code> <p>Minimum value constrain. If <code>None</code>, no minimum value constrain.</p> <code>None</code> <code>max_value</code> <code>int | float | None</code> <p>Maximum value constrain. If <code>None</code>, no maximum value constrain.</p> <code>None</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_numeric_argument(\n    self,\n    *args: Any,\n    type: Callable[[str], int | float] = float,\n    min_value: int | float | None = None,\n    max_value: int | float | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Adds a numeric argument with constrains on its type and its minimum or maximum value.\n\n    Note that the default value (if defined) is not checked unless the argument is an optional argument\n    and no value is provided in the command line.\n\n    Args:\n        type: Type to convert the argument value to when parsing.\n        min_value: Minimum value constrain. If `None`, no minimum value constrain.\n        max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n    \"\"\"\n    # If both minimum and maximum values are defined, ensure min_value &lt;= max_value\n    if (min_value is not None) and (max_value is not None) and (min_value &gt; max_value):\n        raise ArgumentError(\"minimum value is greater than maximum value\")\n    # Add lambda function to check numeric constrains when parsing argument\n    kwargs[\"type\"] = lambda x: self._validate_number(x, type, min_value, max_value)\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.add_server_arguments","title":"<code>add_server_arguments(prefix='', include_database=False, help=None)</code>","text":"<p>Adds the usual set of arguments needed to connect to a server, i.e. <code>--host</code>, <code>--port</code>, <code>--user</code> and <code>--password</code> (optional).</p> <p>Note that the parser will assume this is a MySQL server.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix to add the each argument, e.g. if prefix is <code>src_</code>, the arguments will be <code>--src_host</code>, etc.</p> <code>''</code> <code>include_database</code> <code>bool</code> <p>Include <code>--database</code> argument.</p> <code>False</code> <code>help</code> <code>str | None</code> <p>Description message to include for this set of arguments.</p> <code>None</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_server_arguments(\n    self, prefix: str = \"\", include_database: bool = False, help: str | None = None\n) -&gt; None:\n    \"\"\"Adds the usual set of arguments needed to connect to a server, i.e. `--host`, `--port`, `--user`\n    and `--password` (optional).\n\n    Note that the parser will assume this is a MySQL server.\n\n    Args:\n        prefix: Prefix to add the each argument, e.g. if prefix is `src_`, the arguments will be\n            `--src_host`, etc.\n        include_database: Include `--database` argument.\n        help: Description message to include for this set of arguments.\n\n    \"\"\"\n    group = self.add_argument_group(f\"{prefix}server connection arguments\", description=help)\n    group.add_argument(\n        f\"--{prefix}host\", required=True, metavar=\"HOST\", default=argparse.SUPPRESS, help=\"host name\"\n    )\n    group.add_argument(\n        f\"--{prefix}port\",\n        required=True,\n        type=int,\n        metavar=\"PORT\",\n        default=argparse.SUPPRESS,\n        help=\"port number\",\n    )\n    group.add_argument(\n        f\"--{prefix}user\", required=True, metavar=\"USER\", default=argparse.SUPPRESS, help=\"user name\"\n    )\n    group.add_argument(f\"--{prefix}password\", metavar=\"PWD\", help=\"host password\")\n    if include_database:\n        group.add_argument(\n            f\"--{prefix}database\",\n            required=True,\n            metavar=\"NAME\",\n            default=argparse.SUPPRESS,\n            help=\"database name\",\n        )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.ArgumentParser.parse_args","title":"<code>parse_args(*args, **kwargs)</code>","text":"<p>Extends the parent function by adding a new URL argument for every server group added.</p> <p>The type of this new argument will be <code>sqlalchemy.engine.URL</code>. It also logs all the parsed arguments for debugging purposes when logging arguments have been added.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def parse_args(self, *args: Any, **kwargs: Any) -&gt; argparse.Namespace:  # type: ignore[override]\n    \"\"\"Extends the parent function by adding a new URL argument for every server group added.\n\n    The type of this new argument will be `sqlalchemy.engine.URL`. It also logs all the parsed\n    arguments for debugging purposes when logging arguments have been added.\n\n    \"\"\"\n    arguments = super().parse_args(*args, **kwargs)\n    # Build and add an sqlalchemy.engine.URL object for every server group added\n    pattern = re.compile(r\"([\\w-]*)host$\")\n    server_prefixes = [x.group(1) for x in map(pattern.match, vars(arguments)) if x]\n    for prefix in server_prefixes:\n        # Raise an error rather than overwriting when the URL argument is already present\n        if f\"{prefix}url\" in arguments:\n            self.error(f\"argument '{prefix}url' is already present\")\n        try:\n            server_url = URL.create(\n                \"mysql\",\n                getattr(arguments, f\"{prefix}user\"),\n                getattr(arguments, f\"{prefix}password\"),\n                getattr(arguments, f\"{prefix}host\"),\n                getattr(arguments, f\"{prefix}port\"),\n                getattr(arguments, f\"{prefix}database\", None),\n            )\n        except AttributeError:\n            # Not a database server host argument\n            continue\n        setattr(arguments, f\"{prefix}url\", server_url)\n    return arguments\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.DuplicateIdError","title":"<code>DuplicateIdError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Trying to add a feature with an ID already in use.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>class DuplicateIdError(Exception):\n    \"\"\"Trying to add a feature with an ID already in use.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations","title":"<code>FunctionalAnnotations</code>","text":"<p>List of annotations extracted from a GFF3 file.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>class FunctionalAnnotations:\n    \"\"\"List of annotations extracted from a GFF3 file.\"\"\"\n\n    ignored_xrefs = {\"go\", \"interpro\", \"uniprot\"}\n\n    def __init__(self, provider_name: str = \"\") -&gt; None:\n        self.annotations: List[Annotation] = []\n        self.provider_name = provider_name\n        # Annotated features\n        # Under each feature, each dict's key is a feature ID\n        self.features: Dict[str, Dict[str, Annotation]] = {\n            \"gene\": {},\n            \"transcript\": {},\n            \"translation\": {},\n            \"transposable_element\": {},\n        }\n        # Keep parent info: key is the feature ID, value is the parent ID\n        self.parents: Dict[str, Dict[str, str]] = {\n            \"gene\": {},\n            \"transcript\": {},\n        }\n\n    def get_xrefs(self, feature: GFFSeqFeature) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get the xrefs from the Dbxref field.\"\"\"\n        all_xref: List[Dict[str, str]] = []\n\n        if \"Dbxref\" in feature.qualifiers:\n            for xref in feature.qualifiers[\"Dbxref\"]:\n                dbname, name = xref.split(\":\", maxsplit=1)\n                if dbname == \"GenBank\" and self.provider_name == \"RefSeq\":\n                    dbname = \"RefSeq\"\n\n                if dbname.lower() in self.ignored_xrefs:\n                    continue\n\n                xrefs = {\"dbname\": dbname, \"id\": name}\n                all_xref.append(xrefs)\n\n        # Add RefSeq ID xref if it looks like one\n        if self.provider_name == \"RefSeq\":\n            if feature.type == \"gene\" and feature.id.startswith(\"LOC\"):\n                xref_dbs = {x[\"dbname\"] for x in all_xref}\n                if \"RefSeq\" not in xref_dbs:\n                    all_xref.append({\"dbname\": \"RefSeq\", \"id\": feature.id})\n\n        return all_xref\n\n    def get_features(self, feat_type: str) -&gt; Dict[str, Annotation]:\n        \"\"\"Get all feature annotations for the requested type.\"\"\"\n        try:\n            return self.features[feat_type]\n        except KeyError as err:\n            raise KeyError(f\"No such feature type {feat_type}\") from err\n\n    def add_parent_link(self, parent_type: str, parent_id: str, child_id: str) -&gt; None:\n        \"\"\"Record a parent-child IDs relationship for a given parent biotype.\"\"\"\n        features = self.get_features(parent_type)\n        if parent_id not in features:\n            raise MissingParentError(f\"Parent {parent_type}:{parent_id} not found for {child_id}\")\n        self.parents[parent_type][child_id] = parent_id\n\n    def get_parent(self, parent_type: str, child_id: str) -&gt; str:\n        \"\"\"Returns the parent ID of a given child for a given parent biotype.\"\"\"\n        try:\n            parents = self.parents[parent_type]\n        except KeyError as err:\n            raise KeyError(f\"Unsupported parent type {parent_type}\") from err\n\n        parent_id = parents.get(child_id)\n        if parent_id is None:\n            raise MissingParentError(f\"Can't find {parent_type} parent for {child_id}\")\n        return parent_id\n\n    def add_feature(\n        self,\n        feature: GFFSeqFeature,\n        feat_type: str,\n        parent_id: Optional[str] = None,\n        all_parent_ids: Optional[List[str]] = None,\n    ) -&gt; None:\n        \"\"\"Add annotation for a feature of a given type. If a parent_id is provided, record the relationship.\n\n        Args:\n            feature: The feature to create an annotation.\n            feat_type: Type of the feature to annotate.\n            parent_id: Parent ID of this feature to keep it linked.\n            all_parent_ids: All parent IDs to remove from non-informative descriptions.\n        \"\"\"\n        if all_parent_ids is None:\n            all_parent_ids = []\n        features = self.get_features(feat_type)\n        if feature.id in features:\n            raise AnnotationError(f\"Feature {feat_type} ID {feature.id} already added\")\n\n        feature_object = self._generic_feature(feature, feat_type, all_parent_ids)\n        self.features[feat_type][feature.id] = feature_object\n\n        if parent_id:\n            if feat_type in _PARENTS:\n                parent_type = _PARENTS[feat_type]\n                self.add_parent_link(parent_type, parent_id, feature.id)\n            else:\n                raise AnnotationError(f\"No parent possible for {feat_type} {feature.id}\")\n\n    def _generic_feature(\n        self, feature: GFFSeqFeature, feat_type: str, parent_ids: Optional[List[str]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create a feature object following the specifications.\n\n        Args:\n            feature: The GFFSeqFeature to add to the list.\n            feat_type: Feature type of the feature to store (e.g. gene, transcript, translation).\n            all_parent_ids: All parent IDs to remove from non-informative descriptions.\n\n        \"\"\"\n        if parent_ids is None:\n            parent_ids = []\n\n        feature_object: Annotation = {\"object_type\": feat_type, \"id\": feature.id}\n\n        # Description?\n        for qname in (\"description\", \"product\"):\n            if qname in feature.qualifiers:\n                description = feature.qualifiers[qname][0]\n                if self.product_is_informative(description, feat_ids=parent_ids + [feature.id]):\n                    feature_object[\"description\"] = description\n                    break\n                logging.debug(f\"Non informative description for {feature.id}: {description}\")\n\n        feature_object[\"xrefs\"] = []\n        if \"Dbxref\" in feature.qualifiers:\n            all_xref = self.get_xrefs(feature)\n            feature_object[\"xrefs\"] = all_xref\n\n        xref_values = {xref[\"id\"].lower() for xref in feature_object[\"xrefs\"]}\n\n        # Synonyms?\n        # We add synonyms to the external_synonym table\n        # which is associated with the first xref of that feature type\n        if \"Name\" in feature.qualifiers:\n            feat_name = feature.qualifiers[\"Name\"][0]\n            if feat_name.lower() != feature.id.lower() and feat_name.lower() not in xref_values:\n                feature_object[\"synonyms\"] = [feat_name]\n\n        # is_pseudogene?\n        if feature.type.startswith(\"pseudogen\"):\n            feature_object[\"is_pseudogene\"] = True\n\n        # Don't keep empty xref\n        if not feature_object[\"xrefs\"]:\n            del feature_object[\"xrefs\"]\n        return feature_object\n\n    def transfer_descriptions(self) -&gt; None:\n        \"\"\"Transfers the feature descriptions in 2 steps:\n        - from translations to transcripts (if the transcript description is empty)\n        - from transcripts to genes (same case)\n\n        \"\"\"\n        self._transfer_description_up(\"translation\")\n        self._transfer_description_up(\"transcript\")\n\n    def _transfer_description_up(self, child_feature: str) -&gt; None:\n        \"\"\"Transfer descriptions from all feature of a given type, up to their parent.\n\n        Args:\n            child_feature: Either \"translation\" (transfer to transcript) or \"transcript\" (to gene).\n\n        \"\"\"\n        children_features = self.get_features(child_feature)\n        parent_type = _PARENTS[child_feature]\n        parent_features = self.get_features(parent_type)\n\n        # Transfer description from children to their parent\n        for child_id, child in children_features.items():\n            child_description = child.get(\"description\")\n            if child_description is not None:\n                child_description = self._clean_description(child_description)\n                # Check parent\n                parent_id = self.get_parent(parent_type, child_id)\n                parent = parent_features[parent_id]\n                parent_description = parent.get(\"description\")\n                if parent_description is None:\n                    parent[\"description\"] = child_description\n\n    @staticmethod\n    def _clean_description(description: str) -&gt; str:\n        \"\"\"Returns the description without \"transcript variant\" information.\"\"\"\n        variant_re = re.compile(r\", transcript variant [A-Z][0-9]+$\", re.IGNORECASE)\n        description = re.sub(variant_re, \"\", description)\n        return description\n\n    @staticmethod\n    def product_is_informative(product: str, feat_ids: Optional[List[str]] = None) -&gt; bool:\n        \"\"\"Returns True if the product name contains informative words, False otherwise.\n\n        It is considered uninformative when the description contains words such as \"hypothetical\" or\n        or \"putative\". If feature IDs are provided, consider it uninformative as well (we do not want\n        descriptions to be just the ID).\n\n        Args:\n            product: A product name.\n            feat_ids: List of feature IDs.\n\n        \"\"\"\n        non_informative_words = [\n            \"hypothetical\",\n            \"putative\",\n            \"uncharacterized\",\n            \"unspecified\",\n            \"unknown\",\n            r\"(of )?unknown function\",\n            \"conserved\",\n            \"predicted\",\n            \"fragment\",\n            \"product\",\n            \"function\",\n            \"protein\",\n            \"transcript\",\n            \"gene\",\n            \"RNA\",\n            r\"(variant|isoform)( X?\\d+)?\",\n            r\"low quality protein\",\n        ]\n        non_informative_re = re.compile(r\"|\".join(non_informative_words), re.IGNORECASE)\n\n        # Remove all IDs that are in the description\n        if feat_ids:\n            logging.debug(f\"Filter out {feat_ids} from {product}\")\n            try:\n                for feat_id in feat_ids:\n                    feat_id_re = re.compile(feat_id, re.IGNORECASE)\n                    product = re.sub(feat_id_re, \"\", product)\n            except TypeError as err:\n                raise TypeError(f\"Failed to search {feat_id_re} in '{product}'\") from err\n\n        # Remove punctuations\n        punct_re = re.compile(r\"[,;: _()-]+\")\n        product = re.sub(punct_re, \" \", product)\n\n        # Then remove non informative words\n        product = re.sub(non_informative_re, \" \", product)\n\n        # Anything (informative) left?\n        empty_re = re.compile(r\"^[ ]*$\")\n        return not bool(empty_re.match(product))\n\n    def _to_list(self) -&gt; list[Annotation]:\n        all_list: list[Annotation] = []\n        for feat_dict in self.features.values():\n            all_list += feat_dict.values()\n        return all_list\n\n    def to_json(self, out_path: PathLike) -&gt; None:\n        \"\"\"Print out the current annotation list in a json file.\n\n        Args:\n            out_path: JSON file path where to write the data.\n\n        \"\"\"\n        self.transfer_descriptions()\n        feats_list = self._to_list()\n        print_json(Path(out_path), feats_list)\n\n    def store_gene(self, gene: GFFSeqFeature) -&gt; None:\n        \"\"\"Record the functional_annotations of a gene and its children features.\"\"\"\n        self.add_feature(gene, \"gene\")\n\n        for transcript in gene.sub_features:\n            self.add_feature(transcript, \"transcript\", gene.id, [gene.id])\n            for feat in transcript.sub_features:\n                if feat.type == \"CDS\":\n                    self.add_feature(feat, \"translation\", transcript.id, [gene.id, transcript.id])\n                    # Store CDS functional annotation only once\n                    break\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.annotations","title":"<code>annotations = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.features","title":"<code>features = {'gene': {}, 'transcript': {}, 'translation': {}, 'transposable_element': {}}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.ignored_xrefs","title":"<code>ignored_xrefs = {'go', 'interpro', 'uniprot'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.parents","title":"<code>parents = {'gene': {}, 'transcript': {}}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.provider_name","title":"<code>provider_name = provider_name</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.add_feature","title":"<code>add_feature(feature, feat_type, parent_id=None, all_parent_ids=None)</code>","text":"<p>Add annotation for a feature of a given type. If a parent_id is provided, record the relationship.</p> <p>Parameters:</p> Name Type Description Default <code>feature</code> <code>GFFSeqFeature</code> <p>The feature to create an annotation.</p> required <code>feat_type</code> <code>str</code> <p>Type of the feature to annotate.</p> required <code>parent_id</code> <code>Optional[str]</code> <p>Parent ID of this feature to keep it linked.</p> <code>None</code> <code>all_parent_ids</code> <code>Optional[List[str]]</code> <p>All parent IDs to remove from non-informative descriptions.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def add_feature(\n    self,\n    feature: GFFSeqFeature,\n    feat_type: str,\n    parent_id: Optional[str] = None,\n    all_parent_ids: Optional[List[str]] = None,\n) -&gt; None:\n    \"\"\"Add annotation for a feature of a given type. If a parent_id is provided, record the relationship.\n\n    Args:\n        feature: The feature to create an annotation.\n        feat_type: Type of the feature to annotate.\n        parent_id: Parent ID of this feature to keep it linked.\n        all_parent_ids: All parent IDs to remove from non-informative descriptions.\n    \"\"\"\n    if all_parent_ids is None:\n        all_parent_ids = []\n    features = self.get_features(feat_type)\n    if feature.id in features:\n        raise AnnotationError(f\"Feature {feat_type} ID {feature.id} already added\")\n\n    feature_object = self._generic_feature(feature, feat_type, all_parent_ids)\n    self.features[feat_type][feature.id] = feature_object\n\n    if parent_id:\n        if feat_type in _PARENTS:\n            parent_type = _PARENTS[feat_type]\n            self.add_parent_link(parent_type, parent_id, feature.id)\n        else:\n            raise AnnotationError(f\"No parent possible for {feat_type} {feature.id}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.add_parent_link","title":"<code>add_parent_link(parent_type, parent_id, child_id)</code>","text":"<p>Record a parent-child IDs relationship for a given parent biotype.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def add_parent_link(self, parent_type: str, parent_id: str, child_id: str) -&gt; None:\n    \"\"\"Record a parent-child IDs relationship for a given parent biotype.\"\"\"\n    features = self.get_features(parent_type)\n    if parent_id not in features:\n        raise MissingParentError(f\"Parent {parent_type}:{parent_id} not found for {child_id}\")\n    self.parents[parent_type][child_id] = parent_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.get_features","title":"<code>get_features(feat_type)</code>","text":"<p>Get all feature annotations for the requested type.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def get_features(self, feat_type: str) -&gt; Dict[str, Annotation]:\n    \"\"\"Get all feature annotations for the requested type.\"\"\"\n    try:\n        return self.features[feat_type]\n    except KeyError as err:\n        raise KeyError(f\"No such feature type {feat_type}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.get_parent","title":"<code>get_parent(parent_type, child_id)</code>","text":"<p>Returns the parent ID of a given child for a given parent biotype.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def get_parent(self, parent_type: str, child_id: str) -&gt; str:\n    \"\"\"Returns the parent ID of a given child for a given parent biotype.\"\"\"\n    try:\n        parents = self.parents[parent_type]\n    except KeyError as err:\n        raise KeyError(f\"Unsupported parent type {parent_type}\") from err\n\n    parent_id = parents.get(child_id)\n    if parent_id is None:\n        raise MissingParentError(f\"Can't find {parent_type} parent for {child_id}\")\n    return parent_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.get_xrefs","title":"<code>get_xrefs(feature)</code>","text":"<p>Get the xrefs from the Dbxref field.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def get_xrefs(self, feature: GFFSeqFeature) -&gt; List[Dict[str, Any]]:\n    \"\"\"Get the xrefs from the Dbxref field.\"\"\"\n    all_xref: List[Dict[str, str]] = []\n\n    if \"Dbxref\" in feature.qualifiers:\n        for xref in feature.qualifiers[\"Dbxref\"]:\n            dbname, name = xref.split(\":\", maxsplit=1)\n            if dbname == \"GenBank\" and self.provider_name == \"RefSeq\":\n                dbname = \"RefSeq\"\n\n            if dbname.lower() in self.ignored_xrefs:\n                continue\n\n            xrefs = {\"dbname\": dbname, \"id\": name}\n            all_xref.append(xrefs)\n\n    # Add RefSeq ID xref if it looks like one\n    if self.provider_name == \"RefSeq\":\n        if feature.type == \"gene\" and feature.id.startswith(\"LOC\"):\n            xref_dbs = {x[\"dbname\"] for x in all_xref}\n            if \"RefSeq\" not in xref_dbs:\n                all_xref.append({\"dbname\": \"RefSeq\", \"id\": feature.id})\n\n    return all_xref\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.product_is_informative","title":"<code>product_is_informative(product, feat_ids=None)</code>  <code>staticmethod</code>","text":"<p>Returns True if the product name contains informative words, False otherwise.</p> <p>It is considered uninformative when the description contains words such as \"hypothetical\" or or \"putative\". If feature IDs are provided, consider it uninformative as well (we do not want descriptions to be just the ID).</p> <p>Parameters:</p> Name Type Description Default <code>product</code> <code>str</code> <p>A product name.</p> required <code>feat_ids</code> <code>Optional[List[str]]</code> <p>List of feature IDs.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>@staticmethod\ndef product_is_informative(product: str, feat_ids: Optional[List[str]] = None) -&gt; bool:\n    \"\"\"Returns True if the product name contains informative words, False otherwise.\n\n    It is considered uninformative when the description contains words such as \"hypothetical\" or\n    or \"putative\". If feature IDs are provided, consider it uninformative as well (we do not want\n    descriptions to be just the ID).\n\n    Args:\n        product: A product name.\n        feat_ids: List of feature IDs.\n\n    \"\"\"\n    non_informative_words = [\n        \"hypothetical\",\n        \"putative\",\n        \"uncharacterized\",\n        \"unspecified\",\n        \"unknown\",\n        r\"(of )?unknown function\",\n        \"conserved\",\n        \"predicted\",\n        \"fragment\",\n        \"product\",\n        \"function\",\n        \"protein\",\n        \"transcript\",\n        \"gene\",\n        \"RNA\",\n        r\"(variant|isoform)( X?\\d+)?\",\n        r\"low quality protein\",\n    ]\n    non_informative_re = re.compile(r\"|\".join(non_informative_words), re.IGNORECASE)\n\n    # Remove all IDs that are in the description\n    if feat_ids:\n        logging.debug(f\"Filter out {feat_ids} from {product}\")\n        try:\n            for feat_id in feat_ids:\n                feat_id_re = re.compile(feat_id, re.IGNORECASE)\n                product = re.sub(feat_id_re, \"\", product)\n        except TypeError as err:\n            raise TypeError(f\"Failed to search {feat_id_re} in '{product}'\") from err\n\n    # Remove punctuations\n    punct_re = re.compile(r\"[,;: _()-]+\")\n    product = re.sub(punct_re, \" \", product)\n\n    # Then remove non informative words\n    product = re.sub(non_informative_re, \" \", product)\n\n    # Anything (informative) left?\n    empty_re = re.compile(r\"^[ ]*$\")\n    return not bool(empty_re.match(product))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.store_gene","title":"<code>store_gene(gene)</code>","text":"<p>Record the functional_annotations of a gene and its children features.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def store_gene(self, gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Record the functional_annotations of a gene and its children features.\"\"\"\n    self.add_feature(gene, \"gene\")\n\n    for transcript in gene.sub_features:\n        self.add_feature(transcript, \"transcript\", gene.id, [gene.id])\n        for feat in transcript.sub_features:\n            if feat.type == \"CDS\":\n                self.add_feature(feat, \"translation\", transcript.id, [gene.id, transcript.id])\n                # Store CDS functional annotation only once\n                break\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.to_json","title":"<code>to_json(out_path)</code>","text":"<p>Print out the current annotation list in a json file.</p> <p>Parameters:</p> Name Type Description Default <code>out_path</code> <code>PathLike</code> <p>JSON file path where to write the data.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def to_json(self, out_path: PathLike) -&gt; None:\n    \"\"\"Print out the current annotation list in a json file.\n\n    Args:\n        out_path: JSON file path where to write the data.\n\n    \"\"\"\n    self.transfer_descriptions()\n    feats_list = self._to_list()\n    print_json(Path(out_path), feats_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.FunctionalAnnotations.transfer_descriptions","title":"<code>transfer_descriptions()</code>","text":"<p>Transfers the feature descriptions in 2 steps: - from translations to transcripts (if the transcript description is empty) - from transcripts to genes (same case)</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def transfer_descriptions(self) -&gt; None:\n    \"\"\"Transfers the feature descriptions in 2 steps:\n    - from translations to transcripts (if the transcript description is empty)\n    - from transcripts to genes (same case)\n\n    \"\"\"\n    self._transfer_description_up(\"translation\")\n    self._transfer_description_up(\"transcript\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFGeneMerger","title":"<code>GFFGeneMerger</code>","text":"<p>Specialized class to merge split genes in a GFF3 file, prior to further parsing.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/gene_merger.py</code> <pre><code>class GFFGeneMerger:\n    \"\"\"Specialized class to merge split genes in a GFF3 file, prior to further parsing.\"\"\"\n\n    def __init__(self) -&gt; None:\n        source = files(ensembl.io.genomio.data.gff3).joinpath(\"biotypes.json\")\n        with as_file(source) as biotypes_json:\n            self._biotypes = get_json(biotypes_json)\n\n    def merge(self, in_gff_path: PathLike, out_gff_path: PathLike) -&gt; List[str]:\n        \"\"\"\n        Merge genes in a gff that are split in multiple lines.\n\n        Args:\n            in_gff_path: Input GFF3 that may have split merge.\n            out_gff_path: Output GFF3 with those genes merged.\n\n        Returns:\n            List of all merged genes, each represented as a string of the GFF3 lines of all their parts.\n        \"\"\"\n        to_merge = []\n        merged: List[str] = []\n\n        with Path(in_gff_path).open(\"r\") as in_gff_fh, Path(out_gff_path).open(\"w\") as out_gff_fh:\n            for line in in_gff_fh:\n                # Skip comments\n                if line.startswith(\"#\"):\n                    if line.startswith(\"##FASTA\"):\n                        logging.warning(\"This GFF3 file contains FASTA sequences\")\n                        break\n                    out_gff_fh.write(line)\n                else:\n                    # Parse one line\n                    line = line.rstrip()\n                    fields = line.split(\"\\t\")\n                    attr_fields = fields[8].split(\";\")\n                    attrs = {}\n                    for a in attr_fields:\n                        (key, value) = a.split(\"=\")\n                        attrs[key] = value\n\n                    # Check this is a gene to merge; cache it then\n                    if fields[2] in self._biotypes[\"gene\"][\"supported\"] and (\n                        \"part\" in attrs or \"is_ordered\" in attrs\n                    ):\n                        to_merge.append(fields)\n\n                    # If not, merge previous gene if needed, and print the line\n                    else:\n                        if to_merge:\n                            merged_str = []\n                            for line_to_merge in to_merge:\n                                merged_str.append(\"\\t\".join(line_to_merge))\n                            merged.append(\"\\n\".join(merged_str) + \"\\n\")\n\n                            new_line = self._merge_genes(to_merge)\n                            out_gff_fh.write(new_line)\n                            to_merge = []\n                        out_gff_fh.write(line + \"\\n\")\n\n            # Print last merged gene if there is one\n            if to_merge:\n                merged_str = []\n                for line_to_merge in to_merge:\n                    merged_str.append(\"\\t\".join(line_to_merge))\n                merged.append(\"\\n\".join(merged_str) + \"\\n\")\n\n                new_line = self._merge_genes(to_merge)\n                out_gff_fh.write(new_line)\n\n        logging.debug(f\"Merged lines: {len(merged)}\")\n        return merged\n\n    def _merge_genes(self, to_merge: List) -&gt; str:\n        \"\"\"Returns a single gene gff3 line merged from separate parts.\n\n        Args:\n            to_merge: List of gff3 lines with gene parts.\n\n        \"\"\"\n        min_start = -1\n        max_end = -1\n        for gene in to_merge:\n            start = int(gene[3])\n            end = int(gene[4])\n\n            if start &lt; min_start or min_start &lt; 0:\n                min_start = start\n            if end &gt; max_end or max_end &lt; 0:\n                max_end = end\n\n        # Take the first line as template and replace things\n        new_gene = to_merge[0]\n        new_gene[3] = str(min_start)\n        new_gene[4] = str(max_end)\n\n        attrs = new_gene[8]\n        attrs = attrs.replace(\";is_ordered=true\", \"\")\n        attrs = re.sub(r\";part=\\d+/\\d+\", \"\", attrs)\n        new_gene[8] = attrs\n\n        return \"\\t\".join(new_gene) + \"\\n\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFGeneMerger.merge","title":"<code>merge(in_gff_path, out_gff_path)</code>","text":"<p>Merge genes in a gff that are split in multiple lines.</p> <p>Parameters:</p> Name Type Description Default <code>in_gff_path</code> <code>PathLike</code> <p>Input GFF3 that may have split merge.</p> required <code>out_gff_path</code> <code>PathLike</code> <p>Output GFF3 with those genes merged.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of all merged genes, each represented as a string of the GFF3 lines of all their parts.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/gene_merger.py</code> <pre><code>def merge(self, in_gff_path: PathLike, out_gff_path: PathLike) -&gt; List[str]:\n    \"\"\"\n    Merge genes in a gff that are split in multiple lines.\n\n    Args:\n        in_gff_path: Input GFF3 that may have split merge.\n        out_gff_path: Output GFF3 with those genes merged.\n\n    Returns:\n        List of all merged genes, each represented as a string of the GFF3 lines of all their parts.\n    \"\"\"\n    to_merge = []\n    merged: List[str] = []\n\n    with Path(in_gff_path).open(\"r\") as in_gff_fh, Path(out_gff_path).open(\"w\") as out_gff_fh:\n        for line in in_gff_fh:\n            # Skip comments\n            if line.startswith(\"#\"):\n                if line.startswith(\"##FASTA\"):\n                    logging.warning(\"This GFF3 file contains FASTA sequences\")\n                    break\n                out_gff_fh.write(line)\n            else:\n                # Parse one line\n                line = line.rstrip()\n                fields = line.split(\"\\t\")\n                attr_fields = fields[8].split(\";\")\n                attrs = {}\n                for a in attr_fields:\n                    (key, value) = a.split(\"=\")\n                    attrs[key] = value\n\n                # Check this is a gene to merge; cache it then\n                if fields[2] in self._biotypes[\"gene\"][\"supported\"] and (\n                    \"part\" in attrs or \"is_ordered\" in attrs\n                ):\n                    to_merge.append(fields)\n\n                # If not, merge previous gene if needed, and print the line\n                else:\n                    if to_merge:\n                        merged_str = []\n                        for line_to_merge in to_merge:\n                            merged_str.append(\"\\t\".join(line_to_merge))\n                        merged.append(\"\\n\".join(merged_str) + \"\\n\")\n\n                        new_line = self._merge_genes(to_merge)\n                        out_gff_fh.write(new_line)\n                        to_merge = []\n                    out_gff_fh.write(line + \"\\n\")\n\n        # Print last merged gene if there is one\n        if to_merge:\n            merged_str = []\n            for line_to_merge in to_merge:\n                merged_str.append(\"\\t\".join(line_to_merge))\n            merged.append(\"\\n\".join(merged_str) + \"\\n\")\n\n            new_line = self._merge_genes(to_merge)\n            out_gff_fh.write(new_line)\n\n    logging.debug(f\"Merged lines: {len(merged)}\")\n    return merged\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier","title":"<code>GFFSimplifier</code>","text":"<p>Parse a GGF3 file and output a cleaned up GFF3 + annotation json file.</p> <p>Raises:</p> Type Description <code>GFFParserError</code> <p>If an error cannot be automatically fixed.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>class GFFSimplifier:\n    \"\"\"Parse a GGF3 file and output a cleaned up GFF3 + annotation json file.\n\n    Raises:\n        GFFParserError: If an error cannot be automatically fixed.\n    \"\"\"\n\n    def __init__(\n        self,\n        genome_path: Optional[PathLike] = None,\n        skip_unrecognized: bool = False,\n        allow_pseudogene_with_cds: bool = False,\n    ):\n        \"\"\"Create an object that simplifies `SeqFeature` objects.\n\n        Args:\n            genome_path: Genome metadata file.\n            skip_unrecognized: Do not include unknown biotypes instead of raising an exception.\n            allow_pseudogene_with_cds: Keep CDSs under pseudogenes that have them. Delete them otherwise.\n\n        Raises:\n            GFFParserError: If a biotype is unknown and `skip_unrecognized` is False.\n        \"\"\"\n        self.skip_unrecognized = skip_unrecognized\n        self.allow_pseudogene_with_cds = allow_pseudogene_with_cds\n\n        # Load biotypes\n        source = files(ensembl.io.genomio.data.gff3).joinpath(\"biotypes.json\")\n        with as_file(source) as biotypes_json:\n            self._biotypes = get_json(biotypes_json)\n\n        # Load genome metadata\n        self.genome = {}\n        if genome_path:\n            with Path(genome_path).open(\"r\") as genome_fh:\n                self.genome = json.load(genome_fh)\n\n        self.refseq = False\n        if self.genome and self.genome[\"assembly\"][\"accession\"].startswith(\"GCF\"):\n            self.refseq = True\n\n        # Other preparations\n        self.stable_ids = StableIDAllocator()\n        self.stable_ids.set_prefix(self.genome)\n        self.exclude_seq_regions: List[str] = []\n        self.fail_types: Set = set()\n\n        # Init the actual data we will store\n        self.records = Records()\n        self.annotations = FunctionalAnnotations(self.get_provider_name())\n\n    def get_provider_name(self) -&gt; str:\n        \"\"\"Returns the provider name for this genome.\n\n        If this information is not available, will try to infer it from the assembly accession. Will\n        return \"GenBank\" otherwise.\n        \"\"\"\n        provider_name = \"GenBank\"\n        if self.genome:\n            try:\n                provider_name = self.genome[\"assembly\"][\"provider_name\"]\n            except KeyError:\n                if self.genome[\"assembly\"][\"accession\"].startswith(\"GCF\"):\n                    provider_name = \"RefSeq\"\n        else:\n            logging.warning(f\"No genome file, using the default provider_name: {provider_name}\")\n        return provider_name\n\n    def simpler_gff3(self, in_gff_path: PathLike) -&gt; None:\n        \"\"\"Loads a GFF3 from INSDC and rewrites it in a simpler version, whilst also writing a\n        functional annotation file.\n        \"\"\"\n        self.records.from_gff(in_gff_path, self.exclude_seq_regions)\n        for record in self.records:\n            cleaned_features = []\n            for feature in record.features:\n                split_genes = self.normalize_mirna(feature)\n                if split_genes:\n                    cleaned_features += split_genes\n                else:\n                    try:\n                        clean_feature = self.simpler_gff3_feature(feature)\n                        cleaned_features.append(clean_feature)\n                    except (UnsupportedFeatureError, IgnoredFeatureError) as err:\n                        logging.debug(err.message)\n            record.features = cleaned_features\n\n        if self.fail_types:\n            fail_errors = \"\\n   \".join(list(self.fail_types))\n            logging.warning(f\"Unrecognized types found:\\n   {fail_errors}\")\n            if not self.skip_unrecognized:\n                raise GFFParserError(\"Unrecognized types found, abort\")\n\n    def simpler_gff3_feature(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Creates a simpler version of a GFF3 feature.\n\n        Raises:\n            IgnoredFeatureError: If the feature type is ignored.\n            UnsupportedFeatureError: If the feature type is not supported.\n        \"\"\"\n        # Special cases\n        non_gene = self.normalize_non_gene(gene)\n        if non_gene:\n            return non_gene\n        if gene.type in self._biotypes[\"gene\"][\"ignored\"]:\n            raise IgnoredFeatureError(f\"Ignored type {gene.type} for {gene.id}\")\n\n        # Synonym\n        if gene.type == \"protein_coding_gene\":\n            gene.type = \"gene\"\n\n        # Lone sub-gene features, create a gene\n        gene = self.create_gene_for_lone_transcript(gene)\n        gene = self.create_gene_for_lone_cds(gene)\n\n        # What to do with unsupported gene types\n        if gene.type not in self._biotypes[\"gene\"][\"supported\"]:\n            self.fail_types.add(f\"gene={gene.type}\")\n            raise UnsupportedFeatureError(f\"Unsupported type {gene.type} for {gene.id}\")\n\n        # Normalize and store\n        gene = self.normalize_gene(gene)\n        self.annotations.store_gene(gene)\n        return self.clean_gene(gene)\n\n    def create_gene_for_lone_transcript(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Returns a gene for lone transcripts: 'gene' for tRNA/rRNA/mRNA, and 'ncRNA_gene' for all others.\n\n        Args:\n            feat: The transcript for which we want to create a gene.\n        \"\"\"\n        transcript_types = self._biotypes[\"transcript\"][\"supported\"]\n        if feat.type not in transcript_types:\n            return feat\n\n        new_type = \"ncRNA_gene\"\n        if feat.type in (\"tRNA\", \"rRNA\", \"mRNA\"):\n            new_type = \"gene\"\n        logging.debug(f\"Put the transcript {feat.type} in a {new_type} parent feature\")\n        new_gene = GFFSeqFeature(feat.location, type=new_type)\n        new_gene.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n        new_gene.sub_features = [feat]\n\n        # Use the transcript ID for the gene, and generate a sub ID for the transcript\n        new_gene.id = feat.id\n        new_gene.qualifiers[\"ID\"] = new_gene.id\n        feat.id = self.stable_ids.generate_transcript_id(new_gene.id, 1)\n        feat.qualifiers[\"ID\"] = feat.id\n\n        # Remove the exon/CDS parent so it is properly updated\n        for subfeat in feat.sub_features:\n            del subfeat.qualifiers[\"Parent\"]\n\n        # Check if it's a pseudogene\n        if feat.type == \"mRNA\":\n            is_pseudo = False\n            for subfeat in feat.sub_features:\n                pseudo_qual = subfeat.qualifiers.get(\"pseudo\", [\"\"])[0]\n                if subfeat.type == \"CDS\" and pseudo_qual == \"true\":\n                    is_pseudo = True\n                    del subfeat.qualifiers[\"pseudo\"]\n                    break\n            if is_pseudo:\n                new_gene.type = \"pseudogene\"\n\n        return new_gene\n\n    def create_gene_for_lone_cds(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Returns a gene created for a lone CDS.\n\n        Args:\n            feat: The CDS for which we want to create a gene.\n        \"\"\"\n        if feat.type != \"CDS\":\n            return feat\n\n        logging.debug(f\"Put the lone CDS in gene-mRNA parent features for {feat.id}\")\n\n        # Create a transcript, add the CDS\n        transcript = GFFSeqFeature(feat.location, type=\"mRNA\")\n        transcript.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n        transcript.sub_features = [feat]\n\n        # Add an exon too\n        exon = GFFSeqFeature(feat.location, type=\"exon\")\n        exon.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n        transcript.sub_features.append(exon)\n\n        # Create a gene, add the transcript\n        gene_type = \"gene\"\n        if (\"pseudo\" in feat.qualifiers) and (feat.qualifiers[\"pseudo\"][0] == \"true\"):\n            gene_type = \"pseudogene\"\n            del feat.qualifiers[\"pseudo\"]\n        new_gene = GFFSeqFeature(feat.location, type=gene_type)\n        new_gene.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n        new_gene.sub_features = [transcript]\n        new_gene.id = self.stable_ids.generate_gene_id()\n        new_gene.qualifiers[\"ID\"] = new_gene.id\n        transcript.id = self.stable_ids.generate_transcript_id(new_gene.id, 1)\n        transcript.qualifiers[\"ID\"] = transcript.id\n\n        return new_gene\n\n    def normalize_non_gene(self, feat: GFFSeqFeature) -&gt; Optional[GFFSeqFeature]:\n        \"\"\"Returns a normalised \"non-gene\" or `None` if not applicable.\n\n        Only transposable elements supported at the moment.\n\n        Args:\n            feat: Feature to normalise.\n\n        Raises:\n            NotImplementedError: If the feature is a not supported non-gene.\n        \"\"\"\n\n        if feat.type not in self._biotypes[\"non_gene\"][\"supported\"]:\n            return None\n        if feat.type in (\"mobile_genetic_element\", \"transposable_element\"):\n            feat.type = \"transposable_element\"\n            feat = self._normalize_mobile_genetic_element(feat)\n            # Generate ID if needed\n            feat.id = self.stable_ids.normalize_gene_id(feat, self.refseq)\n            feat.qualifiers[\"ID\"] = feat.id\n\n            self.annotations.add_feature(feat, \"transposable_element\")\n            return self.clean_gene(feat)\n        # This is a failsafe in case you add supported non-genes\n        raise NotImplementedError(f\"Unsupported non-gene: {feat.type} for {feat.id}\")\n\n    def _normalize_mobile_genetic_element(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Normalize a mobile element if it has a mobile_element_type field.\"\"\"\n        try:\n            mobile_element_type = feat.qualifiers[\"mobile_element_type\"]\n        except KeyError:\n            logging.warning(\"No 'mobile_element_type' tag found\")\n            return feat\n\n        # Get the type (and name) from the attrib\n        element_type, _, element_name = mobile_element_type[0].partition(\":\")\n        description = element_type\n        if element_name:\n            description += f\" ({element_name})\"\n\n        # Keep the metadata in the description if the type is known\n        if element_type in (\"transposon\", \"retrotransposon\"):\n            if not feat.qualifiers.get(\"product\"):\n                feat.qualifiers[\"product\"] = [description]\n            return feat\n        raise GFFParserError(f\"'mobile_element_type' is not a transposon: {element_type}\")\n\n    def clean_gene(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Return the same gene without qualifiers unrelated to the gene structure.\"\"\"\n\n        old_gene_qualifiers = gene.qualifiers\n        gene.qualifiers = {\"ID\": gene.id, \"source\": old_gene_qualifiers[\"source\"]}\n        for transcript in gene.sub_features:\n            # Replace qualifiers\n            old_transcript_qualifiers = transcript.qualifiers\n            transcript.qualifiers = {\n                \"ID\": transcript.id,\n                \"Parent\": gene.id,\n                \"source\": old_transcript_qualifiers[\"source\"],\n            }\n\n            for feat in transcript.sub_features:\n                old_qualifiers = feat.qualifiers\n                feat.qualifiers = {\n                    \"ID\": feat.id,\n                    \"Parent\": transcript.id,\n                    \"source\": old_qualifiers[\"source\"],\n                }\n                if feat.type == \"CDS\":\n                    feat.qualifiers[\"phase\"] = old_qualifiers[\"phase\"]\n\n        return gene\n\n    def normalize_gene(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Returns a normalized gene structure, separate from the functional elements.\n\n        Args:\n            gene: Gene object to normalize.\n            functional_annotation: List of feature annotations (appended by this method).\n\n        \"\"\"\n\n        gene.id = self.stable_ids.normalize_gene_id(gene, refseq=self.refseq)\n        restructure_gene(gene)\n        self.normalize_transcripts(gene)\n        self.normalize_pseudogene(gene)\n\n        return gene\n\n    def normalize_pseudogene(self, gene: GFFSeqFeature) -&gt; None:\n        \"\"\"Normalize CDSs if allowed, otherwise remove them.\"\"\"\n        if gene.type != \"pseudogene\":\n            return\n\n        if self.allow_pseudogene_with_cds:\n            self.stable_ids.normalize_pseudogene_cds_id(gene)\n        else:\n            remove_cds_from_pseudogene(gene)\n\n    def normalize_transcripts(self, gene: GFFSeqFeature) -&gt; None:\n        \"\"\"Normalizes a transcript.\"\"\"\n\n        allowed_transcript_types = self._biotypes[\"transcript\"][\"supported\"]\n        ignored_transcript_types = self._biotypes[\"transcript\"][\"ignored\"]\n\n        transcripts_to_delete = []\n        for count, transcript in enumerate(gene.sub_features):\n            if (\n                transcript.type not in allowed_transcript_types\n                and transcript.type not in ignored_transcript_types\n            ):\n                self.fail_types.add(f\"transcript={transcript.type}\")\n                logging.warning(\n                    f\"Unrecognized transcript type: {transcript.type}\" f\" for {transcript.id} ({gene.id})\"\n                )\n                transcripts_to_delete.append(count)\n                continue\n\n            # New transcript ID\n            transcript_number = count + 1\n            transcript.id = self.stable_ids.generate_transcript_id(gene.id, transcript_number)\n\n            transcript = self.format_gene_segments(transcript)\n\n            # EXONS AND CDS\n            transcript = self._normalize_transcript_subfeatures(gene, transcript)\n\n        if transcripts_to_delete:\n            for elt in sorted(transcripts_to_delete, reverse=True):\n                gene.sub_features.pop(elt)\n\n    def format_gene_segments(self, transcript: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Returns the equivalent Ensembl biotype feature for gene segment transcript features.\n\n        Supported features: \"C_gene_segment\" and \"V_gene_segment\".\n\n        Args:\n            transcript: Gene segment transcript feature.\n\n        Raises:\n            GeneSegmentError: Unable to get the segment type information from the feature.\n        \"\"\"\n        if transcript.type not in (\"C_gene_segment\", \"V_gene_segment\"):\n            return transcript\n\n        # Guess the segment type from the transcript attribs\n        seg_type = self._get_segment_type(transcript)\n        if not seg_type:\n            # Get the information from a CDS instead\n            sub_feats: List[GFFSeqFeature] = transcript.sub_features\n            cdss: List[GFFSeqFeature] = list(filter(lambda x: x.type == \"CDS\", sub_feats))\n            if cdss:\n                seg_type = self._get_segment_type(cdss[0])\n            if not seg_type:\n                raise GeneSegmentError(f\"Unable to infer segment from {transcript.id}\")\n\n        # Change V/C_gene_segment into a its corresponding transcript names\n        transcript.type = f\"{seg_type}_{transcript.type.replace('_segment', '')}\"\n        return transcript\n\n    def _get_segment_type(self, feature: GFFSeqFeature) -&gt; str:\n        \"\"\"Infer if a segment is \"IG\" (immunoglobulin) of \"TR\" (t-cell) from the feature attribs.\n\n        Returns an empty string if no segment type info was found.\n        \"\"\"\n\n        product = feature.qualifiers.get(\"standard_name\", [\"\"])[0]\n        if not product:\n            product = feature.qualifiers.get(\"product\", [\"\"])[0]\n        if not product:\n            return \"\"\n\n        if re.search(r\"\\b(immunoglobulin|ig)\\b\", product, flags=re.IGNORECASE):\n            return \"IG\"\n        if re.search(r\"\\bt[- _]cell\\b\", product, flags=re.IGNORECASE):\n            return \"TR\"\n        return \"\"\n\n    def _normalize_transcript_subfeatures(\n        self, gene: GFFSeqFeature, transcript: GFFSeqFeature\n    ) -&gt; GFFSeqFeature:\n        \"\"\"Returns a transcript with normalized sub-features.\"\"\"\n        exons_to_delete = []\n        exon_number = 1\n        for tcount, feat in enumerate(transcript.sub_features):\n            if feat.type == \"exon\":\n                # New exon ID\n                feat.id = f\"{transcript.id}-E{exon_number}\"\n                exon_number += 1\n                # Replace qualifiers\n                old_exon_qualifiers = feat.qualifiers\n                feat.qualifiers = {\"Parent\": transcript.id}\n                feat.qualifiers[\"source\"] = old_exon_qualifiers[\"source\"]\n            elif feat.type == \"CDS\":\n                # New CDS ID\n                feat.id = self.stable_ids.normalize_cds_id(feat.id)\n                if feat.id in (\"\", gene.id, transcript.id):\n                    feat.id = f\"{transcript.id}_cds\"\n            else:\n                if feat.type in self._biotypes[\"transcript\"][\"ignored\"]:\n                    exons_to_delete.append(tcount)\n                    continue\n\n                self.fail_types.add(f\"sub_transcript={feat.type}\")\n                logging.warning(\n                    f\"Unrecognized exon type for {feat.type}: {feat.id}\"\n                    f\" (for transcript {transcript.id} of type {transcript.type})\"\n                )\n                exons_to_delete.append(tcount)\n                continue\n\n        if exons_to_delete:\n            for elt in sorted(exons_to_delete, reverse=True):\n                transcript.sub_features.pop(elt)\n        return transcript\n\n    def normalize_mirna(self, gene: GFFSeqFeature) -&gt; List[GFFSeqFeature]:\n        \"\"\"Returns gene representations from a miRNA gene that can be loaded in an Ensembl database.\n\n        Change the representation from the form `gene[ primary_transcript[ exon, miRNA[ exon ] ] ]`\n        to `ncRNA_gene[ miRNA_primary_transcript[ exon ] ]` and `gene[ miRNA[ exon ] ]`\n\n        Raises:\n            GFFParserError: If gene has more than 1 transcript, the transcript was not formatted\n                correctly or there are unknown sub-features.\n        \"\"\"\n        base_id = gene.id\n        transcripts = gene.sub_features\n\n        # Insert main gene first if needed\n        old_gene = gene\n        if gene.type == \"primary_transcript\":\n            primary = old_gene\n            gene = GFFSeqFeature(primary.location, type=\"gene\")\n            gene.sub_features = [primary]\n            gene.qualifiers = primary.qualifiers\n            transcripts = gene.sub_features\n            gene.id = f\"{base_id}_0\"\n            gene.qualifiers[\"ID\"] = gene.id\n\n        if (len(transcripts) == 0) or (transcripts[0].type != \"primary_transcript\"):\n            return []\n        if len(transcripts) &gt; 1:\n            raise GFFParserError(f\"Gene has too many sub_features for miRNA {gene.id}\")\n\n        # Passed the checks\n        primary = transcripts[0]\n        primary.type = \"miRNA_primary_transcript\"\n        gene.type = \"ncRNA_gene\"\n        logging.debug(f\"Formatting miRNA gene {gene.id}\")\n\n        new_genes = []\n        new_primary_subfeatures = []\n        num = 1\n        for sub in primary.sub_features:\n            if sub.type == \"exon\":\n                new_primary_subfeatures.append(sub)\n            elif sub.type == \"miRNA\":\n                new_gene_id = f\"{base_id}_{num}\"\n                num += 1\n                new_gene = GFFSeqFeature(sub.location, type=\"gene\", id=new_gene_id)\n                new_gene.qualifiers = {\"source\": sub.qualifiers[\"source\"], \"ID\": new_gene_id}\n                new_gene.sub_features = [sub]\n                new_genes.append(new_gene)\n            else:\n                raise GFFParserError(f\"Unknown subtypes for miRNA features: {sub.id}\")\n        primary.sub_features = new_primary_subfeatures\n\n        if not new_genes:\n            logging.debug(f\"Primary_transcript without miRNA in {gene.id}\")\n            all_genes = [gene]\n        else:\n            all_genes = [gene] + new_genes\n\n        # Normalize like other genes\n        all_genes_cleaned = []\n        for new_gene in all_genes:\n            new_gene = self.normalize_gene(new_gene)\n            self.annotations.store_gene(new_gene)\n            all_genes_cleaned.append(self.clean_gene(new_gene))\n        return all_genes_cleaned\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.allow_pseudogene_with_cds","title":"<code>allow_pseudogene_with_cds = allow_pseudogene_with_cds</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.annotations","title":"<code>annotations = FunctionalAnnotations(self.get_provider_name())</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.exclude_seq_regions","title":"<code>exclude_seq_regions = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.fail_types","title":"<code>fail_types = set()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.genome","title":"<code>genome = json.load(genome_fh)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.records","title":"<code>records = Records()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.refseq","title":"<code>refseq = False</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.skip_unrecognized","title":"<code>skip_unrecognized = skip_unrecognized</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.stable_ids","title":"<code>stable_ids = StableIDAllocator()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.clean_gene","title":"<code>clean_gene(gene)</code>","text":"<p>Return the same gene without qualifiers unrelated to the gene structure.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def clean_gene(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Return the same gene without qualifiers unrelated to the gene structure.\"\"\"\n\n    old_gene_qualifiers = gene.qualifiers\n    gene.qualifiers = {\"ID\": gene.id, \"source\": old_gene_qualifiers[\"source\"]}\n    for transcript in gene.sub_features:\n        # Replace qualifiers\n        old_transcript_qualifiers = transcript.qualifiers\n        transcript.qualifiers = {\n            \"ID\": transcript.id,\n            \"Parent\": gene.id,\n            \"source\": old_transcript_qualifiers[\"source\"],\n        }\n\n        for feat in transcript.sub_features:\n            old_qualifiers = feat.qualifiers\n            feat.qualifiers = {\n                \"ID\": feat.id,\n                \"Parent\": transcript.id,\n                \"source\": old_qualifiers[\"source\"],\n            }\n            if feat.type == \"CDS\":\n                feat.qualifiers[\"phase\"] = old_qualifiers[\"phase\"]\n\n    return gene\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.create_gene_for_lone_cds","title":"<code>create_gene_for_lone_cds(feat)</code>","text":"<p>Returns a gene created for a lone CDS.</p> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>GFFSeqFeature</code> <p>The CDS for which we want to create a gene.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def create_gene_for_lone_cds(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Returns a gene created for a lone CDS.\n\n    Args:\n        feat: The CDS for which we want to create a gene.\n    \"\"\"\n    if feat.type != \"CDS\":\n        return feat\n\n    logging.debug(f\"Put the lone CDS in gene-mRNA parent features for {feat.id}\")\n\n    # Create a transcript, add the CDS\n    transcript = GFFSeqFeature(feat.location, type=\"mRNA\")\n    transcript.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n    transcript.sub_features = [feat]\n\n    # Add an exon too\n    exon = GFFSeqFeature(feat.location, type=\"exon\")\n    exon.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n    transcript.sub_features.append(exon)\n\n    # Create a gene, add the transcript\n    gene_type = \"gene\"\n    if (\"pseudo\" in feat.qualifiers) and (feat.qualifiers[\"pseudo\"][0] == \"true\"):\n        gene_type = \"pseudogene\"\n        del feat.qualifiers[\"pseudo\"]\n    new_gene = GFFSeqFeature(feat.location, type=gene_type)\n    new_gene.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n    new_gene.sub_features = [transcript]\n    new_gene.id = self.stable_ids.generate_gene_id()\n    new_gene.qualifiers[\"ID\"] = new_gene.id\n    transcript.id = self.stable_ids.generate_transcript_id(new_gene.id, 1)\n    transcript.qualifiers[\"ID\"] = transcript.id\n\n    return new_gene\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.create_gene_for_lone_transcript","title":"<code>create_gene_for_lone_transcript(feat)</code>","text":"<p>Returns a gene for lone transcripts: 'gene' for tRNA/rRNA/mRNA, and 'ncRNA_gene' for all others.</p> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>GFFSeqFeature</code> <p>The transcript for which we want to create a gene.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def create_gene_for_lone_transcript(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Returns a gene for lone transcripts: 'gene' for tRNA/rRNA/mRNA, and 'ncRNA_gene' for all others.\n\n    Args:\n        feat: The transcript for which we want to create a gene.\n    \"\"\"\n    transcript_types = self._biotypes[\"transcript\"][\"supported\"]\n    if feat.type not in transcript_types:\n        return feat\n\n    new_type = \"ncRNA_gene\"\n    if feat.type in (\"tRNA\", \"rRNA\", \"mRNA\"):\n        new_type = \"gene\"\n    logging.debug(f\"Put the transcript {feat.type} in a {new_type} parent feature\")\n    new_gene = GFFSeqFeature(feat.location, type=new_type)\n    new_gene.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n    new_gene.sub_features = [feat]\n\n    # Use the transcript ID for the gene, and generate a sub ID for the transcript\n    new_gene.id = feat.id\n    new_gene.qualifiers[\"ID\"] = new_gene.id\n    feat.id = self.stable_ids.generate_transcript_id(new_gene.id, 1)\n    feat.qualifiers[\"ID\"] = feat.id\n\n    # Remove the exon/CDS parent so it is properly updated\n    for subfeat in feat.sub_features:\n        del subfeat.qualifiers[\"Parent\"]\n\n    # Check if it's a pseudogene\n    if feat.type == \"mRNA\":\n        is_pseudo = False\n        for subfeat in feat.sub_features:\n            pseudo_qual = subfeat.qualifiers.get(\"pseudo\", [\"\"])[0]\n            if subfeat.type == \"CDS\" and pseudo_qual == \"true\":\n                is_pseudo = True\n                del subfeat.qualifiers[\"pseudo\"]\n                break\n        if is_pseudo:\n            new_gene.type = \"pseudogene\"\n\n    return new_gene\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.format_gene_segments","title":"<code>format_gene_segments(transcript)</code>","text":"<p>Returns the equivalent Ensembl biotype feature for gene segment transcript features.</p> <p>Supported features: \"C_gene_segment\" and \"V_gene_segment\".</p> <p>Parameters:</p> Name Type Description Default <code>transcript</code> <code>GFFSeqFeature</code> <p>Gene segment transcript feature.</p> required <p>Raises:</p> Type Description <code>GeneSegmentError</code> <p>Unable to get the segment type information from the feature.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def format_gene_segments(self, transcript: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Returns the equivalent Ensembl biotype feature for gene segment transcript features.\n\n    Supported features: \"C_gene_segment\" and \"V_gene_segment\".\n\n    Args:\n        transcript: Gene segment transcript feature.\n\n    Raises:\n        GeneSegmentError: Unable to get the segment type information from the feature.\n    \"\"\"\n    if transcript.type not in (\"C_gene_segment\", \"V_gene_segment\"):\n        return transcript\n\n    # Guess the segment type from the transcript attribs\n    seg_type = self._get_segment_type(transcript)\n    if not seg_type:\n        # Get the information from a CDS instead\n        sub_feats: List[GFFSeqFeature] = transcript.sub_features\n        cdss: List[GFFSeqFeature] = list(filter(lambda x: x.type == \"CDS\", sub_feats))\n        if cdss:\n            seg_type = self._get_segment_type(cdss[0])\n        if not seg_type:\n            raise GeneSegmentError(f\"Unable to infer segment from {transcript.id}\")\n\n    # Change V/C_gene_segment into a its corresponding transcript names\n    transcript.type = f\"{seg_type}_{transcript.type.replace('_segment', '')}\"\n    return transcript\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.get_provider_name","title":"<code>get_provider_name()</code>","text":"<p>Returns the provider name for this genome.</p> <p>If this information is not available, will try to infer it from the assembly accession. Will return \"GenBank\" otherwise.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def get_provider_name(self) -&gt; str:\n    \"\"\"Returns the provider name for this genome.\n\n    If this information is not available, will try to infer it from the assembly accession. Will\n    return \"GenBank\" otherwise.\n    \"\"\"\n    provider_name = \"GenBank\"\n    if self.genome:\n        try:\n            provider_name = self.genome[\"assembly\"][\"provider_name\"]\n        except KeyError:\n            if self.genome[\"assembly\"][\"accession\"].startswith(\"GCF\"):\n                provider_name = \"RefSeq\"\n    else:\n        logging.warning(f\"No genome file, using the default provider_name: {provider_name}\")\n    return provider_name\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.normalize_gene","title":"<code>normalize_gene(gene)</code>","text":"<p>Returns a normalized gene structure, separate from the functional elements.</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>GFFSeqFeature</code> <p>Gene object to normalize.</p> required <code>functional_annotation</code> <p>List of feature annotations (appended by this method).</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_gene(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Returns a normalized gene structure, separate from the functional elements.\n\n    Args:\n        gene: Gene object to normalize.\n        functional_annotation: List of feature annotations (appended by this method).\n\n    \"\"\"\n\n    gene.id = self.stable_ids.normalize_gene_id(gene, refseq=self.refseq)\n    restructure_gene(gene)\n    self.normalize_transcripts(gene)\n    self.normalize_pseudogene(gene)\n\n    return gene\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.normalize_mirna","title":"<code>normalize_mirna(gene)</code>","text":"<p>Returns gene representations from a miRNA gene that can be loaded in an Ensembl database.</p> <p>Change the representation from the form <code>gene[ primary_transcript[ exon, miRNA[ exon ] ] ]</code> to <code>ncRNA_gene[ miRNA_primary_transcript[ exon ] ]</code> and <code>gene[ miRNA[ exon ] ]</code></p> <p>Raises:</p> Type Description <code>GFFParserError</code> <p>If gene has more than 1 transcript, the transcript was not formatted correctly or there are unknown sub-features.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_mirna(self, gene: GFFSeqFeature) -&gt; List[GFFSeqFeature]:\n    \"\"\"Returns gene representations from a miRNA gene that can be loaded in an Ensembl database.\n\n    Change the representation from the form `gene[ primary_transcript[ exon, miRNA[ exon ] ] ]`\n    to `ncRNA_gene[ miRNA_primary_transcript[ exon ] ]` and `gene[ miRNA[ exon ] ]`\n\n    Raises:\n        GFFParserError: If gene has more than 1 transcript, the transcript was not formatted\n            correctly or there are unknown sub-features.\n    \"\"\"\n    base_id = gene.id\n    transcripts = gene.sub_features\n\n    # Insert main gene first if needed\n    old_gene = gene\n    if gene.type == \"primary_transcript\":\n        primary = old_gene\n        gene = GFFSeqFeature(primary.location, type=\"gene\")\n        gene.sub_features = [primary]\n        gene.qualifiers = primary.qualifiers\n        transcripts = gene.sub_features\n        gene.id = f\"{base_id}_0\"\n        gene.qualifiers[\"ID\"] = gene.id\n\n    if (len(transcripts) == 0) or (transcripts[0].type != \"primary_transcript\"):\n        return []\n    if len(transcripts) &gt; 1:\n        raise GFFParserError(f\"Gene has too many sub_features for miRNA {gene.id}\")\n\n    # Passed the checks\n    primary = transcripts[0]\n    primary.type = \"miRNA_primary_transcript\"\n    gene.type = \"ncRNA_gene\"\n    logging.debug(f\"Formatting miRNA gene {gene.id}\")\n\n    new_genes = []\n    new_primary_subfeatures = []\n    num = 1\n    for sub in primary.sub_features:\n        if sub.type == \"exon\":\n            new_primary_subfeatures.append(sub)\n        elif sub.type == \"miRNA\":\n            new_gene_id = f\"{base_id}_{num}\"\n            num += 1\n            new_gene = GFFSeqFeature(sub.location, type=\"gene\", id=new_gene_id)\n            new_gene.qualifiers = {\"source\": sub.qualifiers[\"source\"], \"ID\": new_gene_id}\n            new_gene.sub_features = [sub]\n            new_genes.append(new_gene)\n        else:\n            raise GFFParserError(f\"Unknown subtypes for miRNA features: {sub.id}\")\n    primary.sub_features = new_primary_subfeatures\n\n    if not new_genes:\n        logging.debug(f\"Primary_transcript without miRNA in {gene.id}\")\n        all_genes = [gene]\n    else:\n        all_genes = [gene] + new_genes\n\n    # Normalize like other genes\n    all_genes_cleaned = []\n    for new_gene in all_genes:\n        new_gene = self.normalize_gene(new_gene)\n        self.annotations.store_gene(new_gene)\n        all_genes_cleaned.append(self.clean_gene(new_gene))\n    return all_genes_cleaned\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.normalize_non_gene","title":"<code>normalize_non_gene(feat)</code>","text":"<p>Returns a normalised \"non-gene\" or <code>None</code> if not applicable.</p> <p>Only transposable elements supported at the moment.</p> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>GFFSeqFeature</code> <p>Feature to normalise.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the feature is a not supported non-gene.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_non_gene(self, feat: GFFSeqFeature) -&gt; Optional[GFFSeqFeature]:\n    \"\"\"Returns a normalised \"non-gene\" or `None` if not applicable.\n\n    Only transposable elements supported at the moment.\n\n    Args:\n        feat: Feature to normalise.\n\n    Raises:\n        NotImplementedError: If the feature is a not supported non-gene.\n    \"\"\"\n\n    if feat.type not in self._biotypes[\"non_gene\"][\"supported\"]:\n        return None\n    if feat.type in (\"mobile_genetic_element\", \"transposable_element\"):\n        feat.type = \"transposable_element\"\n        feat = self._normalize_mobile_genetic_element(feat)\n        # Generate ID if needed\n        feat.id = self.stable_ids.normalize_gene_id(feat, self.refseq)\n        feat.qualifiers[\"ID\"] = feat.id\n\n        self.annotations.add_feature(feat, \"transposable_element\")\n        return self.clean_gene(feat)\n    # This is a failsafe in case you add supported non-genes\n    raise NotImplementedError(f\"Unsupported non-gene: {feat.type} for {feat.id}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.normalize_pseudogene","title":"<code>normalize_pseudogene(gene)</code>","text":"<p>Normalize CDSs if allowed, otherwise remove them.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_pseudogene(self, gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Normalize CDSs if allowed, otherwise remove them.\"\"\"\n    if gene.type != \"pseudogene\":\n        return\n\n    if self.allow_pseudogene_with_cds:\n        self.stable_ids.normalize_pseudogene_cds_id(gene)\n    else:\n        remove_cds_from_pseudogene(gene)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.normalize_transcripts","title":"<code>normalize_transcripts(gene)</code>","text":"<p>Normalizes a transcript.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_transcripts(self, gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Normalizes a transcript.\"\"\"\n\n    allowed_transcript_types = self._biotypes[\"transcript\"][\"supported\"]\n    ignored_transcript_types = self._biotypes[\"transcript\"][\"ignored\"]\n\n    transcripts_to_delete = []\n    for count, transcript in enumerate(gene.sub_features):\n        if (\n            transcript.type not in allowed_transcript_types\n            and transcript.type not in ignored_transcript_types\n        ):\n            self.fail_types.add(f\"transcript={transcript.type}\")\n            logging.warning(\n                f\"Unrecognized transcript type: {transcript.type}\" f\" for {transcript.id} ({gene.id})\"\n            )\n            transcripts_to_delete.append(count)\n            continue\n\n        # New transcript ID\n        transcript_number = count + 1\n        transcript.id = self.stable_ids.generate_transcript_id(gene.id, transcript_number)\n\n        transcript = self.format_gene_segments(transcript)\n\n        # EXONS AND CDS\n        transcript = self._normalize_transcript_subfeatures(gene, transcript)\n\n    if transcripts_to_delete:\n        for elt in sorted(transcripts_to_delete, reverse=True):\n            gene.sub_features.pop(elt)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.simpler_gff3","title":"<code>simpler_gff3(in_gff_path)</code>","text":"<p>Loads a GFF3 from INSDC and rewrites it in a simpler version, whilst also writing a functional annotation file.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def simpler_gff3(self, in_gff_path: PathLike) -&gt; None:\n    \"\"\"Loads a GFF3 from INSDC and rewrites it in a simpler version, whilst also writing a\n    functional annotation file.\n    \"\"\"\n    self.records.from_gff(in_gff_path, self.exclude_seq_regions)\n    for record in self.records:\n        cleaned_features = []\n        for feature in record.features:\n            split_genes = self.normalize_mirna(feature)\n            if split_genes:\n                cleaned_features += split_genes\n            else:\n                try:\n                    clean_feature = self.simpler_gff3_feature(feature)\n                    cleaned_features.append(clean_feature)\n                except (UnsupportedFeatureError, IgnoredFeatureError) as err:\n                    logging.debug(err.message)\n        record.features = cleaned_features\n\n    if self.fail_types:\n        fail_errors = \"\\n   \".join(list(self.fail_types))\n        logging.warning(f\"Unrecognized types found:\\n   {fail_errors}\")\n        if not self.skip_unrecognized:\n            raise GFFParserError(\"Unrecognized types found, abort\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.GFFSimplifier.simpler_gff3_feature","title":"<code>simpler_gff3_feature(gene)</code>","text":"<p>Creates a simpler version of a GFF3 feature.</p> <p>Raises:</p> Type Description <code>IgnoredFeatureError</code> <p>If the feature type is ignored.</p> <code>UnsupportedFeatureError</code> <p>If the feature type is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def simpler_gff3_feature(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Creates a simpler version of a GFF3 feature.\n\n    Raises:\n        IgnoredFeatureError: If the feature type is ignored.\n        UnsupportedFeatureError: If the feature type is not supported.\n    \"\"\"\n    # Special cases\n    non_gene = self.normalize_non_gene(gene)\n    if non_gene:\n        return non_gene\n    if gene.type in self._biotypes[\"gene\"][\"ignored\"]:\n        raise IgnoredFeatureError(f\"Ignored type {gene.type} for {gene.id}\")\n\n    # Synonym\n    if gene.type == \"protein_coding_gene\":\n        gene.type = \"gene\"\n\n    # Lone sub-gene features, create a gene\n    gene = self.create_gene_for_lone_transcript(gene)\n    gene = self.create_gene_for_lone_cds(gene)\n\n    # What to do with unsupported gene types\n    if gene.type not in self._biotypes[\"gene\"][\"supported\"]:\n        self.fail_types.add(f\"gene={gene.type}\")\n        raise UnsupportedFeatureError(f\"Unsupported type {gene.type} for {gene.id}\")\n\n    # Normalize and store\n    gene = self.normalize_gene(gene)\n    self.annotations.store_gene(gene)\n    return self.clean_gene(gene)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.InvalidStableID","title":"<code>InvalidStableID</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when there is a problem with an stable ID.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>class InvalidStableID(ValueError):\n    \"\"\"Raised when there is a problem with an stable ID.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.MissingParentError","title":"<code>MissingParentError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Trying to add a feature without an expected parent.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>class MissingParentError(Exception):\n    \"\"\"Trying to add a feature without an expected parent.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.Records","title":"<code>Records</code>","text":"<p>               Bases: <code>list</code></p> <p>List of GFF3 SeqRecords.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>class Records(list):\n    \"\"\"List of GFF3 SeqRecords.\"\"\"\n\n    def from_gff(self, in_gff_path: PathLike, excluded: Optional[List[str]] = None) -&gt; None:\n        \"\"\"Loads records from a GFF3 file.\n\n        Args:\n            in_gff_path: Input GFF3 file path.\n            excluded: Record IDs to not load from the GFF3 file.\n        \"\"\"\n        if excluded is None:\n            excluded = []\n        with Path(in_gff_path).open(\"r\") as in_gff_fh:\n            for record in GFF.parse(in_gff_fh):\n                if record.id in excluded:\n                    logging.debug(f\"Skip seq_region {record.id} - in exclusion list\")\n                    continue\n                clean_record = SeqRecord(record.seq, id=record.id)\n                clean_record.features = record.features\n                self.append(clean_record)\n\n    def to_gff(self, out_gff_path: PathLike) -&gt; None:\n        \"\"\"Writes the current list of records in a GFF3 file.\n\n        Args:\n            out_gff_path: Path to GFF3 file where to write the records.\n        \"\"\"\n        with Path(out_gff_path).open(\"w\") as out_gff_fh:\n            GFF.write(self, out_gff_fh)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.Records.from_gff","title":"<code>from_gff(in_gff_path, excluded=None)</code>","text":"<p>Loads records from a GFF3 file.</p> <p>Parameters:</p> Name Type Description Default <code>in_gff_path</code> <code>PathLike</code> <p>Input GFF3 file path.</p> required <code>excluded</code> <code>Optional[List[str]]</code> <p>Record IDs to not load from the GFF3 file.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def from_gff(self, in_gff_path: PathLike, excluded: Optional[List[str]] = None) -&gt; None:\n    \"\"\"Loads records from a GFF3 file.\n\n    Args:\n        in_gff_path: Input GFF3 file path.\n        excluded: Record IDs to not load from the GFF3 file.\n    \"\"\"\n    if excluded is None:\n        excluded = []\n    with Path(in_gff_path).open(\"r\") as in_gff_fh:\n        for record in GFF.parse(in_gff_fh):\n            if record.id in excluded:\n                logging.debug(f\"Skip seq_region {record.id} - in exclusion list\")\n                continue\n            clean_record = SeqRecord(record.seq, id=record.id)\n            clean_record.features = record.features\n            self.append(clean_record)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.Records.to_gff","title":"<code>to_gff(out_gff_path)</code>","text":"<p>Writes the current list of records in a GFF3 file.</p> <p>Parameters:</p> Name Type Description Default <code>out_gff_path</code> <code>PathLike</code> <p>Path to GFF3 file where to write the records.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def to_gff(self, out_gff_path: PathLike) -&gt; None:\n    \"\"\"Writes the current list of records in a GFF3 file.\n\n    Args:\n        out_gff_path: Path to GFF3 file where to write the records.\n    \"\"\"\n    with Path(out_gff_path).open(\"w\") as out_gff_fh:\n        GFF.write(self, out_gff_fh)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator","title":"<code>StableIDAllocator</code>  <code>dataclass</code>","text":"<p>Set of tools to check and allocate stable IDs.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>@dataclass\nclass StableIDAllocator:\n    \"\"\"Set of tools to check and allocate stable IDs.\"\"\"\n\n    # Multiple parameters to automate various fixes\n    skip_gene_id_validation: bool = False\n    min_id_length: int = 7\n    current_id_number: int = 0\n    make_missing_stable_ids: bool = True\n    prefix: str = \"TMP_\"\n    _loaded_ids: Set = field(default_factory=set)\n\n    def set_prefix(self, genome: Dict) -&gt; None:\n        \"\"\"Sets the ID prefix using the organism abbrev if it exists in the genome metadata.\"\"\"\n        try:\n            org = genome[\"BRC4\"][\"organism_abbrev\"]\n        except KeyError:\n            prefix = \"TMP_PREFIX_\"\n        else:\n            prefix = \"TMP_\" + org + \"_\"\n        self.prefix = prefix\n\n    def generate_gene_id(self) -&gt; str:\n        \"\"\"Returns a new unique gene stable_id with a prefix.\n\n        The ID is made up of a prefix and a number, which is auto incremented.\n\n        \"\"\"\n        self.current_id_number += 1\n        new_id = f\"{self.prefix}{self.current_id_number}\"\n        return new_id\n\n    def is_valid(self, stable_id: str) -&gt; bool:\n        \"\"\"Checks that the format of a stable ID is valid.\n        Args:\n            stable_id: Stable ID to validate.\n        \"\"\"\n\n        if self.skip_gene_id_validation:\n            logging.debug(f\"Validation deactivated by user: '{stable_id}' not checked\")\n            return True\n\n        # Trna (from tRNAscan)\n        if re.search(r\"^Trna\", stable_id, re.IGNORECASE):\n            logging.debug(f\"Stable ID is a tRNA from tRNA-scan: {stable_id}\")\n            return False\n\n        # Coordinates\n        if re.search(r\"^.+:\\d+..\\d+\", stable_id):\n            logging.debug(f\"Stable id is a coordinate: {stable_id}\")\n            return False\n\n        # Special characters\n        if re.search(r\"[ |]\", stable_id):\n            logging.debug(f\"Stable id contains special characters: {stable_id}\")\n            return False\n\n        # Min length\n        if len(stable_id) &lt; self.min_id_length:\n            logging.debug(f\"Stable id is too short (&lt;{self.min_id_length}) {stable_id}\")\n            return False\n\n        return True\n\n    @staticmethod\n    def remove_prefix(stable_id: str, prefixes: List[str]) -&gt; str:\n        \"\"\"Returns the stable ID after removing its prefix (if any).\n\n        If more than one prefix may be found, only the first one is removed.\n\n        Args:\n            stable_id: Stable ID to process.\n            prefixes: List of prefixes to search for.\n        \"\"\"\n\n        for prefix in prefixes:\n            if stable_id.startswith(prefix):\n                return stable_id[len(prefix) :]\n        return stable_id\n\n    @staticmethod\n    def generate_transcript_id(gene_id: str, number: int) -&gt; str:\n        \"\"\"Returns a formatted transcript ID generated from a gene ID and number.\n        Args:\n            gene_id: Gene stable ID.\n            number: Positive number.\n        Raises:\n            ValueError: If the number provided is not greater than zero.\n\n        \"\"\"\n        if number &lt; 1:\n            raise ValueError(\"Number has to be a positive integer.\")\n\n        transcript_id = f\"{gene_id}_t{number}\"\n        return transcript_id\n\n    def normalize_cds_id(self, cds_id: str) -&gt; str:\n        \"\"\"Returns a normalized version of the provided CDS ID.\n\n        The normalisation implies to remove any unnecessary prefixes around the CDS ID. However, if\n        the CDS ID is still not proper, an empty string will be returned.\n\n        Args:\n            cds_id: CDS ID to normalize.\n\n        \"\"\"\n\n        prefixes = [\"cds-\", \"cds:\"]\n        normalized_cds_id = StableIDAllocator.remove_prefix(cds_id, prefixes)\n\n        # Special case: if the ID doesn't look like one, remove it - it needs to be regenerated\n        if not self.is_valid(normalized_cds_id):\n            return \"\"\n        return normalized_cds_id\n\n    def normalize_pseudogene_cds_id(self, pseudogene: GFFSeqFeature) -&gt; None:\n        \"\"\"Normalizes every CDS ID of the provided pseudogene.\n\n        Ensure each CDS from a pseudogene has a proper ID:\n        - Different from the gene\n        - Derived from the gene if it is not proper\n\n        Args:\n            pseudogene: Pseudogene feature.\n        \"\"\"\n        for transcript in pseudogene.sub_features:\n            for feat in transcript.sub_features:\n                if feat.type == \"CDS\":\n                    feat.id = self.normalize_cds_id(feat.id)\n                    if feat.id in (\"\", pseudogene.id):\n                        feat.id = f\"{transcript.id}_cds\"\n                        feat.qualifiers[\"ID\"] = feat.id\n\n    def normalize_gene_id(self, gene: GFFSeqFeature, refseq: Optional[bool] = False) -&gt; str:\n        \"\"\"Returns a normalized gene stable ID.\n\n        Removes any unnecessary prefixes, but will generate a new stable ID if the normalized one is\n        not recognized as valid.\n\n        Args:\n            gene: Gene feature to normalize.\n        \"\"\"\n        prefixes = [\"gene-\", \"gene:\"]\n        new_gene_id = StableIDAllocator.remove_prefix(gene.id, prefixes)\n\n        is_valid = False\n        # Special case for RefSeq: only valid Gene IDs are LOC*\n        if refseq:\n            if new_gene_id.startswith(\"LOC\"):\n                is_valid = True\n        else:\n            is_valid = self.is_valid(new_gene_id)\n\n        if is_valid:\n            return new_gene_id\n\n        # In case the normalized gene ID is not valid, use the GeneID\n        logging.debug(f\"Gene ID is not valid: {new_gene_id}\")\n        qual = gene.qualifiers\n        if \"Dbxref\" in qual:\n            for xref in qual[\"Dbxref\"]:\n                (db, value) = xref.split(\":\")\n                if db != \"GeneID\":\n                    continue\n                new_gene_id_base = f\"{db}_{value}\"\n                new_gene_id = new_gene_id_base\n                number = 1\n                while new_gene_id in self._loaded_ids:\n                    number += 1\n                    new_gene_id = f\"{new_gene_id_base}_{number}\"\n                    if number &gt; 10:\n                        raise InvalidStableID(f\"Duplicate ID {new_gene_id_base} (up to {new_gene_id})\")\n                self._loaded_ids.add(new_gene_id)\n                logging.debug(f\"Using GeneID {new_gene_id} for stable_id instead of {gene.id}\")\n                return new_gene_id\n\n        # Make a new stable_id\n        if self.make_missing_stable_ids:\n            new_gene_id = self.generate_gene_id()\n            logging.debug(f\"New ID: {new_gene_id} -&gt; {new_gene_id}\")\n            return new_gene_id\n        raise InvalidStableID(f\"Can't use invalid gene id for {gene}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.current_id_number","title":"<code>current_id_number = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.make_missing_stable_ids","title":"<code>make_missing_stable_ids = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.min_id_length","title":"<code>min_id_length = 7</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.prefix","title":"<code>prefix = 'TMP_'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.skip_gene_id_validation","title":"<code>skip_gene_id_validation = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.generate_gene_id","title":"<code>generate_gene_id()</code>","text":"<p>Returns a new unique gene stable_id with a prefix.</p> <p>The ID is made up of a prefix and a number, which is auto incremented.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def generate_gene_id(self) -&gt; str:\n    \"\"\"Returns a new unique gene stable_id with a prefix.\n\n    The ID is made up of a prefix and a number, which is auto incremented.\n\n    \"\"\"\n    self.current_id_number += 1\n    new_id = f\"{self.prefix}{self.current_id_number}\"\n    return new_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.generate_transcript_id","title":"<code>generate_transcript_id(gene_id, number)</code>  <code>staticmethod</code>","text":"<p>Returns a formatted transcript ID generated from a gene ID and number. Args:     gene_id: Gene stable ID.     number: Positive number. Raises:     ValueError: If the number provided is not greater than zero.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>@staticmethod\ndef generate_transcript_id(gene_id: str, number: int) -&gt; str:\n    \"\"\"Returns a formatted transcript ID generated from a gene ID and number.\n    Args:\n        gene_id: Gene stable ID.\n        number: Positive number.\n    Raises:\n        ValueError: If the number provided is not greater than zero.\n\n    \"\"\"\n    if number &lt; 1:\n        raise ValueError(\"Number has to be a positive integer.\")\n\n    transcript_id = f\"{gene_id}_t{number}\"\n    return transcript_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.is_valid","title":"<code>is_valid(stable_id)</code>","text":"<p>Checks that the format of a stable ID is valid. Args:     stable_id: Stable ID to validate.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def is_valid(self, stable_id: str) -&gt; bool:\n    \"\"\"Checks that the format of a stable ID is valid.\n    Args:\n        stable_id: Stable ID to validate.\n    \"\"\"\n\n    if self.skip_gene_id_validation:\n        logging.debug(f\"Validation deactivated by user: '{stable_id}' not checked\")\n        return True\n\n    # Trna (from tRNAscan)\n    if re.search(r\"^Trna\", stable_id, re.IGNORECASE):\n        logging.debug(f\"Stable ID is a tRNA from tRNA-scan: {stable_id}\")\n        return False\n\n    # Coordinates\n    if re.search(r\"^.+:\\d+..\\d+\", stable_id):\n        logging.debug(f\"Stable id is a coordinate: {stable_id}\")\n        return False\n\n    # Special characters\n    if re.search(r\"[ |]\", stable_id):\n        logging.debug(f\"Stable id contains special characters: {stable_id}\")\n        return False\n\n    # Min length\n    if len(stable_id) &lt; self.min_id_length:\n        logging.debug(f\"Stable id is too short (&lt;{self.min_id_length}) {stable_id}\")\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.normalize_cds_id","title":"<code>normalize_cds_id(cds_id)</code>","text":"<p>Returns a normalized version of the provided CDS ID.</p> <p>The normalisation implies to remove any unnecessary prefixes around the CDS ID. However, if the CDS ID is still not proper, an empty string will be returned.</p> <p>Parameters:</p> Name Type Description Default <code>cds_id</code> <code>str</code> <p>CDS ID to normalize.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def normalize_cds_id(self, cds_id: str) -&gt; str:\n    \"\"\"Returns a normalized version of the provided CDS ID.\n\n    The normalisation implies to remove any unnecessary prefixes around the CDS ID. However, if\n    the CDS ID is still not proper, an empty string will be returned.\n\n    Args:\n        cds_id: CDS ID to normalize.\n\n    \"\"\"\n\n    prefixes = [\"cds-\", \"cds:\"]\n    normalized_cds_id = StableIDAllocator.remove_prefix(cds_id, prefixes)\n\n    # Special case: if the ID doesn't look like one, remove it - it needs to be regenerated\n    if not self.is_valid(normalized_cds_id):\n        return \"\"\n    return normalized_cds_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.normalize_gene_id","title":"<code>normalize_gene_id(gene, refseq=False)</code>","text":"<p>Returns a normalized gene stable ID.</p> <p>Removes any unnecessary prefixes, but will generate a new stable ID if the normalized one is not recognized as valid.</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>GFFSeqFeature</code> <p>Gene feature to normalize.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def normalize_gene_id(self, gene: GFFSeqFeature, refseq: Optional[bool] = False) -&gt; str:\n    \"\"\"Returns a normalized gene stable ID.\n\n    Removes any unnecessary prefixes, but will generate a new stable ID if the normalized one is\n    not recognized as valid.\n\n    Args:\n        gene: Gene feature to normalize.\n    \"\"\"\n    prefixes = [\"gene-\", \"gene:\"]\n    new_gene_id = StableIDAllocator.remove_prefix(gene.id, prefixes)\n\n    is_valid = False\n    # Special case for RefSeq: only valid Gene IDs are LOC*\n    if refseq:\n        if new_gene_id.startswith(\"LOC\"):\n            is_valid = True\n    else:\n        is_valid = self.is_valid(new_gene_id)\n\n    if is_valid:\n        return new_gene_id\n\n    # In case the normalized gene ID is not valid, use the GeneID\n    logging.debug(f\"Gene ID is not valid: {new_gene_id}\")\n    qual = gene.qualifiers\n    if \"Dbxref\" in qual:\n        for xref in qual[\"Dbxref\"]:\n            (db, value) = xref.split(\":\")\n            if db != \"GeneID\":\n                continue\n            new_gene_id_base = f\"{db}_{value}\"\n            new_gene_id = new_gene_id_base\n            number = 1\n            while new_gene_id in self._loaded_ids:\n                number += 1\n                new_gene_id = f\"{new_gene_id_base}_{number}\"\n                if number &gt; 10:\n                    raise InvalidStableID(f\"Duplicate ID {new_gene_id_base} (up to {new_gene_id})\")\n            self._loaded_ids.add(new_gene_id)\n            logging.debug(f\"Using GeneID {new_gene_id} for stable_id instead of {gene.id}\")\n            return new_gene_id\n\n    # Make a new stable_id\n    if self.make_missing_stable_ids:\n        new_gene_id = self.generate_gene_id()\n        logging.debug(f\"New ID: {new_gene_id} -&gt; {new_gene_id}\")\n        return new_gene_id\n    raise InvalidStableID(f\"Can't use invalid gene id for {gene}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.normalize_pseudogene_cds_id","title":"<code>normalize_pseudogene_cds_id(pseudogene)</code>","text":"<p>Normalizes every CDS ID of the provided pseudogene.</p> <p>Ensure each CDS from a pseudogene has a proper ID: - Different from the gene - Derived from the gene if it is not proper</p> <p>Parameters:</p> Name Type Description Default <code>pseudogene</code> <code>GFFSeqFeature</code> <p>Pseudogene feature.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def normalize_pseudogene_cds_id(self, pseudogene: GFFSeqFeature) -&gt; None:\n    \"\"\"Normalizes every CDS ID of the provided pseudogene.\n\n    Ensure each CDS from a pseudogene has a proper ID:\n    - Different from the gene\n    - Derived from the gene if it is not proper\n\n    Args:\n        pseudogene: Pseudogene feature.\n    \"\"\"\n    for transcript in pseudogene.sub_features:\n        for feat in transcript.sub_features:\n            if feat.type == \"CDS\":\n                feat.id = self.normalize_cds_id(feat.id)\n                if feat.id in (\"\", pseudogene.id):\n                    feat.id = f\"{transcript.id}_cds\"\n                    feat.qualifiers[\"ID\"] = feat.id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.remove_prefix","title":"<code>remove_prefix(stable_id, prefixes)</code>  <code>staticmethod</code>","text":"<p>Returns the stable ID after removing its prefix (if any).</p> <p>If more than one prefix may be found, only the first one is removed.</p> <p>Parameters:</p> Name Type Description Default <code>stable_id</code> <code>str</code> <p>Stable ID to process.</p> required <code>prefixes</code> <code>List[str]</code> <p>List of prefixes to search for.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>@staticmethod\ndef remove_prefix(stable_id: str, prefixes: List[str]) -&gt; str:\n    \"\"\"Returns the stable ID after removing its prefix (if any).\n\n    If more than one prefix may be found, only the first one is removed.\n\n    Args:\n        stable_id: Stable ID to process.\n        prefixes: List of prefixes to search for.\n    \"\"\"\n\n    for prefix in prefixes:\n        if stable_id.startswith(prefix):\n            return stable_id[len(prefix) :]\n    return stable_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.StableIDAllocator.set_prefix","title":"<code>set_prefix(genome)</code>","text":"<p>Sets the ID prefix using the organism abbrev if it exists in the genome metadata.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def set_prefix(self, genome: Dict) -&gt; None:\n    \"\"\"Sets the ID prefix using the organism abbrev if it exists in the genome metadata.\"\"\"\n    try:\n        org = genome[\"BRC4\"][\"organism_abbrev\"]\n    except KeyError:\n        prefix = \"TMP_PREFIX_\"\n    else:\n        prefix = \"TMP_\" + org + \"_\"\n    self.prefix = prefix\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.get_intervals","title":"<code>get_intervals(record, genes_dict, seq_dict, seq_name)</code>","text":"<p>Extract start/stop feature coordinates for use in creating intervaltree object.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>SeqRecord</code> <p>Individual sequence record.</p> required <code>genes_dict</code> <code>dict</code> <p>Genes.</p> required <code>seq_dict</code> <code>dict</code> <p>Sequences.</p> required <code>seq_name</code> <code>str</code> <p>Feature sequence name.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def get_intervals(record: SeqRecord, genes_dict: dict, seq_dict: dict, seq_name: str) -&gt; None:\n    \"\"\"Extract start/stop feature coordinates for use in creating intervaltree object.\n\n    Args:\n        record: Individual sequence record.\n        genes_dict: Genes.\n        seq_dict: Sequences.\n        seq_name: Feature sequence name.\n    \"\"\"\n\n    for feature in record.features:\n        genes_dict[str(feature.id)] = {\n            \"sequence\": f\"{record.id}\",\n            \"start\": f\"{int(feature.location.start) + 1}\",\n            \"end\": f\"{int(feature.location.end)}\",\n            \"strand\": f\"{feature.location.strand}\",\n            \"name\": f\"{feature.id}\",\n        }\n\n        if feature.location.strand == 1:\n            seq_dict[seq_name][\"plus\"].append(\n                (int(feature.location.start), int(feature.location.end), str(feature.id))\n            )\n        elif feature.location.strand == -1:\n            seq_dict[seq_name][\"minus\"].append(\n                (int(feature.location.start), int(feature.location.end), str(feature.id))\n            )\n        else:\n            logging.critical(\"Something went wrong with the strand processing!\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.identify_feature_overlaps","title":"<code>identify_feature_overlaps(gff_in, output_file, isolate_feature)</code>","text":"<p>Detect overlapping GFF3 SeqFeature objects and dump to a report.</p> <p>Parameters:</p> Name Type Description Default <code>gff_in</code> <code>Path</code> <p>User supplied GFF3 input file.</p> required <code>output_file</code> <code>Path</code> <p>Output file to write feature overlaps.</p> required <code>isolate_feature</code> <code>str</code> <p>Sequence feature type to filter by.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def identify_feature_overlaps(gff_in: Path, output_file: Path, isolate_feature: str) -&gt; None:\n    \"\"\"Detect overlapping GFF3 SeqFeature objects and dump to a report.\n\n    Args:\n        gff_in: User supplied GFF3 input file.\n        output_file: Output file to write feature overlaps.\n        isolate_feature: Sequence feature type to filter by.\n    \"\"\"\n    logging.info(\"Processing sequence feature overlaps!\")\n    logging.info(f\"Output file = {str(output_file)}\")\n    logging.info(f\"Features filtered by type: {isolate_feature}\")\n\n    gff_type_filter: dict = {\"gff_type\": [isolate_feature]}\n    seq_dict: dict = defaultdict(dict)\n    genes_dict: dict = {}\n    with gff_in.open(\"r\", encoding=\"utf-8\") as input_handle:\n        for record in GFF.parse(input_handle, limit_info=gff_type_filter):\n            seq_name = str(record.id)\n            if seq_name not in seq_dict:\n                seq_dict[seq_name][\"plus\"] = []\n                seq_dict[seq_name][\"minus\"] = []\n\n            get_intervals(record, genes_dict, seq_dict, seq_name)\n\n    overlap_count = _write_report(output_file, seq_dict, genes_dict)\n\n    result_total_features = f\"In total {len(genes_dict)} {isolate_feature} features were scanned.\"\n    print(result_total_features)\n    logging.info(result_total_features)\n\n    result_total_overlaps = f\"In total {overlap_count} overlaps were detected.\"\n    print(result_total_overlaps)\n    logging.info(result_total_overlaps)\n\n    logging.info(\"Finished all processing.\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.init_logging_with_args","title":"<code>init_logging_with_args(args)</code>","text":"<p>Processes the Namespace object provided to call <code>init_logging()</code> with the correct arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Namespace populated by an argument parser.</p> required Source code in <code>ensembl/utils/logging.py</code> <pre><code>def init_logging_with_args(args: argparse.Namespace) -&gt; None:\n    \"\"\"Processes the Namespace object provided to call `init_logging()` with the correct arguments.\n\n    Args:\n        args: Namespace populated by an argument parser.\n\n    \"\"\"\n    args_dict = vars(args)\n    log_args = {x: args_dict[x] for x in [\"log_level\", \"log_file\", \"log_file_level\"] if x in args_dict}\n    init_logging(**log_args)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/process.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(\n        description=(\n            \"Standardize the gene model representation of a GFF3 file, and extract the functional \"\n            \"annotation in a separate file.\"\n        )\n    )\n    parser.add_argument_src_path(\"--in_gff_path\", required=True, help=\"Input GFF3 file\")\n    parser.add_argument_src_path(\"--genome_data\", required=True, help=\"Genome JSON file\")\n    parser.add_argument(\n        \"--fail_missing_stable_ids\", action=\"store_true\", help=\"Do not generate IDs when missing/invalid\"\n    )\n    parser.add_argument_dst_path(\"--out_gff_path\", default=Path(\"gene_models.gff3\"), help=\"Output GFF3 file\")\n    parser.add_argument_dst_path(\n        \"--out_func_path\",\n        default=Path(\"functional_annotation.json\"),\n        help=\"Output functional annotation JSON file\",\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    # Merge multiline gene features in a separate file\n    logging.info(\"Checking for genes to merge...\")\n    interim_gff_path = Path(f\"{args.in_gff_path}_INTERIM_MERGE\")\n    merger = GFFGeneMerger()\n    merged_genes = merger.merge(args.in_gff_path, interim_gff_path)\n    num_merged_genes = len(merged_genes)\n    in_gff_path = args.in_gff_path\n    # If there are split genes, decide to merge, or just die\n    if num_merged_genes &gt; 0:\n        # Report the list of merged genes in case something does not look right\n        logging.info(f\"{num_merged_genes} genes merged\")\n        logging.debug(\"\\n\".join(merged_genes))\n        # Use the GFF with the merged genes for the next part\n        in_gff_path = interim_gff_path\n\n    # Load GFF3 data and write a simpler version that follows our specifications as well as a\n    # functional annotation JSON file\n    logging.info(\"Simplify and fix GFF3\")\n    gff_data = GFFSimplifier(args.genome_data)\n    if args.fail_missing_stable_ids:\n        gff_data.stable_ids.make_missing_stable_ids = False\n    gff_data.simpler_gff3(in_gff_path)\n    gff_data.records.to_gff(args.out_gff_path)\n    gff_data.annotations.to_json(args.out_func_path)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.scan_tree","title":"<code>scan_tree(feature_intervals)</code>","text":"<p>Construct an interval tree using supplied genomic intervals, check all elements on the tree against itself and return any that hit 2 or more intervals (i.e. itself + 1 other)</p> <p>Parameters:</p> Name Type Description Default <code>feature_intervals</code> <code>list</code> <p>Genome features to examine for coordinate (start/end) overlaps.</p> required Return <p>Set of intervals identified in the input GFF3 file that overlap with 2 or more intervals.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def scan_tree(feature_intervals: list) -&gt; set:\n    \"\"\"Construct an interval tree using supplied genomic intervals, check all elements on the tree against\n    itself and return any that hit 2 or more intervals (i.e. itself + 1 other)\n\n    Args:\n        feature_intervals: Genome features to examine for coordinate (start/end) overlaps.\n\n    Return:\n        Set of intervals identified in the input GFF3 file that overlap with 2 or more intervals.\n    \"\"\"\n\n    interval_sets = set()\n    traversed_tree = IntervalTree(Interval(*iv) for iv in feature_intervals)\n\n    for interval in feature_intervals:\n        if len(traversed_tree.overlap(interval[0], interval[1])) &gt; 1:\n            overlap_interval = traversed_tree.overlap(interval[0], interval[1])\n\n            for features in overlap_interval:\n                interval_sets.add(features.data)\n\n    return interval_sets\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/#ensembl.io.genomio.gff3.summarize_feature_stats","title":"<code>summarize_feature_stats(gff_in)</code>","text":"<p>Analyse a GFF3 file and produce a summary of its feature types.</p> <p>Parameters:</p> Name Type Description Default <code>gff_in</code> <code>Path</code> <p>User supplied GFF3 input file.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def summarize_feature_stats(gff_in: Path) -&gt; None:\n    \"\"\"Analyse a GFF3 file and produce a summary of its feature types.\n\n    Args:\n        gff_in: User supplied GFF3 input file.\n    \"\"\"\n\n    logging.info(\"Alt processing: Not parsing the GFF3, producing summary feature stats instead!\")\n\n    examiner = GFFExaminer()\n    with gff_in.open(\"r\", encoding=\"utf-8\") as input_handle:\n        pprint(examiner.available_limits(input_handle))\n    input_handle.close()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/exceptions/","title":"exceptions","text":""},{"location":"reference/ensembl/io/genomio/gff3/exceptions/#ensembl.io.genomio.gff3.exceptions","title":"<code>ensembl.io.genomio.gff3.exceptions</code>","text":"<p>GFF parsing exceptions.</p>"},{"location":"reference/ensembl/io/genomio/gff3/exceptions/#ensembl.io.genomio.gff3.exceptions.GFFParserError","title":"<code>GFFParserError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error when parsing a GFF3 file.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/exceptions.py</code> <pre><code>class GFFParserError(Exception):\n    \"\"\"Error when parsing a GFF3 file.\"\"\"\n\n    def __init__(self, message: str) -&gt; None:\n        super().__init__(message)\n        self.message = message\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/exceptions/#ensembl.io.genomio.gff3.exceptions.GFFParserError.message","title":"<code>message = message</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/exceptions/#ensembl.io.genomio.gff3.exceptions.GeneSegmentError","title":"<code>GeneSegmentError</code>","text":"<p>               Bases: <code>GFFParserError</code></p> <p>GFF3 gene segment parsing error.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/exceptions.py</code> <pre><code>class GeneSegmentError(GFFParserError):\n    \"\"\"GFF3 gene segment parsing error.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/exceptions/#ensembl.io.genomio.gff3.exceptions.IgnoredFeatureError","title":"<code>IgnoredFeatureError</code>","text":"<p>               Bases: <code>GFFParserError</code></p> <p>GFF3 feature can be ignored.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/exceptions.py</code> <pre><code>class IgnoredFeatureError(GFFParserError):\n    \"\"\"GFF3 feature can be ignored.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/exceptions/#ensembl.io.genomio.gff3.exceptions.UnsupportedFeatureError","title":"<code>UnsupportedFeatureError</code>","text":"<p>               Bases: <code>GFFParserError</code></p> <p>GFF3 feature is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/exceptions.py</code> <pre><code>class UnsupportedFeatureError(GFFParserError):\n    \"\"\"GFF3 feature is not supported.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/","title":"extract_annotation","text":""},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation","title":"<code>ensembl.io.genomio.gff3.extract_annotation</code>","text":"<p>Simple representation of gene features functional annotation extracted from a GFF3 file.</p>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.Annotation","title":"<code>Annotation = Dict[str, Any]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.AnnotationError","title":"<code>AnnotationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>If anything wrong happens when recording annotations.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>class AnnotationError(Exception):\n    \"\"\"If anything wrong happens when recording annotations.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.DuplicateIdError","title":"<code>DuplicateIdError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Trying to add a feature with an ID already in use.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>class DuplicateIdError(Exception):\n    \"\"\"Trying to add a feature with an ID already in use.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations","title":"<code>FunctionalAnnotations</code>","text":"<p>List of annotations extracted from a GFF3 file.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>class FunctionalAnnotations:\n    \"\"\"List of annotations extracted from a GFF3 file.\"\"\"\n\n    ignored_xrefs = {\"go\", \"interpro\", \"uniprot\"}\n\n    def __init__(self, provider_name: str = \"\") -&gt; None:\n        self.annotations: List[Annotation] = []\n        self.provider_name = provider_name\n        # Annotated features\n        # Under each feature, each dict's key is a feature ID\n        self.features: Dict[str, Dict[str, Annotation]] = {\n            \"gene\": {},\n            \"transcript\": {},\n            \"translation\": {},\n            \"transposable_element\": {},\n        }\n        # Keep parent info: key is the feature ID, value is the parent ID\n        self.parents: Dict[str, Dict[str, str]] = {\n            \"gene\": {},\n            \"transcript\": {},\n        }\n\n    def get_xrefs(self, feature: GFFSeqFeature) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get the xrefs from the Dbxref field.\"\"\"\n        all_xref: List[Dict[str, str]] = []\n\n        if \"Dbxref\" in feature.qualifiers:\n            for xref in feature.qualifiers[\"Dbxref\"]:\n                dbname, name = xref.split(\":\", maxsplit=1)\n                if dbname == \"GenBank\" and self.provider_name == \"RefSeq\":\n                    dbname = \"RefSeq\"\n\n                if dbname.lower() in self.ignored_xrefs:\n                    continue\n\n                xrefs = {\"dbname\": dbname, \"id\": name}\n                all_xref.append(xrefs)\n\n        # Add RefSeq ID xref if it looks like one\n        if self.provider_name == \"RefSeq\":\n            if feature.type == \"gene\" and feature.id.startswith(\"LOC\"):\n                xref_dbs = {x[\"dbname\"] for x in all_xref}\n                if \"RefSeq\" not in xref_dbs:\n                    all_xref.append({\"dbname\": \"RefSeq\", \"id\": feature.id})\n\n        return all_xref\n\n    def get_features(self, feat_type: str) -&gt; Dict[str, Annotation]:\n        \"\"\"Get all feature annotations for the requested type.\"\"\"\n        try:\n            return self.features[feat_type]\n        except KeyError as err:\n            raise KeyError(f\"No such feature type {feat_type}\") from err\n\n    def add_parent_link(self, parent_type: str, parent_id: str, child_id: str) -&gt; None:\n        \"\"\"Record a parent-child IDs relationship for a given parent biotype.\"\"\"\n        features = self.get_features(parent_type)\n        if parent_id not in features:\n            raise MissingParentError(f\"Parent {parent_type}:{parent_id} not found for {child_id}\")\n        self.parents[parent_type][child_id] = parent_id\n\n    def get_parent(self, parent_type: str, child_id: str) -&gt; str:\n        \"\"\"Returns the parent ID of a given child for a given parent biotype.\"\"\"\n        try:\n            parents = self.parents[parent_type]\n        except KeyError as err:\n            raise KeyError(f\"Unsupported parent type {parent_type}\") from err\n\n        parent_id = parents.get(child_id)\n        if parent_id is None:\n            raise MissingParentError(f\"Can't find {parent_type} parent for {child_id}\")\n        return parent_id\n\n    def add_feature(\n        self,\n        feature: GFFSeqFeature,\n        feat_type: str,\n        parent_id: Optional[str] = None,\n        all_parent_ids: Optional[List[str]] = None,\n    ) -&gt; None:\n        \"\"\"Add annotation for a feature of a given type. If a parent_id is provided, record the relationship.\n\n        Args:\n            feature: The feature to create an annotation.\n            feat_type: Type of the feature to annotate.\n            parent_id: Parent ID of this feature to keep it linked.\n            all_parent_ids: All parent IDs to remove from non-informative descriptions.\n        \"\"\"\n        if all_parent_ids is None:\n            all_parent_ids = []\n        features = self.get_features(feat_type)\n        if feature.id in features:\n            raise AnnotationError(f\"Feature {feat_type} ID {feature.id} already added\")\n\n        feature_object = self._generic_feature(feature, feat_type, all_parent_ids)\n        self.features[feat_type][feature.id] = feature_object\n\n        if parent_id:\n            if feat_type in _PARENTS:\n                parent_type = _PARENTS[feat_type]\n                self.add_parent_link(parent_type, parent_id, feature.id)\n            else:\n                raise AnnotationError(f\"No parent possible for {feat_type} {feature.id}\")\n\n    def _generic_feature(\n        self, feature: GFFSeqFeature, feat_type: str, parent_ids: Optional[List[str]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create a feature object following the specifications.\n\n        Args:\n            feature: The GFFSeqFeature to add to the list.\n            feat_type: Feature type of the feature to store (e.g. gene, transcript, translation).\n            all_parent_ids: All parent IDs to remove from non-informative descriptions.\n\n        \"\"\"\n        if parent_ids is None:\n            parent_ids = []\n\n        feature_object: Annotation = {\"object_type\": feat_type, \"id\": feature.id}\n\n        # Description?\n        for qname in (\"description\", \"product\"):\n            if qname in feature.qualifiers:\n                description = feature.qualifiers[qname][0]\n                if self.product_is_informative(description, feat_ids=parent_ids + [feature.id]):\n                    feature_object[\"description\"] = description\n                    break\n                logging.debug(f\"Non informative description for {feature.id}: {description}\")\n\n        feature_object[\"xrefs\"] = []\n        if \"Dbxref\" in feature.qualifiers:\n            all_xref = self.get_xrefs(feature)\n            feature_object[\"xrefs\"] = all_xref\n\n        xref_values = {xref[\"id\"].lower() for xref in feature_object[\"xrefs\"]}\n\n        # Synonyms?\n        # We add synonyms to the external_synonym table\n        # which is associated with the first xref of that feature type\n        if \"Name\" in feature.qualifiers:\n            feat_name = feature.qualifiers[\"Name\"][0]\n            if feat_name.lower() != feature.id.lower() and feat_name.lower() not in xref_values:\n                feature_object[\"synonyms\"] = [feat_name]\n\n        # is_pseudogene?\n        if feature.type.startswith(\"pseudogen\"):\n            feature_object[\"is_pseudogene\"] = True\n\n        # Don't keep empty xref\n        if not feature_object[\"xrefs\"]:\n            del feature_object[\"xrefs\"]\n        return feature_object\n\n    def transfer_descriptions(self) -&gt; None:\n        \"\"\"Transfers the feature descriptions in 2 steps:\n        - from translations to transcripts (if the transcript description is empty)\n        - from transcripts to genes (same case)\n\n        \"\"\"\n        self._transfer_description_up(\"translation\")\n        self._transfer_description_up(\"transcript\")\n\n    def _transfer_description_up(self, child_feature: str) -&gt; None:\n        \"\"\"Transfer descriptions from all feature of a given type, up to their parent.\n\n        Args:\n            child_feature: Either \"translation\" (transfer to transcript) or \"transcript\" (to gene).\n\n        \"\"\"\n        children_features = self.get_features(child_feature)\n        parent_type = _PARENTS[child_feature]\n        parent_features = self.get_features(parent_type)\n\n        # Transfer description from children to their parent\n        for child_id, child in children_features.items():\n            child_description = child.get(\"description\")\n            if child_description is not None:\n                child_description = self._clean_description(child_description)\n                # Check parent\n                parent_id = self.get_parent(parent_type, child_id)\n                parent = parent_features[parent_id]\n                parent_description = parent.get(\"description\")\n                if parent_description is None:\n                    parent[\"description\"] = child_description\n\n    @staticmethod\n    def _clean_description(description: str) -&gt; str:\n        \"\"\"Returns the description without \"transcript variant\" information.\"\"\"\n        variant_re = re.compile(r\", transcript variant [A-Z][0-9]+$\", re.IGNORECASE)\n        description = re.sub(variant_re, \"\", description)\n        return description\n\n    @staticmethod\n    def product_is_informative(product: str, feat_ids: Optional[List[str]] = None) -&gt; bool:\n        \"\"\"Returns True if the product name contains informative words, False otherwise.\n\n        It is considered uninformative when the description contains words such as \"hypothetical\" or\n        or \"putative\". If feature IDs are provided, consider it uninformative as well (we do not want\n        descriptions to be just the ID).\n\n        Args:\n            product: A product name.\n            feat_ids: List of feature IDs.\n\n        \"\"\"\n        non_informative_words = [\n            \"hypothetical\",\n            \"putative\",\n            \"uncharacterized\",\n            \"unspecified\",\n            \"unknown\",\n            r\"(of )?unknown function\",\n            \"conserved\",\n            \"predicted\",\n            \"fragment\",\n            \"product\",\n            \"function\",\n            \"protein\",\n            \"transcript\",\n            \"gene\",\n            \"RNA\",\n            r\"(variant|isoform)( X?\\d+)?\",\n            r\"low quality protein\",\n        ]\n        non_informative_re = re.compile(r\"|\".join(non_informative_words), re.IGNORECASE)\n\n        # Remove all IDs that are in the description\n        if feat_ids:\n            logging.debug(f\"Filter out {feat_ids} from {product}\")\n            try:\n                for feat_id in feat_ids:\n                    feat_id_re = re.compile(feat_id, re.IGNORECASE)\n                    product = re.sub(feat_id_re, \"\", product)\n            except TypeError as err:\n                raise TypeError(f\"Failed to search {feat_id_re} in '{product}'\") from err\n\n        # Remove punctuations\n        punct_re = re.compile(r\"[,;: _()-]+\")\n        product = re.sub(punct_re, \" \", product)\n\n        # Then remove non informative words\n        product = re.sub(non_informative_re, \" \", product)\n\n        # Anything (informative) left?\n        empty_re = re.compile(r\"^[ ]*$\")\n        return not bool(empty_re.match(product))\n\n    def _to_list(self) -&gt; list[Annotation]:\n        all_list: list[Annotation] = []\n        for feat_dict in self.features.values():\n            all_list += feat_dict.values()\n        return all_list\n\n    def to_json(self, out_path: PathLike) -&gt; None:\n        \"\"\"Print out the current annotation list in a json file.\n\n        Args:\n            out_path: JSON file path where to write the data.\n\n        \"\"\"\n        self.transfer_descriptions()\n        feats_list = self._to_list()\n        print_json(Path(out_path), feats_list)\n\n    def store_gene(self, gene: GFFSeqFeature) -&gt; None:\n        \"\"\"Record the functional_annotations of a gene and its children features.\"\"\"\n        self.add_feature(gene, \"gene\")\n\n        for transcript in gene.sub_features:\n            self.add_feature(transcript, \"transcript\", gene.id, [gene.id])\n            for feat in transcript.sub_features:\n                if feat.type == \"CDS\":\n                    self.add_feature(feat, \"translation\", transcript.id, [gene.id, transcript.id])\n                    # Store CDS functional annotation only once\n                    break\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.annotations","title":"<code>annotations = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.features","title":"<code>features = {'gene': {}, 'transcript': {}, 'translation': {}, 'transposable_element': {}}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.ignored_xrefs","title":"<code>ignored_xrefs = {'go', 'interpro', 'uniprot'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.parents","title":"<code>parents = {'gene': {}, 'transcript': {}}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.provider_name","title":"<code>provider_name = provider_name</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.add_feature","title":"<code>add_feature(feature, feat_type, parent_id=None, all_parent_ids=None)</code>","text":"<p>Add annotation for a feature of a given type. If a parent_id is provided, record the relationship.</p> <p>Parameters:</p> Name Type Description Default <code>feature</code> <code>GFFSeqFeature</code> <p>The feature to create an annotation.</p> required <code>feat_type</code> <code>str</code> <p>Type of the feature to annotate.</p> required <code>parent_id</code> <code>Optional[str]</code> <p>Parent ID of this feature to keep it linked.</p> <code>None</code> <code>all_parent_ids</code> <code>Optional[List[str]]</code> <p>All parent IDs to remove from non-informative descriptions.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def add_feature(\n    self,\n    feature: GFFSeqFeature,\n    feat_type: str,\n    parent_id: Optional[str] = None,\n    all_parent_ids: Optional[List[str]] = None,\n) -&gt; None:\n    \"\"\"Add annotation for a feature of a given type. If a parent_id is provided, record the relationship.\n\n    Args:\n        feature: The feature to create an annotation.\n        feat_type: Type of the feature to annotate.\n        parent_id: Parent ID of this feature to keep it linked.\n        all_parent_ids: All parent IDs to remove from non-informative descriptions.\n    \"\"\"\n    if all_parent_ids is None:\n        all_parent_ids = []\n    features = self.get_features(feat_type)\n    if feature.id in features:\n        raise AnnotationError(f\"Feature {feat_type} ID {feature.id} already added\")\n\n    feature_object = self._generic_feature(feature, feat_type, all_parent_ids)\n    self.features[feat_type][feature.id] = feature_object\n\n    if parent_id:\n        if feat_type in _PARENTS:\n            parent_type = _PARENTS[feat_type]\n            self.add_parent_link(parent_type, parent_id, feature.id)\n        else:\n            raise AnnotationError(f\"No parent possible for {feat_type} {feature.id}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.add_parent_link","title":"<code>add_parent_link(parent_type, parent_id, child_id)</code>","text":"<p>Record a parent-child IDs relationship for a given parent biotype.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def add_parent_link(self, parent_type: str, parent_id: str, child_id: str) -&gt; None:\n    \"\"\"Record a parent-child IDs relationship for a given parent biotype.\"\"\"\n    features = self.get_features(parent_type)\n    if parent_id not in features:\n        raise MissingParentError(f\"Parent {parent_type}:{parent_id} not found for {child_id}\")\n    self.parents[parent_type][child_id] = parent_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.get_features","title":"<code>get_features(feat_type)</code>","text":"<p>Get all feature annotations for the requested type.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def get_features(self, feat_type: str) -&gt; Dict[str, Annotation]:\n    \"\"\"Get all feature annotations for the requested type.\"\"\"\n    try:\n        return self.features[feat_type]\n    except KeyError as err:\n        raise KeyError(f\"No such feature type {feat_type}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.get_parent","title":"<code>get_parent(parent_type, child_id)</code>","text":"<p>Returns the parent ID of a given child for a given parent biotype.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def get_parent(self, parent_type: str, child_id: str) -&gt; str:\n    \"\"\"Returns the parent ID of a given child for a given parent biotype.\"\"\"\n    try:\n        parents = self.parents[parent_type]\n    except KeyError as err:\n        raise KeyError(f\"Unsupported parent type {parent_type}\") from err\n\n    parent_id = parents.get(child_id)\n    if parent_id is None:\n        raise MissingParentError(f\"Can't find {parent_type} parent for {child_id}\")\n    return parent_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.get_xrefs","title":"<code>get_xrefs(feature)</code>","text":"<p>Get the xrefs from the Dbxref field.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def get_xrefs(self, feature: GFFSeqFeature) -&gt; List[Dict[str, Any]]:\n    \"\"\"Get the xrefs from the Dbxref field.\"\"\"\n    all_xref: List[Dict[str, str]] = []\n\n    if \"Dbxref\" in feature.qualifiers:\n        for xref in feature.qualifiers[\"Dbxref\"]:\n            dbname, name = xref.split(\":\", maxsplit=1)\n            if dbname == \"GenBank\" and self.provider_name == \"RefSeq\":\n                dbname = \"RefSeq\"\n\n            if dbname.lower() in self.ignored_xrefs:\n                continue\n\n            xrefs = {\"dbname\": dbname, \"id\": name}\n            all_xref.append(xrefs)\n\n    # Add RefSeq ID xref if it looks like one\n    if self.provider_name == \"RefSeq\":\n        if feature.type == \"gene\" and feature.id.startswith(\"LOC\"):\n            xref_dbs = {x[\"dbname\"] for x in all_xref}\n            if \"RefSeq\" not in xref_dbs:\n                all_xref.append({\"dbname\": \"RefSeq\", \"id\": feature.id})\n\n    return all_xref\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.product_is_informative","title":"<code>product_is_informative(product, feat_ids=None)</code>  <code>staticmethod</code>","text":"<p>Returns True if the product name contains informative words, False otherwise.</p> <p>It is considered uninformative when the description contains words such as \"hypothetical\" or or \"putative\". If feature IDs are provided, consider it uninformative as well (we do not want descriptions to be just the ID).</p> <p>Parameters:</p> Name Type Description Default <code>product</code> <code>str</code> <p>A product name.</p> required <code>feat_ids</code> <code>Optional[List[str]]</code> <p>List of feature IDs.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>@staticmethod\ndef product_is_informative(product: str, feat_ids: Optional[List[str]] = None) -&gt; bool:\n    \"\"\"Returns True if the product name contains informative words, False otherwise.\n\n    It is considered uninformative when the description contains words such as \"hypothetical\" or\n    or \"putative\". If feature IDs are provided, consider it uninformative as well (we do not want\n    descriptions to be just the ID).\n\n    Args:\n        product: A product name.\n        feat_ids: List of feature IDs.\n\n    \"\"\"\n    non_informative_words = [\n        \"hypothetical\",\n        \"putative\",\n        \"uncharacterized\",\n        \"unspecified\",\n        \"unknown\",\n        r\"(of )?unknown function\",\n        \"conserved\",\n        \"predicted\",\n        \"fragment\",\n        \"product\",\n        \"function\",\n        \"protein\",\n        \"transcript\",\n        \"gene\",\n        \"RNA\",\n        r\"(variant|isoform)( X?\\d+)?\",\n        r\"low quality protein\",\n    ]\n    non_informative_re = re.compile(r\"|\".join(non_informative_words), re.IGNORECASE)\n\n    # Remove all IDs that are in the description\n    if feat_ids:\n        logging.debug(f\"Filter out {feat_ids} from {product}\")\n        try:\n            for feat_id in feat_ids:\n                feat_id_re = re.compile(feat_id, re.IGNORECASE)\n                product = re.sub(feat_id_re, \"\", product)\n        except TypeError as err:\n            raise TypeError(f\"Failed to search {feat_id_re} in '{product}'\") from err\n\n    # Remove punctuations\n    punct_re = re.compile(r\"[,;: _()-]+\")\n    product = re.sub(punct_re, \" \", product)\n\n    # Then remove non informative words\n    product = re.sub(non_informative_re, \" \", product)\n\n    # Anything (informative) left?\n    empty_re = re.compile(r\"^[ ]*$\")\n    return not bool(empty_re.match(product))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.store_gene","title":"<code>store_gene(gene)</code>","text":"<p>Record the functional_annotations of a gene and its children features.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def store_gene(self, gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Record the functional_annotations of a gene and its children features.\"\"\"\n    self.add_feature(gene, \"gene\")\n\n    for transcript in gene.sub_features:\n        self.add_feature(transcript, \"transcript\", gene.id, [gene.id])\n        for feat in transcript.sub_features:\n            if feat.type == \"CDS\":\n                self.add_feature(feat, \"translation\", transcript.id, [gene.id, transcript.id])\n                # Store CDS functional annotation only once\n                break\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.to_json","title":"<code>to_json(out_path)</code>","text":"<p>Print out the current annotation list in a json file.</p> <p>Parameters:</p> Name Type Description Default <code>out_path</code> <code>PathLike</code> <p>JSON file path where to write the data.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def to_json(self, out_path: PathLike) -&gt; None:\n    \"\"\"Print out the current annotation list in a json file.\n\n    Args:\n        out_path: JSON file path where to write the data.\n\n    \"\"\"\n    self.transfer_descriptions()\n    feats_list = self._to_list()\n    print_json(Path(out_path), feats_list)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.FunctionalAnnotations.transfer_descriptions","title":"<code>transfer_descriptions()</code>","text":"<p>Transfers the feature descriptions in 2 steps: - from translations to transcripts (if the transcript description is empty) - from transcripts to genes (same case)</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>def transfer_descriptions(self) -&gt; None:\n    \"\"\"Transfers the feature descriptions in 2 steps:\n    - from translations to transcripts (if the transcript description is empty)\n    - from transcripts to genes (same case)\n\n    \"\"\"\n    self._transfer_description_up(\"translation\")\n    self._transfer_description_up(\"transcript\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/extract_annotation/#ensembl.io.genomio.gff3.extract_annotation.MissingParentError","title":"<code>MissingParentError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Trying to add a feature without an expected parent.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/extract_annotation.py</code> <pre><code>class MissingParentError(Exception):\n    \"\"\"Trying to add a feature without an expected parent.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/features/","title":"features","text":""},{"location":"reference/ensembl/io/genomio/gff3/features/#ensembl.io.genomio.gff3.features","title":"<code>ensembl.io.genomio.gff3.features</code>","text":"<p>GFF3 features.</p>"},{"location":"reference/ensembl/io/genomio/gff3/features/#ensembl.io.genomio.gff3.features.GFFSeqFeature","title":"<code>GFFSeqFeature</code>","text":"<p>               Bases: <code>SeqFeature</code></p> <p>Extends <code>Bio.SeqFeature.SeqFeature</code> with sub_features, to be used for typing.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/features.py</code> <pre><code>class GFFSeqFeature(SeqFeature):\n    \"\"\"Extends `Bio.SeqFeature.SeqFeature` with sub_features, to be used for typing.\"\"\"\n\n    def __init__(\n        self,\n        location: Location | None = None,\n        *,\n        type: str = \"\",  # pylint: disable=W0622\n        id: str = \"&lt;unknown id&gt;\",  # pylint: disable=W0622\n        qualifiers: dict | None = None,\n        sub_features: list[GFFSeqFeature] | None = None,\n    ):\n        super().__init__(location, type=type, id=id, qualifiers=qualifiers)\n        if sub_features is None:\n            sub_features = []\n        self.sub_features = sub_features\n\n    @classmethod\n    def cast(cls, feat: SeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Cast a SeqFeature to a GFFSeqFeature.\"\"\"\n        feat.__class__ = cls\n        if not hasattr(feat, \"sub_features\"):\n            feat.sub_features = []  # type: ignore[attr-defined]\n        return feat  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/features/#ensembl.io.genomio.gff3.features.GFFSeqFeature.sub_features","title":"<code>sub_features = sub_features</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/features/#ensembl.io.genomio.gff3.features.GFFSeqFeature.cast","title":"<code>cast(feat)</code>  <code>classmethod</code>","text":"<p>Cast a SeqFeature to a GFFSeqFeature.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/features.py</code> <pre><code>@classmethod\ndef cast(cls, feat: SeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Cast a SeqFeature to a GFFSeqFeature.\"\"\"\n    feat.__class__ = cls\n    if not hasattr(feat, \"sub_features\"):\n        feat.sub_features = []  # type: ignore[attr-defined]\n    return feat  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/gene_merger/","title":"gene_merger","text":""},{"location":"reference/ensembl/io/genomio/gff3/gene_merger/#ensembl.io.genomio.gff3.gene_merger","title":"<code>ensembl.io.genomio.gff3.gene_merger</code>","text":"<p>Merge split genes in a GFF file.</p>"},{"location":"reference/ensembl/io/genomio/gff3/gene_merger/#ensembl.io.genomio.gff3.gene_merger.GFFGeneMerger","title":"<code>GFFGeneMerger</code>","text":"<p>Specialized class to merge split genes in a GFF3 file, prior to further parsing.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/gene_merger.py</code> <pre><code>class GFFGeneMerger:\n    \"\"\"Specialized class to merge split genes in a GFF3 file, prior to further parsing.\"\"\"\n\n    def __init__(self) -&gt; None:\n        source = files(ensembl.io.genomio.data.gff3).joinpath(\"biotypes.json\")\n        with as_file(source) as biotypes_json:\n            self._biotypes = get_json(biotypes_json)\n\n    def merge(self, in_gff_path: PathLike, out_gff_path: PathLike) -&gt; List[str]:\n        \"\"\"\n        Merge genes in a gff that are split in multiple lines.\n\n        Args:\n            in_gff_path: Input GFF3 that may have split merge.\n            out_gff_path: Output GFF3 with those genes merged.\n\n        Returns:\n            List of all merged genes, each represented as a string of the GFF3 lines of all their parts.\n        \"\"\"\n        to_merge = []\n        merged: List[str] = []\n\n        with Path(in_gff_path).open(\"r\") as in_gff_fh, Path(out_gff_path).open(\"w\") as out_gff_fh:\n            for line in in_gff_fh:\n                # Skip comments\n                if line.startswith(\"#\"):\n                    if line.startswith(\"##FASTA\"):\n                        logging.warning(\"This GFF3 file contains FASTA sequences\")\n                        break\n                    out_gff_fh.write(line)\n                else:\n                    # Parse one line\n                    line = line.rstrip()\n                    fields = line.split(\"\\t\")\n                    attr_fields = fields[8].split(\";\")\n                    attrs = {}\n                    for a in attr_fields:\n                        (key, value) = a.split(\"=\")\n                        attrs[key] = value\n\n                    # Check this is a gene to merge; cache it then\n                    if fields[2] in self._biotypes[\"gene\"][\"supported\"] and (\n                        \"part\" in attrs or \"is_ordered\" in attrs\n                    ):\n                        to_merge.append(fields)\n\n                    # If not, merge previous gene if needed, and print the line\n                    else:\n                        if to_merge:\n                            merged_str = []\n                            for line_to_merge in to_merge:\n                                merged_str.append(\"\\t\".join(line_to_merge))\n                            merged.append(\"\\n\".join(merged_str) + \"\\n\")\n\n                            new_line = self._merge_genes(to_merge)\n                            out_gff_fh.write(new_line)\n                            to_merge = []\n                        out_gff_fh.write(line + \"\\n\")\n\n            # Print last merged gene if there is one\n            if to_merge:\n                merged_str = []\n                for line_to_merge in to_merge:\n                    merged_str.append(\"\\t\".join(line_to_merge))\n                merged.append(\"\\n\".join(merged_str) + \"\\n\")\n\n                new_line = self._merge_genes(to_merge)\n                out_gff_fh.write(new_line)\n\n        logging.debug(f\"Merged lines: {len(merged)}\")\n        return merged\n\n    def _merge_genes(self, to_merge: List) -&gt; str:\n        \"\"\"Returns a single gene gff3 line merged from separate parts.\n\n        Args:\n            to_merge: List of gff3 lines with gene parts.\n\n        \"\"\"\n        min_start = -1\n        max_end = -1\n        for gene in to_merge:\n            start = int(gene[3])\n            end = int(gene[4])\n\n            if start &lt; min_start or min_start &lt; 0:\n                min_start = start\n            if end &gt; max_end or max_end &lt; 0:\n                max_end = end\n\n        # Take the first line as template and replace things\n        new_gene = to_merge[0]\n        new_gene[3] = str(min_start)\n        new_gene[4] = str(max_end)\n\n        attrs = new_gene[8]\n        attrs = attrs.replace(\";is_ordered=true\", \"\")\n        attrs = re.sub(r\";part=\\d+/\\d+\", \"\", attrs)\n        new_gene[8] = attrs\n\n        return \"\\t\".join(new_gene) + \"\\n\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/gene_merger/#ensembl.io.genomio.gff3.gene_merger.GFFGeneMerger.merge","title":"<code>merge(in_gff_path, out_gff_path)</code>","text":"<p>Merge genes in a gff that are split in multiple lines.</p> <p>Parameters:</p> Name Type Description Default <code>in_gff_path</code> <code>PathLike</code> <p>Input GFF3 that may have split merge.</p> required <code>out_gff_path</code> <code>PathLike</code> <p>Output GFF3 with those genes merged.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of all merged genes, each represented as a string of the GFF3 lines of all their parts.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/gene_merger.py</code> <pre><code>def merge(self, in_gff_path: PathLike, out_gff_path: PathLike) -&gt; List[str]:\n    \"\"\"\n    Merge genes in a gff that are split in multiple lines.\n\n    Args:\n        in_gff_path: Input GFF3 that may have split merge.\n        out_gff_path: Output GFF3 with those genes merged.\n\n    Returns:\n        List of all merged genes, each represented as a string of the GFF3 lines of all their parts.\n    \"\"\"\n    to_merge = []\n    merged: List[str] = []\n\n    with Path(in_gff_path).open(\"r\") as in_gff_fh, Path(out_gff_path).open(\"w\") as out_gff_fh:\n        for line in in_gff_fh:\n            # Skip comments\n            if line.startswith(\"#\"):\n                if line.startswith(\"##FASTA\"):\n                    logging.warning(\"This GFF3 file contains FASTA sequences\")\n                    break\n                out_gff_fh.write(line)\n            else:\n                # Parse one line\n                line = line.rstrip()\n                fields = line.split(\"\\t\")\n                attr_fields = fields[8].split(\";\")\n                attrs = {}\n                for a in attr_fields:\n                    (key, value) = a.split(\"=\")\n                    attrs[key] = value\n\n                # Check this is a gene to merge; cache it then\n                if fields[2] in self._biotypes[\"gene\"][\"supported\"] and (\n                    \"part\" in attrs or \"is_ordered\" in attrs\n                ):\n                    to_merge.append(fields)\n\n                # If not, merge previous gene if needed, and print the line\n                else:\n                    if to_merge:\n                        merged_str = []\n                        for line_to_merge in to_merge:\n                            merged_str.append(\"\\t\".join(line_to_merge))\n                        merged.append(\"\\n\".join(merged_str) + \"\\n\")\n\n                        new_line = self._merge_genes(to_merge)\n                        out_gff_fh.write(new_line)\n                        to_merge = []\n                    out_gff_fh.write(line + \"\\n\")\n\n        # Print last merged gene if there is one\n        if to_merge:\n            merged_str = []\n            for line_to_merge in to_merge:\n                merged_str.append(\"\\t\".join(line_to_merge))\n            merged.append(\"\\n\".join(merged_str) + \"\\n\")\n\n            new_line = self._merge_genes(to_merge)\n            out_gff_fh.write(new_line)\n\n    logging.debug(f\"Merged lines: {len(merged)}\")\n    return merged\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/","title":"id_allocator","text":""},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator","title":"<code>ensembl.io.genomio.gff3.id_allocator</code>","text":"<p>Check and allocate IDs for gene features in a GFF3 file.</p>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.InvalidStableID","title":"<code>InvalidStableID</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when there is a problem with an stable ID.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>class InvalidStableID(ValueError):\n    \"\"\"Raised when there is a problem with an stable ID.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator","title":"<code>StableIDAllocator</code>  <code>dataclass</code>","text":"<p>Set of tools to check and allocate stable IDs.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>@dataclass\nclass StableIDAllocator:\n    \"\"\"Set of tools to check and allocate stable IDs.\"\"\"\n\n    # Multiple parameters to automate various fixes\n    skip_gene_id_validation: bool = False\n    min_id_length: int = 7\n    current_id_number: int = 0\n    make_missing_stable_ids: bool = True\n    prefix: str = \"TMP_\"\n    _loaded_ids: Set = field(default_factory=set)\n\n    def set_prefix(self, genome: Dict) -&gt; None:\n        \"\"\"Sets the ID prefix using the organism abbrev if it exists in the genome metadata.\"\"\"\n        try:\n            org = genome[\"BRC4\"][\"organism_abbrev\"]\n        except KeyError:\n            prefix = \"TMP_PREFIX_\"\n        else:\n            prefix = \"TMP_\" + org + \"_\"\n        self.prefix = prefix\n\n    def generate_gene_id(self) -&gt; str:\n        \"\"\"Returns a new unique gene stable_id with a prefix.\n\n        The ID is made up of a prefix and a number, which is auto incremented.\n\n        \"\"\"\n        self.current_id_number += 1\n        new_id = f\"{self.prefix}{self.current_id_number}\"\n        return new_id\n\n    def is_valid(self, stable_id: str) -&gt; bool:\n        \"\"\"Checks that the format of a stable ID is valid.\n        Args:\n            stable_id: Stable ID to validate.\n        \"\"\"\n\n        if self.skip_gene_id_validation:\n            logging.debug(f\"Validation deactivated by user: '{stable_id}' not checked\")\n            return True\n\n        # Trna (from tRNAscan)\n        if re.search(r\"^Trna\", stable_id, re.IGNORECASE):\n            logging.debug(f\"Stable ID is a tRNA from tRNA-scan: {stable_id}\")\n            return False\n\n        # Coordinates\n        if re.search(r\"^.+:\\d+..\\d+\", stable_id):\n            logging.debug(f\"Stable id is a coordinate: {stable_id}\")\n            return False\n\n        # Special characters\n        if re.search(r\"[ |]\", stable_id):\n            logging.debug(f\"Stable id contains special characters: {stable_id}\")\n            return False\n\n        # Min length\n        if len(stable_id) &lt; self.min_id_length:\n            logging.debug(f\"Stable id is too short (&lt;{self.min_id_length}) {stable_id}\")\n            return False\n\n        return True\n\n    @staticmethod\n    def remove_prefix(stable_id: str, prefixes: List[str]) -&gt; str:\n        \"\"\"Returns the stable ID after removing its prefix (if any).\n\n        If more than one prefix may be found, only the first one is removed.\n\n        Args:\n            stable_id: Stable ID to process.\n            prefixes: List of prefixes to search for.\n        \"\"\"\n\n        for prefix in prefixes:\n            if stable_id.startswith(prefix):\n                return stable_id[len(prefix) :]\n        return stable_id\n\n    @staticmethod\n    def generate_transcript_id(gene_id: str, number: int) -&gt; str:\n        \"\"\"Returns a formatted transcript ID generated from a gene ID and number.\n        Args:\n            gene_id: Gene stable ID.\n            number: Positive number.\n        Raises:\n            ValueError: If the number provided is not greater than zero.\n\n        \"\"\"\n        if number &lt; 1:\n            raise ValueError(\"Number has to be a positive integer.\")\n\n        transcript_id = f\"{gene_id}_t{number}\"\n        return transcript_id\n\n    def normalize_cds_id(self, cds_id: str) -&gt; str:\n        \"\"\"Returns a normalized version of the provided CDS ID.\n\n        The normalisation implies to remove any unnecessary prefixes around the CDS ID. However, if\n        the CDS ID is still not proper, an empty string will be returned.\n\n        Args:\n            cds_id: CDS ID to normalize.\n\n        \"\"\"\n\n        prefixes = [\"cds-\", \"cds:\"]\n        normalized_cds_id = StableIDAllocator.remove_prefix(cds_id, prefixes)\n\n        # Special case: if the ID doesn't look like one, remove it - it needs to be regenerated\n        if not self.is_valid(normalized_cds_id):\n            return \"\"\n        return normalized_cds_id\n\n    def normalize_pseudogene_cds_id(self, pseudogene: GFFSeqFeature) -&gt; None:\n        \"\"\"Normalizes every CDS ID of the provided pseudogene.\n\n        Ensure each CDS from a pseudogene has a proper ID:\n        - Different from the gene\n        - Derived from the gene if it is not proper\n\n        Args:\n            pseudogene: Pseudogene feature.\n        \"\"\"\n        for transcript in pseudogene.sub_features:\n            for feat in transcript.sub_features:\n                if feat.type == \"CDS\":\n                    feat.id = self.normalize_cds_id(feat.id)\n                    if feat.id in (\"\", pseudogene.id):\n                        feat.id = f\"{transcript.id}_cds\"\n                        feat.qualifiers[\"ID\"] = feat.id\n\n    def normalize_gene_id(self, gene: GFFSeqFeature, refseq: Optional[bool] = False) -&gt; str:\n        \"\"\"Returns a normalized gene stable ID.\n\n        Removes any unnecessary prefixes, but will generate a new stable ID if the normalized one is\n        not recognized as valid.\n\n        Args:\n            gene: Gene feature to normalize.\n        \"\"\"\n        prefixes = [\"gene-\", \"gene:\"]\n        new_gene_id = StableIDAllocator.remove_prefix(gene.id, prefixes)\n\n        is_valid = False\n        # Special case for RefSeq: only valid Gene IDs are LOC*\n        if refseq:\n            if new_gene_id.startswith(\"LOC\"):\n                is_valid = True\n        else:\n            is_valid = self.is_valid(new_gene_id)\n\n        if is_valid:\n            return new_gene_id\n\n        # In case the normalized gene ID is not valid, use the GeneID\n        logging.debug(f\"Gene ID is not valid: {new_gene_id}\")\n        qual = gene.qualifiers\n        if \"Dbxref\" in qual:\n            for xref in qual[\"Dbxref\"]:\n                (db, value) = xref.split(\":\")\n                if db != \"GeneID\":\n                    continue\n                new_gene_id_base = f\"{db}_{value}\"\n                new_gene_id = new_gene_id_base\n                number = 1\n                while new_gene_id in self._loaded_ids:\n                    number += 1\n                    new_gene_id = f\"{new_gene_id_base}_{number}\"\n                    if number &gt; 10:\n                        raise InvalidStableID(f\"Duplicate ID {new_gene_id_base} (up to {new_gene_id})\")\n                self._loaded_ids.add(new_gene_id)\n                logging.debug(f\"Using GeneID {new_gene_id} for stable_id instead of {gene.id}\")\n                return new_gene_id\n\n        # Make a new stable_id\n        if self.make_missing_stable_ids:\n            new_gene_id = self.generate_gene_id()\n            logging.debug(f\"New ID: {new_gene_id} -&gt; {new_gene_id}\")\n            return new_gene_id\n        raise InvalidStableID(f\"Can't use invalid gene id for {gene}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.current_id_number","title":"<code>current_id_number = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.make_missing_stable_ids","title":"<code>make_missing_stable_ids = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.min_id_length","title":"<code>min_id_length = 7</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.prefix","title":"<code>prefix = 'TMP_'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.skip_gene_id_validation","title":"<code>skip_gene_id_validation = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.generate_gene_id","title":"<code>generate_gene_id()</code>","text":"<p>Returns a new unique gene stable_id with a prefix.</p> <p>The ID is made up of a prefix and a number, which is auto incremented.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def generate_gene_id(self) -&gt; str:\n    \"\"\"Returns a new unique gene stable_id with a prefix.\n\n    The ID is made up of a prefix and a number, which is auto incremented.\n\n    \"\"\"\n    self.current_id_number += 1\n    new_id = f\"{self.prefix}{self.current_id_number}\"\n    return new_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.generate_transcript_id","title":"<code>generate_transcript_id(gene_id, number)</code>  <code>staticmethod</code>","text":"<p>Returns a formatted transcript ID generated from a gene ID and number. Args:     gene_id: Gene stable ID.     number: Positive number. Raises:     ValueError: If the number provided is not greater than zero.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>@staticmethod\ndef generate_transcript_id(gene_id: str, number: int) -&gt; str:\n    \"\"\"Returns a formatted transcript ID generated from a gene ID and number.\n    Args:\n        gene_id: Gene stable ID.\n        number: Positive number.\n    Raises:\n        ValueError: If the number provided is not greater than zero.\n\n    \"\"\"\n    if number &lt; 1:\n        raise ValueError(\"Number has to be a positive integer.\")\n\n    transcript_id = f\"{gene_id}_t{number}\"\n    return transcript_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.is_valid","title":"<code>is_valid(stable_id)</code>","text":"<p>Checks that the format of a stable ID is valid. Args:     stable_id: Stable ID to validate.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def is_valid(self, stable_id: str) -&gt; bool:\n    \"\"\"Checks that the format of a stable ID is valid.\n    Args:\n        stable_id: Stable ID to validate.\n    \"\"\"\n\n    if self.skip_gene_id_validation:\n        logging.debug(f\"Validation deactivated by user: '{stable_id}' not checked\")\n        return True\n\n    # Trna (from tRNAscan)\n    if re.search(r\"^Trna\", stable_id, re.IGNORECASE):\n        logging.debug(f\"Stable ID is a tRNA from tRNA-scan: {stable_id}\")\n        return False\n\n    # Coordinates\n    if re.search(r\"^.+:\\d+..\\d+\", stable_id):\n        logging.debug(f\"Stable id is a coordinate: {stable_id}\")\n        return False\n\n    # Special characters\n    if re.search(r\"[ |]\", stable_id):\n        logging.debug(f\"Stable id contains special characters: {stable_id}\")\n        return False\n\n    # Min length\n    if len(stable_id) &lt; self.min_id_length:\n        logging.debug(f\"Stable id is too short (&lt;{self.min_id_length}) {stable_id}\")\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.normalize_cds_id","title":"<code>normalize_cds_id(cds_id)</code>","text":"<p>Returns a normalized version of the provided CDS ID.</p> <p>The normalisation implies to remove any unnecessary prefixes around the CDS ID. However, if the CDS ID is still not proper, an empty string will be returned.</p> <p>Parameters:</p> Name Type Description Default <code>cds_id</code> <code>str</code> <p>CDS ID to normalize.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def normalize_cds_id(self, cds_id: str) -&gt; str:\n    \"\"\"Returns a normalized version of the provided CDS ID.\n\n    The normalisation implies to remove any unnecessary prefixes around the CDS ID. However, if\n    the CDS ID is still not proper, an empty string will be returned.\n\n    Args:\n        cds_id: CDS ID to normalize.\n\n    \"\"\"\n\n    prefixes = [\"cds-\", \"cds:\"]\n    normalized_cds_id = StableIDAllocator.remove_prefix(cds_id, prefixes)\n\n    # Special case: if the ID doesn't look like one, remove it - it needs to be regenerated\n    if not self.is_valid(normalized_cds_id):\n        return \"\"\n    return normalized_cds_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.normalize_gene_id","title":"<code>normalize_gene_id(gene, refseq=False)</code>","text":"<p>Returns a normalized gene stable ID.</p> <p>Removes any unnecessary prefixes, but will generate a new stable ID if the normalized one is not recognized as valid.</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>GFFSeqFeature</code> <p>Gene feature to normalize.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def normalize_gene_id(self, gene: GFFSeqFeature, refseq: Optional[bool] = False) -&gt; str:\n    \"\"\"Returns a normalized gene stable ID.\n\n    Removes any unnecessary prefixes, but will generate a new stable ID if the normalized one is\n    not recognized as valid.\n\n    Args:\n        gene: Gene feature to normalize.\n    \"\"\"\n    prefixes = [\"gene-\", \"gene:\"]\n    new_gene_id = StableIDAllocator.remove_prefix(gene.id, prefixes)\n\n    is_valid = False\n    # Special case for RefSeq: only valid Gene IDs are LOC*\n    if refseq:\n        if new_gene_id.startswith(\"LOC\"):\n            is_valid = True\n    else:\n        is_valid = self.is_valid(new_gene_id)\n\n    if is_valid:\n        return new_gene_id\n\n    # In case the normalized gene ID is not valid, use the GeneID\n    logging.debug(f\"Gene ID is not valid: {new_gene_id}\")\n    qual = gene.qualifiers\n    if \"Dbxref\" in qual:\n        for xref in qual[\"Dbxref\"]:\n            (db, value) = xref.split(\":\")\n            if db != \"GeneID\":\n                continue\n            new_gene_id_base = f\"{db}_{value}\"\n            new_gene_id = new_gene_id_base\n            number = 1\n            while new_gene_id in self._loaded_ids:\n                number += 1\n                new_gene_id = f\"{new_gene_id_base}_{number}\"\n                if number &gt; 10:\n                    raise InvalidStableID(f\"Duplicate ID {new_gene_id_base} (up to {new_gene_id})\")\n            self._loaded_ids.add(new_gene_id)\n            logging.debug(f\"Using GeneID {new_gene_id} for stable_id instead of {gene.id}\")\n            return new_gene_id\n\n    # Make a new stable_id\n    if self.make_missing_stable_ids:\n        new_gene_id = self.generate_gene_id()\n        logging.debug(f\"New ID: {new_gene_id} -&gt; {new_gene_id}\")\n        return new_gene_id\n    raise InvalidStableID(f\"Can't use invalid gene id for {gene}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.normalize_pseudogene_cds_id","title":"<code>normalize_pseudogene_cds_id(pseudogene)</code>","text":"<p>Normalizes every CDS ID of the provided pseudogene.</p> <p>Ensure each CDS from a pseudogene has a proper ID: - Different from the gene - Derived from the gene if it is not proper</p> <p>Parameters:</p> Name Type Description Default <code>pseudogene</code> <code>GFFSeqFeature</code> <p>Pseudogene feature.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def normalize_pseudogene_cds_id(self, pseudogene: GFFSeqFeature) -&gt; None:\n    \"\"\"Normalizes every CDS ID of the provided pseudogene.\n\n    Ensure each CDS from a pseudogene has a proper ID:\n    - Different from the gene\n    - Derived from the gene if it is not proper\n\n    Args:\n        pseudogene: Pseudogene feature.\n    \"\"\"\n    for transcript in pseudogene.sub_features:\n        for feat in transcript.sub_features:\n            if feat.type == \"CDS\":\n                feat.id = self.normalize_cds_id(feat.id)\n                if feat.id in (\"\", pseudogene.id):\n                    feat.id = f\"{transcript.id}_cds\"\n                    feat.qualifiers[\"ID\"] = feat.id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.remove_prefix","title":"<code>remove_prefix(stable_id, prefixes)</code>  <code>staticmethod</code>","text":"<p>Returns the stable ID after removing its prefix (if any).</p> <p>If more than one prefix may be found, only the first one is removed.</p> <p>Parameters:</p> Name Type Description Default <code>stable_id</code> <code>str</code> <p>Stable ID to process.</p> required <code>prefixes</code> <code>List[str]</code> <p>List of prefixes to search for.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>@staticmethod\ndef remove_prefix(stable_id: str, prefixes: List[str]) -&gt; str:\n    \"\"\"Returns the stable ID after removing its prefix (if any).\n\n    If more than one prefix may be found, only the first one is removed.\n\n    Args:\n        stable_id: Stable ID to process.\n        prefixes: List of prefixes to search for.\n    \"\"\"\n\n    for prefix in prefixes:\n        if stable_id.startswith(prefix):\n            return stable_id[len(prefix) :]\n    return stable_id\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/id_allocator/#ensembl.io.genomio.gff3.id_allocator.StableIDAllocator.set_prefix","title":"<code>set_prefix(genome)</code>","text":"<p>Sets the ID prefix using the organism abbrev if it exists in the genome metadata.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/id_allocator.py</code> <pre><code>def set_prefix(self, genome: Dict) -&gt; None:\n    \"\"\"Sets the ID prefix using the organism abbrev if it exists in the genome metadata.\"\"\"\n    try:\n        org = genome[\"BRC4\"][\"organism_abbrev\"]\n    except KeyError:\n        prefix = \"TMP_PREFIX_\"\n    else:\n        prefix = \"TMP_\" + org + \"_\"\n    self.prefix = prefix\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/overlaps/","title":"overlaps","text":""},{"location":"reference/ensembl/io/genomio/gff3/overlaps/#ensembl.io.genomio.gff3.overlaps","title":"<code>ensembl.io.genomio.gff3.overlaps</code>","text":"<p>Scan a GFF3 file to detect overlapping SeqFeature objects. Default object level =&gt; gene.</p>"},{"location":"reference/ensembl/io/genomio/gff3/overlaps/#ensembl.io.genomio.gff3.overlaps.get_intervals","title":"<code>get_intervals(record, genes_dict, seq_dict, seq_name)</code>","text":"<p>Extract start/stop feature coordinates for use in creating intervaltree object.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>SeqRecord</code> <p>Individual sequence record.</p> required <code>genes_dict</code> <code>dict</code> <p>Genes.</p> required <code>seq_dict</code> <code>dict</code> <p>Sequences.</p> required <code>seq_name</code> <code>str</code> <p>Feature sequence name.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def get_intervals(record: SeqRecord, genes_dict: dict, seq_dict: dict, seq_name: str) -&gt; None:\n    \"\"\"Extract start/stop feature coordinates for use in creating intervaltree object.\n\n    Args:\n        record: Individual sequence record.\n        genes_dict: Genes.\n        seq_dict: Sequences.\n        seq_name: Feature sequence name.\n    \"\"\"\n\n    for feature in record.features:\n        genes_dict[str(feature.id)] = {\n            \"sequence\": f\"{record.id}\",\n            \"start\": f\"{int(feature.location.start) + 1}\",\n            \"end\": f\"{int(feature.location.end)}\",\n            \"strand\": f\"{feature.location.strand}\",\n            \"name\": f\"{feature.id}\",\n        }\n\n        if feature.location.strand == 1:\n            seq_dict[seq_name][\"plus\"].append(\n                (int(feature.location.start), int(feature.location.end), str(feature.id))\n            )\n        elif feature.location.strand == -1:\n            seq_dict[seq_name][\"minus\"].append(\n                (int(feature.location.start), int(feature.location.end), str(feature.id))\n            )\n        else:\n            logging.critical(\"Something went wrong with the strand processing!\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/overlaps/#ensembl.io.genomio.gff3.overlaps.identify_feature_overlaps","title":"<code>identify_feature_overlaps(gff_in, output_file, isolate_feature)</code>","text":"<p>Detect overlapping GFF3 SeqFeature objects and dump to a report.</p> <p>Parameters:</p> Name Type Description Default <code>gff_in</code> <code>Path</code> <p>User supplied GFF3 input file.</p> required <code>output_file</code> <code>Path</code> <p>Output file to write feature overlaps.</p> required <code>isolate_feature</code> <code>str</code> <p>Sequence feature type to filter by.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def identify_feature_overlaps(gff_in: Path, output_file: Path, isolate_feature: str) -&gt; None:\n    \"\"\"Detect overlapping GFF3 SeqFeature objects and dump to a report.\n\n    Args:\n        gff_in: User supplied GFF3 input file.\n        output_file: Output file to write feature overlaps.\n        isolate_feature: Sequence feature type to filter by.\n    \"\"\"\n    logging.info(\"Processing sequence feature overlaps!\")\n    logging.info(f\"Output file = {str(output_file)}\")\n    logging.info(f\"Features filtered by type: {isolate_feature}\")\n\n    gff_type_filter: dict = {\"gff_type\": [isolate_feature]}\n    seq_dict: dict = defaultdict(dict)\n    genes_dict: dict = {}\n    with gff_in.open(\"r\", encoding=\"utf-8\") as input_handle:\n        for record in GFF.parse(input_handle, limit_info=gff_type_filter):\n            seq_name = str(record.id)\n            if seq_name not in seq_dict:\n                seq_dict[seq_name][\"plus\"] = []\n                seq_dict[seq_name][\"minus\"] = []\n\n            get_intervals(record, genes_dict, seq_dict, seq_name)\n\n    overlap_count = _write_report(output_file, seq_dict, genes_dict)\n\n    result_total_features = f\"In total {len(genes_dict)} {isolate_feature} features were scanned.\"\n    print(result_total_features)\n    logging.info(result_total_features)\n\n    result_total_overlaps = f\"In total {overlap_count} overlaps were detected.\"\n    print(result_total_overlaps)\n    logging.info(result_total_overlaps)\n\n    logging.info(\"Finished all processing.\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/overlaps/#ensembl.io.genomio.gff3.overlaps.main","title":"<code>main()</code>","text":"<p>Module entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module entry-point.\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    # Create parser with common arguments to be used by both subparsers\n    base_parser = ArgumentParser(add_help=False)\n    base_parser.add_argument_src_path(\"--input_gff\", required=True, help=\"path of GFF3 file to process\")\n    base_parser.add_log_arguments(add_log_file=True)\n    # Add subparsers with their parent being the base parser with the common arguments\n    subparsers = parser.add_subparsers(title=\"Parse GFF3 and \", required=True, dest=\"subcommand\")\n    _ = subparsers.add_parser(\"stats\", parents=[base_parser], help=\"Provide summary of feature types\")\n    overlaps_parser = subparsers.add_parser(\"overlaps\", parents=[base_parser], help=\"Find feature overlaps\")\n    overlaps_parser.add_argument_dst_path(\n        \"--output_file\", default=\"feature_overlaps.txt\", help=\"path of output file\"\n    )\n    overlaps_parser.add_argument(\n        \"--filter_type\", default=\"gene\", help=\"sequence feature type used for overlap isolation\"\n    )\n\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    logging.info(\"Starting processing...\")\n    logging.info(f\"GFF input file = {str(args.input_gff)}\")\n\n    # Check optional processing param\n    if args.subcommand == \"stats\":\n        summarize_feature_stats(args.input_gff)\n    else:\n        identify_feature_overlaps(args.input_gff, args.output_file, args.filter_type)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/overlaps/#ensembl.io.genomio.gff3.overlaps.scan_tree","title":"<code>scan_tree(feature_intervals)</code>","text":"<p>Construct an interval tree using supplied genomic intervals, check all elements on the tree against itself and return any that hit 2 or more intervals (i.e. itself + 1 other)</p> <p>Parameters:</p> Name Type Description Default <code>feature_intervals</code> <code>list</code> <p>Genome features to examine for coordinate (start/end) overlaps.</p> required Return <p>Set of intervals identified in the input GFF3 file that overlap with 2 or more intervals.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def scan_tree(feature_intervals: list) -&gt; set:\n    \"\"\"Construct an interval tree using supplied genomic intervals, check all elements on the tree against\n    itself and return any that hit 2 or more intervals (i.e. itself + 1 other)\n\n    Args:\n        feature_intervals: Genome features to examine for coordinate (start/end) overlaps.\n\n    Return:\n        Set of intervals identified in the input GFF3 file that overlap with 2 or more intervals.\n    \"\"\"\n\n    interval_sets = set()\n    traversed_tree = IntervalTree(Interval(*iv) for iv in feature_intervals)\n\n    for interval in feature_intervals:\n        if len(traversed_tree.overlap(interval[0], interval[1])) &gt; 1:\n            overlap_interval = traversed_tree.overlap(interval[0], interval[1])\n\n            for features in overlap_interval:\n                interval_sets.add(features.data)\n\n    return interval_sets\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/overlaps/#ensembl.io.genomio.gff3.overlaps.summarize_feature_stats","title":"<code>summarize_feature_stats(gff_in)</code>","text":"<p>Analyse a GFF3 file and produce a summary of its feature types.</p> <p>Parameters:</p> Name Type Description Default <code>gff_in</code> <code>Path</code> <p>User supplied GFF3 input file.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/overlaps.py</code> <pre><code>def summarize_feature_stats(gff_in: Path) -&gt; None:\n    \"\"\"Analyse a GFF3 file and produce a summary of its feature types.\n\n    Args:\n        gff_in: User supplied GFF3 input file.\n    \"\"\"\n\n    logging.info(\"Alt processing: Not parsing the GFF3, producing summary feature stats instead!\")\n\n    examiner = GFFExaminer()\n    with gff_in.open(\"r\", encoding=\"utf-8\") as input_handle:\n        pprint(examiner.available_limits(input_handle))\n    input_handle.close()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/process/","title":"process","text":""},{"location":"reference/ensembl/io/genomio/gff3/process/#ensembl.io.genomio.gff3.process","title":"<code>ensembl.io.genomio.gff3.process</code>","text":"<p>Simplify and fix a GFF3 file and returns both a cleaned up GFF3 file and a functional annotation JSON file.</p>"},{"location":"reference/ensembl/io/genomio/gff3/process/#ensembl.io.genomio.gff3.process.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/process.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(\n        description=(\n            \"Standardize the gene model representation of a GFF3 file, and extract the functional \"\n            \"annotation in a separate file.\"\n        )\n    )\n    parser.add_argument_src_path(\"--in_gff_path\", required=True, help=\"Input GFF3 file\")\n    parser.add_argument_src_path(\"--genome_data\", required=True, help=\"Genome JSON file\")\n    parser.add_argument(\n        \"--fail_missing_stable_ids\", action=\"store_true\", help=\"Do not generate IDs when missing/invalid\"\n    )\n    parser.add_argument_dst_path(\"--out_gff_path\", default=Path(\"gene_models.gff3\"), help=\"Output GFF3 file\")\n    parser.add_argument_dst_path(\n        \"--out_func_path\",\n        default=Path(\"functional_annotation.json\"),\n        help=\"Output functional annotation JSON file\",\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    # Merge multiline gene features in a separate file\n    logging.info(\"Checking for genes to merge...\")\n    interim_gff_path = Path(f\"{args.in_gff_path}_INTERIM_MERGE\")\n    merger = GFFGeneMerger()\n    merged_genes = merger.merge(args.in_gff_path, interim_gff_path)\n    num_merged_genes = len(merged_genes)\n    in_gff_path = args.in_gff_path\n    # If there are split genes, decide to merge, or just die\n    if num_merged_genes &gt; 0:\n        # Report the list of merged genes in case something does not look right\n        logging.info(f\"{num_merged_genes} genes merged\")\n        logging.debug(\"\\n\".join(merged_genes))\n        # Use the GFF with the merged genes for the next part\n        in_gff_path = interim_gff_path\n\n    # Load GFF3 data and write a simpler version that follows our specifications as well as a\n    # functional annotation JSON file\n    logging.info(\"Simplify and fix GFF3\")\n    gff_data = GFFSimplifier(args.genome_data)\n    if args.fail_missing_stable_ids:\n        gff_data.stable_ids.make_missing_stable_ids = False\n    gff_data.simpler_gff3(in_gff_path)\n    gff_data.records.to_gff(args.out_gff_path)\n    gff_data.annotations.to_json(args.out_func_path)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/restructure/","title":"restructure","text":""},{"location":"reference/ensembl/io/genomio/gff3/restructure/#ensembl.io.genomio.gff3.restructure","title":"<code>ensembl.io.genomio.gff3.restructure</code>","text":"<p>Restructure a gene model to a standard representation: <code>gene -&gt; [ mRNAs -&gt; [CDSs, exons] ]</code></p>"},{"location":"reference/ensembl/io/genomio/gff3/restructure/#ensembl.io.genomio.gff3.restructure.add_transcript_to_naked_gene","title":"<code>add_transcript_to_naked_gene(gene)</code>","text":"<p>Add an unspecific transcript to a gene without any sub features.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/restructure.py</code> <pre><code>def add_transcript_to_naked_gene(gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Add an unspecific transcript to a gene without any sub features.\"\"\"\n\n    if (len(gene.sub_features) &gt; 0) or (gene.type != \"gene\"):\n        return\n\n    transcript = GFFSeqFeature(gene.location, type=\"transcript\")\n    transcript.qualifiers[\"source\"] = gene.qualifiers[\"source\"]\n    gene.sub_features = [transcript]\n    logging.debug(f\"Inserted 1 transcript for a lone gene {gene.id}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/restructure/#ensembl.io.genomio.gff3.restructure.move_cds_to_existing_mrna","title":"<code>move_cds_to_existing_mrna(gene)</code>","text":"<p>Move CDS child features of a gene to the mRNA.</p> <p>This is to fix the case where we have the following structure::     gene -&gt; [ mRNA, CDSs ]</p> <p>and change it to::     gene -&gt; [ mRNA -&gt; [ CDSs ] ]</p> <p>The mRNA itself might have exons, in which case check that they match the CDS coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>GFFSeqFeature</code> <p>Gene feature to update.</p> required <p>Raises:</p> Type Description <code>GFFParserError</code> <p>If the feature structure is not recognized.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/restructure.py</code> <pre><code>def move_cds_to_existing_mrna(gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Move CDS child features of a gene to the mRNA.\n\n    This is to fix the case where we have the following structure::\n        gene -&gt; [ mRNA, CDSs ]\n\n    and change it to::\n        gene -&gt; [ mRNA -&gt; [ CDSs ] ]\n\n    The mRNA itself might have exons, in which case check that they match the CDS coordinates.\n\n    Args:\n        gene: Gene feature to update.\n\n    Raises:\n        GFFParserError: If the feature structure is not recognized.\n    \"\"\"\n    counts = _get_feat_counts(gene)\n    if not counts.get(\"mRNA\") or not counts.get(\"CDS\"):\n        return\n    if counts[\"mRNA\"] &gt; 1:\n        raise GFFParserError(\n            f\"Can't fix gene {gene.id}: contains several mRNAs and CDSs, all children of the gene\"\n        )\n\n    # First, count the types\n    mrnas = []\n    cdss = []\n\n    gene_subf_clean = []\n    for subf in gene.sub_features:\n        if subf.type == \"mRNA\":\n            mrnas.append(subf)\n        elif subf.type == \"CDS\":\n            cdss.append(subf)\n        else:\n            gene_subf_clean.append(subf)\n\n    mrna = mrnas[0]\n\n    # Check if there are exons (or CDSs) under the mRNA\n    sub_cdss = []\n    sub_exons = []\n    for subf in mrna.sub_features:\n        if subf.type == \"CDS\":\n            sub_cdss.append(subf)\n        elif subf.type == \"exon\":\n            sub_exons.append(subf)\n\n    # Check sub CDSs\n    if sub_cdss:\n        raise GFFParserError(f\"Gene {gene.id} has CDSs as children in both the gene and mRNA\")\n\n    # If there are exons, check they overlap with the CDSs\n    _check_sub_exons(mrna, cdss, sub_exons)\n\n    # No more issues? Move the CDSs, and add any new exons\n    mrna.sub_features += cdss\n    # And remove them from the gene\n    gene.sub_features = gene_subf_clean\n    gene.sub_features.append(mrna)\n    logging.debug(f\"Gene {gene.id}: moved {len(cdss)} CDSs to the mRNA\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/restructure/#ensembl.io.genomio.gff3.restructure.move_only_cdss_to_new_mrna","title":"<code>move_only_cdss_to_new_mrna(gene)</code>","text":"<p>Add intermediate mRNAs to a gene with only CDS children. Do nothing if some sub-features are not CDS.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/restructure.py</code> <pre><code>def move_only_cdss_to_new_mrna(gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Add intermediate mRNAs to a gene with only CDS children.\n    Do nothing if some sub-features are not CDS.\n    \"\"\"\n\n    counts = _get_feat_counts(gene)\n    if (len(counts) != 1) or not counts.get(\"CDS\"):\n        return\n\n    transcripts_dict = {}\n\n    for cds in gene.sub_features:\n        # We create as many transcripts as there are different CDS IDs\n        if cds.id not in transcripts_dict:\n            logging.debug(f\"Create a new mRNA for {cds.id}\")\n            transcript = GFFSeqFeature(gene.location, type=\"mRNA\")\n            transcript.qualifiers[\"source\"] = gene.qualifiers[\"source\"]\n            transcripts_dict[cds.id] = transcript\n\n        # Add the CDS to the transcript\n        transcripts_dict[cds.id].sub_features.append(cds)\n\n        # Also add an exon in the same location\n        exon = GFFSeqFeature(cds.location, type=\"exon\")\n        exon.qualifiers[\"source\"] = gene.qualifiers[\"source\"]\n        transcripts_dict[cds.id].sub_features.append(exon)\n\n    transcripts = list(transcripts_dict.values())\n    gene.sub_features = transcripts\n\n    logging.debug(f\"Insert transcript-exon feats for {gene.id} ({len(transcripts)} CDSs)\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/restructure/#ensembl.io.genomio.gff3.restructure.move_only_exons_to_new_mrna","title":"<code>move_only_exons_to_new_mrna(gene)</code>","text":"<p>Add an mRNA for a gene that only has exons and move the exons under the mRNA. No change if the gene has other sub_features than exon.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/restructure.py</code> <pre><code>def move_only_exons_to_new_mrna(gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Add an mRNA for a gene that only has exons and move the exons under the mRNA.\n    No change if the gene has other sub_features than exon.\n    \"\"\"\n\n    counts = _get_feat_counts(gene)\n    if (len(counts) != 1) or not counts.get(\"exon\"):\n        return\n\n    transcript = GFFSeqFeature(gene.location, type=\"mRNA\")\n    transcript.qualifiers[\"source\"] = gene.qualifiers[\"source\"]\n    transcript.sub_features = gene.sub_features\n    gene.sub_features = [transcript]\n\n    logging.debug(f\"Insert transcript for {gene.id} ({len(gene.sub_features)} exons)\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/restructure/#ensembl.io.genomio.gff3.restructure.remove_cds_from_pseudogene","title":"<code>remove_cds_from_pseudogene(gene)</code>","text":"<p>Removes the CDSs from a pseudogene.</p> <p>This assumes the CDSs are sub features of the transcript or the gene.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/restructure.py</code> <pre><code>def remove_cds_from_pseudogene(gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Removes the CDSs from a pseudogene.\n\n    This assumes the CDSs are sub features of the transcript or the gene.\n\n    \"\"\"\n    if gene.type != \"pseudogene\":\n        return\n\n    gene_subfeats = []\n    for transcript in gene.sub_features:\n        if transcript.type == \"CDS\":\n            logging.debug(f\"Remove pseudo CDS {transcript.id}\")\n        else:\n            new_subfeats = []\n            for feat in transcript.sub_features:\n                if feat.type == \"CDS\":\n                    logging.debug(f\"Remove pseudo CDS {feat.id}\")\n                else:\n                    new_subfeats.append(feat)\n            transcript.sub_features = new_subfeats\n            gene_subfeats.append(transcript)\n    gene.sub_features = gene_subfeats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/restructure/#ensembl.io.genomio.gff3.restructure.remove_extra_exons","title":"<code>remove_extra_exons(gene)</code>","text":"<p>Remove duplicated exons existing in both the gene and the mRNAs.</p> <p>This is a special case where a gene contains proper mRNAs, etc. but also extra exons for the same features. Those exons usually have an ID starting with \"id-\", so that is what we use to detect them.</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>GFFSeqFeature</code> <p>Gene feature to update.</p> required <p>Raises:</p> Type Description <code>GFFParserError</code> <p>If not all exons of this gene start with \"id-\".</p> Source code in <code>src/python/ensembl/io/genomio/gff3/restructure.py</code> <pre><code>def remove_extra_exons(gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Remove duplicated exons existing in both the gene and the mRNAs.\n\n    This is a special case where a gene contains proper mRNAs, etc. but also extra exons for the same\n    features. Those exons usually have an ID starting with \"id-\", so that is what we use to detect them.\n\n    Args:\n        gene: Gene feature to update.\n\n    Raises:\n        GFFParserError: If not all exons of this gene start with \"id-\".\n    \"\"\"\n    counts = _get_feat_counts(gene)\n    if not counts.get(\"mRNA\") and not counts.get(\"exon\"):\n        return\n\n    exons = []\n    mrnas = []\n    others = []\n    for subf in gene.sub_features:\n        if subf.type == \"exon\":\n            exons.append(subf)\n        elif subf.type == \"mRNA\":\n            mrnas.append(subf)\n        else:\n            others.append(subf)\n\n    if exons and mrnas:\n        exon_has_id = 0\n        # Check if the exon ids start with \"id-\", which is an indication that they do not belong here\n        for exon in exons:\n            if exon.id.startswith(\"id-\"):\n                exon_has_id += 1\n        if exon_has_id == len(exons):\n            logging.debug(f\"Remove {exon_has_id} extra exons from {gene.id}\")\n            gene.sub_features = mrnas\n            gene.sub_features += others\n        else:\n            raise GFFParserError(f\"Can't remove extra exons for {gene.id}, not all start with 'id-'\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/restructure/#ensembl.io.genomio.gff3.restructure.restructure_gene","title":"<code>restructure_gene(gene)</code>","text":"<p>Standardize the structure of a gene model: - Add a transcript if there are no children - Move the CDS and exons to an mRNA if they are directly under the gene</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>GFFSeqFeature</code> <p>Gene feature to restructure.</p> required <p>Raises:</p> Type Description <code>GFFParserError</code> <p>If there are CDSs/exons remaining under the gene after applying the fixes.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/restructure.py</code> <pre><code>def restructure_gene(gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Standardize the structure of a gene model:\n    - Add a transcript if there are no children\n    - Move the CDS and exons to an mRNA if they are directly under the gene\n\n    Args:\n        gene: Gene feature to restructure.\n\n    Raises:\n        GFFParserError: If there are CDSs/exons remaining under the gene after applying the fixes.\n    \"\"\"\n    # Skip if the children of the gene look ok\n    counts = _get_feat_counts(gene)\n    if (len(counts) &gt; 0) and not counts.get(\"CDS\") and not counts.get(\"exon\"):\n        return\n\n    # Make sure the gene has a transcript if nothing else\n    add_transcript_to_naked_gene(gene)\n\n    # Corrections if there are CDSs or exons directly under the gene level\n    move_only_cdss_to_new_mrna(gene)\n    move_only_exons_to_new_mrna(gene)\n    move_cds_to_existing_mrna(gene)\n    remove_extra_exons(gene)\n\n    # Check again after fixes that no CDS or exon remain under the gene\n    counts = _get_feat_counts(gene)\n    if counts.get(\"CDS\") or counts.get(\"exon\"):\n        raise GFFParserError(f\"Gene {gene.id} contains direct CDSs and exons children\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/","title":"simplifier","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier","title":"<code>ensembl.io.genomio.gff3.simplifier</code>","text":"<p>Standardize the gene model representation of a GFF3 file, and extract the functional annotation in a separate file.</p>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier","title":"<code>GFFSimplifier</code>","text":"<p>Parse a GGF3 file and output a cleaned up GFF3 + annotation json file.</p> <p>Raises:</p> Type Description <code>GFFParserError</code> <p>If an error cannot be automatically fixed.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>class GFFSimplifier:\n    \"\"\"Parse a GGF3 file and output a cleaned up GFF3 + annotation json file.\n\n    Raises:\n        GFFParserError: If an error cannot be automatically fixed.\n    \"\"\"\n\n    def __init__(\n        self,\n        genome_path: Optional[PathLike] = None,\n        skip_unrecognized: bool = False,\n        allow_pseudogene_with_cds: bool = False,\n    ):\n        \"\"\"Create an object that simplifies `SeqFeature` objects.\n\n        Args:\n            genome_path: Genome metadata file.\n            skip_unrecognized: Do not include unknown biotypes instead of raising an exception.\n            allow_pseudogene_with_cds: Keep CDSs under pseudogenes that have them. Delete them otherwise.\n\n        Raises:\n            GFFParserError: If a biotype is unknown and `skip_unrecognized` is False.\n        \"\"\"\n        self.skip_unrecognized = skip_unrecognized\n        self.allow_pseudogene_with_cds = allow_pseudogene_with_cds\n\n        # Load biotypes\n        source = files(ensembl.io.genomio.data.gff3).joinpath(\"biotypes.json\")\n        with as_file(source) as biotypes_json:\n            self._biotypes = get_json(biotypes_json)\n\n        # Load genome metadata\n        self.genome = {}\n        if genome_path:\n            with Path(genome_path).open(\"r\") as genome_fh:\n                self.genome = json.load(genome_fh)\n\n        self.refseq = False\n        if self.genome and self.genome[\"assembly\"][\"accession\"].startswith(\"GCF\"):\n            self.refseq = True\n\n        # Other preparations\n        self.stable_ids = StableIDAllocator()\n        self.stable_ids.set_prefix(self.genome)\n        self.exclude_seq_regions: List[str] = []\n        self.fail_types: Set = set()\n\n        # Init the actual data we will store\n        self.records = Records()\n        self.annotations = FunctionalAnnotations(self.get_provider_name())\n\n    def get_provider_name(self) -&gt; str:\n        \"\"\"Returns the provider name for this genome.\n\n        If this information is not available, will try to infer it from the assembly accession. Will\n        return \"GenBank\" otherwise.\n        \"\"\"\n        provider_name = \"GenBank\"\n        if self.genome:\n            try:\n                provider_name = self.genome[\"assembly\"][\"provider_name\"]\n            except KeyError:\n                if self.genome[\"assembly\"][\"accession\"].startswith(\"GCF\"):\n                    provider_name = \"RefSeq\"\n        else:\n            logging.warning(f\"No genome file, using the default provider_name: {provider_name}\")\n        return provider_name\n\n    def simpler_gff3(self, in_gff_path: PathLike) -&gt; None:\n        \"\"\"Loads a GFF3 from INSDC and rewrites it in a simpler version, whilst also writing a\n        functional annotation file.\n        \"\"\"\n        self.records.from_gff(in_gff_path, self.exclude_seq_regions)\n        for record in self.records:\n            cleaned_features = []\n            for feature in record.features:\n                split_genes = self.normalize_mirna(feature)\n                if split_genes:\n                    cleaned_features += split_genes\n                else:\n                    try:\n                        clean_feature = self.simpler_gff3_feature(feature)\n                        cleaned_features.append(clean_feature)\n                    except (UnsupportedFeatureError, IgnoredFeatureError) as err:\n                        logging.debug(err.message)\n            record.features = cleaned_features\n\n        if self.fail_types:\n            fail_errors = \"\\n   \".join(list(self.fail_types))\n            logging.warning(f\"Unrecognized types found:\\n   {fail_errors}\")\n            if not self.skip_unrecognized:\n                raise GFFParserError(\"Unrecognized types found, abort\")\n\n    def simpler_gff3_feature(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Creates a simpler version of a GFF3 feature.\n\n        Raises:\n            IgnoredFeatureError: If the feature type is ignored.\n            UnsupportedFeatureError: If the feature type is not supported.\n        \"\"\"\n        # Special cases\n        non_gene = self.normalize_non_gene(gene)\n        if non_gene:\n            return non_gene\n        if gene.type in self._biotypes[\"gene\"][\"ignored\"]:\n            raise IgnoredFeatureError(f\"Ignored type {gene.type} for {gene.id}\")\n\n        # Synonym\n        if gene.type == \"protein_coding_gene\":\n            gene.type = \"gene\"\n\n        # Lone sub-gene features, create a gene\n        gene = self.create_gene_for_lone_transcript(gene)\n        gene = self.create_gene_for_lone_cds(gene)\n\n        # What to do with unsupported gene types\n        if gene.type not in self._biotypes[\"gene\"][\"supported\"]:\n            self.fail_types.add(f\"gene={gene.type}\")\n            raise UnsupportedFeatureError(f\"Unsupported type {gene.type} for {gene.id}\")\n\n        # Normalize and store\n        gene = self.normalize_gene(gene)\n        self.annotations.store_gene(gene)\n        return self.clean_gene(gene)\n\n    def create_gene_for_lone_transcript(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Returns a gene for lone transcripts: 'gene' for tRNA/rRNA/mRNA, and 'ncRNA_gene' for all others.\n\n        Args:\n            feat: The transcript for which we want to create a gene.\n        \"\"\"\n        transcript_types = self._biotypes[\"transcript\"][\"supported\"]\n        if feat.type not in transcript_types:\n            return feat\n\n        new_type = \"ncRNA_gene\"\n        if feat.type in (\"tRNA\", \"rRNA\", \"mRNA\"):\n            new_type = \"gene\"\n        logging.debug(f\"Put the transcript {feat.type} in a {new_type} parent feature\")\n        new_gene = GFFSeqFeature(feat.location, type=new_type)\n        new_gene.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n        new_gene.sub_features = [feat]\n\n        # Use the transcript ID for the gene, and generate a sub ID for the transcript\n        new_gene.id = feat.id\n        new_gene.qualifiers[\"ID\"] = new_gene.id\n        feat.id = self.stable_ids.generate_transcript_id(new_gene.id, 1)\n        feat.qualifiers[\"ID\"] = feat.id\n\n        # Remove the exon/CDS parent so it is properly updated\n        for subfeat in feat.sub_features:\n            del subfeat.qualifiers[\"Parent\"]\n\n        # Check if it's a pseudogene\n        if feat.type == \"mRNA\":\n            is_pseudo = False\n            for subfeat in feat.sub_features:\n                pseudo_qual = subfeat.qualifiers.get(\"pseudo\", [\"\"])[0]\n                if subfeat.type == \"CDS\" and pseudo_qual == \"true\":\n                    is_pseudo = True\n                    del subfeat.qualifiers[\"pseudo\"]\n                    break\n            if is_pseudo:\n                new_gene.type = \"pseudogene\"\n\n        return new_gene\n\n    def create_gene_for_lone_cds(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Returns a gene created for a lone CDS.\n\n        Args:\n            feat: The CDS for which we want to create a gene.\n        \"\"\"\n        if feat.type != \"CDS\":\n            return feat\n\n        logging.debug(f\"Put the lone CDS in gene-mRNA parent features for {feat.id}\")\n\n        # Create a transcript, add the CDS\n        transcript = GFFSeqFeature(feat.location, type=\"mRNA\")\n        transcript.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n        transcript.sub_features = [feat]\n\n        # Add an exon too\n        exon = GFFSeqFeature(feat.location, type=\"exon\")\n        exon.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n        transcript.sub_features.append(exon)\n\n        # Create a gene, add the transcript\n        gene_type = \"gene\"\n        if (\"pseudo\" in feat.qualifiers) and (feat.qualifiers[\"pseudo\"][0] == \"true\"):\n            gene_type = \"pseudogene\"\n            del feat.qualifiers[\"pseudo\"]\n        new_gene = GFFSeqFeature(feat.location, type=gene_type)\n        new_gene.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n        new_gene.sub_features = [transcript]\n        new_gene.id = self.stable_ids.generate_gene_id()\n        new_gene.qualifiers[\"ID\"] = new_gene.id\n        transcript.id = self.stable_ids.generate_transcript_id(new_gene.id, 1)\n        transcript.qualifiers[\"ID\"] = transcript.id\n\n        return new_gene\n\n    def normalize_non_gene(self, feat: GFFSeqFeature) -&gt; Optional[GFFSeqFeature]:\n        \"\"\"Returns a normalised \"non-gene\" or `None` if not applicable.\n\n        Only transposable elements supported at the moment.\n\n        Args:\n            feat: Feature to normalise.\n\n        Raises:\n            NotImplementedError: If the feature is a not supported non-gene.\n        \"\"\"\n\n        if feat.type not in self._biotypes[\"non_gene\"][\"supported\"]:\n            return None\n        if feat.type in (\"mobile_genetic_element\", \"transposable_element\"):\n            feat.type = \"transposable_element\"\n            feat = self._normalize_mobile_genetic_element(feat)\n            # Generate ID if needed\n            feat.id = self.stable_ids.normalize_gene_id(feat, self.refseq)\n            feat.qualifiers[\"ID\"] = feat.id\n\n            self.annotations.add_feature(feat, \"transposable_element\")\n            return self.clean_gene(feat)\n        # This is a failsafe in case you add supported non-genes\n        raise NotImplementedError(f\"Unsupported non-gene: {feat.type} for {feat.id}\")\n\n    def _normalize_mobile_genetic_element(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Normalize a mobile element if it has a mobile_element_type field.\"\"\"\n        try:\n            mobile_element_type = feat.qualifiers[\"mobile_element_type\"]\n        except KeyError:\n            logging.warning(\"No 'mobile_element_type' tag found\")\n            return feat\n\n        # Get the type (and name) from the attrib\n        element_type, _, element_name = mobile_element_type[0].partition(\":\")\n        description = element_type\n        if element_name:\n            description += f\" ({element_name})\"\n\n        # Keep the metadata in the description if the type is known\n        if element_type in (\"transposon\", \"retrotransposon\"):\n            if not feat.qualifiers.get(\"product\"):\n                feat.qualifiers[\"product\"] = [description]\n            return feat\n        raise GFFParserError(f\"'mobile_element_type' is not a transposon: {element_type}\")\n\n    def clean_gene(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Return the same gene without qualifiers unrelated to the gene structure.\"\"\"\n\n        old_gene_qualifiers = gene.qualifiers\n        gene.qualifiers = {\"ID\": gene.id, \"source\": old_gene_qualifiers[\"source\"]}\n        for transcript in gene.sub_features:\n            # Replace qualifiers\n            old_transcript_qualifiers = transcript.qualifiers\n            transcript.qualifiers = {\n                \"ID\": transcript.id,\n                \"Parent\": gene.id,\n                \"source\": old_transcript_qualifiers[\"source\"],\n            }\n\n            for feat in transcript.sub_features:\n                old_qualifiers = feat.qualifiers\n                feat.qualifiers = {\n                    \"ID\": feat.id,\n                    \"Parent\": transcript.id,\n                    \"source\": old_qualifiers[\"source\"],\n                }\n                if feat.type == \"CDS\":\n                    feat.qualifiers[\"phase\"] = old_qualifiers[\"phase\"]\n\n        return gene\n\n    def normalize_gene(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Returns a normalized gene structure, separate from the functional elements.\n\n        Args:\n            gene: Gene object to normalize.\n            functional_annotation: List of feature annotations (appended by this method).\n\n        \"\"\"\n\n        gene.id = self.stable_ids.normalize_gene_id(gene, refseq=self.refseq)\n        restructure_gene(gene)\n        self.normalize_transcripts(gene)\n        self.normalize_pseudogene(gene)\n\n        return gene\n\n    def normalize_pseudogene(self, gene: GFFSeqFeature) -&gt; None:\n        \"\"\"Normalize CDSs if allowed, otherwise remove them.\"\"\"\n        if gene.type != \"pseudogene\":\n            return\n\n        if self.allow_pseudogene_with_cds:\n            self.stable_ids.normalize_pseudogene_cds_id(gene)\n        else:\n            remove_cds_from_pseudogene(gene)\n\n    def normalize_transcripts(self, gene: GFFSeqFeature) -&gt; None:\n        \"\"\"Normalizes a transcript.\"\"\"\n\n        allowed_transcript_types = self._biotypes[\"transcript\"][\"supported\"]\n        ignored_transcript_types = self._biotypes[\"transcript\"][\"ignored\"]\n\n        transcripts_to_delete = []\n        for count, transcript in enumerate(gene.sub_features):\n            if (\n                transcript.type not in allowed_transcript_types\n                and transcript.type not in ignored_transcript_types\n            ):\n                self.fail_types.add(f\"transcript={transcript.type}\")\n                logging.warning(\n                    f\"Unrecognized transcript type: {transcript.type}\" f\" for {transcript.id} ({gene.id})\"\n                )\n                transcripts_to_delete.append(count)\n                continue\n\n            # New transcript ID\n            transcript_number = count + 1\n            transcript.id = self.stable_ids.generate_transcript_id(gene.id, transcript_number)\n\n            transcript = self.format_gene_segments(transcript)\n\n            # EXONS AND CDS\n            transcript = self._normalize_transcript_subfeatures(gene, transcript)\n\n        if transcripts_to_delete:\n            for elt in sorted(transcripts_to_delete, reverse=True):\n                gene.sub_features.pop(elt)\n\n    def format_gene_segments(self, transcript: GFFSeqFeature) -&gt; GFFSeqFeature:\n        \"\"\"Returns the equivalent Ensembl biotype feature for gene segment transcript features.\n\n        Supported features: \"C_gene_segment\" and \"V_gene_segment\".\n\n        Args:\n            transcript: Gene segment transcript feature.\n\n        Raises:\n            GeneSegmentError: Unable to get the segment type information from the feature.\n        \"\"\"\n        if transcript.type not in (\"C_gene_segment\", \"V_gene_segment\"):\n            return transcript\n\n        # Guess the segment type from the transcript attribs\n        seg_type = self._get_segment_type(transcript)\n        if not seg_type:\n            # Get the information from a CDS instead\n            sub_feats: List[GFFSeqFeature] = transcript.sub_features\n            cdss: List[GFFSeqFeature] = list(filter(lambda x: x.type == \"CDS\", sub_feats))\n            if cdss:\n                seg_type = self._get_segment_type(cdss[0])\n            if not seg_type:\n                raise GeneSegmentError(f\"Unable to infer segment from {transcript.id}\")\n\n        # Change V/C_gene_segment into a its corresponding transcript names\n        transcript.type = f\"{seg_type}_{transcript.type.replace('_segment', '')}\"\n        return transcript\n\n    def _get_segment_type(self, feature: GFFSeqFeature) -&gt; str:\n        \"\"\"Infer if a segment is \"IG\" (immunoglobulin) of \"TR\" (t-cell) from the feature attribs.\n\n        Returns an empty string if no segment type info was found.\n        \"\"\"\n\n        product = feature.qualifiers.get(\"standard_name\", [\"\"])[0]\n        if not product:\n            product = feature.qualifiers.get(\"product\", [\"\"])[0]\n        if not product:\n            return \"\"\n\n        if re.search(r\"\\b(immunoglobulin|ig)\\b\", product, flags=re.IGNORECASE):\n            return \"IG\"\n        if re.search(r\"\\bt[- _]cell\\b\", product, flags=re.IGNORECASE):\n            return \"TR\"\n        return \"\"\n\n    def _normalize_transcript_subfeatures(\n        self, gene: GFFSeqFeature, transcript: GFFSeqFeature\n    ) -&gt; GFFSeqFeature:\n        \"\"\"Returns a transcript with normalized sub-features.\"\"\"\n        exons_to_delete = []\n        exon_number = 1\n        for tcount, feat in enumerate(transcript.sub_features):\n            if feat.type == \"exon\":\n                # New exon ID\n                feat.id = f\"{transcript.id}-E{exon_number}\"\n                exon_number += 1\n                # Replace qualifiers\n                old_exon_qualifiers = feat.qualifiers\n                feat.qualifiers = {\"Parent\": transcript.id}\n                feat.qualifiers[\"source\"] = old_exon_qualifiers[\"source\"]\n            elif feat.type == \"CDS\":\n                # New CDS ID\n                feat.id = self.stable_ids.normalize_cds_id(feat.id)\n                if feat.id in (\"\", gene.id, transcript.id):\n                    feat.id = f\"{transcript.id}_cds\"\n            else:\n                if feat.type in self._biotypes[\"transcript\"][\"ignored\"]:\n                    exons_to_delete.append(tcount)\n                    continue\n\n                self.fail_types.add(f\"sub_transcript={feat.type}\")\n                logging.warning(\n                    f\"Unrecognized exon type for {feat.type}: {feat.id}\"\n                    f\" (for transcript {transcript.id} of type {transcript.type})\"\n                )\n                exons_to_delete.append(tcount)\n                continue\n\n        if exons_to_delete:\n            for elt in sorted(exons_to_delete, reverse=True):\n                transcript.sub_features.pop(elt)\n        return transcript\n\n    def normalize_mirna(self, gene: GFFSeqFeature) -&gt; List[GFFSeqFeature]:\n        \"\"\"Returns gene representations from a miRNA gene that can be loaded in an Ensembl database.\n\n        Change the representation from the form `gene[ primary_transcript[ exon, miRNA[ exon ] ] ]`\n        to `ncRNA_gene[ miRNA_primary_transcript[ exon ] ]` and `gene[ miRNA[ exon ] ]`\n\n        Raises:\n            GFFParserError: If gene has more than 1 transcript, the transcript was not formatted\n                correctly or there are unknown sub-features.\n        \"\"\"\n        base_id = gene.id\n        transcripts = gene.sub_features\n\n        # Insert main gene first if needed\n        old_gene = gene\n        if gene.type == \"primary_transcript\":\n            primary = old_gene\n            gene = GFFSeqFeature(primary.location, type=\"gene\")\n            gene.sub_features = [primary]\n            gene.qualifiers = primary.qualifiers\n            transcripts = gene.sub_features\n            gene.id = f\"{base_id}_0\"\n            gene.qualifiers[\"ID\"] = gene.id\n\n        if (len(transcripts) == 0) or (transcripts[0].type != \"primary_transcript\"):\n            return []\n        if len(transcripts) &gt; 1:\n            raise GFFParserError(f\"Gene has too many sub_features for miRNA {gene.id}\")\n\n        # Passed the checks\n        primary = transcripts[0]\n        primary.type = \"miRNA_primary_transcript\"\n        gene.type = \"ncRNA_gene\"\n        logging.debug(f\"Formatting miRNA gene {gene.id}\")\n\n        new_genes = []\n        new_primary_subfeatures = []\n        num = 1\n        for sub in primary.sub_features:\n            if sub.type == \"exon\":\n                new_primary_subfeatures.append(sub)\n            elif sub.type == \"miRNA\":\n                new_gene_id = f\"{base_id}_{num}\"\n                num += 1\n                new_gene = GFFSeqFeature(sub.location, type=\"gene\", id=new_gene_id)\n                new_gene.qualifiers = {\"source\": sub.qualifiers[\"source\"], \"ID\": new_gene_id}\n                new_gene.sub_features = [sub]\n                new_genes.append(new_gene)\n            else:\n                raise GFFParserError(f\"Unknown subtypes for miRNA features: {sub.id}\")\n        primary.sub_features = new_primary_subfeatures\n\n        if not new_genes:\n            logging.debug(f\"Primary_transcript without miRNA in {gene.id}\")\n            all_genes = [gene]\n        else:\n            all_genes = [gene] + new_genes\n\n        # Normalize like other genes\n        all_genes_cleaned = []\n        for new_gene in all_genes:\n            new_gene = self.normalize_gene(new_gene)\n            self.annotations.store_gene(new_gene)\n            all_genes_cleaned.append(self.clean_gene(new_gene))\n        return all_genes_cleaned\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.allow_pseudogene_with_cds","title":"<code>allow_pseudogene_with_cds = allow_pseudogene_with_cds</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.annotations","title":"<code>annotations = FunctionalAnnotations(self.get_provider_name())</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.exclude_seq_regions","title":"<code>exclude_seq_regions = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.fail_types","title":"<code>fail_types = set()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.genome","title":"<code>genome = json.load(genome_fh)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.records","title":"<code>records = Records()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.refseq","title":"<code>refseq = False</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.skip_unrecognized","title":"<code>skip_unrecognized = skip_unrecognized</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.stable_ids","title":"<code>stable_ids = StableIDAllocator()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.clean_gene","title":"<code>clean_gene(gene)</code>","text":"<p>Return the same gene without qualifiers unrelated to the gene structure.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def clean_gene(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Return the same gene without qualifiers unrelated to the gene structure.\"\"\"\n\n    old_gene_qualifiers = gene.qualifiers\n    gene.qualifiers = {\"ID\": gene.id, \"source\": old_gene_qualifiers[\"source\"]}\n    for transcript in gene.sub_features:\n        # Replace qualifiers\n        old_transcript_qualifiers = transcript.qualifiers\n        transcript.qualifiers = {\n            \"ID\": transcript.id,\n            \"Parent\": gene.id,\n            \"source\": old_transcript_qualifiers[\"source\"],\n        }\n\n        for feat in transcript.sub_features:\n            old_qualifiers = feat.qualifiers\n            feat.qualifiers = {\n                \"ID\": feat.id,\n                \"Parent\": transcript.id,\n                \"source\": old_qualifiers[\"source\"],\n            }\n            if feat.type == \"CDS\":\n                feat.qualifiers[\"phase\"] = old_qualifiers[\"phase\"]\n\n    return gene\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.create_gene_for_lone_cds","title":"<code>create_gene_for_lone_cds(feat)</code>","text":"<p>Returns a gene created for a lone CDS.</p> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>GFFSeqFeature</code> <p>The CDS for which we want to create a gene.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def create_gene_for_lone_cds(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Returns a gene created for a lone CDS.\n\n    Args:\n        feat: The CDS for which we want to create a gene.\n    \"\"\"\n    if feat.type != \"CDS\":\n        return feat\n\n    logging.debug(f\"Put the lone CDS in gene-mRNA parent features for {feat.id}\")\n\n    # Create a transcript, add the CDS\n    transcript = GFFSeqFeature(feat.location, type=\"mRNA\")\n    transcript.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n    transcript.sub_features = [feat]\n\n    # Add an exon too\n    exon = GFFSeqFeature(feat.location, type=\"exon\")\n    exon.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n    transcript.sub_features.append(exon)\n\n    # Create a gene, add the transcript\n    gene_type = \"gene\"\n    if (\"pseudo\" in feat.qualifiers) and (feat.qualifiers[\"pseudo\"][0] == \"true\"):\n        gene_type = \"pseudogene\"\n        del feat.qualifiers[\"pseudo\"]\n    new_gene = GFFSeqFeature(feat.location, type=gene_type)\n    new_gene.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n    new_gene.sub_features = [transcript]\n    new_gene.id = self.stable_ids.generate_gene_id()\n    new_gene.qualifiers[\"ID\"] = new_gene.id\n    transcript.id = self.stable_ids.generate_transcript_id(new_gene.id, 1)\n    transcript.qualifiers[\"ID\"] = transcript.id\n\n    return new_gene\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.create_gene_for_lone_transcript","title":"<code>create_gene_for_lone_transcript(feat)</code>","text":"<p>Returns a gene for lone transcripts: 'gene' for tRNA/rRNA/mRNA, and 'ncRNA_gene' for all others.</p> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>GFFSeqFeature</code> <p>The transcript for which we want to create a gene.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def create_gene_for_lone_transcript(self, feat: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Returns a gene for lone transcripts: 'gene' for tRNA/rRNA/mRNA, and 'ncRNA_gene' for all others.\n\n    Args:\n        feat: The transcript for which we want to create a gene.\n    \"\"\"\n    transcript_types = self._biotypes[\"transcript\"][\"supported\"]\n    if feat.type not in transcript_types:\n        return feat\n\n    new_type = \"ncRNA_gene\"\n    if feat.type in (\"tRNA\", \"rRNA\", \"mRNA\"):\n        new_type = \"gene\"\n    logging.debug(f\"Put the transcript {feat.type} in a {new_type} parent feature\")\n    new_gene = GFFSeqFeature(feat.location, type=new_type)\n    new_gene.qualifiers[\"source\"] = feat.qualifiers[\"source\"]\n    new_gene.sub_features = [feat]\n\n    # Use the transcript ID for the gene, and generate a sub ID for the transcript\n    new_gene.id = feat.id\n    new_gene.qualifiers[\"ID\"] = new_gene.id\n    feat.id = self.stable_ids.generate_transcript_id(new_gene.id, 1)\n    feat.qualifiers[\"ID\"] = feat.id\n\n    # Remove the exon/CDS parent so it is properly updated\n    for subfeat in feat.sub_features:\n        del subfeat.qualifiers[\"Parent\"]\n\n    # Check if it's a pseudogene\n    if feat.type == \"mRNA\":\n        is_pseudo = False\n        for subfeat in feat.sub_features:\n            pseudo_qual = subfeat.qualifiers.get(\"pseudo\", [\"\"])[0]\n            if subfeat.type == \"CDS\" and pseudo_qual == \"true\":\n                is_pseudo = True\n                del subfeat.qualifiers[\"pseudo\"]\n                break\n        if is_pseudo:\n            new_gene.type = \"pseudogene\"\n\n    return new_gene\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.format_gene_segments","title":"<code>format_gene_segments(transcript)</code>","text":"<p>Returns the equivalent Ensembl biotype feature for gene segment transcript features.</p> <p>Supported features: \"C_gene_segment\" and \"V_gene_segment\".</p> <p>Parameters:</p> Name Type Description Default <code>transcript</code> <code>GFFSeqFeature</code> <p>Gene segment transcript feature.</p> required <p>Raises:</p> Type Description <code>GeneSegmentError</code> <p>Unable to get the segment type information from the feature.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def format_gene_segments(self, transcript: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Returns the equivalent Ensembl biotype feature for gene segment transcript features.\n\n    Supported features: \"C_gene_segment\" and \"V_gene_segment\".\n\n    Args:\n        transcript: Gene segment transcript feature.\n\n    Raises:\n        GeneSegmentError: Unable to get the segment type information from the feature.\n    \"\"\"\n    if transcript.type not in (\"C_gene_segment\", \"V_gene_segment\"):\n        return transcript\n\n    # Guess the segment type from the transcript attribs\n    seg_type = self._get_segment_type(transcript)\n    if not seg_type:\n        # Get the information from a CDS instead\n        sub_feats: List[GFFSeqFeature] = transcript.sub_features\n        cdss: List[GFFSeqFeature] = list(filter(lambda x: x.type == \"CDS\", sub_feats))\n        if cdss:\n            seg_type = self._get_segment_type(cdss[0])\n        if not seg_type:\n            raise GeneSegmentError(f\"Unable to infer segment from {transcript.id}\")\n\n    # Change V/C_gene_segment into a its corresponding transcript names\n    transcript.type = f\"{seg_type}_{transcript.type.replace('_segment', '')}\"\n    return transcript\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.get_provider_name","title":"<code>get_provider_name()</code>","text":"<p>Returns the provider name for this genome.</p> <p>If this information is not available, will try to infer it from the assembly accession. Will return \"GenBank\" otherwise.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def get_provider_name(self) -&gt; str:\n    \"\"\"Returns the provider name for this genome.\n\n    If this information is not available, will try to infer it from the assembly accession. Will\n    return \"GenBank\" otherwise.\n    \"\"\"\n    provider_name = \"GenBank\"\n    if self.genome:\n        try:\n            provider_name = self.genome[\"assembly\"][\"provider_name\"]\n        except KeyError:\n            if self.genome[\"assembly\"][\"accession\"].startswith(\"GCF\"):\n                provider_name = \"RefSeq\"\n    else:\n        logging.warning(f\"No genome file, using the default provider_name: {provider_name}\")\n    return provider_name\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.normalize_gene","title":"<code>normalize_gene(gene)</code>","text":"<p>Returns a normalized gene structure, separate from the functional elements.</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>GFFSeqFeature</code> <p>Gene object to normalize.</p> required <code>functional_annotation</code> <p>List of feature annotations (appended by this method).</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_gene(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Returns a normalized gene structure, separate from the functional elements.\n\n    Args:\n        gene: Gene object to normalize.\n        functional_annotation: List of feature annotations (appended by this method).\n\n    \"\"\"\n\n    gene.id = self.stable_ids.normalize_gene_id(gene, refseq=self.refseq)\n    restructure_gene(gene)\n    self.normalize_transcripts(gene)\n    self.normalize_pseudogene(gene)\n\n    return gene\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.normalize_mirna","title":"<code>normalize_mirna(gene)</code>","text":"<p>Returns gene representations from a miRNA gene that can be loaded in an Ensembl database.</p> <p>Change the representation from the form <code>gene[ primary_transcript[ exon, miRNA[ exon ] ] ]</code> to <code>ncRNA_gene[ miRNA_primary_transcript[ exon ] ]</code> and <code>gene[ miRNA[ exon ] ]</code></p> <p>Raises:</p> Type Description <code>GFFParserError</code> <p>If gene has more than 1 transcript, the transcript was not formatted correctly or there are unknown sub-features.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_mirna(self, gene: GFFSeqFeature) -&gt; List[GFFSeqFeature]:\n    \"\"\"Returns gene representations from a miRNA gene that can be loaded in an Ensembl database.\n\n    Change the representation from the form `gene[ primary_transcript[ exon, miRNA[ exon ] ] ]`\n    to `ncRNA_gene[ miRNA_primary_transcript[ exon ] ]` and `gene[ miRNA[ exon ] ]`\n\n    Raises:\n        GFFParserError: If gene has more than 1 transcript, the transcript was not formatted\n            correctly or there are unknown sub-features.\n    \"\"\"\n    base_id = gene.id\n    transcripts = gene.sub_features\n\n    # Insert main gene first if needed\n    old_gene = gene\n    if gene.type == \"primary_transcript\":\n        primary = old_gene\n        gene = GFFSeqFeature(primary.location, type=\"gene\")\n        gene.sub_features = [primary]\n        gene.qualifiers = primary.qualifiers\n        transcripts = gene.sub_features\n        gene.id = f\"{base_id}_0\"\n        gene.qualifiers[\"ID\"] = gene.id\n\n    if (len(transcripts) == 0) or (transcripts[0].type != \"primary_transcript\"):\n        return []\n    if len(transcripts) &gt; 1:\n        raise GFFParserError(f\"Gene has too many sub_features for miRNA {gene.id}\")\n\n    # Passed the checks\n    primary = transcripts[0]\n    primary.type = \"miRNA_primary_transcript\"\n    gene.type = \"ncRNA_gene\"\n    logging.debug(f\"Formatting miRNA gene {gene.id}\")\n\n    new_genes = []\n    new_primary_subfeatures = []\n    num = 1\n    for sub in primary.sub_features:\n        if sub.type == \"exon\":\n            new_primary_subfeatures.append(sub)\n        elif sub.type == \"miRNA\":\n            new_gene_id = f\"{base_id}_{num}\"\n            num += 1\n            new_gene = GFFSeqFeature(sub.location, type=\"gene\", id=new_gene_id)\n            new_gene.qualifiers = {\"source\": sub.qualifiers[\"source\"], \"ID\": new_gene_id}\n            new_gene.sub_features = [sub]\n            new_genes.append(new_gene)\n        else:\n            raise GFFParserError(f\"Unknown subtypes for miRNA features: {sub.id}\")\n    primary.sub_features = new_primary_subfeatures\n\n    if not new_genes:\n        logging.debug(f\"Primary_transcript without miRNA in {gene.id}\")\n        all_genes = [gene]\n    else:\n        all_genes = [gene] + new_genes\n\n    # Normalize like other genes\n    all_genes_cleaned = []\n    for new_gene in all_genes:\n        new_gene = self.normalize_gene(new_gene)\n        self.annotations.store_gene(new_gene)\n        all_genes_cleaned.append(self.clean_gene(new_gene))\n    return all_genes_cleaned\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.normalize_non_gene","title":"<code>normalize_non_gene(feat)</code>","text":"<p>Returns a normalised \"non-gene\" or <code>None</code> if not applicable.</p> <p>Only transposable elements supported at the moment.</p> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>GFFSeqFeature</code> <p>Feature to normalise.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the feature is a not supported non-gene.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_non_gene(self, feat: GFFSeqFeature) -&gt; Optional[GFFSeqFeature]:\n    \"\"\"Returns a normalised \"non-gene\" or `None` if not applicable.\n\n    Only transposable elements supported at the moment.\n\n    Args:\n        feat: Feature to normalise.\n\n    Raises:\n        NotImplementedError: If the feature is a not supported non-gene.\n    \"\"\"\n\n    if feat.type not in self._biotypes[\"non_gene\"][\"supported\"]:\n        return None\n    if feat.type in (\"mobile_genetic_element\", \"transposable_element\"):\n        feat.type = \"transposable_element\"\n        feat = self._normalize_mobile_genetic_element(feat)\n        # Generate ID if needed\n        feat.id = self.stable_ids.normalize_gene_id(feat, self.refseq)\n        feat.qualifiers[\"ID\"] = feat.id\n\n        self.annotations.add_feature(feat, \"transposable_element\")\n        return self.clean_gene(feat)\n    # This is a failsafe in case you add supported non-genes\n    raise NotImplementedError(f\"Unsupported non-gene: {feat.type} for {feat.id}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.normalize_pseudogene","title":"<code>normalize_pseudogene(gene)</code>","text":"<p>Normalize CDSs if allowed, otherwise remove them.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_pseudogene(self, gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Normalize CDSs if allowed, otherwise remove them.\"\"\"\n    if gene.type != \"pseudogene\":\n        return\n\n    if self.allow_pseudogene_with_cds:\n        self.stable_ids.normalize_pseudogene_cds_id(gene)\n    else:\n        remove_cds_from_pseudogene(gene)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.normalize_transcripts","title":"<code>normalize_transcripts(gene)</code>","text":"<p>Normalizes a transcript.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def normalize_transcripts(self, gene: GFFSeqFeature) -&gt; None:\n    \"\"\"Normalizes a transcript.\"\"\"\n\n    allowed_transcript_types = self._biotypes[\"transcript\"][\"supported\"]\n    ignored_transcript_types = self._biotypes[\"transcript\"][\"ignored\"]\n\n    transcripts_to_delete = []\n    for count, transcript in enumerate(gene.sub_features):\n        if (\n            transcript.type not in allowed_transcript_types\n            and transcript.type not in ignored_transcript_types\n        ):\n            self.fail_types.add(f\"transcript={transcript.type}\")\n            logging.warning(\n                f\"Unrecognized transcript type: {transcript.type}\" f\" for {transcript.id} ({gene.id})\"\n            )\n            transcripts_to_delete.append(count)\n            continue\n\n        # New transcript ID\n        transcript_number = count + 1\n        transcript.id = self.stable_ids.generate_transcript_id(gene.id, transcript_number)\n\n        transcript = self.format_gene_segments(transcript)\n\n        # EXONS AND CDS\n        transcript = self._normalize_transcript_subfeatures(gene, transcript)\n\n    if transcripts_to_delete:\n        for elt in sorted(transcripts_to_delete, reverse=True):\n            gene.sub_features.pop(elt)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.simpler_gff3","title":"<code>simpler_gff3(in_gff_path)</code>","text":"<p>Loads a GFF3 from INSDC and rewrites it in a simpler version, whilst also writing a functional annotation file.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def simpler_gff3(self, in_gff_path: PathLike) -&gt; None:\n    \"\"\"Loads a GFF3 from INSDC and rewrites it in a simpler version, whilst also writing a\n    functional annotation file.\n    \"\"\"\n    self.records.from_gff(in_gff_path, self.exclude_seq_regions)\n    for record in self.records:\n        cleaned_features = []\n        for feature in record.features:\n            split_genes = self.normalize_mirna(feature)\n            if split_genes:\n                cleaned_features += split_genes\n            else:\n                try:\n                    clean_feature = self.simpler_gff3_feature(feature)\n                    cleaned_features.append(clean_feature)\n                except (UnsupportedFeatureError, IgnoredFeatureError) as err:\n                    logging.debug(err.message)\n        record.features = cleaned_features\n\n    if self.fail_types:\n        fail_errors = \"\\n   \".join(list(self.fail_types))\n        logging.warning(f\"Unrecognized types found:\\n   {fail_errors}\")\n        if not self.skip_unrecognized:\n            raise GFFParserError(\"Unrecognized types found, abort\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.GFFSimplifier.simpler_gff3_feature","title":"<code>simpler_gff3_feature(gene)</code>","text":"<p>Creates a simpler version of a GFF3 feature.</p> <p>Raises:</p> Type Description <code>IgnoredFeatureError</code> <p>If the feature type is ignored.</p> <code>UnsupportedFeatureError</code> <p>If the feature type is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def simpler_gff3_feature(self, gene: GFFSeqFeature) -&gt; GFFSeqFeature:\n    \"\"\"Creates a simpler version of a GFF3 feature.\n\n    Raises:\n        IgnoredFeatureError: If the feature type is ignored.\n        UnsupportedFeatureError: If the feature type is not supported.\n    \"\"\"\n    # Special cases\n    non_gene = self.normalize_non_gene(gene)\n    if non_gene:\n        return non_gene\n    if gene.type in self._biotypes[\"gene\"][\"ignored\"]:\n        raise IgnoredFeatureError(f\"Ignored type {gene.type} for {gene.id}\")\n\n    # Synonym\n    if gene.type == \"protein_coding_gene\":\n        gene.type = \"gene\"\n\n    # Lone sub-gene features, create a gene\n    gene = self.create_gene_for_lone_transcript(gene)\n    gene = self.create_gene_for_lone_cds(gene)\n\n    # What to do with unsupported gene types\n    if gene.type not in self._biotypes[\"gene\"][\"supported\"]:\n        self.fail_types.add(f\"gene={gene.type}\")\n        raise UnsupportedFeatureError(f\"Unsupported type {gene.type} for {gene.id}\")\n\n    # Normalize and store\n    gene = self.normalize_gene(gene)\n    self.annotations.store_gene(gene)\n    return self.clean_gene(gene)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.Records","title":"<code>Records</code>","text":"<p>               Bases: <code>list</code></p> <p>List of GFF3 SeqRecords.</p> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>class Records(list):\n    \"\"\"List of GFF3 SeqRecords.\"\"\"\n\n    def from_gff(self, in_gff_path: PathLike, excluded: Optional[List[str]] = None) -&gt; None:\n        \"\"\"Loads records from a GFF3 file.\n\n        Args:\n            in_gff_path: Input GFF3 file path.\n            excluded: Record IDs to not load from the GFF3 file.\n        \"\"\"\n        if excluded is None:\n            excluded = []\n        with Path(in_gff_path).open(\"r\") as in_gff_fh:\n            for record in GFF.parse(in_gff_fh):\n                if record.id in excluded:\n                    logging.debug(f\"Skip seq_region {record.id} - in exclusion list\")\n                    continue\n                clean_record = SeqRecord(record.seq, id=record.id)\n                clean_record.features = record.features\n                self.append(clean_record)\n\n    def to_gff(self, out_gff_path: PathLike) -&gt; None:\n        \"\"\"Writes the current list of records in a GFF3 file.\n\n        Args:\n            out_gff_path: Path to GFF3 file where to write the records.\n        \"\"\"\n        with Path(out_gff_path).open(\"w\") as out_gff_fh:\n            GFF.write(self, out_gff_fh)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.Records.from_gff","title":"<code>from_gff(in_gff_path, excluded=None)</code>","text":"<p>Loads records from a GFF3 file.</p> <p>Parameters:</p> Name Type Description Default <code>in_gff_path</code> <code>PathLike</code> <p>Input GFF3 file path.</p> required <code>excluded</code> <code>Optional[List[str]]</code> <p>Record IDs to not load from the GFF3 file.</p> <code>None</code> Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def from_gff(self, in_gff_path: PathLike, excluded: Optional[List[str]] = None) -&gt; None:\n    \"\"\"Loads records from a GFF3 file.\n\n    Args:\n        in_gff_path: Input GFF3 file path.\n        excluded: Record IDs to not load from the GFF3 file.\n    \"\"\"\n    if excluded is None:\n        excluded = []\n    with Path(in_gff_path).open(\"r\") as in_gff_fh:\n        for record in GFF.parse(in_gff_fh):\n            if record.id in excluded:\n                logging.debug(f\"Skip seq_region {record.id} - in exclusion list\")\n                continue\n            clean_record = SeqRecord(record.seq, id=record.id)\n            clean_record.features = record.features\n            self.append(clean_record)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/gff3/simplifier/#ensembl.io.genomio.gff3.simplifier.Records.to_gff","title":"<code>to_gff(out_gff_path)</code>","text":"<p>Writes the current list of records in a GFF3 file.</p> <p>Parameters:</p> Name Type Description Default <code>out_gff_path</code> <code>PathLike</code> <p>Path to GFF3 file where to write the records.</p> required Source code in <code>src/python/ensembl/io/genomio/gff3/simplifier.py</code> <pre><code>def to_gff(self, out_gff_path: PathLike) -&gt; None:\n    \"\"\"Writes the current list of records in a GFF3 file.\n\n    Args:\n        out_gff_path: Path to GFF3 file where to write the records.\n    \"\"\"\n    with Path(out_gff_path).open(\"w\") as out_gff_fh:\n        GFF.write(self, out_gff_fh)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/","title":"manifest","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest","title":"<code>ensembl.io.genomio.manifest</code>","text":"<p>Manifest files handling module.</p>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.StatsLengths","title":"<code>StatsLengths = dict[str, int]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser","title":"<code>ArgumentParser</code>","text":"<p>               Bases: <code>ArgumentParser</code></p> <p>Extends <code>argparse.ArgumentParser</code> with additional methods and functionality.</p> <p>The default behaviour of the help text will be to display the default values on every non-required argument, i.e. optional arguments with <code>required=False</code>.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>class ArgumentParser(argparse.ArgumentParser):\n    \"\"\"Extends `argparse.ArgumentParser` with additional methods and functionality.\n\n    The default behaviour of the help text will be to display the default values on every non-required\n    argument, i.e. optional arguments with `required=False`.\n\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Extends the base class to include the information about default argument values by default.\"\"\"\n        super().__init__(*args, **kwargs)\n        self.formatter_class = argparse.ArgumentDefaultsHelpFormatter\n\n    def _validate_src_path(self, src_path: StrPath) -&gt; Path:\n        \"\"\"Returns the path if exists and it is readable, raises an error through the parser otherwise.\n\n        Args:\n            src_path: File or directory path to check.\n\n        \"\"\"\n        src_path = Path(src_path)\n        if not src_path.exists():\n            self.error(f\"'{src_path}' not found\")\n        elif not os.access(src_path, os.R_OK):\n            self.error(f\"'{src_path}' not readable\")\n        return src_path\n\n    def _validate_dst_path(self, dst_path: StrPath, exists_ok: bool = False) -&gt; Path:\n        \"\"\"Returns the path if it is writable, raises an error through the parser otherwise.\n\n        Args:\n            dst_path: File or directory path to check.\n            exists_ok: Do not raise an error during parsing if the destination path already exists.\n\n        \"\"\"\n        dst_path = Path(dst_path)\n        if dst_path.exists():\n            if os.access(dst_path, os.W_OK):\n                if exists_ok:\n                    return dst_path\n                self.error(f\"'{dst_path}' already exists\")\n            else:\n                self.error(f\"'{dst_path}' is not writable\")\n        # Check if the first parent directory that exists is writable\n        for parent_path in dst_path.parents:\n            if parent_path.exists():\n                if not os.access(parent_path, os.W_OK):\n                    self.error(f\"'{dst_path}' is not writable\")\n                break\n        return dst_path\n\n    def _validate_number(\n        self,\n        value: str,\n        value_type: Callable[[str], int | float],\n        min_value: int | float | None,\n        max_value: int | float | None,\n    ) -&gt; int | float:\n        \"\"\"Returns the numeric value if it is of the expected type and it is within the specified range.\n\n        Args:\n            value: String representation of numeric value to check.\n            value_type: Expected type of the numeric value.\n            min_value: Minimum value constrain. If `None`, no minimum value constrain.\n            max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n        \"\"\"\n        # Check if the string representation can be converted to the expected type\n        try:\n            result = value_type(value)\n        except (TypeError, ValueError):\n            self.error(f\"invalid {value_type.__name__} value: {value}\")\n        # Check if numeric value is within range\n        if (min_value is not None) and (result &lt; min_value):\n            self.error(f\"{value} is lower than minimum value ({min_value})\")\n        if (max_value is not None) and (result &gt; max_value):\n            self.error(f\"{value} is greater than maximum value ({max_value})\")\n        return result\n\n    def add_argument(self, *args: Any, **kwargs: Any) -&gt; None:  # type: ignore[override]\n        \"\"\"Extends the parent function by excluding the default value in the help text when not provided.\n\n        Only applied to required arguments without a default value, i.e. positional arguments or optional\n        arguments with `required=True`.\n\n        \"\"\"\n        if kwargs.get(\"required\", False):\n            kwargs.setdefault(\"default\", argparse.SUPPRESS)\n        super().add_argument(*args, **kwargs)\n\n    def add_argument_src_path(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `pathlib.Path` argument, checking if it exists and it is readable at parsing time.\n\n        If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"PATH\")\n        kwargs[\"type\"] = self._validate_src_path\n        self.add_argument(*args, **kwargs)\n\n    def add_argument_dst_path(self, *args: Any, exists_ok: bool = True, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `pathlib.Path` argument, checking if it is writable at parsing time.\n\n        If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.\n\n        Args:\n            exists_ok: Do not raise an error if the destination path already exists.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"PATH\")\n        kwargs[\"type\"] = lambda x: self._validate_dst_path(x, exists_ok)\n        self.add_argument(*args, **kwargs)\n\n    def add_argument_url(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `sqlalchemy.engine.URL` argument.\n\n        If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"URI\")\n        kwargs[\"type\"] = make_url\n        self.add_argument(*args, **kwargs)\n\n    # pylint: disable=redefined-builtin\n    def add_numeric_argument(\n        self,\n        *args: Any,\n        type: Callable[[str], int | float] = float,\n        min_value: int | float | None = None,\n        max_value: int | float | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Adds a numeric argument with constrains on its type and its minimum or maximum value.\n\n        Note that the default value (if defined) is not checked unless the argument is an optional argument\n        and no value is provided in the command line.\n\n        Args:\n            type: Type to convert the argument value to when parsing.\n            min_value: Minimum value constrain. If `None`, no minimum value constrain.\n            max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n        \"\"\"\n        # If both minimum and maximum values are defined, ensure min_value &lt;= max_value\n        if (min_value is not None) and (max_value is not None) and (min_value &gt; max_value):\n            raise ArgumentError(\"minimum value is greater than maximum value\")\n        # Add lambda function to check numeric constrains when parsing argument\n        kwargs[\"type\"] = lambda x: self._validate_number(x, type, min_value, max_value)\n        self.add_argument(*args, **kwargs)\n\n    # pylint: disable=redefined-builtin\n    def add_server_arguments(\n        self, prefix: str = \"\", include_database: bool = False, help: str | None = None\n    ) -&gt; None:\n        \"\"\"Adds the usual set of arguments needed to connect to a server, i.e. `--host`, `--port`, `--user`\n        and `--password` (optional).\n\n        Note that the parser will assume this is a MySQL server.\n\n        Args:\n            prefix: Prefix to add the each argument, e.g. if prefix is `src_`, the arguments will be\n                `--src_host`, etc.\n            include_database: Include `--database` argument.\n            help: Description message to include for this set of arguments.\n\n        \"\"\"\n        group = self.add_argument_group(f\"{prefix}server connection arguments\", description=help)\n        group.add_argument(\n            f\"--{prefix}host\", required=True, metavar=\"HOST\", default=argparse.SUPPRESS, help=\"host name\"\n        )\n        group.add_argument(\n            f\"--{prefix}port\",\n            required=True,\n            type=int,\n            metavar=\"PORT\",\n            default=argparse.SUPPRESS,\n            help=\"port number\",\n        )\n        group.add_argument(\n            f\"--{prefix}user\", required=True, metavar=\"USER\", default=argparse.SUPPRESS, help=\"user name\"\n        )\n        group.add_argument(f\"--{prefix}password\", metavar=\"PWD\", help=\"host password\")\n        if include_database:\n            group.add_argument(\n                f\"--{prefix}database\",\n                required=True,\n                metavar=\"NAME\",\n                default=argparse.SUPPRESS,\n                help=\"database name\",\n            )\n\n    def add_log_arguments(self, add_log_file: bool = False) -&gt; None:\n        \"\"\"Adds the usual set of arguments required to set and initialise a logging system.\n\n        The current set includes a mutually exclusive group for the default logging level: `--verbose`,\n        `--debug`, `--quiet` or `--log LEVEL`.\n\n        Args:\n            add_log_file: Add arguments to allow storing messages into a file, i.e. `--log_file` and\n                `--log_file_level`.\n\n        \"\"\"\n        # Define the list of log levels available\n        log_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n        # NOTE: from 3.11 this list can be changed to: logging.getLevelNamesMapping().keys()\n        # Create logging arguments group\n        group = self.add_argument_group(\"logging arguments\")\n        # Add 3 mutually exclusive options to set the logging level\n        subgroup = group.add_mutually_exclusive_group()\n        subgroup.add_argument(\n            \"-v\",\n            \"--verbose\",\n            action=\"store_const\",\n            const=\"INFO\",\n            dest=\"log_level\",\n            help=\"verbose mode, i.e. 'INFO' log level\",\n        )\n        subgroup.add_argument(\n            \"--debug\",\n            action=\"store_const\",\n            const=\"DEBUG\",\n            dest=\"log_level\",\n            help=\"debugging mode, i.e. 'DEBUG' log level\",\n        )\n        subgroup.add_argument(\n            \"--quiet\",\n            action=\"store_const\",\n            const=\"CRITICAL\",\n            dest=\"log_level\",\n            help=\"quiet mode, i.e. 'CRITICAL' log level\",\n        )\n        subgroup.add_argument(\n            \"--log\",\n            choices=log_levels,\n            type=str.upper,\n            default=\"WARNING\",\n            metavar=\"LEVEL\",\n            dest=\"log_level\",\n            help=\"level of the events to track: %(choices)s\",\n        )\n        subgroup.set_defaults(log_level=\"WARNING\")\n        if add_log_file:\n            # Add log file-related arguments\n            group.add_argument(\n                \"--log_file\",\n                type=lambda x: self._validate_dst_path(x, exists_ok=True),\n                metavar=\"PATH\",\n                default=None,\n                help=\"log file path\",\n            )\n            group.add_argument(\n                \"--log_file_level\",\n                choices=log_levels,\n                type=str.upper,\n                default=\"DEBUG\",\n                metavar=\"LEVEL\",\n                help=\"level of the events to track in the log file: %(choices)s\",\n            )\n\n    def parse_args(self, *args: Any, **kwargs: Any) -&gt; argparse.Namespace:  # type: ignore[override]\n        \"\"\"Extends the parent function by adding a new URL argument for every server group added.\n\n        The type of this new argument will be `sqlalchemy.engine.URL`. It also logs all the parsed\n        arguments for debugging purposes when logging arguments have been added.\n\n        \"\"\"\n        arguments = super().parse_args(*args, **kwargs)\n        # Build and add an sqlalchemy.engine.URL object for every server group added\n        pattern = re.compile(r\"([\\w-]*)host$\")\n        server_prefixes = [x.group(1) for x in map(pattern.match, vars(arguments)) if x]\n        for prefix in server_prefixes:\n            # Raise an error rather than overwriting when the URL argument is already present\n            if f\"{prefix}url\" in arguments:\n                self.error(f\"argument '{prefix}url' is already present\")\n            try:\n                server_url = URL.create(\n                    \"mysql\",\n                    getattr(arguments, f\"{prefix}user\"),\n                    getattr(arguments, f\"{prefix}password\"),\n                    getattr(arguments, f\"{prefix}host\"),\n                    getattr(arguments, f\"{prefix}port\"),\n                    getattr(arguments, f\"{prefix}database\", None),\n                )\n            except AttributeError:\n                # Not a database server host argument\n                continue\n            setattr(arguments, f\"{prefix}url\", server_url)\n        return arguments\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.formatter_class","title":"<code>formatter_class = argparse.ArgumentDefaultsHelpFormatter</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.add_argument","title":"<code>add_argument(*args, **kwargs)</code>","text":"<p>Extends the parent function by excluding the default value in the help text when not provided.</p> <p>Only applied to required arguments without a default value, i.e. positional arguments or optional arguments with <code>required=True</code>.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument(self, *args: Any, **kwargs: Any) -&gt; None:  # type: ignore[override]\n    \"\"\"Extends the parent function by excluding the default value in the help text when not provided.\n\n    Only applied to required arguments without a default value, i.e. positional arguments or optional\n    arguments with `required=True`.\n\n    \"\"\"\n    if kwargs.get(\"required\", False):\n        kwargs.setdefault(\"default\", argparse.SUPPRESS)\n    super().add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.add_argument_dst_path","title":"<code>add_argument_dst_path(*args, exists_ok=True, **kwargs)</code>","text":"<p>Adds <code>pathlib.Path</code> argument, checking if it is writable at parsing time.</p> <p>If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.</p> <p>Parameters:</p> Name Type Description Default <code>exists_ok</code> <code>bool</code> <p>Do not raise an error if the destination path already exists.</p> <code>True</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_dst_path(self, *args: Any, exists_ok: bool = True, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `pathlib.Path` argument, checking if it is writable at parsing time.\n\n    If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.\n\n    Args:\n        exists_ok: Do not raise an error if the destination path already exists.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"PATH\")\n    kwargs[\"type\"] = lambda x: self._validate_dst_path(x, exists_ok)\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.add_argument_src_path","title":"<code>add_argument_src_path(*args, **kwargs)</code>","text":"<p>Adds <code>pathlib.Path</code> argument, checking if it exists and it is readable at parsing time.</p> <p>If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_src_path(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `pathlib.Path` argument, checking if it exists and it is readable at parsing time.\n\n    If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"PATH\")\n    kwargs[\"type\"] = self._validate_src_path\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.add_argument_url","title":"<code>add_argument_url(*args, **kwargs)</code>","text":"<p>Adds <code>sqlalchemy.engine.URL</code> argument.</p> <p>If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_url(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `sqlalchemy.engine.URL` argument.\n\n    If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"URI\")\n    kwargs[\"type\"] = make_url\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.add_log_arguments","title":"<code>add_log_arguments(add_log_file=False)</code>","text":"<p>Adds the usual set of arguments required to set and initialise a logging system.</p> <p>The current set includes a mutually exclusive group for the default logging level: <code>--verbose</code>, <code>--debug</code>, <code>--quiet</code> or <code>--log LEVEL</code>.</p> <p>Parameters:</p> Name Type Description Default <code>add_log_file</code> <code>bool</code> <p>Add arguments to allow storing messages into a file, i.e. <code>--log_file</code> and <code>--log_file_level</code>.</p> <code>False</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_log_arguments(self, add_log_file: bool = False) -&gt; None:\n    \"\"\"Adds the usual set of arguments required to set and initialise a logging system.\n\n    The current set includes a mutually exclusive group for the default logging level: `--verbose`,\n    `--debug`, `--quiet` or `--log LEVEL`.\n\n    Args:\n        add_log_file: Add arguments to allow storing messages into a file, i.e. `--log_file` and\n            `--log_file_level`.\n\n    \"\"\"\n    # Define the list of log levels available\n    log_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n    # NOTE: from 3.11 this list can be changed to: logging.getLevelNamesMapping().keys()\n    # Create logging arguments group\n    group = self.add_argument_group(\"logging arguments\")\n    # Add 3 mutually exclusive options to set the logging level\n    subgroup = group.add_mutually_exclusive_group()\n    subgroup.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_const\",\n        const=\"INFO\",\n        dest=\"log_level\",\n        help=\"verbose mode, i.e. 'INFO' log level\",\n    )\n    subgroup.add_argument(\n        \"--debug\",\n        action=\"store_const\",\n        const=\"DEBUG\",\n        dest=\"log_level\",\n        help=\"debugging mode, i.e. 'DEBUG' log level\",\n    )\n    subgroup.add_argument(\n        \"--quiet\",\n        action=\"store_const\",\n        const=\"CRITICAL\",\n        dest=\"log_level\",\n        help=\"quiet mode, i.e. 'CRITICAL' log level\",\n    )\n    subgroup.add_argument(\n        \"--log\",\n        choices=log_levels,\n        type=str.upper,\n        default=\"WARNING\",\n        metavar=\"LEVEL\",\n        dest=\"log_level\",\n        help=\"level of the events to track: %(choices)s\",\n    )\n    subgroup.set_defaults(log_level=\"WARNING\")\n    if add_log_file:\n        # Add log file-related arguments\n        group.add_argument(\n            \"--log_file\",\n            type=lambda x: self._validate_dst_path(x, exists_ok=True),\n            metavar=\"PATH\",\n            default=None,\n            help=\"log file path\",\n        )\n        group.add_argument(\n            \"--log_file_level\",\n            choices=log_levels,\n            type=str.upper,\n            default=\"DEBUG\",\n            metavar=\"LEVEL\",\n            help=\"level of the events to track in the log file: %(choices)s\",\n        )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.add_numeric_argument","title":"<code>add_numeric_argument(*args, type=float, min_value=None, max_value=None, **kwargs)</code>","text":"<p>Adds a numeric argument with constrains on its type and its minimum or maximum value.</p> <p>Note that the default value (if defined) is not checked unless the argument is an optional argument and no value is provided in the command line.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Callable[[str], int | float]</code> <p>Type to convert the argument value to when parsing.</p> <code>float</code> <code>min_value</code> <code>int | float | None</code> <p>Minimum value constrain. If <code>None</code>, no minimum value constrain.</p> <code>None</code> <code>max_value</code> <code>int | float | None</code> <p>Maximum value constrain. If <code>None</code>, no maximum value constrain.</p> <code>None</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_numeric_argument(\n    self,\n    *args: Any,\n    type: Callable[[str], int | float] = float,\n    min_value: int | float | None = None,\n    max_value: int | float | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Adds a numeric argument with constrains on its type and its minimum or maximum value.\n\n    Note that the default value (if defined) is not checked unless the argument is an optional argument\n    and no value is provided in the command line.\n\n    Args:\n        type: Type to convert the argument value to when parsing.\n        min_value: Minimum value constrain. If `None`, no minimum value constrain.\n        max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n    \"\"\"\n    # If both minimum and maximum values are defined, ensure min_value &lt;= max_value\n    if (min_value is not None) and (max_value is not None) and (min_value &gt; max_value):\n        raise ArgumentError(\"minimum value is greater than maximum value\")\n    # Add lambda function to check numeric constrains when parsing argument\n    kwargs[\"type\"] = lambda x: self._validate_number(x, type, min_value, max_value)\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.add_server_arguments","title":"<code>add_server_arguments(prefix='', include_database=False, help=None)</code>","text":"<p>Adds the usual set of arguments needed to connect to a server, i.e. <code>--host</code>, <code>--port</code>, <code>--user</code> and <code>--password</code> (optional).</p> <p>Note that the parser will assume this is a MySQL server.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix to add the each argument, e.g. if prefix is <code>src_</code>, the arguments will be <code>--src_host</code>, etc.</p> <code>''</code> <code>include_database</code> <code>bool</code> <p>Include <code>--database</code> argument.</p> <code>False</code> <code>help</code> <code>str | None</code> <p>Description message to include for this set of arguments.</p> <code>None</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_server_arguments(\n    self, prefix: str = \"\", include_database: bool = False, help: str | None = None\n) -&gt; None:\n    \"\"\"Adds the usual set of arguments needed to connect to a server, i.e. `--host`, `--port`, `--user`\n    and `--password` (optional).\n\n    Note that the parser will assume this is a MySQL server.\n\n    Args:\n        prefix: Prefix to add the each argument, e.g. if prefix is `src_`, the arguments will be\n            `--src_host`, etc.\n        include_database: Include `--database` argument.\n        help: Description message to include for this set of arguments.\n\n    \"\"\"\n    group = self.add_argument_group(f\"{prefix}server connection arguments\", description=help)\n    group.add_argument(\n        f\"--{prefix}host\", required=True, metavar=\"HOST\", default=argparse.SUPPRESS, help=\"host name\"\n    )\n    group.add_argument(\n        f\"--{prefix}port\",\n        required=True,\n        type=int,\n        metavar=\"PORT\",\n        default=argparse.SUPPRESS,\n        help=\"port number\",\n    )\n    group.add_argument(\n        f\"--{prefix}user\", required=True, metavar=\"USER\", default=argparse.SUPPRESS, help=\"user name\"\n    )\n    group.add_argument(f\"--{prefix}password\", metavar=\"PWD\", help=\"host password\")\n    if include_database:\n        group.add_argument(\n            f\"--{prefix}database\",\n            required=True,\n            metavar=\"NAME\",\n            default=argparse.SUPPRESS,\n            help=\"database name\",\n        )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ArgumentParser.parse_args","title":"<code>parse_args(*args, **kwargs)</code>","text":"<p>Extends the parent function by adding a new URL argument for every server group added.</p> <p>The type of this new argument will be <code>sqlalchemy.engine.URL</code>. It also logs all the parsed arguments for debugging purposes when logging arguments have been added.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def parse_args(self, *args: Any, **kwargs: Any) -&gt; argparse.Namespace:  # type: ignore[override]\n    \"\"\"Extends the parent function by adding a new URL argument for every server group added.\n\n    The type of this new argument will be `sqlalchemy.engine.URL`. It also logs all the parsed\n    arguments for debugging purposes when logging arguments have been added.\n\n    \"\"\"\n    arguments = super().parse_args(*args, **kwargs)\n    # Build and add an sqlalchemy.engine.URL object for every server group added\n    pattern = re.compile(r\"([\\w-]*)host$\")\n    server_prefixes = [x.group(1) for x in map(pattern.match, vars(arguments)) if x]\n    for prefix in server_prefixes:\n        # Raise an error rather than overwriting when the URL argument is already present\n        if f\"{prefix}url\" in arguments:\n            self.error(f\"argument '{prefix}url' is already present\")\n        try:\n            server_url = URL.create(\n                \"mysql\",\n                getattr(arguments, f\"{prefix}user\"),\n                getattr(arguments, f\"{prefix}password\"),\n                getattr(arguments, f\"{prefix}host\"),\n                getattr(arguments, f\"{prefix}port\"),\n                getattr(arguments, f\"{prefix}database\", None),\n            )\n        except AttributeError:\n            # Not a database server host argument\n            continue\n        setattr(arguments, f\"{prefix}url\", server_url)\n    return arguments\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.BiotypeCounter","title":"<code>BiotypeCounter</code>","text":"<p>A counter for a given biotype, given a list of features.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>class BiotypeCounter:\n    \"\"\"A counter for a given biotype, given a list of features.\"\"\"\n\n    def __init__(self, count: int = 0, ids: Optional[Set[str]] = None, example: Optional[str] = None) -&gt; None:\n        self.count: int = count\n        if ids is None:\n            ids = set()\n        self.ids: Set[str] = ids\n        if example is None:\n            example = \"\"\n        self.example: str = example\n\n    def add_id(self, feature_id: str) -&gt; None:\n        \"\"\"Add a feature to the counter.\n\n        Args:\n            feature_id (str): Feature id to add.\n        \"\"\"\n        self.count += 1\n        self.ids.add(feature_id)\n\n    def unique_count(self) -&gt; int:\n        \"\"\"Total number feature ids added to the counter so far.\n\n        Returns:\n            int: number of features in the counter.\n        \"\"\"\n        return len(self.ids)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.BiotypeCounter.count","title":"<code>count = count</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.BiotypeCounter.example","title":"<code>example = example</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.BiotypeCounter.ids","title":"<code>ids = ids</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.BiotypeCounter.add_id","title":"<code>add_id(feature_id)</code>","text":"<p>Add a feature to the counter.</p> <p>Parameters:</p> Name Type Description Default <code>feature_id</code> <code>str</code> <p>Feature id to add.</p> required Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def add_id(self, feature_id: str) -&gt; None:\n    \"\"\"Add a feature to the counter.\n\n    Args:\n        feature_id (str): Feature id to add.\n    \"\"\"\n    self.count += 1\n    self.ids.add(feature_id)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.BiotypeCounter.unique_count","title":"<code>unique_count()</code>","text":"<p>Total number feature ids added to the counter so far.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of features in the counter.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def unique_count(self) -&gt; int:\n    \"\"\"Total number feature ids added to the counter so far.\n\n    Returns:\n        int: number of features in the counter.\n    \"\"\"\n    return len(self.ids)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool","title":"<code>IntegrityTool</code>","text":"<p>Check the integrity of sequence and annotation files in the genome</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>class IntegrityTool:\n    \"\"\"Check the integrity of sequence and annotation files in the genome\"\"\"\n\n    def __init__(\n        self,\n        manifest_file: Path,\n        ignore_final_stops: bool = False,\n        no_fail: bool = False,\n    ) -&gt; None:\n        self.manifest = ManifestStats(manifest_file)\n        self.ignore_final_stops = False\n        self.set_ignore_final_stops(ignore_final_stops)\n        self.errors: list[str] = []\n        self.no_fail = no_fail\n\n    def add_errors(self, errors: list[str] | str) -&gt; None:\n        \"\"\"Store the given errors (list or single string) in the list of all errors.\"\"\"\n        if isinstance(errors, str):\n            self.errors.append(errors)\n        else:\n            self.errors += errors\n\n    def check_integrity(self) -&gt; None:\n        \"\"\"Load files listed in the manifest.json and check the integrity.\n        Check if the files are correct by verifying the MD5 hash.\n        Check if translation, functional annotation and sequence region ids\n        and lengths are consistent with the information in gff.\n        Compare sequence length from fasta_dna file to seq_region.json metadata.\n        \"\"\"\n\n        # Load the manifest integrity counts\n        manifest = self.manifest\n        manifest.prepare_integrity_data()\n\n        genome = manifest.genome\n\n        dna = manifest.get_lengths(\"dna_sequences\")\n        pep = manifest.get_lengths(\"peptide_sequences\")\n        seq_lengths = manifest.get_lengths(\"seq_regions\")\n        seq_circular = manifest.get_circular(\"seq_regions\")\n\n        agp_seqr = manifest.get_lengths(\"agp\")\n\n        # Then, run the checks\n        self._check_genome(genome)\n\n        if self.manifest.errors:\n            errors_str = \"\\n\".join(self.manifest.errors)\n            raise InvalidIntegrityError(f\"Manifest files parsing failed:\\n{errors_str}\")\n\n        # Check gff3\n        if manifest.has_lengths(\"gff3_genes\"):\n            gff_genes = manifest.get_lengths(\"gff3_genes\")\n            gff_seq_regions = manifest.get_lengths(\"gff3_seq_regions\")\n            gff_translations = manifest.get_lengths(\"gff3_translations\")\n            gff_all_translations = manifest.get_lengths(\"gff3_all_translations\")\n            gff_transposable_elements = manifest.get_lengths(\"gff3_transposable_elements\")\n\n            ann_genes = manifest.get_lengths(\"ann_genes\")\n            ann_translations = manifest.get_lengths(\"ann_translations\")\n            ann_transposable_elements = manifest.get_lengths(\"ann_transposable_elements\")\n\n            # Check fasta_pep.fa integrity\n            # The sequence length and id retrieved from the fasta_pep file\n            # and compared to the translated CDS id and length in the gff\n            # We do not compare the peptide lengths because of sequence edits\n            if pep:\n                tr_errors = self.check_lengths(\n                    pep, gff_translations, \"Fasta translations vs gff\", special_diff=True\n                )\n                if len(tr_errors) &gt; 0:\n                    # The pseudo CDSs are included in this check\n                    # Pseudo CDSs are not translated, if the pseudo translation ids are not ignored\n                    # in the gff it will give an error\n                    tr_errors_all = self.check_lengths(\n                        pep,\n                        gff_all_translations,\n                        \"Fasta translations vs gff (include pseudo CDS)\",\n                        special_diff=True,\n                    )\n                    if tr_errors_all:\n                        self.add_errors(tr_errors)\n                        self.add_errors(tr_errors_all)\n\n            # Check functional_annotation.json integrity\n            # Gene ids, translated CDS ids and translated CDSs\n            # including pseudogenes are compared to the gff\n            if ann_genes:\n                self.add_errors(self.check_ids(ann_genes, gff_genes, \"Gene ids metadata vs gff\"))\n                tr_id_errors = self.check_ids(\n                    ann_translations, gff_translations, \"Translation ids metadata vs gff\"\n                )\n                if tr_id_errors:\n                    tr_id_errors_all = self.check_ids(\n                        ann_translations,\n                        gff_all_translations,\n                        \"Translation ids metadata vs gff (include pseudo CDS)\",\n                    )\n                    if tr_id_errors_all:\n                        self.add_errors(tr_id_errors)\n                        self.add_errors(tr_id_errors_all)\n                self.add_errors(\n                    self.check_ids(\n                        ann_transposable_elements,\n                        gff_transposable_elements,\n                        \"TE ids metadata vs gff\",\n                    )\n                )\n\n            self.check_seq_region_lengths(\n                seq_lengths, gff_seq_regions, \"seq_regions JSON vs GFF3 lengths\", seq_circular\n            )\n\n        self.check_seq_region_lengths(seq_lengths, dna, \"seq_regions JSON vs DNA lengths\")\n        self.check_seq_region_lengths(seq_lengths, agp_seqr, \"seq_regions JSON vs AGPs lengths\")\n\n        if self.errors:\n            errors_str = \"\\n\".join(self.errors)\n            message = f\"Integrity test failed:\\n{errors_str}\"\n            if self.no_fail:\n                print(message)\n            else:\n                raise InvalidIntegrityError(message)\n\n    def set_ignore_final_stops(self, ignore_final_stops: bool) -&gt; None:\n        \"\"\"Set ignore_final_stops (when calculating peptide length) for this tool and the manifest.\"\"\"\n        self.ignore_final_stops = ignore_final_stops\n        self.manifest.ignore_final_stops = ignore_final_stops\n\n    def _check_genome(self, genome: dict[str, Any]) -&gt; None:\n        \"\"\"Check if the accession is correct in genome.json.\"\"\"\n        genome_accession = genome.get(\"assembly\", {}).get(\"accession\", \"\")\n        if not genome_accession:\n            return\n        if not re.match(r\"GC[AF]_\\d{9}(\\.\\d+)?\", genome_accession):\n            self.add_errors(f\"Genome assembly accession is wrong: '{genome_accession}'\")\n\n    def check_ids(self, list1: dict[str, Any], list2: dict[str, Any], name: str) -&gt; list[str]:\n        \"\"\"Compare the ids in list1 and list2.\n\n        Args:\n            list1: Sequence IDs retrieved from `functional.json`.\n            list2: Sequence IDs retrieved from the GFF3 file.\n            name: Source name.\n\n        Return:\n            List of message errors of sequence IDs found only in one of the lists provided.\n        \"\"\"\n\n        only1 = []\n        only2 = []\n        common = []\n\n        for item_id in list1:\n            if item_id in list2:\n                common.append(item_id)\n            else:\n                only1.append(item_id)\n        for item_id in list2:\n            if item_id not in common:\n                only2.append(item_id)\n\n        errors = []\n        if common:\n            logging.info(f\"{len(common)} common elements in {name}\")\n        if only1:\n            errors.append(f\"{len(only1)} only in first list in {name} (first: {only1[0]})\")\n            logging.debug(f\"{len(only1)} only in first list in {name}\")\n        if only2:\n            errors.append(f\"{len(only2)} only in second list in {name} (first: {only2[0]})\")\n            logging.debug(f\"{len(only1)} only in second list in {name}\")\n\n        return errors\n\n    def check_lengths(\n        self,\n        list1: dict[str, int],\n        list2: dict[str, int],\n        name: str,\n        *,\n        allowed_len_diff: int | None = None,\n        special_diff: bool = False,\n    ) -&gt; list[str]:\n        \"\"\"Check the difference in ids and length between list1 and list2.\n            There are a few special cases here where we allow a certain asymmetry\n            by changing the values of the arguments.\n\n        Args:\n            list1: dict containing length and id of the sequence from fasta files.\n            list2: dict containing length and id in the retrieved from the gff.\n            name:  string\n\n        allowed_len_diff : None to to not accept differences in length between list1 and list2.\n            The value can be changed based on how much difference in sequence length we are wanting to accept.\n\n        special_diff: set as False when no special length difference is expected between the lists.\n                    This can be changed if we want to report common sequences with 1 BP difference.\n\n        Returns:\n            Error if there is a difference in length or ids between the lists.\n        \"\"\"\n\n        # check list differences, checks if abs(values diff) &lt; allowed_len_diff\n\n        set1 = frozenset(list1)\n        set2 = frozenset(list2)\n        list1_2 = list(set1 - set2)\n        list2_1 = list(set2 - set1)\n\n        errors = []\n        if len(list1_2) &gt; 0:\n            errors.append(f\"{name}: {len(list1_2)} from the first list only (i.e. {list1_2[0]})\")\n        if len(list2_1) &gt; 0:\n            errors.append(f\"{name}: {len(list2_1)} from the second list only (i.e. {list2_1[0]})\")\n\n        common_len = 0\n        if allowed_len_diff is None:\n            common_len = len(set1 &amp; set2)\n        else:\n            # check for the sequence length difference\n            diff_len_list: list[str] = []\n            diff_len_special_list: list[str] = []\n            for e in set1 &amp; set2:\n                dl12 = list1[e] - list2[e]\n                if abs(dl12) &lt;= allowed_len_diff:\n                    common_len += 1\n                else:\n                    _dlist = diff_len_list\n                    # Special case: 1 AA /BP shorter,\n                    #   so assuming the stop codon is not included in the CDS (when it should be)\n                    if dl12 == 1 and special_diff:\n                        _dlist = diff_len_special_list\n                    _dlist.append(f\"{e}: {list1[e]}, {list2[e]}\")\n            if diff_len_special_list:\n                errors.append(\n                    (\n                        f\"{len(diff_len_special_list)} common elements with one BP/AA length diff for {name}\"\n                        f\"(e.g. {diff_len_special_list[0]})\"\n                    )\n                )\n            if diff_len_list:\n                errors.append(\n                    (\n                        f\"{len(diff_len_list)} common elements with length diff for {name}\"\n                        f\"(e.g. {diff_len_list[0]})\"\n                    )\n                )\n        if common_len &gt; 0:\n            logging.warning(f\"{common_len} common elements between lists for {name}\")\n\n        return errors\n\n    def check_seq_region_lengths(\n        self,\n        seqrs: dict[str, Any] | None,\n        feats: dict[str, Any] | None,\n        name: str,\n        circular: dict[str, Any] | None = None,\n    ) -&gt; None:\n        \"\"\"Check the integrity of seq_region.json file by comparing the length of the sequence\n            to fasta files and the gff.\n\n            Seq_region file is in json format containing the metadata of the sequence.\n            It contains sequence id, length, location and the synonyms for the sequence name\n            from different sources.\n\n        Args:\n            seqs: Sequence name and length retrieved from seq_region.json file.\n            feats: Sequence name and length retrieved from the fasta and gff file.\n            name: Name of the check to show in the logs.\n            circular: Whether any sequence is circular.\n\n        Returns:\n            Error if there are common sequences with difference in ids\n            and if the sequences are not consistent in the files.\n        \"\"\"\n        if not seqrs or not feats:\n            return\n        comp = self._compare_seqs(seqrs, feats, circular)\n\n        common = comp[\"common\"]\n        diff = comp[\"diff\"]\n        diff_circular = comp[\"diff_circular\"]\n        only_seqr = comp[\"only_seqr\"]\n        only_feat = comp[\"only_feat\"]\n\n        if common:\n            logging.info(f\"{len(common)} common elements in {name}\")\n        if diff_circular:\n            example = diff_circular[0]\n            logging.info(f\"{len(diff_circular)} differences for circular elements in {name} (e.g. {example})\")\n        if diff:\n            self.add_errors(f\"{len(diff)} common elements with higher length in {name} (e.g. {diff[0]})\")\n        if only_seqr:\n            # Not an error!\n            logging.info(f\"{len(only_seqr)} only in seq_region list in {name} (first: {only_seqr[0]})\")\n        if only_feat:\n            self.add_errors(f\"{len(only_feat)} only in second list in {name} (first: {only_feat[0]})\")\n\n    def _compare_seqs(\n        self, seqrs: dict[str, Any], feats: dict[str, Any], circular: dict[str, Any] | None = None\n    ) -&gt; dict[str, list[str]]:\n        \"\"\"Give the intersection and other comparison between two groups of sequences.\n\n        Args:\n            seqs: Sequence name and length retrieved from seq_region.json file.\n            feats: Sequence name and length retrieved from the fasta and gff file.\n            circular: Whether any sequence is circular.\n\n        Returns: Dict with 5 stats:\n            common: Common elements.\n            only_seqr: Elements only in the first one.\n            only_feat: Elements only in the second one.\n            diff: Elements that differ.\n            diff_circular: Elements that differ in a circular sequence.\n\n        \"\"\"\n        comp: dict[str, list[str]] = {\n            \"common\": [],\n            \"only_seqr\": [],\n            \"only_feat\": [],\n            \"diff\": [],\n            \"diff_circular\": [],\n        }\n\n        for seq_id in seqrs:\n            if seq_id in feats:\n                # Check that feature is within the seq_region length\n                if feats[seq_id] &gt; seqrs[seq_id]:\n                    diff_str = f\"{seq_id}: {seqrs[seq_id]} vs {feats[seq_id]}\"\n                    if circular and circular.get(seq_id, False):\n                        comp[\"diff_circular\"].append(diff_str)\n                    else:\n                        comp[\"diff\"].append(diff_str)\n                else:\n                    comp[\"common\"].append(seq_id)\n            else:\n                comp[\"only_seqr\"].append(seq_id)\n\n        for seq_id in feats:\n            if (\n                seq_id not in comp[\"common\"]\n                and seq_id not in comp[\"diff\"]\n                and seq_id not in comp[\"diff_circular\"]\n                and seq_id not in seqrs\n            ):\n                comp[\"only_feat\"].append(seq_id)\n\n        return comp\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.errors","title":"<code>errors = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.ignore_final_stops","title":"<code>ignore_final_stops = False</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.manifest","title":"<code>manifest = ManifestStats(manifest_file)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.no_fail","title":"<code>no_fail = no_fail</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.add_errors","title":"<code>add_errors(errors)</code>","text":"<p>Store the given errors (list or single string) in the list of all errors.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def add_errors(self, errors: list[str] | str) -&gt; None:\n    \"\"\"Store the given errors (list or single string) in the list of all errors.\"\"\"\n    if isinstance(errors, str):\n        self.errors.append(errors)\n    else:\n        self.errors += errors\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.check_ids","title":"<code>check_ids(list1, list2, name)</code>","text":"<p>Compare the ids in list1 and list2.</p> <p>Parameters:</p> Name Type Description Default <code>list1</code> <code>dict[str, Any]</code> <p>Sequence IDs retrieved from <code>functional.json</code>.</p> required <code>list2</code> <code>dict[str, Any]</code> <p>Sequence IDs retrieved from the GFF3 file.</p> required <code>name</code> <code>str</code> <p>Source name.</p> required Return <p>List of message errors of sequence IDs found only in one of the lists provided.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def check_ids(self, list1: dict[str, Any], list2: dict[str, Any], name: str) -&gt; list[str]:\n    \"\"\"Compare the ids in list1 and list2.\n\n    Args:\n        list1: Sequence IDs retrieved from `functional.json`.\n        list2: Sequence IDs retrieved from the GFF3 file.\n        name: Source name.\n\n    Return:\n        List of message errors of sequence IDs found only in one of the lists provided.\n    \"\"\"\n\n    only1 = []\n    only2 = []\n    common = []\n\n    for item_id in list1:\n        if item_id in list2:\n            common.append(item_id)\n        else:\n            only1.append(item_id)\n    for item_id in list2:\n        if item_id not in common:\n            only2.append(item_id)\n\n    errors = []\n    if common:\n        logging.info(f\"{len(common)} common elements in {name}\")\n    if only1:\n        errors.append(f\"{len(only1)} only in first list in {name} (first: {only1[0]})\")\n        logging.debug(f\"{len(only1)} only in first list in {name}\")\n    if only2:\n        errors.append(f\"{len(only2)} only in second list in {name} (first: {only2[0]})\")\n        logging.debug(f\"{len(only1)} only in second list in {name}\")\n\n    return errors\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.check_integrity","title":"<code>check_integrity()</code>","text":"<p>Load files listed in the manifest.json and check the integrity. Check if the files are correct by verifying the MD5 hash. Check if translation, functional annotation and sequence region ids and lengths are consistent with the information in gff. Compare sequence length from fasta_dna file to seq_region.json metadata.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def check_integrity(self) -&gt; None:\n    \"\"\"Load files listed in the manifest.json and check the integrity.\n    Check if the files are correct by verifying the MD5 hash.\n    Check if translation, functional annotation and sequence region ids\n    and lengths are consistent with the information in gff.\n    Compare sequence length from fasta_dna file to seq_region.json metadata.\n    \"\"\"\n\n    # Load the manifest integrity counts\n    manifest = self.manifest\n    manifest.prepare_integrity_data()\n\n    genome = manifest.genome\n\n    dna = manifest.get_lengths(\"dna_sequences\")\n    pep = manifest.get_lengths(\"peptide_sequences\")\n    seq_lengths = manifest.get_lengths(\"seq_regions\")\n    seq_circular = manifest.get_circular(\"seq_regions\")\n\n    agp_seqr = manifest.get_lengths(\"agp\")\n\n    # Then, run the checks\n    self._check_genome(genome)\n\n    if self.manifest.errors:\n        errors_str = \"\\n\".join(self.manifest.errors)\n        raise InvalidIntegrityError(f\"Manifest files parsing failed:\\n{errors_str}\")\n\n    # Check gff3\n    if manifest.has_lengths(\"gff3_genes\"):\n        gff_genes = manifest.get_lengths(\"gff3_genes\")\n        gff_seq_regions = manifest.get_lengths(\"gff3_seq_regions\")\n        gff_translations = manifest.get_lengths(\"gff3_translations\")\n        gff_all_translations = manifest.get_lengths(\"gff3_all_translations\")\n        gff_transposable_elements = manifest.get_lengths(\"gff3_transposable_elements\")\n\n        ann_genes = manifest.get_lengths(\"ann_genes\")\n        ann_translations = manifest.get_lengths(\"ann_translations\")\n        ann_transposable_elements = manifest.get_lengths(\"ann_transposable_elements\")\n\n        # Check fasta_pep.fa integrity\n        # The sequence length and id retrieved from the fasta_pep file\n        # and compared to the translated CDS id and length in the gff\n        # We do not compare the peptide lengths because of sequence edits\n        if pep:\n            tr_errors = self.check_lengths(\n                pep, gff_translations, \"Fasta translations vs gff\", special_diff=True\n            )\n            if len(tr_errors) &gt; 0:\n                # The pseudo CDSs are included in this check\n                # Pseudo CDSs are not translated, if the pseudo translation ids are not ignored\n                # in the gff it will give an error\n                tr_errors_all = self.check_lengths(\n                    pep,\n                    gff_all_translations,\n                    \"Fasta translations vs gff (include pseudo CDS)\",\n                    special_diff=True,\n                )\n                if tr_errors_all:\n                    self.add_errors(tr_errors)\n                    self.add_errors(tr_errors_all)\n\n        # Check functional_annotation.json integrity\n        # Gene ids, translated CDS ids and translated CDSs\n        # including pseudogenes are compared to the gff\n        if ann_genes:\n            self.add_errors(self.check_ids(ann_genes, gff_genes, \"Gene ids metadata vs gff\"))\n            tr_id_errors = self.check_ids(\n                ann_translations, gff_translations, \"Translation ids metadata vs gff\"\n            )\n            if tr_id_errors:\n                tr_id_errors_all = self.check_ids(\n                    ann_translations,\n                    gff_all_translations,\n                    \"Translation ids metadata vs gff (include pseudo CDS)\",\n                )\n                if tr_id_errors_all:\n                    self.add_errors(tr_id_errors)\n                    self.add_errors(tr_id_errors_all)\n            self.add_errors(\n                self.check_ids(\n                    ann_transposable_elements,\n                    gff_transposable_elements,\n                    \"TE ids metadata vs gff\",\n                )\n            )\n\n        self.check_seq_region_lengths(\n            seq_lengths, gff_seq_regions, \"seq_regions JSON vs GFF3 lengths\", seq_circular\n        )\n\n    self.check_seq_region_lengths(seq_lengths, dna, \"seq_regions JSON vs DNA lengths\")\n    self.check_seq_region_lengths(seq_lengths, agp_seqr, \"seq_regions JSON vs AGPs lengths\")\n\n    if self.errors:\n        errors_str = \"\\n\".join(self.errors)\n        message = f\"Integrity test failed:\\n{errors_str}\"\n        if self.no_fail:\n            print(message)\n        else:\n            raise InvalidIntegrityError(message)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.check_lengths","title":"<code>check_lengths(list1, list2, name, *, allowed_len_diff=None, special_diff=False)</code>","text":"<p>Check the difference in ids and length between list1 and list2.     There are a few special cases here where we allow a certain asymmetry     by changing the values of the arguments.</p> <p>Parameters:</p> Name Type Description Default <code>list1</code> <code>dict[str, int]</code> <p>dict containing length and id of the sequence from fasta files.</p> required <code>list2</code> <code>dict[str, int]</code> <p>dict containing length and id in the retrieved from the gff.</p> required <code>name</code> <code>str</code> <p>string</p> required None to to not accept differences in length between list1 and list2. <p>The value can be changed based on how much difference in sequence length we are wanting to accept.</p> set as False when no special length difference is expected between the lists. <p>This can be changed if we want to report common sequences with 1 BP difference.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Error if there is a difference in length or ids between the lists.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def check_lengths(\n    self,\n    list1: dict[str, int],\n    list2: dict[str, int],\n    name: str,\n    *,\n    allowed_len_diff: int | None = None,\n    special_diff: bool = False,\n) -&gt; list[str]:\n    \"\"\"Check the difference in ids and length between list1 and list2.\n        There are a few special cases here where we allow a certain asymmetry\n        by changing the values of the arguments.\n\n    Args:\n        list1: dict containing length and id of the sequence from fasta files.\n        list2: dict containing length and id in the retrieved from the gff.\n        name:  string\n\n    allowed_len_diff : None to to not accept differences in length between list1 and list2.\n        The value can be changed based on how much difference in sequence length we are wanting to accept.\n\n    special_diff: set as False when no special length difference is expected between the lists.\n                This can be changed if we want to report common sequences with 1 BP difference.\n\n    Returns:\n        Error if there is a difference in length or ids between the lists.\n    \"\"\"\n\n    # check list differences, checks if abs(values diff) &lt; allowed_len_diff\n\n    set1 = frozenset(list1)\n    set2 = frozenset(list2)\n    list1_2 = list(set1 - set2)\n    list2_1 = list(set2 - set1)\n\n    errors = []\n    if len(list1_2) &gt; 0:\n        errors.append(f\"{name}: {len(list1_2)} from the first list only (i.e. {list1_2[0]})\")\n    if len(list2_1) &gt; 0:\n        errors.append(f\"{name}: {len(list2_1)} from the second list only (i.e. {list2_1[0]})\")\n\n    common_len = 0\n    if allowed_len_diff is None:\n        common_len = len(set1 &amp; set2)\n    else:\n        # check for the sequence length difference\n        diff_len_list: list[str] = []\n        diff_len_special_list: list[str] = []\n        for e in set1 &amp; set2:\n            dl12 = list1[e] - list2[e]\n            if abs(dl12) &lt;= allowed_len_diff:\n                common_len += 1\n            else:\n                _dlist = diff_len_list\n                # Special case: 1 AA /BP shorter,\n                #   so assuming the stop codon is not included in the CDS (when it should be)\n                if dl12 == 1 and special_diff:\n                    _dlist = diff_len_special_list\n                _dlist.append(f\"{e}: {list1[e]}, {list2[e]}\")\n        if diff_len_special_list:\n            errors.append(\n                (\n                    f\"{len(diff_len_special_list)} common elements with one BP/AA length diff for {name}\"\n                    f\"(e.g. {diff_len_special_list[0]})\"\n                )\n            )\n        if diff_len_list:\n            errors.append(\n                (\n                    f\"{len(diff_len_list)} common elements with length diff for {name}\"\n                    f\"(e.g. {diff_len_list[0]})\"\n                )\n            )\n    if common_len &gt; 0:\n        logging.warning(f\"{common_len} common elements between lists for {name}\")\n\n    return errors\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.check_seq_region_lengths","title":"<code>check_seq_region_lengths(seqrs, feats, name, circular=None)</code>","text":"<p>Check the integrity of seq_region.json file by comparing the length of the sequence     to fasta files and the gff.</p> <pre><code>Seq_region file is in json format containing the metadata of the sequence.\nIt contains sequence id, length, location and the synonyms for the sequence name\nfrom different sources.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>seqs</code> <p>Sequence name and length retrieved from seq_region.json file.</p> required <code>feats</code> <code>dict[str, Any] | None</code> <p>Sequence name and length retrieved from the fasta and gff file.</p> required <code>name</code> <code>str</code> <p>Name of the check to show in the logs.</p> required <code>circular</code> <code>dict[str, Any] | None</code> <p>Whether any sequence is circular.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>Error if there are common sequences with difference in ids</p> <code>None</code> <p>and if the sequences are not consistent in the files.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def check_seq_region_lengths(\n    self,\n    seqrs: dict[str, Any] | None,\n    feats: dict[str, Any] | None,\n    name: str,\n    circular: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"Check the integrity of seq_region.json file by comparing the length of the sequence\n        to fasta files and the gff.\n\n        Seq_region file is in json format containing the metadata of the sequence.\n        It contains sequence id, length, location and the synonyms for the sequence name\n        from different sources.\n\n    Args:\n        seqs: Sequence name and length retrieved from seq_region.json file.\n        feats: Sequence name and length retrieved from the fasta and gff file.\n        name: Name of the check to show in the logs.\n        circular: Whether any sequence is circular.\n\n    Returns:\n        Error if there are common sequences with difference in ids\n        and if the sequences are not consistent in the files.\n    \"\"\"\n    if not seqrs or not feats:\n        return\n    comp = self._compare_seqs(seqrs, feats, circular)\n\n    common = comp[\"common\"]\n    diff = comp[\"diff\"]\n    diff_circular = comp[\"diff_circular\"]\n    only_seqr = comp[\"only_seqr\"]\n    only_feat = comp[\"only_feat\"]\n\n    if common:\n        logging.info(f\"{len(common)} common elements in {name}\")\n    if diff_circular:\n        example = diff_circular[0]\n        logging.info(f\"{len(diff_circular)} differences for circular elements in {name} (e.g. {example})\")\n    if diff:\n        self.add_errors(f\"{len(diff)} common elements with higher length in {name} (e.g. {diff[0]})\")\n    if only_seqr:\n        # Not an error!\n        logging.info(f\"{len(only_seqr)} only in seq_region list in {name} (first: {only_seqr[0]})\")\n    if only_feat:\n        self.add_errors(f\"{len(only_feat)} only in second list in {name} (first: {only_feat[0]})\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.IntegrityTool.set_ignore_final_stops","title":"<code>set_ignore_final_stops(ignore_final_stops)</code>","text":"<p>Set ignore_final_stops (when calculating peptide length) for this tool and the manifest.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def set_ignore_final_stops(self, ignore_final_stops: bool) -&gt; None:\n    \"\"\"Set ignore_final_stops (when calculating peptide length) for this tool and the manifest.\"\"\"\n    self.ignore_final_stops = ignore_final_stops\n    self.manifest.ignore_final_stops = ignore_final_stops\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.InvalidIntegrityError","title":"<code>InvalidIntegrityError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a file integrity check fails</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>class InvalidIntegrityError(Exception):\n    \"\"\"When a file integrity check fails\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest","title":"<code>Manifest</code>","text":"<p>Records of a manifest file and its files and md5 checksums.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>class Manifest:\n    \"\"\"Records of a manifest file and its files and md5 checksums.\"\"\"\n\n    _same_names = {\n        \"gff3\",\n        \"fasta_dna\",\n        \"fasta_pep\",\n        \"functional_annotation\",\n        \"genome\",\n        \"seq_attrib\",\n        \"seq_region\",\n        \"agp\",\n        \"events\",\n    }\n    _alias_names = {\n        \"gene_models\": \"gff3\",\n        \"dna\": \"fasta_dna\",\n        \"pep\": \"fasta_pep\",\n    }\n    _same_names_dict = {name: name for name in _same_names}\n    names = {**_same_names_dict, **_alias_names}\n    multi_files = {\"agp\"}\n\n    def __init__(self, manifest_dir: Path) -&gt; None:\n        \"\"\"Initializes a manifest with the directory containing the files (and a manifest if it exists).\n\n        Args:\n            manifest_dir: directory where the files are contained.\n        \"\"\"\n        self.root_dir = manifest_dir\n        self.file_path = manifest_dir / \"manifest.json\"\n        self.files: dict = {}\n\n    def create(self) -&gt; None:\n        \"\"\"Creates a manifest file from the files in a directory.\"\"\"\n        self.get_files_checksums()\n        with self.file_path.open(\"w\") as json_out:\n            json_out.write(json.dumps(self.files, sort_keys=True, indent=4))\n\n    def get_files_checksums(self) -&gt; ManifestDict:\n        \"\"\"Records all the files in the directory with their checksum.\"\"\"\n        manifest_files: ManifestDict = {}\n        for subfile in self.root_dir.iterdir():\n            logging.debug(f\"Check file {subfile} ({subfile.stem}, {subfile.suffix})\")\n            used_file = False\n            if subfile.is_dir():\n                logging.warning(\"Can't create manifest for subdirectory\")\n                continue\n\n            # Delete and skip empty files\n            if subfile.stat().st_size == 0:\n                logging.warning(f\"Skip and delete empty file: {subfile}\")\n                subfile.unlink()\n                continue\n\n            for name, standard_name in self.names.items():\n                # Either the last element of the stem or the suffix is a known name\n                if subfile.stem.endswith(name) or subfile.suffix == f\".{name}\":\n                    logging.debug(f\"Matched to {name} ({standard_name}) = {subfile}\")\n                    used_file = True\n                    md5 = self._get_md5sum(subfile)\n                    file_obj = {\"file\": subfile.name, \"md5sum\": md5}\n\n                    # Multiple files stored, each with a name\n                    if standard_name in self.multi_files:\n                        manifest_files.setdefault(standard_name, {})\n                        obj_name = self._prepare_object_name(subfile, name, manifest_files[standard_name])\n                        manifest_files[standard_name][obj_name] = file_obj\n\n                    # Single file/init\n                    else:\n                        manifest_files[standard_name] = file_obj\n\n            if not used_file:\n                logging.warning(f\"File {subfile} was not included in the manifest\")\n\n        self.files = manifest_files\n        return self.files\n\n    def _prepare_object_name(\n        self, subfile: Path, name: str, manifest_file_dict: dict[str, dict[str, str]]\n    ) -&gt; str:\n        # Prepare object name\n        try:\n            # If we recognize the suffix, then the name is the part after the last \"_\"\n            if subfile.suffix == f\".{name}\":\n                obj_name = subfile.stem.split(sep=\"_\")[-1]\n            # If we recognize the end of the name, then the name is the part before the last \"_\"\n            else:\n                obj_name = subfile.stem.split(sep=\"_\")[-2]\n        except IndexError:\n            obj_name = \"file\"\n\n        # Add number if duplicate name\n        obj_name_base = obj_name\n        count = 1\n        while obj_name in manifest_file_dict.keys():\n            obj_name = f\"{obj_name_base}.{count}\"\n            count += 1\n            if count &gt;= 10:\n                raise ValueError(f\"Too many files with same name {obj_name_base}\")\n        return obj_name\n\n    def load(self) -&gt; ManifestDict:\n        \"\"\"Load the content of an existing manifest file.\"\"\"\n        if not self.file_path.exists():\n            raise ManifestError(f\"Cannot load non-existing manifest file: {self.file_path}\")\n\n        with self.file_path.open(\"r\") as manifest_fh:\n            manifest = json.load(manifest_fh)\n\n            # Use dir name from the manifest\n            for name in manifest:\n                if \"file\" in manifest[name]:\n                    file_path = self.root_dir / manifest[name][\"file\"]\n                    # check if the md5sum is correct\n                    md5sum = manifest[name][\"md5sum\"]\n                    self._check_md5sum(file_path, md5sum)\n                else:\n                    for f in manifest[name]:\n                        file_path = self.root_dir / manifest[name][f][\"file\"]\n                        # check if the md5sum is correct\n                        md5sum = manifest[name][f][\"md5sum\"]\n                        self._check_md5sum(file_path, md5sum)\n\n            self.files = manifest\n        return self.files\n\n    @staticmethod\n    def _get_md5sum(file_path: Path) -&gt; str:\n        \"\"\"Returns the md5 checksum for a given file.\"\"\"\n        with file_path.open(\"rb\") as f:\n            data_bytes = f.read()\n            return hashlib.md5(data_bytes).hexdigest()\n\n    def _check_md5sum(self, file_path: Path, md5sum: str) -&gt; None:\n        \"\"\"Checks a file against an md5 checksum, raises a ManifestError if the checksum fails.\n\n        Args:\n            file_path: Path to a genome file.\n            md5sum: MD5 hash for the files.\n        \"\"\"\n        file_md5sum = self._get_md5sum(file_path)\n        if file_md5sum != md5sum:\n            raise ManifestError(f\"Invalid md5 checksum for {file_path}: got {file_md5sum}, expected {md5sum}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest.file_path","title":"<code>file_path = manifest_dir / 'manifest.json'</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest.files","title":"<code>files = {}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest.multi_files","title":"<code>multi_files = {'agp'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest.names","title":"<code>names = {None: _same_names_dict, None: _alias_names}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest.root_dir","title":"<code>root_dir = manifest_dir</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest.create","title":"<code>create()</code>","text":"<p>Creates a manifest file from the files in a directory.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>def create(self) -&gt; None:\n    \"\"\"Creates a manifest file from the files in a directory.\"\"\"\n    self.get_files_checksums()\n    with self.file_path.open(\"w\") as json_out:\n        json_out.write(json.dumps(self.files, sort_keys=True, indent=4))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest.get_files_checksums","title":"<code>get_files_checksums()</code>","text":"<p>Records all the files in the directory with their checksum.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>def get_files_checksums(self) -&gt; ManifestDict:\n    \"\"\"Records all the files in the directory with their checksum.\"\"\"\n    manifest_files: ManifestDict = {}\n    for subfile in self.root_dir.iterdir():\n        logging.debug(f\"Check file {subfile} ({subfile.stem}, {subfile.suffix})\")\n        used_file = False\n        if subfile.is_dir():\n            logging.warning(\"Can't create manifest for subdirectory\")\n            continue\n\n        # Delete and skip empty files\n        if subfile.stat().st_size == 0:\n            logging.warning(f\"Skip and delete empty file: {subfile}\")\n            subfile.unlink()\n            continue\n\n        for name, standard_name in self.names.items():\n            # Either the last element of the stem or the suffix is a known name\n            if subfile.stem.endswith(name) or subfile.suffix == f\".{name}\":\n                logging.debug(f\"Matched to {name} ({standard_name}) = {subfile}\")\n                used_file = True\n                md5 = self._get_md5sum(subfile)\n                file_obj = {\"file\": subfile.name, \"md5sum\": md5}\n\n                # Multiple files stored, each with a name\n                if standard_name in self.multi_files:\n                    manifest_files.setdefault(standard_name, {})\n                    obj_name = self._prepare_object_name(subfile, name, manifest_files[standard_name])\n                    manifest_files[standard_name][obj_name] = file_obj\n\n                # Single file/init\n                else:\n                    manifest_files[standard_name] = file_obj\n\n        if not used_file:\n            logging.warning(f\"File {subfile} was not included in the manifest\")\n\n    self.files = manifest_files\n    return self.files\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.Manifest.load","title":"<code>load()</code>","text":"<p>Load the content of an existing manifest file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>def load(self) -&gt; ManifestDict:\n    \"\"\"Load the content of an existing manifest file.\"\"\"\n    if not self.file_path.exists():\n        raise ManifestError(f\"Cannot load non-existing manifest file: {self.file_path}\")\n\n    with self.file_path.open(\"r\") as manifest_fh:\n        manifest = json.load(manifest_fh)\n\n        # Use dir name from the manifest\n        for name in manifest:\n            if \"file\" in manifest[name]:\n                file_path = self.root_dir / manifest[name][\"file\"]\n                # check if the md5sum is correct\n                md5sum = manifest[name][\"md5sum\"]\n                self._check_md5sum(file_path, md5sum)\n            else:\n                for f in manifest[name]:\n                    file_path = self.root_dir / manifest[name][f][\"file\"]\n                    # check if the md5sum is correct\n                    md5sum = manifest[name][f][\"md5sum\"]\n                    self._check_md5sum(file_path, md5sum)\n\n        self.files = manifest\n    return self.files\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats","title":"<code>ManifestStats</code>","text":"<p>Representation of the main stats of the files in a manifest for comparison.</p> <p>The stats in question are: - lengths of sequences (DNA, genes and peptides) - sequences and features IDs - sequences circularity</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>class ManifestStats:\n    \"\"\"Representation of the main stats of the files in a manifest for comparison.\n\n    The stats in question are:\n    - lengths of sequences (DNA, genes and peptides)\n    - sequences and features IDs\n    - sequences circularity\n    \"\"\"\n\n    def __init__(self, manifest_path: StrPath, ignore_final_stops: bool = False) -&gt; None:\n        self.manifest_files = self._get_manifest(manifest_path)\n        self.genome: dict[str, Any] = {}\n\n        self.lengths: dict[str, StatsLengths] = {\n            \"dna_sequences\": {},\n            \"peptide_sequences\": {},\n            \"seq_region_levels\": {},\n            \"annotations\": {},\n            \"agp\": {},\n            \"gff3_seq_regions\": {},\n            \"gff3_genes\": {},\n            \"gff3_translations\": {},\n            \"gff3_all_translations\": {},\n            \"gff3_transposable_elements\": {},\n            \"ann_genes\": {},\n            \"ann_translations\": {},\n            \"ann_transposable_elements\": {},\n            \"seq_regions\": {},\n        }\n\n        self.circular: dict[str, StatsLengths] = {\n            \"seq_regions\": {},\n        }\n\n        self.errors: list[str] = []\n\n        self.ignore_final_stops = ignore_final_stops\n\n    def _get_manifest(self, manifest_path: PathLike) -&gt; dict[str, Any]:\n        \"\"\"Load the content of a manifest file.\n\n        Returns:\n            Dict: Content of the manifest file.\n        \"\"\"\n        manifest = Manifest(Path(manifest_path).parent)\n        manifest_files = manifest.load()\n\n        # Replace the {file, md5} dict with the file path\n        for name in manifest_files:\n            if \"file\" in manifest_files[name]:\n                manifest_files[name] = Path(manifest_path).parent / manifest_files[name][\"file\"]\n            else:\n                for f in manifest_files[name]:\n                    manifest_files[name][f] = Path(manifest_path).parent / manifest_files[name][f][\"file\"]\n        return manifest_files\n\n    def add_error(self, error: str) -&gt; None:\n        \"\"\"Record an error.\"\"\"\n        self.errors.append(error)\n\n    def load_seq_regions(self) -&gt; None:\n        \"\"\"Retrieve seq_regions lengths and circular information from the seq_region JSON file.\"\"\"\n\n        if \"seq_region\" not in self.manifest_files:\n            return\n        logging.info(\"Manifest contains seq_region JSON\")\n        seq_regions = get_json(Path(self.manifest_files[\"seq_region\"]))\n        seqr_seqlevel = {}\n        seq_lengths = {}\n        seq_circular = {}\n        # Store the length as int\n        for seq in seq_regions:\n            seq_lengths[seq[\"name\"]] = int(seq[\"length\"])\n            seq_circular[seq[\"name\"]] = seq.get(\"circular\", False)\n            if seq[\"coord_system_level\"] == \"contig\":\n                seqr_seqlevel[seq[\"name\"]] = int(seq[\"length\"])\n            # Also record synonyms (in case GFF file uses synonyms)\n            if \"synonyms\" in seq:\n                for synonym in seq[\"synonyms\"]:\n                    seq_lengths[synonym[\"name\"]] = int(seq[\"length\"])\n        self.lengths[\"seq_regions\"] = seq_lengths\n        self.circular[\"seq_regions\"] = seq_circular\n\n    def load_peptides_fasta_lengths(self) -&gt; None:\n        \"\"\"Retrieve peptides sequences lengths from their FASTA file.\"\"\"\n        if \"fasta_pep\" not in self.manifest_files:\n            return\n        self.lengths[\"peptide_sequences\"] = self._get_fasta_lengths(\n            self.manifest_files[\"fasta_pep\"], ignore_final_stops=self.ignore_final_stops\n        )\n\n    def load_dna_fasta_lengths(self) -&gt; None:\n        \"\"\"Retrieve DNA sequences lengths from their FASTA file.\"\"\"\n        if \"fasta_dna\" not in self.manifest_files:\n            return\n        self.lengths[\"dna_sequences\"] = self._get_fasta_lengths(self.manifest_files[\"fasta_dna\"])\n\n    def _get_fasta_lengths(self, fasta_path: StrPath, ignore_final_stops: bool = False) -&gt; dict[str, int]:\n        \"\"\"Returns every sequence ID and its length from a FASTA file (DNA or peptide).\n\n        An error will be added for every empty id, non-unique id or stop codon found in the FASTA file.\n\n        Args:\n            fasta_path: Path to FASTA file.\n            ignore_final_stops: Do not include final stop in the total length.\n\n        \"\"\"\n\n        data = {}\n        non_unique = {}\n        non_unique_count = 0\n        empty_id_count = 0\n        contains_stop_codon = 0\n        rec_count = 0\n        for rec in SeqIO.parse(fasta_path, \"fasta\"):\n            rec_count += 1\n\n            # Flag empty ids\n            if rec.id == \"\":\n                empty_id_count += 1\n                continue\n            # Flag redundant ids\n            if rec.id in data:\n                non_unique[rec.id] = 1\n                non_unique_count += 1\n            # Store sequence id and length\n            data[rec.id] = len(rec.seq)\n            stops = rec.seq.count(\"*\")\n            if stops &gt;= 1 and not rec.seq.endswith(\"*\"):\n                contains_stop_codon += 1\n            elif rec.seq.endswith(\"*\") and not ignore_final_stops:\n                contains_stop_codon += 1\n\n        if empty_id_count &gt; 0:\n            self.add_error(f\"{empty_id_count} sequences with empty ids in {fasta_path}\")\n        if non_unique_count &gt; 0:\n            self.add_error(f\"{non_unique_count} non unique sequence ids in {fasta_path}\")\n        if contains_stop_codon &gt; 0:\n            self.add_error(f\"{contains_stop_codon} sequences with stop codons in {fasta_path}\")\n        if rec_count == 0:\n            self.add_error(f\"No sequences found in {fasta_path}\")\n        return data\n\n    def load_functional_annotation(self) -&gt; None:\n        \"\"\"Load the functional annotation file to retrieve the gene_id and translation id.\n\n        The functional annotation file is stored in a JSON format containing the description, id\n        and object type, eg: \"gene\", \"transcript\", \"translation\".\n\n        \"\"\"\n        if \"functional_annotation\" not in self.manifest_files:\n            return\n        logging.info(\"Manifest contains functional annotation(s)\")\n\n        # Load the json file\n        with open(self.manifest_files[\"functional_annotation\"]) as json_file:\n            data = json.load(json_file)\n\n        # Get gene ids and translation ids\n        genes = {}\n        translations = {}\n        transposons = {}\n\n        for item in data:\n            if item[\"object_type\"] == \"gene\":\n                genes[item[\"id\"]] = 1\n            elif item[\"object_type\"] == \"translation\":\n                translations[item[\"id\"]] = 1\n            if item[\"object_type\"] == \"transposable_element\":\n                transposons[item[\"id\"]] = 1\n\n        stats = {\n            \"ann_genes\": genes,\n            \"ann_translations\": translations,\n            \"ann_transposable_elements\": transposons,\n        }\n        self.lengths = {**self.lengths, **stats}\n\n    def load_gff3(self) -&gt; None:\n        \"\"\"A GFF3 parser is used to retrieve information in the GFF3 file such as\n        gene and CDS ids and their corresponding lengths.\n        \"\"\"\n        if \"gff3\" not in self.manifest_files:\n            return\n        logging.info(\"Manifest contains GFF3 gene annotations\")\n        gff3_path = self.manifest_files[\"gff3\"]\n\n        seqs: StatsLengths = {}\n        genes: StatsLengths = {}\n        peps: StatsLengths = {}\n        all_peps: StatsLengths = {}\n        tes: StatsLengths = {}\n\n        with open_gz_file(gff3_path) as gff3_handle:\n            gff = GFF.parse(gff3_handle)\n            for seq in gff:\n                seqs[seq.id] = len(seq.seq)\n\n                for feat in seq.features:\n                    feat_length = abs(feat.location.end - feat.location.start)\n                    # Store gene id and length\n                    if feat.type in [\"gene\", \"ncRNA_gene\", \"pseudogene\"]:\n                        self._retrieve_gff_gene_lengths(feat, genes, peps, all_peps)\n                    if feat.type == \"transposable_element\":\n                        tes[feat.id] = feat_length\n\n        stats: dict[str, StatsLengths] = {\n            \"gff3_seq_regions\": seqs,\n            \"gff3_genes\": genes,\n            \"gff3_translations\": peps,\n            \"gff3_all_translations\": all_peps,\n            \"gff3_transposable_elements\": tes,\n        }\n        self.lengths = {**self.lengths, **stats}\n\n    def _retrieve_gff_gene_lengths(\n        self, feat: GFFSeqFeature, genes: StatsLengths, peps: StatsLengths, all_peps: StatsLengths\n    ) -&gt; None:\n        \"\"\"Record genes and peptides lengths from a feature.\n\n        Args:\n            feat : Gene feature to check.\n            genes: Record of genes lengths to update.\n            peps: Record of peptides lengths to update.\n            all_peps: Record of all peptides lengths to update (include pseudogenes).\n\n        \"\"\"\n        gene_id = feat.id\n        gene_id = gene_id.replace(\"gene:\", \"\")\n        genes[gene_id] = abs(feat.location.end - feat.location.start)\n        # Get CDS id and length\n        protein_transcripts = {\n            \"mRNA\",\n            \"pseudogenic_transcript\",\n        }\n        ig_transcripts = {\n            \"IG_V_gene\",\n            \"IG_C_gene\",\n            \"TR_C_gene\",\n            \"TR_V_gene\",\n        }\n        cds_transcripts = protein_transcripts.union(ig_transcripts)\n        for feat2 in feat.sub_features:\n            if feat2.type not in cds_transcripts:\n                continue\n            length: dict[str, int] = {}\n            for feat3 in feat2.sub_features:\n                if feat3.type != \"CDS\":\n                    continue\n                pep_id = feat3.id\n                pep_id = pep_id.replace(\"CDS:\", \"\")\n                length.setdefault(pep_id, 0)\n                length[pep_id] += abs(feat3.location.end - feat3.location.start)\n            for pep_id, pep_length in length.items():\n                # Store length for translations, add pseudo translations separately\n                pep_length = floor(pep_length / 3) - 1\n                if feat.type != \"pseudogene\" and feat2.type in protein_transcripts:\n                    peps[pep_id] = pep_length\n                all_peps[pep_id] = pep_length\n\n    def load_agp_seq_regions(self, agp_dict: dict | None) -&gt; None:\n        \"\"\"AGP files describe the assembly of larger sequence objects using smaller objects.\n\n        E.g. describes the assembly of scaffolds from contigs.\n\n        Args:\n            agp_dict: Dict containing the information about the sequence.\n\n        Note:\n            AGP file is only used in the older builds, not used for current processing.\n        \"\"\"\n        if not agp_dict:\n            return\n        logging.info(\"Manifest contains AGP files\")\n\n        seqr: StatsLengths = {}\n        for agp_path in agp_dict.values():\n            with open(agp_path, \"r\") as agph:\n                for line in agph:\n                    (\n                        asm_id,\n                        _,  # asm_start\n                        asm_end,\n                        _,  # asm_part\n                        typ,\n                        cmp_id,\n                        _,  # cmp_start\n                        cmp_end,\n                        _,  # cmp_strand\n                    ) = line.split(\"\\t\")\n                    # Ignore WGS contig\n                    if typ != \"W\":\n                        continue\n\n                    # Assembled seq length\n                    if asm_id not in seqr or seqr[asm_id] &lt; int(asm_end):\n                        seqr[asm_id] = int(asm_end)\n\n                    # Composite seq length\n                    if cmp_id not in seqr or seqr[cmp_id] &lt; int(cmp_end):\n                        seqr[cmp_id] = int(cmp_end)\n\n        self.lengths[\"agp\"] = seqr\n\n    def load_genome(self) -&gt; None:\n        \"\"\"Load the genome data.\"\"\"\n        if \"genome\" not in self.manifest_files:\n            return\n        logging.info(\"Manifest contains genome JSON\")\n        self.genome = get_json(Path(self.manifest_files[\"genome\"]))\n\n    def prepare_integrity_data(self) -&gt; None:  # pylint: disable=too-many-branches\n        \"\"\"Read all the files and keep a record (IDs and their lengths) for each case to be compared later.\"\"\"\n        self.load_gff3()\n        self.load_dna_fasta_lengths()\n        self.load_peptides_fasta_lengths()\n        self.load_seq_regions()\n        self.load_functional_annotation()\n        self.load_agp_seq_regions(self.manifest_files.get(\"agp\"))\n        self.load_genome()\n\n    def has_lengths(self, name: str) -&gt; bool:\n        \"\"\"Check if a given name has lengths records.\n\n        Args:\n            name: Name for the lengths to check.\n\n        Raises:\n            KeyError: If the name is not supported.\n        \"\"\"\n        try:\n            return bool(self.lengths[name])\n        except KeyError as err:\n            raise KeyError(f\"There is no length record for {name}\") from err\n\n    def get_lengths(self, name: str) -&gt; dict[str, Any]:\n        \"\"\"Returns a dict associating IDs with their length from a given file name.\n\n        Args:\n            name: Name for the lengths to get.\n\n        Raises:\n            KeyError: If the name is not supported.\n        \"\"\"\n        try:\n            return self.lengths[name]\n        except KeyError as err:\n            raise KeyError(f\"There is no length record for {name}\") from err\n\n    def get_circular(self, name: str) -&gt; dict[str, Any]:\n        \"\"\"Returns a dict associating IDs with their is_circular flag from a given file name.\n\n        Args:\n            name: Name for the circular data to get.\n\n        Raises:\n            KeyError: If the name is not supported.\n        \"\"\"\n        try:\n            return self.circular[name]\n        except KeyError as err:\n            raise KeyError(f\"No length available for key {name}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.circular","title":"<code>circular = {'seq_regions': {}}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.errors","title":"<code>errors = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.genome","title":"<code>genome = {}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.ignore_final_stops","title":"<code>ignore_final_stops = ignore_final_stops</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.lengths","title":"<code>lengths = {'dna_sequences': {}, 'peptide_sequences': {}, 'seq_region_levels': {}, 'annotations': {}, 'agp': {}, 'gff3_seq_regions': {}, 'gff3_genes': {}, 'gff3_translations': {}, 'gff3_all_translations': {}, 'gff3_transposable_elements': {}, 'ann_genes': {}, 'ann_translations': {}, 'ann_transposable_elements': {}, 'seq_regions': {}}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.manifest_files","title":"<code>manifest_files = self._get_manifest(manifest_path)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.add_error","title":"<code>add_error(error)</code>","text":"<p>Record an error.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def add_error(self, error: str) -&gt; None:\n    \"\"\"Record an error.\"\"\"\n    self.errors.append(error)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.get_circular","title":"<code>get_circular(name)</code>","text":"<p>Returns a dict associating IDs with their is_circular flag from a given file name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the circular data to get.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the name is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def get_circular(self, name: str) -&gt; dict[str, Any]:\n    \"\"\"Returns a dict associating IDs with their is_circular flag from a given file name.\n\n    Args:\n        name: Name for the circular data to get.\n\n    Raises:\n        KeyError: If the name is not supported.\n    \"\"\"\n    try:\n        return self.circular[name]\n    except KeyError as err:\n        raise KeyError(f\"No length available for key {name}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.get_lengths","title":"<code>get_lengths(name)</code>","text":"<p>Returns a dict associating IDs with their length from a given file name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the lengths to get.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the name is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def get_lengths(self, name: str) -&gt; dict[str, Any]:\n    \"\"\"Returns a dict associating IDs with their length from a given file name.\n\n    Args:\n        name: Name for the lengths to get.\n\n    Raises:\n        KeyError: If the name is not supported.\n    \"\"\"\n    try:\n        return self.lengths[name]\n    except KeyError as err:\n        raise KeyError(f\"There is no length record for {name}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.has_lengths","title":"<code>has_lengths(name)</code>","text":"<p>Check if a given name has lengths records.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the lengths to check.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the name is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def has_lengths(self, name: str) -&gt; bool:\n    \"\"\"Check if a given name has lengths records.\n\n    Args:\n        name: Name for the lengths to check.\n\n    Raises:\n        KeyError: If the name is not supported.\n    \"\"\"\n    try:\n        return bool(self.lengths[name])\n    except KeyError as err:\n        raise KeyError(f\"There is no length record for {name}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.load_agp_seq_regions","title":"<code>load_agp_seq_regions(agp_dict)</code>","text":"<p>AGP files describe the assembly of larger sequence objects using smaller objects.</p> <p>E.g. describes the assembly of scaffolds from contigs.</p> <p>Parameters:</p> Name Type Description Default <code>agp_dict</code> <code>dict | None</code> <p>Dict containing the information about the sequence.</p> required Note <p>AGP file is only used in the older builds, not used for current processing.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_agp_seq_regions(self, agp_dict: dict | None) -&gt; None:\n    \"\"\"AGP files describe the assembly of larger sequence objects using smaller objects.\n\n    E.g. describes the assembly of scaffolds from contigs.\n\n    Args:\n        agp_dict: Dict containing the information about the sequence.\n\n    Note:\n        AGP file is only used in the older builds, not used for current processing.\n    \"\"\"\n    if not agp_dict:\n        return\n    logging.info(\"Manifest contains AGP files\")\n\n    seqr: StatsLengths = {}\n    for agp_path in agp_dict.values():\n        with open(agp_path, \"r\") as agph:\n            for line in agph:\n                (\n                    asm_id,\n                    _,  # asm_start\n                    asm_end,\n                    _,  # asm_part\n                    typ,\n                    cmp_id,\n                    _,  # cmp_start\n                    cmp_end,\n                    _,  # cmp_strand\n                ) = line.split(\"\\t\")\n                # Ignore WGS contig\n                if typ != \"W\":\n                    continue\n\n                # Assembled seq length\n                if asm_id not in seqr or seqr[asm_id] &lt; int(asm_end):\n                    seqr[asm_id] = int(asm_end)\n\n                # Composite seq length\n                if cmp_id not in seqr or seqr[cmp_id] &lt; int(cmp_end):\n                    seqr[cmp_id] = int(cmp_end)\n\n    self.lengths[\"agp\"] = seqr\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.load_dna_fasta_lengths","title":"<code>load_dna_fasta_lengths()</code>","text":"<p>Retrieve DNA sequences lengths from their FASTA file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_dna_fasta_lengths(self) -&gt; None:\n    \"\"\"Retrieve DNA sequences lengths from their FASTA file.\"\"\"\n    if \"fasta_dna\" not in self.manifest_files:\n        return\n    self.lengths[\"dna_sequences\"] = self._get_fasta_lengths(self.manifest_files[\"fasta_dna\"])\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.load_functional_annotation","title":"<code>load_functional_annotation()</code>","text":"<p>Load the functional annotation file to retrieve the gene_id and translation id.</p> <p>The functional annotation file is stored in a JSON format containing the description, id and object type, eg: \"gene\", \"transcript\", \"translation\".</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_functional_annotation(self) -&gt; None:\n    \"\"\"Load the functional annotation file to retrieve the gene_id and translation id.\n\n    The functional annotation file is stored in a JSON format containing the description, id\n    and object type, eg: \"gene\", \"transcript\", \"translation\".\n\n    \"\"\"\n    if \"functional_annotation\" not in self.manifest_files:\n        return\n    logging.info(\"Manifest contains functional annotation(s)\")\n\n    # Load the json file\n    with open(self.manifest_files[\"functional_annotation\"]) as json_file:\n        data = json.load(json_file)\n\n    # Get gene ids and translation ids\n    genes = {}\n    translations = {}\n    transposons = {}\n\n    for item in data:\n        if item[\"object_type\"] == \"gene\":\n            genes[item[\"id\"]] = 1\n        elif item[\"object_type\"] == \"translation\":\n            translations[item[\"id\"]] = 1\n        if item[\"object_type\"] == \"transposable_element\":\n            transposons[item[\"id\"]] = 1\n\n    stats = {\n        \"ann_genes\": genes,\n        \"ann_translations\": translations,\n        \"ann_transposable_elements\": transposons,\n    }\n    self.lengths = {**self.lengths, **stats}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.load_genome","title":"<code>load_genome()</code>","text":"<p>Load the genome data.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_genome(self) -&gt; None:\n    \"\"\"Load the genome data.\"\"\"\n    if \"genome\" not in self.manifest_files:\n        return\n    logging.info(\"Manifest contains genome JSON\")\n    self.genome = get_json(Path(self.manifest_files[\"genome\"]))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.load_gff3","title":"<code>load_gff3()</code>","text":"<p>A GFF3 parser is used to retrieve information in the GFF3 file such as gene and CDS ids and their corresponding lengths.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_gff3(self) -&gt; None:\n    \"\"\"A GFF3 parser is used to retrieve information in the GFF3 file such as\n    gene and CDS ids and their corresponding lengths.\n    \"\"\"\n    if \"gff3\" not in self.manifest_files:\n        return\n    logging.info(\"Manifest contains GFF3 gene annotations\")\n    gff3_path = self.manifest_files[\"gff3\"]\n\n    seqs: StatsLengths = {}\n    genes: StatsLengths = {}\n    peps: StatsLengths = {}\n    all_peps: StatsLengths = {}\n    tes: StatsLengths = {}\n\n    with open_gz_file(gff3_path) as gff3_handle:\n        gff = GFF.parse(gff3_handle)\n        for seq in gff:\n            seqs[seq.id] = len(seq.seq)\n\n            for feat in seq.features:\n                feat_length = abs(feat.location.end - feat.location.start)\n                # Store gene id and length\n                if feat.type in [\"gene\", \"ncRNA_gene\", \"pseudogene\"]:\n                    self._retrieve_gff_gene_lengths(feat, genes, peps, all_peps)\n                if feat.type == \"transposable_element\":\n                    tes[feat.id] = feat_length\n\n    stats: dict[str, StatsLengths] = {\n        \"gff3_seq_regions\": seqs,\n        \"gff3_genes\": genes,\n        \"gff3_translations\": peps,\n        \"gff3_all_translations\": all_peps,\n        \"gff3_transposable_elements\": tes,\n    }\n    self.lengths = {**self.lengths, **stats}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.load_peptides_fasta_lengths","title":"<code>load_peptides_fasta_lengths()</code>","text":"<p>Retrieve peptides sequences lengths from their FASTA file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_peptides_fasta_lengths(self) -&gt; None:\n    \"\"\"Retrieve peptides sequences lengths from their FASTA file.\"\"\"\n    if \"fasta_pep\" not in self.manifest_files:\n        return\n    self.lengths[\"peptide_sequences\"] = self._get_fasta_lengths(\n        self.manifest_files[\"fasta_pep\"], ignore_final_stops=self.ignore_final_stops\n    )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.load_seq_regions","title":"<code>load_seq_regions()</code>","text":"<p>Retrieve seq_regions lengths and circular information from the seq_region JSON file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_seq_regions(self) -&gt; None:\n    \"\"\"Retrieve seq_regions lengths and circular information from the seq_region JSON file.\"\"\"\n\n    if \"seq_region\" not in self.manifest_files:\n        return\n    logging.info(\"Manifest contains seq_region JSON\")\n    seq_regions = get_json(Path(self.manifest_files[\"seq_region\"]))\n    seqr_seqlevel = {}\n    seq_lengths = {}\n    seq_circular = {}\n    # Store the length as int\n    for seq in seq_regions:\n        seq_lengths[seq[\"name\"]] = int(seq[\"length\"])\n        seq_circular[seq[\"name\"]] = seq.get(\"circular\", False)\n        if seq[\"coord_system_level\"] == \"contig\":\n            seqr_seqlevel[seq[\"name\"]] = int(seq[\"length\"])\n        # Also record synonyms (in case GFF file uses synonyms)\n        if \"synonyms\" in seq:\n            for synonym in seq[\"synonyms\"]:\n                seq_lengths[synonym[\"name\"]] = int(seq[\"length\"])\n    self.lengths[\"seq_regions\"] = seq_lengths\n    self.circular[\"seq_regions\"] = seq_circular\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.ManifestStats.prepare_integrity_data","title":"<code>prepare_integrity_data()</code>","text":"<p>Read all the files and keep a record (IDs and their lengths) for each case to be compared later.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def prepare_integrity_data(self) -&gt; None:  # pylint: disable=too-many-branches\n    \"\"\"Read all the files and keep a record (IDs and their lengths) for each case to be compared later.\"\"\"\n    self.load_gff3()\n    self.load_dna_fasta_lengths()\n    self.load_peptides_fasta_lengths()\n    self.load_seq_regions()\n    self.load_functional_annotation()\n    self.load_agp_seq_regions(self.manifest_files.get(\"agp\"))\n    self.load_genome()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.StatsError","title":"<code>StatsError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when stats could not be computed.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>class StatsError(Exception):\n    \"\"\"Raised when stats could not be computed.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.init_logging_with_args","title":"<code>init_logging_with_args(args)</code>","text":"<p>Processes the Namespace object provided to call <code>init_logging()</code> with the correct arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Namespace populated by an argument parser.</p> required Source code in <code>ensembl/utils/logging.py</code> <pre><code>def init_logging_with_args(args: argparse.Namespace) -&gt; None:\n    \"\"\"Processes the Namespace object provided to call `init_logging()` with the correct arguments.\n\n    Args:\n        args: Namespace populated by an argument parser.\n\n    \"\"\"\n    args_dict = vars(args)\n    log_args = {x: args_dict[x] for x in [\"log_level\", \"log_file\", \"log_file_level\"] if x in args_dict}\n    init_logging(**log_args)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/#ensembl.io.genomio.manifest.main","title":"<code>main()</code>","text":"<p>Main entrypoint.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/generate.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entrypoint.\"\"\"\n    parser = ArgumentParser(\n        description=\"Compare the genomic data between the files present in a manifest file.\"\n    )\n    parser.add_argument_dst_path(\n        \"--manifest_dir\", required=True, help=\"Folder where to create a manifest file\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    manifest = Manifest(args.manifest_dir)\n    manifest.create()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/","title":"check_integrity","text":""},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity","title":"<code>ensembl.io.genomio.manifest.check_integrity</code>","text":"<p>Compare the genomic data in a DNA FASTA file, seq_region JSON, gene models GFF3 and peptide FASTA to ensure their contents are in sync.</p>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool","title":"<code>IntegrityTool</code>","text":"<p>Check the integrity of sequence and annotation files in the genome</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>class IntegrityTool:\n    \"\"\"Check the integrity of sequence and annotation files in the genome\"\"\"\n\n    def __init__(\n        self,\n        manifest_file: Path,\n        ignore_final_stops: bool = False,\n        no_fail: bool = False,\n    ) -&gt; None:\n        self.manifest = ManifestStats(manifest_file)\n        self.ignore_final_stops = False\n        self.set_ignore_final_stops(ignore_final_stops)\n        self.errors: list[str] = []\n        self.no_fail = no_fail\n\n    def add_errors(self, errors: list[str] | str) -&gt; None:\n        \"\"\"Store the given errors (list or single string) in the list of all errors.\"\"\"\n        if isinstance(errors, str):\n            self.errors.append(errors)\n        else:\n            self.errors += errors\n\n    def check_integrity(self) -&gt; None:\n        \"\"\"Load files listed in the manifest.json and check the integrity.\n        Check if the files are correct by verifying the MD5 hash.\n        Check if translation, functional annotation and sequence region ids\n        and lengths are consistent with the information in gff.\n        Compare sequence length from fasta_dna file to seq_region.json metadata.\n        \"\"\"\n\n        # Load the manifest integrity counts\n        manifest = self.manifest\n        manifest.prepare_integrity_data()\n\n        genome = manifest.genome\n\n        dna = manifest.get_lengths(\"dna_sequences\")\n        pep = manifest.get_lengths(\"peptide_sequences\")\n        seq_lengths = manifest.get_lengths(\"seq_regions\")\n        seq_circular = manifest.get_circular(\"seq_regions\")\n\n        agp_seqr = manifest.get_lengths(\"agp\")\n\n        # Then, run the checks\n        self._check_genome(genome)\n\n        if self.manifest.errors:\n            errors_str = \"\\n\".join(self.manifest.errors)\n            raise InvalidIntegrityError(f\"Manifest files parsing failed:\\n{errors_str}\")\n\n        # Check gff3\n        if manifest.has_lengths(\"gff3_genes\"):\n            gff_genes = manifest.get_lengths(\"gff3_genes\")\n            gff_seq_regions = manifest.get_lengths(\"gff3_seq_regions\")\n            gff_translations = manifest.get_lengths(\"gff3_translations\")\n            gff_all_translations = manifest.get_lengths(\"gff3_all_translations\")\n            gff_transposable_elements = manifest.get_lengths(\"gff3_transposable_elements\")\n\n            ann_genes = manifest.get_lengths(\"ann_genes\")\n            ann_translations = manifest.get_lengths(\"ann_translations\")\n            ann_transposable_elements = manifest.get_lengths(\"ann_transposable_elements\")\n\n            # Check fasta_pep.fa integrity\n            # The sequence length and id retrieved from the fasta_pep file\n            # and compared to the translated CDS id and length in the gff\n            # We do not compare the peptide lengths because of sequence edits\n            if pep:\n                tr_errors = self.check_lengths(\n                    pep, gff_translations, \"Fasta translations vs gff\", special_diff=True\n                )\n                if len(tr_errors) &gt; 0:\n                    # The pseudo CDSs are included in this check\n                    # Pseudo CDSs are not translated, if the pseudo translation ids are not ignored\n                    # in the gff it will give an error\n                    tr_errors_all = self.check_lengths(\n                        pep,\n                        gff_all_translations,\n                        \"Fasta translations vs gff (include pseudo CDS)\",\n                        special_diff=True,\n                    )\n                    if tr_errors_all:\n                        self.add_errors(tr_errors)\n                        self.add_errors(tr_errors_all)\n\n            # Check functional_annotation.json integrity\n            # Gene ids, translated CDS ids and translated CDSs\n            # including pseudogenes are compared to the gff\n            if ann_genes:\n                self.add_errors(self.check_ids(ann_genes, gff_genes, \"Gene ids metadata vs gff\"))\n                tr_id_errors = self.check_ids(\n                    ann_translations, gff_translations, \"Translation ids metadata vs gff\"\n                )\n                if tr_id_errors:\n                    tr_id_errors_all = self.check_ids(\n                        ann_translations,\n                        gff_all_translations,\n                        \"Translation ids metadata vs gff (include pseudo CDS)\",\n                    )\n                    if tr_id_errors_all:\n                        self.add_errors(tr_id_errors)\n                        self.add_errors(tr_id_errors_all)\n                self.add_errors(\n                    self.check_ids(\n                        ann_transposable_elements,\n                        gff_transposable_elements,\n                        \"TE ids metadata vs gff\",\n                    )\n                )\n\n            self.check_seq_region_lengths(\n                seq_lengths, gff_seq_regions, \"seq_regions JSON vs GFF3 lengths\", seq_circular\n            )\n\n        self.check_seq_region_lengths(seq_lengths, dna, \"seq_regions JSON vs DNA lengths\")\n        self.check_seq_region_lengths(seq_lengths, agp_seqr, \"seq_regions JSON vs AGPs lengths\")\n\n        if self.errors:\n            errors_str = \"\\n\".join(self.errors)\n            message = f\"Integrity test failed:\\n{errors_str}\"\n            if self.no_fail:\n                print(message)\n            else:\n                raise InvalidIntegrityError(message)\n\n    def set_ignore_final_stops(self, ignore_final_stops: bool) -&gt; None:\n        \"\"\"Set ignore_final_stops (when calculating peptide length) for this tool and the manifest.\"\"\"\n        self.ignore_final_stops = ignore_final_stops\n        self.manifest.ignore_final_stops = ignore_final_stops\n\n    def _check_genome(self, genome: dict[str, Any]) -&gt; None:\n        \"\"\"Check if the accession is correct in genome.json.\"\"\"\n        genome_accession = genome.get(\"assembly\", {}).get(\"accession\", \"\")\n        if not genome_accession:\n            return\n        if not re.match(r\"GC[AF]_\\d{9}(\\.\\d+)?\", genome_accession):\n            self.add_errors(f\"Genome assembly accession is wrong: '{genome_accession}'\")\n\n    def check_ids(self, list1: dict[str, Any], list2: dict[str, Any], name: str) -&gt; list[str]:\n        \"\"\"Compare the ids in list1 and list2.\n\n        Args:\n            list1: Sequence IDs retrieved from `functional.json`.\n            list2: Sequence IDs retrieved from the GFF3 file.\n            name: Source name.\n\n        Return:\n            List of message errors of sequence IDs found only in one of the lists provided.\n        \"\"\"\n\n        only1 = []\n        only2 = []\n        common = []\n\n        for item_id in list1:\n            if item_id in list2:\n                common.append(item_id)\n            else:\n                only1.append(item_id)\n        for item_id in list2:\n            if item_id not in common:\n                only2.append(item_id)\n\n        errors = []\n        if common:\n            logging.info(f\"{len(common)} common elements in {name}\")\n        if only1:\n            errors.append(f\"{len(only1)} only in first list in {name} (first: {only1[0]})\")\n            logging.debug(f\"{len(only1)} only in first list in {name}\")\n        if only2:\n            errors.append(f\"{len(only2)} only in second list in {name} (first: {only2[0]})\")\n            logging.debug(f\"{len(only1)} only in second list in {name}\")\n\n        return errors\n\n    def check_lengths(\n        self,\n        list1: dict[str, int],\n        list2: dict[str, int],\n        name: str,\n        *,\n        allowed_len_diff: int | None = None,\n        special_diff: bool = False,\n    ) -&gt; list[str]:\n        \"\"\"Check the difference in ids and length between list1 and list2.\n            There are a few special cases here where we allow a certain asymmetry\n            by changing the values of the arguments.\n\n        Args:\n            list1: dict containing length and id of the sequence from fasta files.\n            list2: dict containing length and id in the retrieved from the gff.\n            name:  string\n\n        allowed_len_diff : None to to not accept differences in length between list1 and list2.\n            The value can be changed based on how much difference in sequence length we are wanting to accept.\n\n        special_diff: set as False when no special length difference is expected between the lists.\n                    This can be changed if we want to report common sequences with 1 BP difference.\n\n        Returns:\n            Error if there is a difference in length or ids between the lists.\n        \"\"\"\n\n        # check list differences, checks if abs(values diff) &lt; allowed_len_diff\n\n        set1 = frozenset(list1)\n        set2 = frozenset(list2)\n        list1_2 = list(set1 - set2)\n        list2_1 = list(set2 - set1)\n\n        errors = []\n        if len(list1_2) &gt; 0:\n            errors.append(f\"{name}: {len(list1_2)} from the first list only (i.e. {list1_2[0]})\")\n        if len(list2_1) &gt; 0:\n            errors.append(f\"{name}: {len(list2_1)} from the second list only (i.e. {list2_1[0]})\")\n\n        common_len = 0\n        if allowed_len_diff is None:\n            common_len = len(set1 &amp; set2)\n        else:\n            # check for the sequence length difference\n            diff_len_list: list[str] = []\n            diff_len_special_list: list[str] = []\n            for e in set1 &amp; set2:\n                dl12 = list1[e] - list2[e]\n                if abs(dl12) &lt;= allowed_len_diff:\n                    common_len += 1\n                else:\n                    _dlist = diff_len_list\n                    # Special case: 1 AA /BP shorter,\n                    #   so assuming the stop codon is not included in the CDS (when it should be)\n                    if dl12 == 1 and special_diff:\n                        _dlist = diff_len_special_list\n                    _dlist.append(f\"{e}: {list1[e]}, {list2[e]}\")\n            if diff_len_special_list:\n                errors.append(\n                    (\n                        f\"{len(diff_len_special_list)} common elements with one BP/AA length diff for {name}\"\n                        f\"(e.g. {diff_len_special_list[0]})\"\n                    )\n                )\n            if diff_len_list:\n                errors.append(\n                    (\n                        f\"{len(diff_len_list)} common elements with length diff for {name}\"\n                        f\"(e.g. {diff_len_list[0]})\"\n                    )\n                )\n        if common_len &gt; 0:\n            logging.warning(f\"{common_len} common elements between lists for {name}\")\n\n        return errors\n\n    def check_seq_region_lengths(\n        self,\n        seqrs: dict[str, Any] | None,\n        feats: dict[str, Any] | None,\n        name: str,\n        circular: dict[str, Any] | None = None,\n    ) -&gt; None:\n        \"\"\"Check the integrity of seq_region.json file by comparing the length of the sequence\n            to fasta files and the gff.\n\n            Seq_region file is in json format containing the metadata of the sequence.\n            It contains sequence id, length, location and the synonyms for the sequence name\n            from different sources.\n\n        Args:\n            seqs: Sequence name and length retrieved from seq_region.json file.\n            feats: Sequence name and length retrieved from the fasta and gff file.\n            name: Name of the check to show in the logs.\n            circular: Whether any sequence is circular.\n\n        Returns:\n            Error if there are common sequences with difference in ids\n            and if the sequences are not consistent in the files.\n        \"\"\"\n        if not seqrs or not feats:\n            return\n        comp = self._compare_seqs(seqrs, feats, circular)\n\n        common = comp[\"common\"]\n        diff = comp[\"diff\"]\n        diff_circular = comp[\"diff_circular\"]\n        only_seqr = comp[\"only_seqr\"]\n        only_feat = comp[\"only_feat\"]\n\n        if common:\n            logging.info(f\"{len(common)} common elements in {name}\")\n        if diff_circular:\n            example = diff_circular[0]\n            logging.info(f\"{len(diff_circular)} differences for circular elements in {name} (e.g. {example})\")\n        if diff:\n            self.add_errors(f\"{len(diff)} common elements with higher length in {name} (e.g. {diff[0]})\")\n        if only_seqr:\n            # Not an error!\n            logging.info(f\"{len(only_seqr)} only in seq_region list in {name} (first: {only_seqr[0]})\")\n        if only_feat:\n            self.add_errors(f\"{len(only_feat)} only in second list in {name} (first: {only_feat[0]})\")\n\n    def _compare_seqs(\n        self, seqrs: dict[str, Any], feats: dict[str, Any], circular: dict[str, Any] | None = None\n    ) -&gt; dict[str, list[str]]:\n        \"\"\"Give the intersection and other comparison between two groups of sequences.\n\n        Args:\n            seqs: Sequence name and length retrieved from seq_region.json file.\n            feats: Sequence name and length retrieved from the fasta and gff file.\n            circular: Whether any sequence is circular.\n\n        Returns: Dict with 5 stats:\n            common: Common elements.\n            only_seqr: Elements only in the first one.\n            only_feat: Elements only in the second one.\n            diff: Elements that differ.\n            diff_circular: Elements that differ in a circular sequence.\n\n        \"\"\"\n        comp: dict[str, list[str]] = {\n            \"common\": [],\n            \"only_seqr\": [],\n            \"only_feat\": [],\n            \"diff\": [],\n            \"diff_circular\": [],\n        }\n\n        for seq_id in seqrs:\n            if seq_id in feats:\n                # Check that feature is within the seq_region length\n                if feats[seq_id] &gt; seqrs[seq_id]:\n                    diff_str = f\"{seq_id}: {seqrs[seq_id]} vs {feats[seq_id]}\"\n                    if circular and circular.get(seq_id, False):\n                        comp[\"diff_circular\"].append(diff_str)\n                    else:\n                        comp[\"diff\"].append(diff_str)\n                else:\n                    comp[\"common\"].append(seq_id)\n            else:\n                comp[\"only_seqr\"].append(seq_id)\n\n        for seq_id in feats:\n            if (\n                seq_id not in comp[\"common\"]\n                and seq_id not in comp[\"diff\"]\n                and seq_id not in comp[\"diff_circular\"]\n                and seq_id not in seqrs\n            ):\n                comp[\"only_feat\"].append(seq_id)\n\n        return comp\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.errors","title":"<code>errors = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.ignore_final_stops","title":"<code>ignore_final_stops = False</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.manifest","title":"<code>manifest = ManifestStats(manifest_file)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.no_fail","title":"<code>no_fail = no_fail</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.add_errors","title":"<code>add_errors(errors)</code>","text":"<p>Store the given errors (list or single string) in the list of all errors.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def add_errors(self, errors: list[str] | str) -&gt; None:\n    \"\"\"Store the given errors (list or single string) in the list of all errors.\"\"\"\n    if isinstance(errors, str):\n        self.errors.append(errors)\n    else:\n        self.errors += errors\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.check_ids","title":"<code>check_ids(list1, list2, name)</code>","text":"<p>Compare the ids in list1 and list2.</p> <p>Parameters:</p> Name Type Description Default <code>list1</code> <code>dict[str, Any]</code> <p>Sequence IDs retrieved from <code>functional.json</code>.</p> required <code>list2</code> <code>dict[str, Any]</code> <p>Sequence IDs retrieved from the GFF3 file.</p> required <code>name</code> <code>str</code> <p>Source name.</p> required Return <p>List of message errors of sequence IDs found only in one of the lists provided.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def check_ids(self, list1: dict[str, Any], list2: dict[str, Any], name: str) -&gt; list[str]:\n    \"\"\"Compare the ids in list1 and list2.\n\n    Args:\n        list1: Sequence IDs retrieved from `functional.json`.\n        list2: Sequence IDs retrieved from the GFF3 file.\n        name: Source name.\n\n    Return:\n        List of message errors of sequence IDs found only in one of the lists provided.\n    \"\"\"\n\n    only1 = []\n    only2 = []\n    common = []\n\n    for item_id in list1:\n        if item_id in list2:\n            common.append(item_id)\n        else:\n            only1.append(item_id)\n    for item_id in list2:\n        if item_id not in common:\n            only2.append(item_id)\n\n    errors = []\n    if common:\n        logging.info(f\"{len(common)} common elements in {name}\")\n    if only1:\n        errors.append(f\"{len(only1)} only in first list in {name} (first: {only1[0]})\")\n        logging.debug(f\"{len(only1)} only in first list in {name}\")\n    if only2:\n        errors.append(f\"{len(only2)} only in second list in {name} (first: {only2[0]})\")\n        logging.debug(f\"{len(only1)} only in second list in {name}\")\n\n    return errors\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.check_integrity","title":"<code>check_integrity()</code>","text":"<p>Load files listed in the manifest.json and check the integrity. Check if the files are correct by verifying the MD5 hash. Check if translation, functional annotation and sequence region ids and lengths are consistent with the information in gff. Compare sequence length from fasta_dna file to seq_region.json metadata.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def check_integrity(self) -&gt; None:\n    \"\"\"Load files listed in the manifest.json and check the integrity.\n    Check if the files are correct by verifying the MD5 hash.\n    Check if translation, functional annotation and sequence region ids\n    and lengths are consistent with the information in gff.\n    Compare sequence length from fasta_dna file to seq_region.json metadata.\n    \"\"\"\n\n    # Load the manifest integrity counts\n    manifest = self.manifest\n    manifest.prepare_integrity_data()\n\n    genome = manifest.genome\n\n    dna = manifest.get_lengths(\"dna_sequences\")\n    pep = manifest.get_lengths(\"peptide_sequences\")\n    seq_lengths = manifest.get_lengths(\"seq_regions\")\n    seq_circular = manifest.get_circular(\"seq_regions\")\n\n    agp_seqr = manifest.get_lengths(\"agp\")\n\n    # Then, run the checks\n    self._check_genome(genome)\n\n    if self.manifest.errors:\n        errors_str = \"\\n\".join(self.manifest.errors)\n        raise InvalidIntegrityError(f\"Manifest files parsing failed:\\n{errors_str}\")\n\n    # Check gff3\n    if manifest.has_lengths(\"gff3_genes\"):\n        gff_genes = manifest.get_lengths(\"gff3_genes\")\n        gff_seq_regions = manifest.get_lengths(\"gff3_seq_regions\")\n        gff_translations = manifest.get_lengths(\"gff3_translations\")\n        gff_all_translations = manifest.get_lengths(\"gff3_all_translations\")\n        gff_transposable_elements = manifest.get_lengths(\"gff3_transposable_elements\")\n\n        ann_genes = manifest.get_lengths(\"ann_genes\")\n        ann_translations = manifest.get_lengths(\"ann_translations\")\n        ann_transposable_elements = manifest.get_lengths(\"ann_transposable_elements\")\n\n        # Check fasta_pep.fa integrity\n        # The sequence length and id retrieved from the fasta_pep file\n        # and compared to the translated CDS id and length in the gff\n        # We do not compare the peptide lengths because of sequence edits\n        if pep:\n            tr_errors = self.check_lengths(\n                pep, gff_translations, \"Fasta translations vs gff\", special_diff=True\n            )\n            if len(tr_errors) &gt; 0:\n                # The pseudo CDSs are included in this check\n                # Pseudo CDSs are not translated, if the pseudo translation ids are not ignored\n                # in the gff it will give an error\n                tr_errors_all = self.check_lengths(\n                    pep,\n                    gff_all_translations,\n                    \"Fasta translations vs gff (include pseudo CDS)\",\n                    special_diff=True,\n                )\n                if tr_errors_all:\n                    self.add_errors(tr_errors)\n                    self.add_errors(tr_errors_all)\n\n        # Check functional_annotation.json integrity\n        # Gene ids, translated CDS ids and translated CDSs\n        # including pseudogenes are compared to the gff\n        if ann_genes:\n            self.add_errors(self.check_ids(ann_genes, gff_genes, \"Gene ids metadata vs gff\"))\n            tr_id_errors = self.check_ids(\n                ann_translations, gff_translations, \"Translation ids metadata vs gff\"\n            )\n            if tr_id_errors:\n                tr_id_errors_all = self.check_ids(\n                    ann_translations,\n                    gff_all_translations,\n                    \"Translation ids metadata vs gff (include pseudo CDS)\",\n                )\n                if tr_id_errors_all:\n                    self.add_errors(tr_id_errors)\n                    self.add_errors(tr_id_errors_all)\n            self.add_errors(\n                self.check_ids(\n                    ann_transposable_elements,\n                    gff_transposable_elements,\n                    \"TE ids metadata vs gff\",\n                )\n            )\n\n        self.check_seq_region_lengths(\n            seq_lengths, gff_seq_regions, \"seq_regions JSON vs GFF3 lengths\", seq_circular\n        )\n\n    self.check_seq_region_lengths(seq_lengths, dna, \"seq_regions JSON vs DNA lengths\")\n    self.check_seq_region_lengths(seq_lengths, agp_seqr, \"seq_regions JSON vs AGPs lengths\")\n\n    if self.errors:\n        errors_str = \"\\n\".join(self.errors)\n        message = f\"Integrity test failed:\\n{errors_str}\"\n        if self.no_fail:\n            print(message)\n        else:\n            raise InvalidIntegrityError(message)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.check_lengths","title":"<code>check_lengths(list1, list2, name, *, allowed_len_diff=None, special_diff=False)</code>","text":"<p>Check the difference in ids and length between list1 and list2.     There are a few special cases here where we allow a certain asymmetry     by changing the values of the arguments.</p> <p>Parameters:</p> Name Type Description Default <code>list1</code> <code>dict[str, int]</code> <p>dict containing length and id of the sequence from fasta files.</p> required <code>list2</code> <code>dict[str, int]</code> <p>dict containing length and id in the retrieved from the gff.</p> required <code>name</code> <code>str</code> <p>string</p> required None to to not accept differences in length between list1 and list2. <p>The value can be changed based on how much difference in sequence length we are wanting to accept.</p> set as False when no special length difference is expected between the lists. <p>This can be changed if we want to report common sequences with 1 BP difference.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Error if there is a difference in length or ids between the lists.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def check_lengths(\n    self,\n    list1: dict[str, int],\n    list2: dict[str, int],\n    name: str,\n    *,\n    allowed_len_diff: int | None = None,\n    special_diff: bool = False,\n) -&gt; list[str]:\n    \"\"\"Check the difference in ids and length between list1 and list2.\n        There are a few special cases here where we allow a certain asymmetry\n        by changing the values of the arguments.\n\n    Args:\n        list1: dict containing length and id of the sequence from fasta files.\n        list2: dict containing length and id in the retrieved from the gff.\n        name:  string\n\n    allowed_len_diff : None to to not accept differences in length between list1 and list2.\n        The value can be changed based on how much difference in sequence length we are wanting to accept.\n\n    special_diff: set as False when no special length difference is expected between the lists.\n                This can be changed if we want to report common sequences with 1 BP difference.\n\n    Returns:\n        Error if there is a difference in length or ids between the lists.\n    \"\"\"\n\n    # check list differences, checks if abs(values diff) &lt; allowed_len_diff\n\n    set1 = frozenset(list1)\n    set2 = frozenset(list2)\n    list1_2 = list(set1 - set2)\n    list2_1 = list(set2 - set1)\n\n    errors = []\n    if len(list1_2) &gt; 0:\n        errors.append(f\"{name}: {len(list1_2)} from the first list only (i.e. {list1_2[0]})\")\n    if len(list2_1) &gt; 0:\n        errors.append(f\"{name}: {len(list2_1)} from the second list only (i.e. {list2_1[0]})\")\n\n    common_len = 0\n    if allowed_len_diff is None:\n        common_len = len(set1 &amp; set2)\n    else:\n        # check for the sequence length difference\n        diff_len_list: list[str] = []\n        diff_len_special_list: list[str] = []\n        for e in set1 &amp; set2:\n            dl12 = list1[e] - list2[e]\n            if abs(dl12) &lt;= allowed_len_diff:\n                common_len += 1\n            else:\n                _dlist = diff_len_list\n                # Special case: 1 AA /BP shorter,\n                #   so assuming the stop codon is not included in the CDS (when it should be)\n                if dl12 == 1 and special_diff:\n                    _dlist = diff_len_special_list\n                _dlist.append(f\"{e}: {list1[e]}, {list2[e]}\")\n        if diff_len_special_list:\n            errors.append(\n                (\n                    f\"{len(diff_len_special_list)} common elements with one BP/AA length diff for {name}\"\n                    f\"(e.g. {diff_len_special_list[0]})\"\n                )\n            )\n        if diff_len_list:\n            errors.append(\n                (\n                    f\"{len(diff_len_list)} common elements with length diff for {name}\"\n                    f\"(e.g. {diff_len_list[0]})\"\n                )\n            )\n    if common_len &gt; 0:\n        logging.warning(f\"{common_len} common elements between lists for {name}\")\n\n    return errors\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.check_seq_region_lengths","title":"<code>check_seq_region_lengths(seqrs, feats, name, circular=None)</code>","text":"<p>Check the integrity of seq_region.json file by comparing the length of the sequence     to fasta files and the gff.</p> <pre><code>Seq_region file is in json format containing the metadata of the sequence.\nIt contains sequence id, length, location and the synonyms for the sequence name\nfrom different sources.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>seqs</code> <p>Sequence name and length retrieved from seq_region.json file.</p> required <code>feats</code> <code>dict[str, Any] | None</code> <p>Sequence name and length retrieved from the fasta and gff file.</p> required <code>name</code> <code>str</code> <p>Name of the check to show in the logs.</p> required <code>circular</code> <code>dict[str, Any] | None</code> <p>Whether any sequence is circular.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>Error if there are common sequences with difference in ids</p> <code>None</code> <p>and if the sequences are not consistent in the files.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def check_seq_region_lengths(\n    self,\n    seqrs: dict[str, Any] | None,\n    feats: dict[str, Any] | None,\n    name: str,\n    circular: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"Check the integrity of seq_region.json file by comparing the length of the sequence\n        to fasta files and the gff.\n\n        Seq_region file is in json format containing the metadata of the sequence.\n        It contains sequence id, length, location and the synonyms for the sequence name\n        from different sources.\n\n    Args:\n        seqs: Sequence name and length retrieved from seq_region.json file.\n        feats: Sequence name and length retrieved from the fasta and gff file.\n        name: Name of the check to show in the logs.\n        circular: Whether any sequence is circular.\n\n    Returns:\n        Error if there are common sequences with difference in ids\n        and if the sequences are not consistent in the files.\n    \"\"\"\n    if not seqrs or not feats:\n        return\n    comp = self._compare_seqs(seqrs, feats, circular)\n\n    common = comp[\"common\"]\n    diff = comp[\"diff\"]\n    diff_circular = comp[\"diff_circular\"]\n    only_seqr = comp[\"only_seqr\"]\n    only_feat = comp[\"only_feat\"]\n\n    if common:\n        logging.info(f\"{len(common)} common elements in {name}\")\n    if diff_circular:\n        example = diff_circular[0]\n        logging.info(f\"{len(diff_circular)} differences for circular elements in {name} (e.g. {example})\")\n    if diff:\n        self.add_errors(f\"{len(diff)} common elements with higher length in {name} (e.g. {diff[0]})\")\n    if only_seqr:\n        # Not an error!\n        logging.info(f\"{len(only_seqr)} only in seq_region list in {name} (first: {only_seqr[0]})\")\n    if only_feat:\n        self.add_errors(f\"{len(only_feat)} only in second list in {name} (first: {only_feat[0]})\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.IntegrityTool.set_ignore_final_stops","title":"<code>set_ignore_final_stops(ignore_final_stops)</code>","text":"<p>Set ignore_final_stops (when calculating peptide length) for this tool and the manifest.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def set_ignore_final_stops(self, ignore_final_stops: bool) -&gt; None:\n    \"\"\"Set ignore_final_stops (when calculating peptide length) for this tool and the manifest.\"\"\"\n    self.ignore_final_stops = ignore_final_stops\n    self.manifest.ignore_final_stops = ignore_final_stops\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/check_integrity/#ensembl.io.genomio.manifest.check_integrity.main","title":"<code>main()</code>","text":"<p>Main entrypoint.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/check_integrity.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entrypoint.\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument_src_path(\"--manifest_file\", required=True, help=\"Manifest file for the data to check\")\n    parser.add_argument(\n        \"--ignore_final_stops\", action=\"store_true\", help=\"Ignore final stop when calculating peptide length\"\n    )\n    parser.add_argument(\n        \"--no_fail\", action=\"store_true\", help=\"In case of errors, don't fail but print errors to stdout.\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    inspector = IntegrityTool(args.manifest_file, args.ignore_final_stops, args.no_fail)\n    inspector.check_integrity()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/","title":"compute_stats","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats","title":"<code>ensembl.io.genomio.manifest.compute_stats</code>","text":"<p>Compute stats from the current genome files associated with the manifest.</p>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.BiotypeCounter","title":"<code>BiotypeCounter</code>","text":"<p>A counter for a given biotype, given a list of features.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>class BiotypeCounter:\n    \"\"\"A counter for a given biotype, given a list of features.\"\"\"\n\n    def __init__(self, count: int = 0, ids: Optional[Set[str]] = None, example: Optional[str] = None) -&gt; None:\n        self.count: int = count\n        if ids is None:\n            ids = set()\n        self.ids: Set[str] = ids\n        if example is None:\n            example = \"\"\n        self.example: str = example\n\n    def add_id(self, feature_id: str) -&gt; None:\n        \"\"\"Add a feature to the counter.\n\n        Args:\n            feature_id (str): Feature id to add.\n        \"\"\"\n        self.count += 1\n        self.ids.add(feature_id)\n\n    def unique_count(self) -&gt; int:\n        \"\"\"Total number feature ids added to the counter so far.\n\n        Returns:\n            int: number of features in the counter.\n        \"\"\"\n        return len(self.ids)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.BiotypeCounter.count","title":"<code>count = count</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.BiotypeCounter.example","title":"<code>example = example</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.BiotypeCounter.ids","title":"<code>ids = ids</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.BiotypeCounter.add_id","title":"<code>add_id(feature_id)</code>","text":"<p>Add a feature to the counter.</p> <p>Parameters:</p> Name Type Description Default <code>feature_id</code> <code>str</code> <p>Feature id to add.</p> required Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def add_id(self, feature_id: str) -&gt; None:\n    \"\"\"Add a feature to the counter.\n\n    Args:\n        feature_id (str): Feature id to add.\n    \"\"\"\n    self.count += 1\n    self.ids.add(feature_id)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.BiotypeCounter.unique_count","title":"<code>unique_count()</code>","text":"<p>Total number feature ids added to the counter so far.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of features in the counter.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def unique_count(self) -&gt; int:\n    \"\"\"Total number feature ids added to the counter so far.\n\n    Returns:\n        int: number of features in the counter.\n    \"\"\"\n    return len(self.ids)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.StatsError","title":"<code>StatsError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when stats could not be computed.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>class StatsError(Exception):\n    \"\"\"Raised when stats could not be computed.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats","title":"<code>manifest_stats</code>","text":"<p>Representation of the statistics of the set of files listed in the manifest file provided.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>class manifest_stats:\n    \"\"\"Representation of the statistics of the set of files listed in the manifest file provided.\"\"\"\n\n    def __init__(self, manifest_dir: str, accession: Optional[str], datasets_bin: Optional[str]):\n        self.manifest = f\"{manifest_dir}/manifest.json\"\n        self.accession: Optional[str] = accession\n        self.errors: List[str] = []\n        self.errors_file = Path(manifest_dir) / \"stats_diff.log\"\n        if datasets_bin is None:\n            datasets_bin = \"datasets\"\n        self.datasets_bin = datasets_bin\n        self.manifest_parent = manifest_dir\n        self.check_ncbi = False\n\n    def run(self, stats_path: StrPath) -&gt; None:\n        \"\"\"Compute stats in the files and output a stats.txt file in the same folder.\n\n        Raises:\n            StatsError: Could not compute some stats.\n        \"\"\"\n        manifest = self.get_manifest()\n\n        stats = []\n        if self.accession is not None:\n            stats.append(self.accession)\n\n        # Compute the stats from the GFF3 file\n        if \"gff3\" in manifest:\n            stats += self.get_gff3_stats(Path(manifest[\"gff3\"]))\n\n        # Compute the stats from the seq_region file\n        if \"seq_region\" in manifest:\n            stats += self.get_seq_region_stats(Path(manifest[\"seq_region\"]))\n\n        # Print out the stats in a separate file\n        with Path(stats_path).open(\"w\") as stats_out:\n            stats_out.write(\"\\n\".join(stats))\n\n        # Die if there were errors in stats comparison\n        if self.errors:\n            with self.errors_file.open(\"w\") as errors_fh:\n                for error_line in self.errors:\n                    errors_fh.write(error_line)\n\n    def get_manifest(self) -&gt; Dict:\n        \"\"\"Get the files metadata from the manifest json file.\n\n        Returns:\n            Dict: A representation of the manifest json data.\n        \"\"\"\n        with open(self.manifest) as f_json:\n            manifest = json.load(f_json)\n            manifest_root = self.manifest_parent\n\n        # Use dir name from the manifest\n        for name in manifest:\n            if \"file\" in manifest[name]:\n                file_name = manifest[name][\"file\"]\n                file_name = f\"{manifest_root}/{file_name}\"\n                manifest[name] = file_name\n            else:\n                for f in manifest[name]:\n                    if \"file\" in manifest[name][f]:\n                        file_name = manifest[name][f][\"file\"]\n                        file_name = manifest_root, file_name\n                        manifest[name][f] = file_name\n\n        return manifest\n\n    def get_seq_region_stats(self, seq_region_path: Path) -&gt; List[str]:\n        \"\"\"Compute stats from the seq_region json file.\n\n        Args:\n            seq_region_path (Path): the seq_region json file.\n\n        Returns:\n            List[str]: Stats from the seq_regions.\n        \"\"\"\n        with seq_region_path.open(\"r\") as json_file:\n            seq_regions = json.load(json_file)\n\n        # Get basic data\n        coord_systems: Dict[str, List[int]] = {}\n        circular = 0\n        locations = []\n        codon_tables = []\n        for seqr in seq_regions:\n            # Get readable seq_region name:\n            # either use a Genbank synonym, or just the provided seq_region name\n            genbank = \"synonyms\" in seqr and [x for x in seqr[\"synonyms\"] if x[\"source\"] == \"GenBank\"]\n            seqr_name = genbank and genbank[0][\"name\"] or seqr[\"name\"]\n\n            # Record the lengths of the elements of each coord_system\n            coord_level = seqr[\"coord_system_level\"]\n            if coord_level not in coord_systems:\n                coord_systems[coord_level] = []\n            coord_systems[coord_level].append(seqr[\"length\"])\n\n            # Additional metadata records to count\n            if \"circular\" in seqr:\n                circular += 1\n            if \"codon_table\" in seqr:\n                codon_tables.append(f\"{seqr_name} = {seqr['codon_table']}\")\n            if \"location\" in seqr:\n                locations.append(f\"{seqr_name} = {seqr['location']}\")\n\n        # Stats\n        stats: List[str] = []\n        stats.append(seq_region_path.name)\n        stats += self.coord_systems_stats(coord_systems)\n        stats += self.seq_region_special_stats(circular, locations, codon_tables)\n        stats.append(\"\\n\")\n        return stats\n\n    def coord_systems_stats(self, coord_systems: Dict[str, List[int]]) -&gt; List[str]:\n        \"\"\"For each coord_system compute various stats:\n            - number of sequences\n            - sequence length sum, minimum, maximum, mean\n\n        Args:\n            coord_systems: Coordinate system dictionary of lengths.\n\n        Returns:\n            A list with the computed statistics in a printable format.\n        \"\"\"\n        stats: List[str] = []\n        stats.append(f\"Total coord_systems {len(coord_systems)}\")\n        for coord_name, lengths in coord_systems.items():\n            stats.append(f\"\\nCoord_system: {coord_name}\")\n\n            stat_counts: Dict[str, Union[int, float]] = {\n                \"Number of sequences\": len(lengths),\n                \"Sequence length sum\": sum(lengths),\n                \"Sequence length minimum\": min(lengths),\n                \"Sequence length maximum\": max(lengths),\n                \"Sequence length mean\": mean(lengths),\n            }\n\n            for name, count in stat_counts.items():\n                if isinstance(count, int):\n                    stats.append(f\"{count: 9d}\\t{name}\")\n                else:\n                    stats.append(f\"{count: 9f}\\t{name}\")\n        return stats\n\n    def seq_region_special_stats(\n        self,\n        circular: int = 0,\n        locations: Optional[List[str]] = None,\n        codon_tables: Optional[List[str]] = None,\n    ) -&gt; List[str]:\n        \"\"\"Prepare stats in case there are circular regions, specific locations and codon_tables.\n                stats.append(f\"{count: 9f}\\t{name}\")\n\n        Args:\n            circular: Number of circular regions. Defaults to 0.\n            locations: The regions and their location. Defaults to None.\n            codon_tables: The regions and their codon_table. Defaults to None.\n\n        Returns:\n            A list with the computed statistics in a printable format.\n        \"\"\"\n        stats: List[str] = []\n        if circular or locations or codon_tables:\n            stats.append(\"\\nSpecial\")\n            if circular:\n                stats.append(f\"{circular: 9d}\\tcircular sequences\")\n            if locations is not None:\n                stats.append(f\"{len(locations): 9d} sequences with location\")\n                for loc in locations:\n                    stats.append(f\"\\t\\t\\t{loc}\")\n            if codon_tables:\n                stats.append(f\"{len(codon_tables): 9d} sequences with codon_table\")\n                for table in codon_tables:\n                    stats.append(f\"\\t\\t\\t{table}\")\n        return stats\n\n    def get_gff3_stats(self, gff3_path: Path) -&gt; List[str]:\n        \"\"\"Extract the gene models from the GFF3 file and compute stats.\n\n        Args:\n            gff3_path (Path): the GFF3 file.\n\n        Returns:\n            List: Stats from the gene model.\n        \"\"\"\n\n        biotypes = self.count_biotypes(gff3_path)\n        # Compile final stats\n        stats = self.biotypes_stats(biotypes)\n        stats += self.check_ncbi_stats(biotypes)\n        return stats\n\n    def count_biotypes(self, gff3_path: Path) -&gt; Dict[str, BiotypeCounter]:\n        \"\"\"Count the biotypes in a GFF3 file.\n\n        Args:\n            gff3_path: Path to the GFF3 file.\n\n        Returns:\n            Dictionary of biotype counters.\n        \"\"\"\n\n        biotypes: Dict[str, BiotypeCounter] = {}\n\n        with open_gz_file(gff3_path) as gff3_handle:\n            for rec in GFF.parse(gff3_handle):\n                for feat1 in rec.features:\n                    # Check if the gene contains proteins (CDSs),\n                    # and keep a count of all hierarchies (e.g. gene-mRNA-CDS)\n                    is_protein = False\n                    for feat2 in feat1.sub_features:\n                        if feat2.type == \"mRNA\":\n                            types2 = {f.type for f in feat2.sub_features}\n                            if \"CDS\" in types2:\n                                is_protein = True\n                        manifest_stats.increment_biotype(biotypes, feat2.id, f\"{feat1.type}-{feat2.type}\")\n                        for feat3 in feat2.sub_features:\n                            if feat3.type == \"exon\":\n                                continue\n                            manifest_stats.increment_biotype(\n                                biotypes, feat3.id, f\"{feat1.type}-{feat2.type}-{feat3.type}\"\n                            )\n\n                    # Main categories counts\n                    if feat1.type == \"pseudogene\":\n                        manifest_stats.increment_biotype(biotypes, feat1.id, \"pseudogene\")\n                    elif is_protein:\n                        manifest_stats.increment_biotype(biotypes, feat1.id, f\"PROT_{feat1.type}\")\n                    else:\n                        # Special case, undefined gene-transcript\n                        if (\n                            feat1.type == \"gene\"\n                            and feat1.sub_features\n                            and feat1.sub_features[0].type == \"transcript\"\n                        ):\n                            manifest_stats.increment_biotype(biotypes, feat1.id, \"OTHER\")\n                        else:\n                            manifest_stats.increment_biotype(biotypes, feat1.id, f\"NONPROT_{feat1.type}\")\n\n                    # Total\n                    if feat1.type in (\"gene\", \"pseudogene\"):\n                        manifest_stats.increment_biotype(biotypes, feat1.id, \"ALL_GENES\")\n        return biotypes\n\n    def biotypes_stats(self, biotypes: Dict[str, BiotypeCounter]) -&gt; List[str]:\n        \"\"\"Prepare biotype stats in order of their name.\n\n        Args:\n            biotypes: Biotypes counters.\n\n        Returns:\n            A list with the computed statistics in a printable format.\n        \"\"\"\n        sorted_biotypes = {}\n        for name in sorted(biotypes.keys()):\n            data: BiotypeCounter = biotypes[name]\n            sorted_biotypes[name] = data\n\n        stats = [\n            f\"{data.unique_count():&gt;9}\\t{biotype:&lt;20}\\tID = {data.example}\"\n            for (biotype, data) in sorted_biotypes.items()\n        ]\n        return stats\n\n    def check_ncbi_stats(self, biotypes: Dict[str, BiotypeCounter]) -&gt; List[str]:\n        \"\"\"Use the dataset tool from NCBI to get stats and compare with what we have\"\"\"\n        stats: List[str] = []\n        if not self.check_ncbi:\n            return stats\n\n        if self.accession is None:\n            return stats\n\n        accession: str = self.accession\n\n        datasets_bin = self.datasets_bin\n        if not which(datasets_bin):\n            return stats\n\n        # Get the dataset summary from NCBI\n        command = [datasets_bin, \"summary\", \"genome\", \"accession\", accession]\n        result_out = subprocess.run(command, stdout=subprocess.PIPE, check=True)\n        result = json.loads(result_out.stdout)\n\n        # Get stats\n        if \"reports\" in result:\n            genome = result[\"reports\"][0]\n            if \"annotation_info\" in genome and \"stats\" in genome[\"annotation_info\"]:\n                ncbi_stats = genome[\"annotation_info\"][\"stats\"]\n\n                if \"gene_counts\" in ncbi_stats:\n                    counts = ncbi_stats[\"gene_counts\"]\n                    stats = self.compare_ncbi_counts(biotypes, counts)\n        return stats\n\n    def compare_ncbi_counts(self, biotypes: Dict[str, BiotypeCounter], ncbi: Dict) -&gt; List[str]:\n        \"\"\"Compare specific gene stats from NCBI\"\"\"\n        stats: List[str] = []\n\n        maps = [\n            [\"total\", \"ALL_GENES\"],\n            [\"protein_coding\", \"PROT_gene\"],\n            [\"pseudogene\", \"pseudogene\"],\n            [\"non_coding\", \"NONPROT_gene\"],\n            [\"other\", \"OTHER\"],\n        ]\n\n        for count_map in maps:\n            ncbi_name, prep_name = count_map\n            ncbi_count = ncbi.get(ncbi_name, 0)\n            prepped: Optional[BiotypeCounter] = biotypes.get(prep_name)\n            prep_count = 0\n            if prepped is not None:\n                prep_count = prepped.count\n\n            if prep_count != ncbi_count:\n                diff = prep_count - ncbi_count\n                self.errors.append(f\"DIFF gene count for {count_map}: {prep_count} - {ncbi_count} = {diff}\")\n            else:\n                stats.append(f\"Same count for {count_map}: {prep_count}\")\n\n        return stats\n\n    @staticmethod\n    def increment_biotype(biotypes: Dict[str, BiotypeCounter], feature_id: str, feature_biotype: str) -&gt; None:\n        \"\"\"Add the feature to their respective biotype counter.\n\n        Args:\n            biotypes (Dict[str, BiotypeCounter]): All current biotypes, with their counter.\n            feature_id (str): Feature id to be counted.\n            feature_biotype (str): The biotype of the feature.\n        \"\"\"\n        if feature_biotype not in biotypes:\n            biotypes[feature_biotype] = BiotypeCounter(example=feature_id)\n        biotypes[feature_biotype].add_id(feature_id)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.accession","title":"<code>accession = accession</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.check_ncbi","title":"<code>check_ncbi = False</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.datasets_bin","title":"<code>datasets_bin = datasets_bin</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.errors","title":"<code>errors = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.errors_file","title":"<code>errors_file = Path(manifest_dir) / 'stats_diff.log'</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.manifest","title":"<code>manifest = f'{manifest_dir}/manifest.json'</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.manifest_parent","title":"<code>manifest_parent = manifest_dir</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.biotypes_stats","title":"<code>biotypes_stats(biotypes)</code>","text":"<p>Prepare biotype stats in order of their name.</p> <p>Parameters:</p> Name Type Description Default <code>biotypes</code> <code>Dict[str, BiotypeCounter]</code> <p>Biotypes counters.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list with the computed statistics in a printable format.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def biotypes_stats(self, biotypes: Dict[str, BiotypeCounter]) -&gt; List[str]:\n    \"\"\"Prepare biotype stats in order of their name.\n\n    Args:\n        biotypes: Biotypes counters.\n\n    Returns:\n        A list with the computed statistics in a printable format.\n    \"\"\"\n    sorted_biotypes = {}\n    for name in sorted(biotypes.keys()):\n        data: BiotypeCounter = biotypes[name]\n        sorted_biotypes[name] = data\n\n    stats = [\n        f\"{data.unique_count():&gt;9}\\t{biotype:&lt;20}\\tID = {data.example}\"\n        for (biotype, data) in sorted_biotypes.items()\n    ]\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.check_ncbi_stats","title":"<code>check_ncbi_stats(biotypes)</code>","text":"<p>Use the dataset tool from NCBI to get stats and compare with what we have</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def check_ncbi_stats(self, biotypes: Dict[str, BiotypeCounter]) -&gt; List[str]:\n    \"\"\"Use the dataset tool from NCBI to get stats and compare with what we have\"\"\"\n    stats: List[str] = []\n    if not self.check_ncbi:\n        return stats\n\n    if self.accession is None:\n        return stats\n\n    accession: str = self.accession\n\n    datasets_bin = self.datasets_bin\n    if not which(datasets_bin):\n        return stats\n\n    # Get the dataset summary from NCBI\n    command = [datasets_bin, \"summary\", \"genome\", \"accession\", accession]\n    result_out = subprocess.run(command, stdout=subprocess.PIPE, check=True)\n    result = json.loads(result_out.stdout)\n\n    # Get stats\n    if \"reports\" in result:\n        genome = result[\"reports\"][0]\n        if \"annotation_info\" in genome and \"stats\" in genome[\"annotation_info\"]:\n            ncbi_stats = genome[\"annotation_info\"][\"stats\"]\n\n            if \"gene_counts\" in ncbi_stats:\n                counts = ncbi_stats[\"gene_counts\"]\n                stats = self.compare_ncbi_counts(biotypes, counts)\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.compare_ncbi_counts","title":"<code>compare_ncbi_counts(biotypes, ncbi)</code>","text":"<p>Compare specific gene stats from NCBI</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def compare_ncbi_counts(self, biotypes: Dict[str, BiotypeCounter], ncbi: Dict) -&gt; List[str]:\n    \"\"\"Compare specific gene stats from NCBI\"\"\"\n    stats: List[str] = []\n\n    maps = [\n        [\"total\", \"ALL_GENES\"],\n        [\"protein_coding\", \"PROT_gene\"],\n        [\"pseudogene\", \"pseudogene\"],\n        [\"non_coding\", \"NONPROT_gene\"],\n        [\"other\", \"OTHER\"],\n    ]\n\n    for count_map in maps:\n        ncbi_name, prep_name = count_map\n        ncbi_count = ncbi.get(ncbi_name, 0)\n        prepped: Optional[BiotypeCounter] = biotypes.get(prep_name)\n        prep_count = 0\n        if prepped is not None:\n            prep_count = prepped.count\n\n        if prep_count != ncbi_count:\n            diff = prep_count - ncbi_count\n            self.errors.append(f\"DIFF gene count for {count_map}: {prep_count} - {ncbi_count} = {diff}\")\n        else:\n            stats.append(f\"Same count for {count_map}: {prep_count}\")\n\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.coord_systems_stats","title":"<code>coord_systems_stats(coord_systems)</code>","text":"For each coord_system compute various stats <ul> <li>number of sequences</li> <li>sequence length sum, minimum, maximum, mean</li> </ul> <p>Parameters:</p> Name Type Description Default <code>coord_systems</code> <code>Dict[str, List[int]]</code> <p>Coordinate system dictionary of lengths.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list with the computed statistics in a printable format.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def coord_systems_stats(self, coord_systems: Dict[str, List[int]]) -&gt; List[str]:\n    \"\"\"For each coord_system compute various stats:\n        - number of sequences\n        - sequence length sum, minimum, maximum, mean\n\n    Args:\n        coord_systems: Coordinate system dictionary of lengths.\n\n    Returns:\n        A list with the computed statistics in a printable format.\n    \"\"\"\n    stats: List[str] = []\n    stats.append(f\"Total coord_systems {len(coord_systems)}\")\n    for coord_name, lengths in coord_systems.items():\n        stats.append(f\"\\nCoord_system: {coord_name}\")\n\n        stat_counts: Dict[str, Union[int, float]] = {\n            \"Number of sequences\": len(lengths),\n            \"Sequence length sum\": sum(lengths),\n            \"Sequence length minimum\": min(lengths),\n            \"Sequence length maximum\": max(lengths),\n            \"Sequence length mean\": mean(lengths),\n        }\n\n        for name, count in stat_counts.items():\n            if isinstance(count, int):\n                stats.append(f\"{count: 9d}\\t{name}\")\n            else:\n                stats.append(f\"{count: 9f}\\t{name}\")\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.count_biotypes","title":"<code>count_biotypes(gff3_path)</code>","text":"<p>Count the biotypes in a GFF3 file.</p> <p>Parameters:</p> Name Type Description Default <code>gff3_path</code> <code>Path</code> <p>Path to the GFF3 file.</p> required <p>Returns:</p> Type Description <code>Dict[str, BiotypeCounter]</code> <p>Dictionary of biotype counters.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def count_biotypes(self, gff3_path: Path) -&gt; Dict[str, BiotypeCounter]:\n    \"\"\"Count the biotypes in a GFF3 file.\n\n    Args:\n        gff3_path: Path to the GFF3 file.\n\n    Returns:\n        Dictionary of biotype counters.\n    \"\"\"\n\n    biotypes: Dict[str, BiotypeCounter] = {}\n\n    with open_gz_file(gff3_path) as gff3_handle:\n        for rec in GFF.parse(gff3_handle):\n            for feat1 in rec.features:\n                # Check if the gene contains proteins (CDSs),\n                # and keep a count of all hierarchies (e.g. gene-mRNA-CDS)\n                is_protein = False\n                for feat2 in feat1.sub_features:\n                    if feat2.type == \"mRNA\":\n                        types2 = {f.type for f in feat2.sub_features}\n                        if \"CDS\" in types2:\n                            is_protein = True\n                    manifest_stats.increment_biotype(biotypes, feat2.id, f\"{feat1.type}-{feat2.type}\")\n                    for feat3 in feat2.sub_features:\n                        if feat3.type == \"exon\":\n                            continue\n                        manifest_stats.increment_biotype(\n                            biotypes, feat3.id, f\"{feat1.type}-{feat2.type}-{feat3.type}\"\n                        )\n\n                # Main categories counts\n                if feat1.type == \"pseudogene\":\n                    manifest_stats.increment_biotype(biotypes, feat1.id, \"pseudogene\")\n                elif is_protein:\n                    manifest_stats.increment_biotype(biotypes, feat1.id, f\"PROT_{feat1.type}\")\n                else:\n                    # Special case, undefined gene-transcript\n                    if (\n                        feat1.type == \"gene\"\n                        and feat1.sub_features\n                        and feat1.sub_features[0].type == \"transcript\"\n                    ):\n                        manifest_stats.increment_biotype(biotypes, feat1.id, \"OTHER\")\n                    else:\n                        manifest_stats.increment_biotype(biotypes, feat1.id, f\"NONPROT_{feat1.type}\")\n\n                # Total\n                if feat1.type in (\"gene\", \"pseudogene\"):\n                    manifest_stats.increment_biotype(biotypes, feat1.id, \"ALL_GENES\")\n    return biotypes\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.get_gff3_stats","title":"<code>get_gff3_stats(gff3_path)</code>","text":"<p>Extract the gene models from the GFF3 file and compute stats.</p> <p>Parameters:</p> Name Type Description Default <code>gff3_path</code> <code>Path</code> <p>the GFF3 file.</p> required <p>Returns:</p> Name Type Description <code>List</code> <code>List[str]</code> <p>Stats from the gene model.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def get_gff3_stats(self, gff3_path: Path) -&gt; List[str]:\n    \"\"\"Extract the gene models from the GFF3 file and compute stats.\n\n    Args:\n        gff3_path (Path): the GFF3 file.\n\n    Returns:\n        List: Stats from the gene model.\n    \"\"\"\n\n    biotypes = self.count_biotypes(gff3_path)\n    # Compile final stats\n    stats = self.biotypes_stats(biotypes)\n    stats += self.check_ncbi_stats(biotypes)\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.get_manifest","title":"<code>get_manifest()</code>","text":"<p>Get the files metadata from the manifest json file.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A representation of the manifest json data.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def get_manifest(self) -&gt; Dict:\n    \"\"\"Get the files metadata from the manifest json file.\n\n    Returns:\n        Dict: A representation of the manifest json data.\n    \"\"\"\n    with open(self.manifest) as f_json:\n        manifest = json.load(f_json)\n        manifest_root = self.manifest_parent\n\n    # Use dir name from the manifest\n    for name in manifest:\n        if \"file\" in manifest[name]:\n            file_name = manifest[name][\"file\"]\n            file_name = f\"{manifest_root}/{file_name}\"\n            manifest[name] = file_name\n        else:\n            for f in manifest[name]:\n                if \"file\" in manifest[name][f]:\n                    file_name = manifest[name][f][\"file\"]\n                    file_name = manifest_root, file_name\n                    manifest[name][f] = file_name\n\n    return manifest\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.get_seq_region_stats","title":"<code>get_seq_region_stats(seq_region_path)</code>","text":"<p>Compute stats from the seq_region json file.</p> <p>Parameters:</p> Name Type Description Default <code>seq_region_path</code> <code>Path</code> <p>the seq_region json file.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: Stats from the seq_regions.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def get_seq_region_stats(self, seq_region_path: Path) -&gt; List[str]:\n    \"\"\"Compute stats from the seq_region json file.\n\n    Args:\n        seq_region_path (Path): the seq_region json file.\n\n    Returns:\n        List[str]: Stats from the seq_regions.\n    \"\"\"\n    with seq_region_path.open(\"r\") as json_file:\n        seq_regions = json.load(json_file)\n\n    # Get basic data\n    coord_systems: Dict[str, List[int]] = {}\n    circular = 0\n    locations = []\n    codon_tables = []\n    for seqr in seq_regions:\n        # Get readable seq_region name:\n        # either use a Genbank synonym, or just the provided seq_region name\n        genbank = \"synonyms\" in seqr and [x for x in seqr[\"synonyms\"] if x[\"source\"] == \"GenBank\"]\n        seqr_name = genbank and genbank[0][\"name\"] or seqr[\"name\"]\n\n        # Record the lengths of the elements of each coord_system\n        coord_level = seqr[\"coord_system_level\"]\n        if coord_level not in coord_systems:\n            coord_systems[coord_level] = []\n        coord_systems[coord_level].append(seqr[\"length\"])\n\n        # Additional metadata records to count\n        if \"circular\" in seqr:\n            circular += 1\n        if \"codon_table\" in seqr:\n            codon_tables.append(f\"{seqr_name} = {seqr['codon_table']}\")\n        if \"location\" in seqr:\n            locations.append(f\"{seqr_name} = {seqr['location']}\")\n\n    # Stats\n    stats: List[str] = []\n    stats.append(seq_region_path.name)\n    stats += self.coord_systems_stats(coord_systems)\n    stats += self.seq_region_special_stats(circular, locations, codon_tables)\n    stats.append(\"\\n\")\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.increment_biotype","title":"<code>increment_biotype(biotypes, feature_id, feature_biotype)</code>  <code>staticmethod</code>","text":"<p>Add the feature to their respective biotype counter.</p> <p>Parameters:</p> Name Type Description Default <code>biotypes</code> <code>Dict[str, BiotypeCounter]</code> <p>All current biotypes, with their counter.</p> required <code>feature_id</code> <code>str</code> <p>Feature id to be counted.</p> required <code>feature_biotype</code> <code>str</code> <p>The biotype of the feature.</p> required Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>@staticmethod\ndef increment_biotype(biotypes: Dict[str, BiotypeCounter], feature_id: str, feature_biotype: str) -&gt; None:\n    \"\"\"Add the feature to their respective biotype counter.\n\n    Args:\n        biotypes (Dict[str, BiotypeCounter]): All current biotypes, with their counter.\n        feature_id (str): Feature id to be counted.\n        feature_biotype (str): The biotype of the feature.\n    \"\"\"\n    if feature_biotype not in biotypes:\n        biotypes[feature_biotype] = BiotypeCounter(example=feature_id)\n    biotypes[feature_biotype].add_id(feature_id)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.run","title":"<code>run(stats_path)</code>","text":"<p>Compute stats in the files and output a stats.txt file in the same folder.</p> <p>Raises:</p> Type Description <code>StatsError</code> <p>Could not compute some stats.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def run(self, stats_path: StrPath) -&gt; None:\n    \"\"\"Compute stats in the files and output a stats.txt file in the same folder.\n\n    Raises:\n        StatsError: Could not compute some stats.\n    \"\"\"\n    manifest = self.get_manifest()\n\n    stats = []\n    if self.accession is not None:\n        stats.append(self.accession)\n\n    # Compute the stats from the GFF3 file\n    if \"gff3\" in manifest:\n        stats += self.get_gff3_stats(Path(manifest[\"gff3\"]))\n\n    # Compute the stats from the seq_region file\n    if \"seq_region\" in manifest:\n        stats += self.get_seq_region_stats(Path(manifest[\"seq_region\"]))\n\n    # Print out the stats in a separate file\n    with Path(stats_path).open(\"w\") as stats_out:\n        stats_out.write(\"\\n\".join(stats))\n\n    # Die if there were errors in stats comparison\n    if self.errors:\n        with self.errors_file.open(\"w\") as errors_fh:\n            for error_line in self.errors:\n                errors_fh.write(error_line)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.manifest_stats.seq_region_special_stats","title":"<code>seq_region_special_stats(circular=0, locations=None, codon_tables=None)</code>","text":"<p>Prepare stats in case there are circular regions, specific locations and codon_tables.         stats.append(f\"{count: 9f}      {name}\")</p> <p>Parameters:</p> Name Type Description Default <code>circular</code> <code>int</code> <p>Number of circular regions. Defaults to 0.</p> <code>0</code> <code>locations</code> <code>Optional[List[str]]</code> <p>The regions and their location. Defaults to None.</p> <code>None</code> <code>codon_tables</code> <code>Optional[List[str]]</code> <p>The regions and their codon_table. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list with the computed statistics in a printable format.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def seq_region_special_stats(\n    self,\n    circular: int = 0,\n    locations: Optional[List[str]] = None,\n    codon_tables: Optional[List[str]] = None,\n) -&gt; List[str]:\n    \"\"\"Prepare stats in case there are circular regions, specific locations and codon_tables.\n            stats.append(f\"{count: 9f}\\t{name}\")\n\n    Args:\n        circular: Number of circular regions. Defaults to 0.\n        locations: The regions and their location. Defaults to None.\n        codon_tables: The regions and their codon_table. Defaults to None.\n\n    Returns:\n        A list with the computed statistics in a printable format.\n    \"\"\"\n    stats: List[str] = []\n    if circular or locations or codon_tables:\n        stats.append(\"\\nSpecial\")\n        if circular:\n            stats.append(f\"{circular: 9d}\\tcircular sequences\")\n        if locations is not None:\n            stats.append(f\"{len(locations): 9d} sequences with location\")\n            for loc in locations:\n                stats.append(f\"\\t\\t\\t{loc}\")\n        if codon_tables:\n            stats.append(f\"{len(codon_tables): 9d} sequences with codon_table\")\n            for table in codon_tables:\n                stats.append(f\"\\t\\t\\t{table}\")\n    return stats\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/compute_stats/#ensembl.io.genomio.manifest.compute_stats.main","title":"<code>main()</code>","text":"<p>Main entrypoint.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/compute_stats.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entrypoint.\"\"\"\n    parser = ArgumentParser(\n        description=\"Compute stats from the current genome files associated with the manifest.\"\n    )\n    parser.add_argument_src_path(\n        \"--manifest_dir\", required=True, help=\"Manifest directory where 'manifest.json' file is located\"\n    )\n    parser.add_argument(\"--accession\", help=\"Sequence accession ID to compare stats with NCBI\")\n    parser.add_argument(\"--datasets_bin\", help=\"Datasets bin status\")\n    parser.add_argument_dst_path(\"--stats_file\", help=\"Output file with the stats\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    mstats = manifest_stats(args.manifest_dir, args.accession, args.datasets_bin)\n    if args.accession is not None:\n        mstats.check_ncbi = True\n    stats_file = args.stats_file if args.stats_file is not None else args.manifest_dir / \"stats.txt\"\n    mstats.run(stats_file)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/generate/","title":"generate","text":""},{"location":"reference/ensembl/io/genomio/manifest/generate/#ensembl.io.genomio.manifest.generate","title":"<code>ensembl.io.genomio.manifest.generate</code>","text":"<p>Creates a manifest file in a folder depending on the file names ends.</p>"},{"location":"reference/ensembl/io/genomio/manifest/generate/#ensembl.io.genomio.manifest.generate.main","title":"<code>main()</code>","text":"<p>Main entrypoint.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/generate.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entrypoint.\"\"\"\n    parser = ArgumentParser(\n        description=\"Compare the genomic data between the files present in a manifest file.\"\n    )\n    parser.add_argument_dst_path(\n        \"--manifest_dir\", required=True, help=\"Folder where to create a manifest file\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    manifest = Manifest(args.manifest_dir)\n    manifest.create()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest/","title":"manifest","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest","title":"<code>ensembl.io.genomio.manifest.manifest</code>","text":"<p>Representation of a manifest file.</p>"},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.ManifestDict","title":"<code>ManifestDict = dict[str, dict[str, Any]]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest","title":"<code>Manifest</code>","text":"<p>Records of a manifest file and its files and md5 checksums.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>class Manifest:\n    \"\"\"Records of a manifest file and its files and md5 checksums.\"\"\"\n\n    _same_names = {\n        \"gff3\",\n        \"fasta_dna\",\n        \"fasta_pep\",\n        \"functional_annotation\",\n        \"genome\",\n        \"seq_attrib\",\n        \"seq_region\",\n        \"agp\",\n        \"events\",\n    }\n    _alias_names = {\n        \"gene_models\": \"gff3\",\n        \"dna\": \"fasta_dna\",\n        \"pep\": \"fasta_pep\",\n    }\n    _same_names_dict = {name: name for name in _same_names}\n    names = {**_same_names_dict, **_alias_names}\n    multi_files = {\"agp\"}\n\n    def __init__(self, manifest_dir: Path) -&gt; None:\n        \"\"\"Initializes a manifest with the directory containing the files (and a manifest if it exists).\n\n        Args:\n            manifest_dir: directory where the files are contained.\n        \"\"\"\n        self.root_dir = manifest_dir\n        self.file_path = manifest_dir / \"manifest.json\"\n        self.files: dict = {}\n\n    def create(self) -&gt; None:\n        \"\"\"Creates a manifest file from the files in a directory.\"\"\"\n        self.get_files_checksums()\n        with self.file_path.open(\"w\") as json_out:\n            json_out.write(json.dumps(self.files, sort_keys=True, indent=4))\n\n    def get_files_checksums(self) -&gt; ManifestDict:\n        \"\"\"Records all the files in the directory with their checksum.\"\"\"\n        manifest_files: ManifestDict = {}\n        for subfile in self.root_dir.iterdir():\n            logging.debug(f\"Check file {subfile} ({subfile.stem}, {subfile.suffix})\")\n            used_file = False\n            if subfile.is_dir():\n                logging.warning(\"Can't create manifest for subdirectory\")\n                continue\n\n            # Delete and skip empty files\n            if subfile.stat().st_size == 0:\n                logging.warning(f\"Skip and delete empty file: {subfile}\")\n                subfile.unlink()\n                continue\n\n            for name, standard_name in self.names.items():\n                # Either the last element of the stem or the suffix is a known name\n                if subfile.stem.endswith(name) or subfile.suffix == f\".{name}\":\n                    logging.debug(f\"Matched to {name} ({standard_name}) = {subfile}\")\n                    used_file = True\n                    md5 = self._get_md5sum(subfile)\n                    file_obj = {\"file\": subfile.name, \"md5sum\": md5}\n\n                    # Multiple files stored, each with a name\n                    if standard_name in self.multi_files:\n                        manifest_files.setdefault(standard_name, {})\n                        obj_name = self._prepare_object_name(subfile, name, manifest_files[standard_name])\n                        manifest_files[standard_name][obj_name] = file_obj\n\n                    # Single file/init\n                    else:\n                        manifest_files[standard_name] = file_obj\n\n            if not used_file:\n                logging.warning(f\"File {subfile} was not included in the manifest\")\n\n        self.files = manifest_files\n        return self.files\n\n    def _prepare_object_name(\n        self, subfile: Path, name: str, manifest_file_dict: dict[str, dict[str, str]]\n    ) -&gt; str:\n        # Prepare object name\n        try:\n            # If we recognize the suffix, then the name is the part after the last \"_\"\n            if subfile.suffix == f\".{name}\":\n                obj_name = subfile.stem.split(sep=\"_\")[-1]\n            # If we recognize the end of the name, then the name is the part before the last \"_\"\n            else:\n                obj_name = subfile.stem.split(sep=\"_\")[-2]\n        except IndexError:\n            obj_name = \"file\"\n\n        # Add number if duplicate name\n        obj_name_base = obj_name\n        count = 1\n        while obj_name in manifest_file_dict.keys():\n            obj_name = f\"{obj_name_base}.{count}\"\n            count += 1\n            if count &gt;= 10:\n                raise ValueError(f\"Too many files with same name {obj_name_base}\")\n        return obj_name\n\n    def load(self) -&gt; ManifestDict:\n        \"\"\"Load the content of an existing manifest file.\"\"\"\n        if not self.file_path.exists():\n            raise ManifestError(f\"Cannot load non-existing manifest file: {self.file_path}\")\n\n        with self.file_path.open(\"r\") as manifest_fh:\n            manifest = json.load(manifest_fh)\n\n            # Use dir name from the manifest\n            for name in manifest:\n                if \"file\" in manifest[name]:\n                    file_path = self.root_dir / manifest[name][\"file\"]\n                    # check if the md5sum is correct\n                    md5sum = manifest[name][\"md5sum\"]\n                    self._check_md5sum(file_path, md5sum)\n                else:\n                    for f in manifest[name]:\n                        file_path = self.root_dir / manifest[name][f][\"file\"]\n                        # check if the md5sum is correct\n                        md5sum = manifest[name][f][\"md5sum\"]\n                        self._check_md5sum(file_path, md5sum)\n\n            self.files = manifest\n        return self.files\n\n    @staticmethod\n    def _get_md5sum(file_path: Path) -&gt; str:\n        \"\"\"Returns the md5 checksum for a given file.\"\"\"\n        with file_path.open(\"rb\") as f:\n            data_bytes = f.read()\n            return hashlib.md5(data_bytes).hexdigest()\n\n    def _check_md5sum(self, file_path: Path, md5sum: str) -&gt; None:\n        \"\"\"Checks a file against an md5 checksum, raises a ManifestError if the checksum fails.\n\n        Args:\n            file_path: Path to a genome file.\n            md5sum: MD5 hash for the files.\n        \"\"\"\n        file_md5sum = self._get_md5sum(file_path)\n        if file_md5sum != md5sum:\n            raise ManifestError(f\"Invalid md5 checksum for {file_path}: got {file_md5sum}, expected {md5sum}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest.file_path","title":"<code>file_path = manifest_dir / 'manifest.json'</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest.files","title":"<code>files = {}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest.multi_files","title":"<code>multi_files = {'agp'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest.names","title":"<code>names = {None: _same_names_dict, None: _alias_names}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest.root_dir","title":"<code>root_dir = manifest_dir</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest.create","title":"<code>create()</code>","text":"<p>Creates a manifest file from the files in a directory.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>def create(self) -&gt; None:\n    \"\"\"Creates a manifest file from the files in a directory.\"\"\"\n    self.get_files_checksums()\n    with self.file_path.open(\"w\") as json_out:\n        json_out.write(json.dumps(self.files, sort_keys=True, indent=4))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest.get_files_checksums","title":"<code>get_files_checksums()</code>","text":"<p>Records all the files in the directory with their checksum.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>def get_files_checksums(self) -&gt; ManifestDict:\n    \"\"\"Records all the files in the directory with their checksum.\"\"\"\n    manifest_files: ManifestDict = {}\n    for subfile in self.root_dir.iterdir():\n        logging.debug(f\"Check file {subfile} ({subfile.stem}, {subfile.suffix})\")\n        used_file = False\n        if subfile.is_dir():\n            logging.warning(\"Can't create manifest for subdirectory\")\n            continue\n\n        # Delete and skip empty files\n        if subfile.stat().st_size == 0:\n            logging.warning(f\"Skip and delete empty file: {subfile}\")\n            subfile.unlink()\n            continue\n\n        for name, standard_name in self.names.items():\n            # Either the last element of the stem or the suffix is a known name\n            if subfile.stem.endswith(name) or subfile.suffix == f\".{name}\":\n                logging.debug(f\"Matched to {name} ({standard_name}) = {subfile}\")\n                used_file = True\n                md5 = self._get_md5sum(subfile)\n                file_obj = {\"file\": subfile.name, \"md5sum\": md5}\n\n                # Multiple files stored, each with a name\n                if standard_name in self.multi_files:\n                    manifest_files.setdefault(standard_name, {})\n                    obj_name = self._prepare_object_name(subfile, name, manifest_files[standard_name])\n                    manifest_files[standard_name][obj_name] = file_obj\n\n                # Single file/init\n                else:\n                    manifest_files[standard_name] = file_obj\n\n        if not used_file:\n            logging.warning(f\"File {subfile} was not included in the manifest\")\n\n    self.files = manifest_files\n    return self.files\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.Manifest.load","title":"<code>load()</code>","text":"<p>Load the content of an existing manifest file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>def load(self) -&gt; ManifestDict:\n    \"\"\"Load the content of an existing manifest file.\"\"\"\n    if not self.file_path.exists():\n        raise ManifestError(f\"Cannot load non-existing manifest file: {self.file_path}\")\n\n    with self.file_path.open(\"r\") as manifest_fh:\n        manifest = json.load(manifest_fh)\n\n        # Use dir name from the manifest\n        for name in manifest:\n            if \"file\" in manifest[name]:\n                file_path = self.root_dir / manifest[name][\"file\"]\n                # check if the md5sum is correct\n                md5sum = manifest[name][\"md5sum\"]\n                self._check_md5sum(file_path, md5sum)\n            else:\n                for f in manifest[name]:\n                    file_path = self.root_dir / manifest[name][f][\"file\"]\n                    # check if the md5sum is correct\n                    md5sum = manifest[name][f][\"md5sum\"]\n                    self._check_md5sum(file_path, md5sum)\n\n        self.files = manifest\n    return self.files\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest/#ensembl.io.genomio.manifest.manifest.ManifestError","title":"<code>ManifestError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Could not load a manifest file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest.py</code> <pre><code>class ManifestError(Exception):\n    \"\"\"Could not load a manifest file.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/","title":"manifest_stats","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats","title":"<code>ensembl.io.genomio.manifest.manifest_stats</code>","text":"<p>Register the main stats for all files from a manifest for comparison.</p>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.StatsLengths","title":"<code>StatsLengths = dict[str, int]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.InvalidIntegrityError","title":"<code>InvalidIntegrityError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When a file integrity check fails</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>class InvalidIntegrityError(Exception):\n    \"\"\"When a file integrity check fails\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats","title":"<code>ManifestStats</code>","text":"<p>Representation of the main stats of the files in a manifest for comparison.</p> <p>The stats in question are: - lengths of sequences (DNA, genes and peptides) - sequences and features IDs - sequences circularity</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>class ManifestStats:\n    \"\"\"Representation of the main stats of the files in a manifest for comparison.\n\n    The stats in question are:\n    - lengths of sequences (DNA, genes and peptides)\n    - sequences and features IDs\n    - sequences circularity\n    \"\"\"\n\n    def __init__(self, manifest_path: StrPath, ignore_final_stops: bool = False) -&gt; None:\n        self.manifest_files = self._get_manifest(manifest_path)\n        self.genome: dict[str, Any] = {}\n\n        self.lengths: dict[str, StatsLengths] = {\n            \"dna_sequences\": {},\n            \"peptide_sequences\": {},\n            \"seq_region_levels\": {},\n            \"annotations\": {},\n            \"agp\": {},\n            \"gff3_seq_regions\": {},\n            \"gff3_genes\": {},\n            \"gff3_translations\": {},\n            \"gff3_all_translations\": {},\n            \"gff3_transposable_elements\": {},\n            \"ann_genes\": {},\n            \"ann_translations\": {},\n            \"ann_transposable_elements\": {},\n            \"seq_regions\": {},\n        }\n\n        self.circular: dict[str, StatsLengths] = {\n            \"seq_regions\": {},\n        }\n\n        self.errors: list[str] = []\n\n        self.ignore_final_stops = ignore_final_stops\n\n    def _get_manifest(self, manifest_path: PathLike) -&gt; dict[str, Any]:\n        \"\"\"Load the content of a manifest file.\n\n        Returns:\n            Dict: Content of the manifest file.\n        \"\"\"\n        manifest = Manifest(Path(manifest_path).parent)\n        manifest_files = manifest.load()\n\n        # Replace the {file, md5} dict with the file path\n        for name in manifest_files:\n            if \"file\" in manifest_files[name]:\n                manifest_files[name] = Path(manifest_path).parent / manifest_files[name][\"file\"]\n            else:\n                for f in manifest_files[name]:\n                    manifest_files[name][f] = Path(manifest_path).parent / manifest_files[name][f][\"file\"]\n        return manifest_files\n\n    def add_error(self, error: str) -&gt; None:\n        \"\"\"Record an error.\"\"\"\n        self.errors.append(error)\n\n    def load_seq_regions(self) -&gt; None:\n        \"\"\"Retrieve seq_regions lengths and circular information from the seq_region JSON file.\"\"\"\n\n        if \"seq_region\" not in self.manifest_files:\n            return\n        logging.info(\"Manifest contains seq_region JSON\")\n        seq_regions = get_json(Path(self.manifest_files[\"seq_region\"]))\n        seqr_seqlevel = {}\n        seq_lengths = {}\n        seq_circular = {}\n        # Store the length as int\n        for seq in seq_regions:\n            seq_lengths[seq[\"name\"]] = int(seq[\"length\"])\n            seq_circular[seq[\"name\"]] = seq.get(\"circular\", False)\n            if seq[\"coord_system_level\"] == \"contig\":\n                seqr_seqlevel[seq[\"name\"]] = int(seq[\"length\"])\n            # Also record synonyms (in case GFF file uses synonyms)\n            if \"synonyms\" in seq:\n                for synonym in seq[\"synonyms\"]:\n                    seq_lengths[synonym[\"name\"]] = int(seq[\"length\"])\n        self.lengths[\"seq_regions\"] = seq_lengths\n        self.circular[\"seq_regions\"] = seq_circular\n\n    def load_peptides_fasta_lengths(self) -&gt; None:\n        \"\"\"Retrieve peptides sequences lengths from their FASTA file.\"\"\"\n        if \"fasta_pep\" not in self.manifest_files:\n            return\n        self.lengths[\"peptide_sequences\"] = self._get_fasta_lengths(\n            self.manifest_files[\"fasta_pep\"], ignore_final_stops=self.ignore_final_stops\n        )\n\n    def load_dna_fasta_lengths(self) -&gt; None:\n        \"\"\"Retrieve DNA sequences lengths from their FASTA file.\"\"\"\n        if \"fasta_dna\" not in self.manifest_files:\n            return\n        self.lengths[\"dna_sequences\"] = self._get_fasta_lengths(self.manifest_files[\"fasta_dna\"])\n\n    def _get_fasta_lengths(self, fasta_path: StrPath, ignore_final_stops: bool = False) -&gt; dict[str, int]:\n        \"\"\"Returns every sequence ID and its length from a FASTA file (DNA or peptide).\n\n        An error will be added for every empty id, non-unique id or stop codon found in the FASTA file.\n\n        Args:\n            fasta_path: Path to FASTA file.\n            ignore_final_stops: Do not include final stop in the total length.\n\n        \"\"\"\n\n        data = {}\n        non_unique = {}\n        non_unique_count = 0\n        empty_id_count = 0\n        contains_stop_codon = 0\n        rec_count = 0\n        for rec in SeqIO.parse(fasta_path, \"fasta\"):\n            rec_count += 1\n\n            # Flag empty ids\n            if rec.id == \"\":\n                empty_id_count += 1\n                continue\n            # Flag redundant ids\n            if rec.id in data:\n                non_unique[rec.id] = 1\n                non_unique_count += 1\n            # Store sequence id and length\n            data[rec.id] = len(rec.seq)\n            stops = rec.seq.count(\"*\")\n            if stops &gt;= 1 and not rec.seq.endswith(\"*\"):\n                contains_stop_codon += 1\n            elif rec.seq.endswith(\"*\") and not ignore_final_stops:\n                contains_stop_codon += 1\n\n        if empty_id_count &gt; 0:\n            self.add_error(f\"{empty_id_count} sequences with empty ids in {fasta_path}\")\n        if non_unique_count &gt; 0:\n            self.add_error(f\"{non_unique_count} non unique sequence ids in {fasta_path}\")\n        if contains_stop_codon &gt; 0:\n            self.add_error(f\"{contains_stop_codon} sequences with stop codons in {fasta_path}\")\n        if rec_count == 0:\n            self.add_error(f\"No sequences found in {fasta_path}\")\n        return data\n\n    def load_functional_annotation(self) -&gt; None:\n        \"\"\"Load the functional annotation file to retrieve the gene_id and translation id.\n\n        The functional annotation file is stored in a JSON format containing the description, id\n        and object type, eg: \"gene\", \"transcript\", \"translation\".\n\n        \"\"\"\n        if \"functional_annotation\" not in self.manifest_files:\n            return\n        logging.info(\"Manifest contains functional annotation(s)\")\n\n        # Load the json file\n        with open(self.manifest_files[\"functional_annotation\"]) as json_file:\n            data = json.load(json_file)\n\n        # Get gene ids and translation ids\n        genes = {}\n        translations = {}\n        transposons = {}\n\n        for item in data:\n            if item[\"object_type\"] == \"gene\":\n                genes[item[\"id\"]] = 1\n            elif item[\"object_type\"] == \"translation\":\n                translations[item[\"id\"]] = 1\n            if item[\"object_type\"] == \"transposable_element\":\n                transposons[item[\"id\"]] = 1\n\n        stats = {\n            \"ann_genes\": genes,\n            \"ann_translations\": translations,\n            \"ann_transposable_elements\": transposons,\n        }\n        self.lengths = {**self.lengths, **stats}\n\n    def load_gff3(self) -&gt; None:\n        \"\"\"A GFF3 parser is used to retrieve information in the GFF3 file such as\n        gene and CDS ids and their corresponding lengths.\n        \"\"\"\n        if \"gff3\" not in self.manifest_files:\n            return\n        logging.info(\"Manifest contains GFF3 gene annotations\")\n        gff3_path = self.manifest_files[\"gff3\"]\n\n        seqs: StatsLengths = {}\n        genes: StatsLengths = {}\n        peps: StatsLengths = {}\n        all_peps: StatsLengths = {}\n        tes: StatsLengths = {}\n\n        with open_gz_file(gff3_path) as gff3_handle:\n            gff = GFF.parse(gff3_handle)\n            for seq in gff:\n                seqs[seq.id] = len(seq.seq)\n\n                for feat in seq.features:\n                    feat_length = abs(feat.location.end - feat.location.start)\n                    # Store gene id and length\n                    if feat.type in [\"gene\", \"ncRNA_gene\", \"pseudogene\"]:\n                        self._retrieve_gff_gene_lengths(feat, genes, peps, all_peps)\n                    if feat.type == \"transposable_element\":\n                        tes[feat.id] = feat_length\n\n        stats: dict[str, StatsLengths] = {\n            \"gff3_seq_regions\": seqs,\n            \"gff3_genes\": genes,\n            \"gff3_translations\": peps,\n            \"gff3_all_translations\": all_peps,\n            \"gff3_transposable_elements\": tes,\n        }\n        self.lengths = {**self.lengths, **stats}\n\n    def _retrieve_gff_gene_lengths(\n        self, feat: GFFSeqFeature, genes: StatsLengths, peps: StatsLengths, all_peps: StatsLengths\n    ) -&gt; None:\n        \"\"\"Record genes and peptides lengths from a feature.\n\n        Args:\n            feat : Gene feature to check.\n            genes: Record of genes lengths to update.\n            peps: Record of peptides lengths to update.\n            all_peps: Record of all peptides lengths to update (include pseudogenes).\n\n        \"\"\"\n        gene_id = feat.id\n        gene_id = gene_id.replace(\"gene:\", \"\")\n        genes[gene_id] = abs(feat.location.end - feat.location.start)\n        # Get CDS id and length\n        protein_transcripts = {\n            \"mRNA\",\n            \"pseudogenic_transcript\",\n        }\n        ig_transcripts = {\n            \"IG_V_gene\",\n            \"IG_C_gene\",\n            \"TR_C_gene\",\n            \"TR_V_gene\",\n        }\n        cds_transcripts = protein_transcripts.union(ig_transcripts)\n        for feat2 in feat.sub_features:\n            if feat2.type not in cds_transcripts:\n                continue\n            length: dict[str, int] = {}\n            for feat3 in feat2.sub_features:\n                if feat3.type != \"CDS\":\n                    continue\n                pep_id = feat3.id\n                pep_id = pep_id.replace(\"CDS:\", \"\")\n                length.setdefault(pep_id, 0)\n                length[pep_id] += abs(feat3.location.end - feat3.location.start)\n            for pep_id, pep_length in length.items():\n                # Store length for translations, add pseudo translations separately\n                pep_length = floor(pep_length / 3) - 1\n                if feat.type != \"pseudogene\" and feat2.type in protein_transcripts:\n                    peps[pep_id] = pep_length\n                all_peps[pep_id] = pep_length\n\n    def load_agp_seq_regions(self, agp_dict: dict | None) -&gt; None:\n        \"\"\"AGP files describe the assembly of larger sequence objects using smaller objects.\n\n        E.g. describes the assembly of scaffolds from contigs.\n\n        Args:\n            agp_dict: Dict containing the information about the sequence.\n\n        Note:\n            AGP file is only used in the older builds, not used for current processing.\n        \"\"\"\n        if not agp_dict:\n            return\n        logging.info(\"Manifest contains AGP files\")\n\n        seqr: StatsLengths = {}\n        for agp_path in agp_dict.values():\n            with open(agp_path, \"r\") as agph:\n                for line in agph:\n                    (\n                        asm_id,\n                        _,  # asm_start\n                        asm_end,\n                        _,  # asm_part\n                        typ,\n                        cmp_id,\n                        _,  # cmp_start\n                        cmp_end,\n                        _,  # cmp_strand\n                    ) = line.split(\"\\t\")\n                    # Ignore WGS contig\n                    if typ != \"W\":\n                        continue\n\n                    # Assembled seq length\n                    if asm_id not in seqr or seqr[asm_id] &lt; int(asm_end):\n                        seqr[asm_id] = int(asm_end)\n\n                    # Composite seq length\n                    if cmp_id not in seqr or seqr[cmp_id] &lt; int(cmp_end):\n                        seqr[cmp_id] = int(cmp_end)\n\n        self.lengths[\"agp\"] = seqr\n\n    def load_genome(self) -&gt; None:\n        \"\"\"Load the genome data.\"\"\"\n        if \"genome\" not in self.manifest_files:\n            return\n        logging.info(\"Manifest contains genome JSON\")\n        self.genome = get_json(Path(self.manifest_files[\"genome\"]))\n\n    def prepare_integrity_data(self) -&gt; None:  # pylint: disable=too-many-branches\n        \"\"\"Read all the files and keep a record (IDs and their lengths) for each case to be compared later.\"\"\"\n        self.load_gff3()\n        self.load_dna_fasta_lengths()\n        self.load_peptides_fasta_lengths()\n        self.load_seq_regions()\n        self.load_functional_annotation()\n        self.load_agp_seq_regions(self.manifest_files.get(\"agp\"))\n        self.load_genome()\n\n    def has_lengths(self, name: str) -&gt; bool:\n        \"\"\"Check if a given name has lengths records.\n\n        Args:\n            name: Name for the lengths to check.\n\n        Raises:\n            KeyError: If the name is not supported.\n        \"\"\"\n        try:\n            return bool(self.lengths[name])\n        except KeyError as err:\n            raise KeyError(f\"There is no length record for {name}\") from err\n\n    def get_lengths(self, name: str) -&gt; dict[str, Any]:\n        \"\"\"Returns a dict associating IDs with their length from a given file name.\n\n        Args:\n            name: Name for the lengths to get.\n\n        Raises:\n            KeyError: If the name is not supported.\n        \"\"\"\n        try:\n            return self.lengths[name]\n        except KeyError as err:\n            raise KeyError(f\"There is no length record for {name}\") from err\n\n    def get_circular(self, name: str) -&gt; dict[str, Any]:\n        \"\"\"Returns a dict associating IDs with their is_circular flag from a given file name.\n\n        Args:\n            name: Name for the circular data to get.\n\n        Raises:\n            KeyError: If the name is not supported.\n        \"\"\"\n        try:\n            return self.circular[name]\n        except KeyError as err:\n            raise KeyError(f\"No length available for key {name}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.circular","title":"<code>circular = {'seq_regions': {}}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.errors","title":"<code>errors = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.genome","title":"<code>genome = {}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.ignore_final_stops","title":"<code>ignore_final_stops = ignore_final_stops</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.lengths","title":"<code>lengths = {'dna_sequences': {}, 'peptide_sequences': {}, 'seq_region_levels': {}, 'annotations': {}, 'agp': {}, 'gff3_seq_regions': {}, 'gff3_genes': {}, 'gff3_translations': {}, 'gff3_all_translations': {}, 'gff3_transposable_elements': {}, 'ann_genes': {}, 'ann_translations': {}, 'ann_transposable_elements': {}, 'seq_regions': {}}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.manifest_files","title":"<code>manifest_files = self._get_manifest(manifest_path)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.add_error","title":"<code>add_error(error)</code>","text":"<p>Record an error.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def add_error(self, error: str) -&gt; None:\n    \"\"\"Record an error.\"\"\"\n    self.errors.append(error)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.get_circular","title":"<code>get_circular(name)</code>","text":"<p>Returns a dict associating IDs with their is_circular flag from a given file name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the circular data to get.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the name is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def get_circular(self, name: str) -&gt; dict[str, Any]:\n    \"\"\"Returns a dict associating IDs with their is_circular flag from a given file name.\n\n    Args:\n        name: Name for the circular data to get.\n\n    Raises:\n        KeyError: If the name is not supported.\n    \"\"\"\n    try:\n        return self.circular[name]\n    except KeyError as err:\n        raise KeyError(f\"No length available for key {name}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.get_lengths","title":"<code>get_lengths(name)</code>","text":"<p>Returns a dict associating IDs with their length from a given file name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the lengths to get.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the name is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def get_lengths(self, name: str) -&gt; dict[str, Any]:\n    \"\"\"Returns a dict associating IDs with their length from a given file name.\n\n    Args:\n        name: Name for the lengths to get.\n\n    Raises:\n        KeyError: If the name is not supported.\n    \"\"\"\n    try:\n        return self.lengths[name]\n    except KeyError as err:\n        raise KeyError(f\"There is no length record for {name}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.has_lengths","title":"<code>has_lengths(name)</code>","text":"<p>Check if a given name has lengths records.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the lengths to check.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the name is not supported.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def has_lengths(self, name: str) -&gt; bool:\n    \"\"\"Check if a given name has lengths records.\n\n    Args:\n        name: Name for the lengths to check.\n\n    Raises:\n        KeyError: If the name is not supported.\n    \"\"\"\n    try:\n        return bool(self.lengths[name])\n    except KeyError as err:\n        raise KeyError(f\"There is no length record for {name}\") from err\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.load_agp_seq_regions","title":"<code>load_agp_seq_regions(agp_dict)</code>","text":"<p>AGP files describe the assembly of larger sequence objects using smaller objects.</p> <p>E.g. describes the assembly of scaffolds from contigs.</p> <p>Parameters:</p> Name Type Description Default <code>agp_dict</code> <code>dict | None</code> <p>Dict containing the information about the sequence.</p> required Note <p>AGP file is only used in the older builds, not used for current processing.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_agp_seq_regions(self, agp_dict: dict | None) -&gt; None:\n    \"\"\"AGP files describe the assembly of larger sequence objects using smaller objects.\n\n    E.g. describes the assembly of scaffolds from contigs.\n\n    Args:\n        agp_dict: Dict containing the information about the sequence.\n\n    Note:\n        AGP file is only used in the older builds, not used for current processing.\n    \"\"\"\n    if not agp_dict:\n        return\n    logging.info(\"Manifest contains AGP files\")\n\n    seqr: StatsLengths = {}\n    for agp_path in agp_dict.values():\n        with open(agp_path, \"r\") as agph:\n            for line in agph:\n                (\n                    asm_id,\n                    _,  # asm_start\n                    asm_end,\n                    _,  # asm_part\n                    typ,\n                    cmp_id,\n                    _,  # cmp_start\n                    cmp_end,\n                    _,  # cmp_strand\n                ) = line.split(\"\\t\")\n                # Ignore WGS contig\n                if typ != \"W\":\n                    continue\n\n                # Assembled seq length\n                if asm_id not in seqr or seqr[asm_id] &lt; int(asm_end):\n                    seqr[asm_id] = int(asm_end)\n\n                # Composite seq length\n                if cmp_id not in seqr or seqr[cmp_id] &lt; int(cmp_end):\n                    seqr[cmp_id] = int(cmp_end)\n\n    self.lengths[\"agp\"] = seqr\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.load_dna_fasta_lengths","title":"<code>load_dna_fasta_lengths()</code>","text":"<p>Retrieve DNA sequences lengths from their FASTA file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_dna_fasta_lengths(self) -&gt; None:\n    \"\"\"Retrieve DNA sequences lengths from their FASTA file.\"\"\"\n    if \"fasta_dna\" not in self.manifest_files:\n        return\n    self.lengths[\"dna_sequences\"] = self._get_fasta_lengths(self.manifest_files[\"fasta_dna\"])\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.load_functional_annotation","title":"<code>load_functional_annotation()</code>","text":"<p>Load the functional annotation file to retrieve the gene_id and translation id.</p> <p>The functional annotation file is stored in a JSON format containing the description, id and object type, eg: \"gene\", \"transcript\", \"translation\".</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_functional_annotation(self) -&gt; None:\n    \"\"\"Load the functional annotation file to retrieve the gene_id and translation id.\n\n    The functional annotation file is stored in a JSON format containing the description, id\n    and object type, eg: \"gene\", \"transcript\", \"translation\".\n\n    \"\"\"\n    if \"functional_annotation\" not in self.manifest_files:\n        return\n    logging.info(\"Manifest contains functional annotation(s)\")\n\n    # Load the json file\n    with open(self.manifest_files[\"functional_annotation\"]) as json_file:\n        data = json.load(json_file)\n\n    # Get gene ids and translation ids\n    genes = {}\n    translations = {}\n    transposons = {}\n\n    for item in data:\n        if item[\"object_type\"] == \"gene\":\n            genes[item[\"id\"]] = 1\n        elif item[\"object_type\"] == \"translation\":\n            translations[item[\"id\"]] = 1\n        if item[\"object_type\"] == \"transposable_element\":\n            transposons[item[\"id\"]] = 1\n\n    stats = {\n        \"ann_genes\": genes,\n        \"ann_translations\": translations,\n        \"ann_transposable_elements\": transposons,\n    }\n    self.lengths = {**self.lengths, **stats}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.load_genome","title":"<code>load_genome()</code>","text":"<p>Load the genome data.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_genome(self) -&gt; None:\n    \"\"\"Load the genome data.\"\"\"\n    if \"genome\" not in self.manifest_files:\n        return\n    logging.info(\"Manifest contains genome JSON\")\n    self.genome = get_json(Path(self.manifest_files[\"genome\"]))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.load_gff3","title":"<code>load_gff3()</code>","text":"<p>A GFF3 parser is used to retrieve information in the GFF3 file such as gene and CDS ids and their corresponding lengths.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_gff3(self) -&gt; None:\n    \"\"\"A GFF3 parser is used to retrieve information in the GFF3 file such as\n    gene and CDS ids and their corresponding lengths.\n    \"\"\"\n    if \"gff3\" not in self.manifest_files:\n        return\n    logging.info(\"Manifest contains GFF3 gene annotations\")\n    gff3_path = self.manifest_files[\"gff3\"]\n\n    seqs: StatsLengths = {}\n    genes: StatsLengths = {}\n    peps: StatsLengths = {}\n    all_peps: StatsLengths = {}\n    tes: StatsLengths = {}\n\n    with open_gz_file(gff3_path) as gff3_handle:\n        gff = GFF.parse(gff3_handle)\n        for seq in gff:\n            seqs[seq.id] = len(seq.seq)\n\n            for feat in seq.features:\n                feat_length = abs(feat.location.end - feat.location.start)\n                # Store gene id and length\n                if feat.type in [\"gene\", \"ncRNA_gene\", \"pseudogene\"]:\n                    self._retrieve_gff_gene_lengths(feat, genes, peps, all_peps)\n                if feat.type == \"transposable_element\":\n                    tes[feat.id] = feat_length\n\n    stats: dict[str, StatsLengths] = {\n        \"gff3_seq_regions\": seqs,\n        \"gff3_genes\": genes,\n        \"gff3_translations\": peps,\n        \"gff3_all_translations\": all_peps,\n        \"gff3_transposable_elements\": tes,\n    }\n    self.lengths = {**self.lengths, **stats}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.load_peptides_fasta_lengths","title":"<code>load_peptides_fasta_lengths()</code>","text":"<p>Retrieve peptides sequences lengths from their FASTA file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_peptides_fasta_lengths(self) -&gt; None:\n    \"\"\"Retrieve peptides sequences lengths from their FASTA file.\"\"\"\n    if \"fasta_pep\" not in self.manifest_files:\n        return\n    self.lengths[\"peptide_sequences\"] = self._get_fasta_lengths(\n        self.manifest_files[\"fasta_pep\"], ignore_final_stops=self.ignore_final_stops\n    )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.load_seq_regions","title":"<code>load_seq_regions()</code>","text":"<p>Retrieve seq_regions lengths and circular information from the seq_region JSON file.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def load_seq_regions(self) -&gt; None:\n    \"\"\"Retrieve seq_regions lengths and circular information from the seq_region JSON file.\"\"\"\n\n    if \"seq_region\" not in self.manifest_files:\n        return\n    logging.info(\"Manifest contains seq_region JSON\")\n    seq_regions = get_json(Path(self.manifest_files[\"seq_region\"]))\n    seqr_seqlevel = {}\n    seq_lengths = {}\n    seq_circular = {}\n    # Store the length as int\n    for seq in seq_regions:\n        seq_lengths[seq[\"name\"]] = int(seq[\"length\"])\n        seq_circular[seq[\"name\"]] = seq.get(\"circular\", False)\n        if seq[\"coord_system_level\"] == \"contig\":\n            seqr_seqlevel[seq[\"name\"]] = int(seq[\"length\"])\n        # Also record synonyms (in case GFF file uses synonyms)\n        if \"synonyms\" in seq:\n            for synonym in seq[\"synonyms\"]:\n                seq_lengths[synonym[\"name\"]] = int(seq[\"length\"])\n    self.lengths[\"seq_regions\"] = seq_lengths\n    self.circular[\"seq_regions\"] = seq_circular\n</code></pre>"},{"location":"reference/ensembl/io/genomio/manifest/manifest_stats/#ensembl.io.genomio.manifest.manifest_stats.ManifestStats.prepare_integrity_data","title":"<code>prepare_integrity_data()</code>","text":"<p>Read all the files and keep a record (IDs and their lengths) for each case to be compared later.</p> Source code in <code>src/python/ensembl/io/genomio/manifest/manifest_stats.py</code> <pre><code>def prepare_integrity_data(self) -&gt; None:  # pylint: disable=too-many-branches\n    \"\"\"Read all the files and keep a record (IDs and their lengths) for each case to be compared later.\"\"\"\n    self.load_gff3()\n    self.load_dna_fasta_lengths()\n    self.load_peptides_fasta_lengths()\n    self.load_seq_regions()\n    self.load_functional_annotation()\n    self.load_agp_seq_regions(self.manifest_files.get(\"agp\"))\n    self.load_genome()\n</code></pre>"},{"location":"reference/ensembl/io/genomio/schemas/","title":"schemas","text":""},{"location":"reference/ensembl/io/genomio/schemas/#ensembl.io.genomio.schemas","title":"<code>ensembl.io.genomio.schemas</code>","text":"<p>Handling and verification of different format schemas module.</p>"},{"location":"reference/ensembl/io/genomio/schemas/json/","title":"json","text":""},{"location":"reference/ensembl/io/genomio/schemas/json/#ensembl.io.genomio.schemas.json","title":"<code>ensembl.io.genomio.schemas.json</code>","text":"<p>Handling and verification of JSON schemas module.</p>"},{"location":"reference/ensembl/io/genomio/schemas/json/#ensembl.io.genomio.schemas.json.schema_factory","title":"<code>schema_factory(manifest_dir, metadata_types, output_dir)</code>","text":"<p>Generates one JSON file per metadata type inside <code>manifest</code>, including \"manifest.json\" itself.</p> <p>Each JSON file will have the file name of the metadata type, e.g. \"seq_region.json\".</p> <p>Parameters:</p> Name Type Description Default <code>manifest_dir</code> <code>PathLike</code> <p>Path to the folder with the manifest JSON file to check.</p> required <code>metadata_types</code> <code>List[str]</code> <p>Metadata types to extract from <code>manifest</code> as JSON files.</p> required <code>output_dir</code> <code>PathLike</code> <p>Path to the folder where to generate the JSON files.</p> required Source code in <code>src/python/ensembl/io/genomio/schemas/json/factory.py</code> <pre><code>def schema_factory(manifest_dir: PathLike, metadata_types: List[str], output_dir: PathLike) -&gt; None:\n    \"\"\"Generates one JSON file per metadata type inside `manifest`, including \"manifest.json\" itself.\n\n    Each JSON file will have the file name of the metadata type, e.g. \"seq_region.json\".\n\n    Args:\n        manifest_dir: Path to the folder with the manifest JSON file to check.\n        metadata_types: Metadata types to extract from `manifest` as JSON files.\n        output_dir: Path to the folder where to generate the JSON files.\n\n    \"\"\"\n    manifest_path = Path(manifest_dir, \"manifest.json\")\n    with manifest_path.open() as manifest_file:\n        content = json.load(manifest_file)\n        shutil.copyfile(manifest_path, Path(output_dir, \"manifest.json\"))\n        json_files = {}\n        # Use dir name from the manifest\n        for name in content:\n            if \"file\" in content[name]:\n                file_name = content[name][\"file\"]\n                json_files[name] = manifest_path.parent / file_name\n            else:\n                for key in content[name]:\n                    if \"file\" in content[name][key]:\n                        file_name = content[name][key][\"file\"]\n                        json_files[name] = {key: manifest_path.parent / file_name}\n        # Check the other JSON schemas\n        for metadata_key in metadata_types:\n            if metadata_key in json_files:\n                if isinstance(json_files[metadata_key], dict):\n                    for key, filepath in json_files[metadata_key].items():\n                        shutil.copyfile(filepath, Path(output_dir, f\"{metadata_key}_{key}.json\"))\n                else:\n                    shutil.copyfile(json_files[metadata_key], Path(output_dir, f\"{metadata_key}.json\"))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/schemas/json/#ensembl.io.genomio.schemas.json.schema_validator","title":"<code>schema_validator(json_file, json_schema)</code>","text":"<p>Validates a JSON file with the provided JSON schema.</p> <p>Parameters:</p> Name Type Description Default <code>json_file</code> <code>PathLike</code> <p>Path to the JSON file to check.</p> required <code>json_schema</code> <code>Union[str, PathLike]</code> <p>JSON schema to validate <code>json_file</code> against, either a string matching a existing schema (in data/schemas) or a JSON schema file.</p> required Source code in <code>src/python/ensembl/io/genomio/schemas/json/validate.py</code> <pre><code>def schema_validator(json_file: PathLike, json_schema: Union[str, PathLike]) -&gt; None:\n    \"\"\"Validates a JSON file with the provided JSON schema.\n\n    Args:\n        json_file: Path to the JSON file to check.\n        json_schema: JSON schema to validate `json_file` against, either a string matching a existing\n            schema (in data/schemas) or a JSON schema file.\n\n    \"\"\"\n    # Open IO for JSON files and validate it\n    with Path(json_file).open(\"r\") as fh:\n        content = json.load(fh)\n    # Find the json_schema file if a known identifier is provided (if not, treat it as a file path)\n    if isinstance(json_schema, str) and (json_schema in _JSON_SCHEMAS):\n        json_schema = _JSON_SCHEMAS[json_schema]\n    with Path(json_schema).open(\"r\") as fh:\n        schema = json.load(fh)\n    jsonschema.validate(instance=content, schema=schema)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/schemas/json/factory/","title":"factory","text":""},{"location":"reference/ensembl/io/genomio/schemas/json/factory/#ensembl.io.genomio.schemas.json.factory","title":"<code>ensembl.io.genomio.schemas.json.factory</code>","text":"<p>Generates one JSON file per metadata type inside <code>manifest</code>, including the manifest itself.</p>"},{"location":"reference/ensembl/io/genomio/schemas/json/factory/#ensembl.io.genomio.schemas.json.factory.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/schemas/json/factory.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(\n        description=\"Generates one JSON file per metadata type in the provided manifest, including itself.\"\n    )\n    parser.add_argument_src_path(\n        \"--manifest_dir\", required=True, help=\"Folder containing the 'manifest.json' file to check\"\n    )\n    parser.add_argument(\n        \"--metadata_types\", required=True, nargs=\"+\", metavar=\"TYPE\", help=\"Metadata types to extract\"\n    )\n    parser.add_argument_dst_path(\n        \"--output_dir\", default=Path.cwd(), help=\"Folder to store the produced files\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    schema_factory(**vars(args))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/schemas/json/factory/#ensembl.io.genomio.schemas.json.factory.schema_factory","title":"<code>schema_factory(manifest_dir, metadata_types, output_dir)</code>","text":"<p>Generates one JSON file per metadata type inside <code>manifest</code>, including \"manifest.json\" itself.</p> <p>Each JSON file will have the file name of the metadata type, e.g. \"seq_region.json\".</p> <p>Parameters:</p> Name Type Description Default <code>manifest_dir</code> <code>PathLike</code> <p>Path to the folder with the manifest JSON file to check.</p> required <code>metadata_types</code> <code>List[str]</code> <p>Metadata types to extract from <code>manifest</code> as JSON files.</p> required <code>output_dir</code> <code>PathLike</code> <p>Path to the folder where to generate the JSON files.</p> required Source code in <code>src/python/ensembl/io/genomio/schemas/json/factory.py</code> <pre><code>def schema_factory(manifest_dir: PathLike, metadata_types: List[str], output_dir: PathLike) -&gt; None:\n    \"\"\"Generates one JSON file per metadata type inside `manifest`, including \"manifest.json\" itself.\n\n    Each JSON file will have the file name of the metadata type, e.g. \"seq_region.json\".\n\n    Args:\n        manifest_dir: Path to the folder with the manifest JSON file to check.\n        metadata_types: Metadata types to extract from `manifest` as JSON files.\n        output_dir: Path to the folder where to generate the JSON files.\n\n    \"\"\"\n    manifest_path = Path(manifest_dir, \"manifest.json\")\n    with manifest_path.open() as manifest_file:\n        content = json.load(manifest_file)\n        shutil.copyfile(manifest_path, Path(output_dir, \"manifest.json\"))\n        json_files = {}\n        # Use dir name from the manifest\n        for name in content:\n            if \"file\" in content[name]:\n                file_name = content[name][\"file\"]\n                json_files[name] = manifest_path.parent / file_name\n            else:\n                for key in content[name]:\n                    if \"file\" in content[name][key]:\n                        file_name = content[name][key][\"file\"]\n                        json_files[name] = {key: manifest_path.parent / file_name}\n        # Check the other JSON schemas\n        for metadata_key in metadata_types:\n            if metadata_key in json_files:\n                if isinstance(json_files[metadata_key], dict):\n                    for key, filepath in json_files[metadata_key].items():\n                        shutil.copyfile(filepath, Path(output_dir, f\"{metadata_key}_{key}.json\"))\n                else:\n                    shutil.copyfile(json_files[metadata_key], Path(output_dir, f\"{metadata_key}.json\"))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/schemas/json/validate/","title":"validate","text":""},{"location":"reference/ensembl/io/genomio/schemas/json/validate/#ensembl.io.genomio.schemas.json.validate","title":"<code>ensembl.io.genomio.schemas.json.validate</code>","text":"<p>Validates a JSON file with the provided JSON schema.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from ensembl.io.genomio.schemas import json\n&gt;&gt;&gt; json.schema_validator(json_file=\"functional_annotation.json\", json_schema=\"functional_annotation\")\n&gt;&gt;&gt; json.schema_validator(json_file=\"functional_annotation.json\", json_schema=\"genome\")\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"ensembl-genomio/src/python/ensembl/io/genomio/schemas/json/validate.py\", line 63,\n  in schema_validator\n    jsonschema.validate(instance=content, schema=schema)\n  File \".venv/dev/lib/python3.10/site-packages/jsonschema/validators.py\", line 1306, in validate\n    raise error\n&lt;list of all the elements from functional_annotation.json that failed validation&gt;\n</code></pre>"},{"location":"reference/ensembl/io/genomio/schemas/json/validate/#ensembl.io.genomio.schemas.json.validate.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/schemas/json/validate.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(description=\"Validates a JSON file against a JSON schema.\")\n    parser.add_argument_src_path(\"--json_file\", required=True, help=\"JSON file to check\")\n    parser.add_argument(\n        \"--json_schema\", required=True, choices=_JSON_SCHEMAS.keys(), help=\"JSON schema to validate against\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    args = parser.parse_args()\n\n    schema_validator(args.json_file, args.json_schema)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/schemas/json/validate/#ensembl.io.genomio.schemas.json.validate.schema_validator","title":"<code>schema_validator(json_file, json_schema)</code>","text":"<p>Validates a JSON file with the provided JSON schema.</p> <p>Parameters:</p> Name Type Description Default <code>json_file</code> <code>PathLike</code> <p>Path to the JSON file to check.</p> required <code>json_schema</code> <code>Union[str, PathLike]</code> <p>JSON schema to validate <code>json_file</code> against, either a string matching a existing schema (in data/schemas) or a JSON schema file.</p> required Source code in <code>src/python/ensembl/io/genomio/schemas/json/validate.py</code> <pre><code>def schema_validator(json_file: PathLike, json_schema: Union[str, PathLike]) -&gt; None:\n    \"\"\"Validates a JSON file with the provided JSON schema.\n\n    Args:\n        json_file: Path to the JSON file to check.\n        json_schema: JSON schema to validate `json_file` against, either a string matching a existing\n            schema (in data/schemas) or a JSON schema file.\n\n    \"\"\"\n    # Open IO for JSON files and validate it\n    with Path(json_file).open(\"r\") as fh:\n        content = json.load(fh)\n    # Find the json_schema file if a known identifier is provided (if not, treat it as a file path)\n    if isinstance(json_schema, str) and (json_schema in _JSON_SCHEMAS):\n        json_schema = _JSON_SCHEMAS[json_schema]\n    with Path(json_schema).open(\"r\") as fh:\n        schema = json.load(fh)\n    jsonschema.validate(instance=content, schema=schema)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/","title":"seq_region","text":""},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region","title":"<code>ensembl.io.genomio.seq_region</code>","text":"<p>Sequence regions handling module.</p>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.StrPath","title":"<code>StrPath = TypeVar('StrPath', str, os.PathLike)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser","title":"<code>ArgumentParser</code>","text":"<p>               Bases: <code>ArgumentParser</code></p> <p>Extends <code>argparse.ArgumentParser</code> with additional methods and functionality.</p> <p>The default behaviour of the help text will be to display the default values on every non-required argument, i.e. optional arguments with <code>required=False</code>.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>class ArgumentParser(argparse.ArgumentParser):\n    \"\"\"Extends `argparse.ArgumentParser` with additional methods and functionality.\n\n    The default behaviour of the help text will be to display the default values on every non-required\n    argument, i.e. optional arguments with `required=False`.\n\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Extends the base class to include the information about default argument values by default.\"\"\"\n        super().__init__(*args, **kwargs)\n        self.formatter_class = argparse.ArgumentDefaultsHelpFormatter\n\n    def _validate_src_path(self, src_path: StrPath) -&gt; Path:\n        \"\"\"Returns the path if exists and it is readable, raises an error through the parser otherwise.\n\n        Args:\n            src_path: File or directory path to check.\n\n        \"\"\"\n        src_path = Path(src_path)\n        if not src_path.exists():\n            self.error(f\"'{src_path}' not found\")\n        elif not os.access(src_path, os.R_OK):\n            self.error(f\"'{src_path}' not readable\")\n        return src_path\n\n    def _validate_dst_path(self, dst_path: StrPath, exists_ok: bool = False) -&gt; Path:\n        \"\"\"Returns the path if it is writable, raises an error through the parser otherwise.\n\n        Args:\n            dst_path: File or directory path to check.\n            exists_ok: Do not raise an error during parsing if the destination path already exists.\n\n        \"\"\"\n        dst_path = Path(dst_path)\n        if dst_path.exists():\n            if os.access(dst_path, os.W_OK):\n                if exists_ok:\n                    return dst_path\n                self.error(f\"'{dst_path}' already exists\")\n            else:\n                self.error(f\"'{dst_path}' is not writable\")\n        # Check if the first parent directory that exists is writable\n        for parent_path in dst_path.parents:\n            if parent_path.exists():\n                if not os.access(parent_path, os.W_OK):\n                    self.error(f\"'{dst_path}' is not writable\")\n                break\n        return dst_path\n\n    def _validate_number(\n        self,\n        value: str,\n        value_type: Callable[[str], int | float],\n        min_value: int | float | None,\n        max_value: int | float | None,\n    ) -&gt; int | float:\n        \"\"\"Returns the numeric value if it is of the expected type and it is within the specified range.\n\n        Args:\n            value: String representation of numeric value to check.\n            value_type: Expected type of the numeric value.\n            min_value: Minimum value constrain. If `None`, no minimum value constrain.\n            max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n        \"\"\"\n        # Check if the string representation can be converted to the expected type\n        try:\n            result = value_type(value)\n        except (TypeError, ValueError):\n            self.error(f\"invalid {value_type.__name__} value: {value}\")\n        # Check if numeric value is within range\n        if (min_value is not None) and (result &lt; min_value):\n            self.error(f\"{value} is lower than minimum value ({min_value})\")\n        if (max_value is not None) and (result &gt; max_value):\n            self.error(f\"{value} is greater than maximum value ({max_value})\")\n        return result\n\n    def add_argument(self, *args: Any, **kwargs: Any) -&gt; None:  # type: ignore[override]\n        \"\"\"Extends the parent function by excluding the default value in the help text when not provided.\n\n        Only applied to required arguments without a default value, i.e. positional arguments or optional\n        arguments with `required=True`.\n\n        \"\"\"\n        if kwargs.get(\"required\", False):\n            kwargs.setdefault(\"default\", argparse.SUPPRESS)\n        super().add_argument(*args, **kwargs)\n\n    def add_argument_src_path(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `pathlib.Path` argument, checking if it exists and it is readable at parsing time.\n\n        If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"PATH\")\n        kwargs[\"type\"] = self._validate_src_path\n        self.add_argument(*args, **kwargs)\n\n    def add_argument_dst_path(self, *args: Any, exists_ok: bool = True, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `pathlib.Path` argument, checking if it is writable at parsing time.\n\n        If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.\n\n        Args:\n            exists_ok: Do not raise an error if the destination path already exists.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"PATH\")\n        kwargs[\"type\"] = lambda x: self._validate_dst_path(x, exists_ok)\n        self.add_argument(*args, **kwargs)\n\n    def add_argument_url(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `sqlalchemy.engine.URL` argument.\n\n        If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"URI\")\n        kwargs[\"type\"] = make_url\n        self.add_argument(*args, **kwargs)\n\n    # pylint: disable=redefined-builtin\n    def add_numeric_argument(\n        self,\n        *args: Any,\n        type: Callable[[str], int | float] = float,\n        min_value: int | float | None = None,\n        max_value: int | float | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Adds a numeric argument with constrains on its type and its minimum or maximum value.\n\n        Note that the default value (if defined) is not checked unless the argument is an optional argument\n        and no value is provided in the command line.\n\n        Args:\n            type: Type to convert the argument value to when parsing.\n            min_value: Minimum value constrain. If `None`, no minimum value constrain.\n            max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n        \"\"\"\n        # If both minimum and maximum values are defined, ensure min_value &lt;= max_value\n        if (min_value is not None) and (max_value is not None) and (min_value &gt; max_value):\n            raise ArgumentError(\"minimum value is greater than maximum value\")\n        # Add lambda function to check numeric constrains when parsing argument\n        kwargs[\"type\"] = lambda x: self._validate_number(x, type, min_value, max_value)\n        self.add_argument(*args, **kwargs)\n\n    # pylint: disable=redefined-builtin\n    def add_server_arguments(\n        self, prefix: str = \"\", include_database: bool = False, help: str | None = None\n    ) -&gt; None:\n        \"\"\"Adds the usual set of arguments needed to connect to a server, i.e. `--host`, `--port`, `--user`\n        and `--password` (optional).\n\n        Note that the parser will assume this is a MySQL server.\n\n        Args:\n            prefix: Prefix to add the each argument, e.g. if prefix is `src_`, the arguments will be\n                `--src_host`, etc.\n            include_database: Include `--database` argument.\n            help: Description message to include for this set of arguments.\n\n        \"\"\"\n        group = self.add_argument_group(f\"{prefix}server connection arguments\", description=help)\n        group.add_argument(\n            f\"--{prefix}host\", required=True, metavar=\"HOST\", default=argparse.SUPPRESS, help=\"host name\"\n        )\n        group.add_argument(\n            f\"--{prefix}port\",\n            required=True,\n            type=int,\n            metavar=\"PORT\",\n            default=argparse.SUPPRESS,\n            help=\"port number\",\n        )\n        group.add_argument(\n            f\"--{prefix}user\", required=True, metavar=\"USER\", default=argparse.SUPPRESS, help=\"user name\"\n        )\n        group.add_argument(f\"--{prefix}password\", metavar=\"PWD\", help=\"host password\")\n        if include_database:\n            group.add_argument(\n                f\"--{prefix}database\",\n                required=True,\n                metavar=\"NAME\",\n                default=argparse.SUPPRESS,\n                help=\"database name\",\n            )\n\n    def add_log_arguments(self, add_log_file: bool = False) -&gt; None:\n        \"\"\"Adds the usual set of arguments required to set and initialise a logging system.\n\n        The current set includes a mutually exclusive group for the default logging level: `--verbose`,\n        `--debug`, `--quiet` or `--log LEVEL`.\n\n        Args:\n            add_log_file: Add arguments to allow storing messages into a file, i.e. `--log_file` and\n                `--log_file_level`.\n\n        \"\"\"\n        # Define the list of log levels available\n        log_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n        # NOTE: from 3.11 this list can be changed to: logging.getLevelNamesMapping().keys()\n        # Create logging arguments group\n        group = self.add_argument_group(\"logging arguments\")\n        # Add 3 mutually exclusive options to set the logging level\n        subgroup = group.add_mutually_exclusive_group()\n        subgroup.add_argument(\n            \"-v\",\n            \"--verbose\",\n            action=\"store_const\",\n            const=\"INFO\",\n            dest=\"log_level\",\n            help=\"verbose mode, i.e. 'INFO' log level\",\n        )\n        subgroup.add_argument(\n            \"--debug\",\n            action=\"store_const\",\n            const=\"DEBUG\",\n            dest=\"log_level\",\n            help=\"debugging mode, i.e. 'DEBUG' log level\",\n        )\n        subgroup.add_argument(\n            \"--quiet\",\n            action=\"store_const\",\n            const=\"CRITICAL\",\n            dest=\"log_level\",\n            help=\"quiet mode, i.e. 'CRITICAL' log level\",\n        )\n        subgroup.add_argument(\n            \"--log\",\n            choices=log_levels,\n            type=str.upper,\n            default=\"WARNING\",\n            metavar=\"LEVEL\",\n            dest=\"log_level\",\n            help=\"level of the events to track: %(choices)s\",\n        )\n        subgroup.set_defaults(log_level=\"WARNING\")\n        if add_log_file:\n            # Add log file-related arguments\n            group.add_argument(\n                \"--log_file\",\n                type=lambda x: self._validate_dst_path(x, exists_ok=True),\n                metavar=\"PATH\",\n                default=None,\n                help=\"log file path\",\n            )\n            group.add_argument(\n                \"--log_file_level\",\n                choices=log_levels,\n                type=str.upper,\n                default=\"DEBUG\",\n                metavar=\"LEVEL\",\n                help=\"level of the events to track in the log file: %(choices)s\",\n            )\n\n    def parse_args(self, *args: Any, **kwargs: Any) -&gt; argparse.Namespace:  # type: ignore[override]\n        \"\"\"Extends the parent function by adding a new URL argument for every server group added.\n\n        The type of this new argument will be `sqlalchemy.engine.URL`. It also logs all the parsed\n        arguments for debugging purposes when logging arguments have been added.\n\n        \"\"\"\n        arguments = super().parse_args(*args, **kwargs)\n        # Build and add an sqlalchemy.engine.URL object for every server group added\n        pattern = re.compile(r\"([\\w-]*)host$\")\n        server_prefixes = [x.group(1) for x in map(pattern.match, vars(arguments)) if x]\n        for prefix in server_prefixes:\n            # Raise an error rather than overwriting when the URL argument is already present\n            if f\"{prefix}url\" in arguments:\n                self.error(f\"argument '{prefix}url' is already present\")\n            try:\n                server_url = URL.create(\n                    \"mysql\",\n                    getattr(arguments, f\"{prefix}user\"),\n                    getattr(arguments, f\"{prefix}password\"),\n                    getattr(arguments, f\"{prefix}host\"),\n                    getattr(arguments, f\"{prefix}port\"),\n                    getattr(arguments, f\"{prefix}database\", None),\n                )\n            except AttributeError:\n                # Not a database server host argument\n                continue\n            setattr(arguments, f\"{prefix}url\", server_url)\n        return arguments\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.formatter_class","title":"<code>formatter_class = argparse.ArgumentDefaultsHelpFormatter</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.add_argument","title":"<code>add_argument(*args, **kwargs)</code>","text":"<p>Extends the parent function by excluding the default value in the help text when not provided.</p> <p>Only applied to required arguments without a default value, i.e. positional arguments or optional arguments with <code>required=True</code>.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument(self, *args: Any, **kwargs: Any) -&gt; None:  # type: ignore[override]\n    \"\"\"Extends the parent function by excluding the default value in the help text when not provided.\n\n    Only applied to required arguments without a default value, i.e. positional arguments or optional\n    arguments with `required=True`.\n\n    \"\"\"\n    if kwargs.get(\"required\", False):\n        kwargs.setdefault(\"default\", argparse.SUPPRESS)\n    super().add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.add_argument_dst_path","title":"<code>add_argument_dst_path(*args, exists_ok=True, **kwargs)</code>","text":"<p>Adds <code>pathlib.Path</code> argument, checking if it is writable at parsing time.</p> <p>If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.</p> <p>Parameters:</p> Name Type Description Default <code>exists_ok</code> <code>bool</code> <p>Do not raise an error if the destination path already exists.</p> <code>True</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_dst_path(self, *args: Any, exists_ok: bool = True, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `pathlib.Path` argument, checking if it is writable at parsing time.\n\n    If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.\n\n    Args:\n        exists_ok: Do not raise an error if the destination path already exists.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"PATH\")\n    kwargs[\"type\"] = lambda x: self._validate_dst_path(x, exists_ok)\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.add_argument_src_path","title":"<code>add_argument_src_path(*args, **kwargs)</code>","text":"<p>Adds <code>pathlib.Path</code> argument, checking if it exists and it is readable at parsing time.</p> <p>If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_src_path(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `pathlib.Path` argument, checking if it exists and it is readable at parsing time.\n\n    If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"PATH\")\n    kwargs[\"type\"] = self._validate_src_path\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.add_argument_url","title":"<code>add_argument_url(*args, **kwargs)</code>","text":"<p>Adds <code>sqlalchemy.engine.URL</code> argument.</p> <p>If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_argument_url(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `sqlalchemy.engine.URL` argument.\n\n    If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"URI\")\n    kwargs[\"type\"] = make_url\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.add_log_arguments","title":"<code>add_log_arguments(add_log_file=False)</code>","text":"<p>Adds the usual set of arguments required to set and initialise a logging system.</p> <p>The current set includes a mutually exclusive group for the default logging level: <code>--verbose</code>, <code>--debug</code>, <code>--quiet</code> or <code>--log LEVEL</code>.</p> <p>Parameters:</p> Name Type Description Default <code>add_log_file</code> <code>bool</code> <p>Add arguments to allow storing messages into a file, i.e. <code>--log_file</code> and <code>--log_file_level</code>.</p> <code>False</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_log_arguments(self, add_log_file: bool = False) -&gt; None:\n    \"\"\"Adds the usual set of arguments required to set and initialise a logging system.\n\n    The current set includes a mutually exclusive group for the default logging level: `--verbose`,\n    `--debug`, `--quiet` or `--log LEVEL`.\n\n    Args:\n        add_log_file: Add arguments to allow storing messages into a file, i.e. `--log_file` and\n            `--log_file_level`.\n\n    \"\"\"\n    # Define the list of log levels available\n    log_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n    # NOTE: from 3.11 this list can be changed to: logging.getLevelNamesMapping().keys()\n    # Create logging arguments group\n    group = self.add_argument_group(\"logging arguments\")\n    # Add 3 mutually exclusive options to set the logging level\n    subgroup = group.add_mutually_exclusive_group()\n    subgroup.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_const\",\n        const=\"INFO\",\n        dest=\"log_level\",\n        help=\"verbose mode, i.e. 'INFO' log level\",\n    )\n    subgroup.add_argument(\n        \"--debug\",\n        action=\"store_const\",\n        const=\"DEBUG\",\n        dest=\"log_level\",\n        help=\"debugging mode, i.e. 'DEBUG' log level\",\n    )\n    subgroup.add_argument(\n        \"--quiet\",\n        action=\"store_const\",\n        const=\"CRITICAL\",\n        dest=\"log_level\",\n        help=\"quiet mode, i.e. 'CRITICAL' log level\",\n    )\n    subgroup.add_argument(\n        \"--log\",\n        choices=log_levels,\n        type=str.upper,\n        default=\"WARNING\",\n        metavar=\"LEVEL\",\n        dest=\"log_level\",\n        help=\"level of the events to track: %(choices)s\",\n    )\n    subgroup.set_defaults(log_level=\"WARNING\")\n    if add_log_file:\n        # Add log file-related arguments\n        group.add_argument(\n            \"--log_file\",\n            type=lambda x: self._validate_dst_path(x, exists_ok=True),\n            metavar=\"PATH\",\n            default=None,\n            help=\"log file path\",\n        )\n        group.add_argument(\n            \"--log_file_level\",\n            choices=log_levels,\n            type=str.upper,\n            default=\"DEBUG\",\n            metavar=\"LEVEL\",\n            help=\"level of the events to track in the log file: %(choices)s\",\n        )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.add_numeric_argument","title":"<code>add_numeric_argument(*args, type=float, min_value=None, max_value=None, **kwargs)</code>","text":"<p>Adds a numeric argument with constrains on its type and its minimum or maximum value.</p> <p>Note that the default value (if defined) is not checked unless the argument is an optional argument and no value is provided in the command line.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Callable[[str], int | float]</code> <p>Type to convert the argument value to when parsing.</p> <code>float</code> <code>min_value</code> <code>int | float | None</code> <p>Minimum value constrain. If <code>None</code>, no minimum value constrain.</p> <code>None</code> <code>max_value</code> <code>int | float | None</code> <p>Maximum value constrain. If <code>None</code>, no maximum value constrain.</p> <code>None</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_numeric_argument(\n    self,\n    *args: Any,\n    type: Callable[[str], int | float] = float,\n    min_value: int | float | None = None,\n    max_value: int | float | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Adds a numeric argument with constrains on its type and its minimum or maximum value.\n\n    Note that the default value (if defined) is not checked unless the argument is an optional argument\n    and no value is provided in the command line.\n\n    Args:\n        type: Type to convert the argument value to when parsing.\n        min_value: Minimum value constrain. If `None`, no minimum value constrain.\n        max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n    \"\"\"\n    # If both minimum and maximum values are defined, ensure min_value &lt;= max_value\n    if (min_value is not None) and (max_value is not None) and (min_value &gt; max_value):\n        raise ArgumentError(\"minimum value is greater than maximum value\")\n    # Add lambda function to check numeric constrains when parsing argument\n    kwargs[\"type\"] = lambda x: self._validate_number(x, type, min_value, max_value)\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.add_server_arguments","title":"<code>add_server_arguments(prefix='', include_database=False, help=None)</code>","text":"<p>Adds the usual set of arguments needed to connect to a server, i.e. <code>--host</code>, <code>--port</code>, <code>--user</code> and <code>--password</code> (optional).</p> <p>Note that the parser will assume this is a MySQL server.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix to add the each argument, e.g. if prefix is <code>src_</code>, the arguments will be <code>--src_host</code>, etc.</p> <code>''</code> <code>include_database</code> <code>bool</code> <p>Include <code>--database</code> argument.</p> <code>False</code> <code>help</code> <code>str | None</code> <p>Description message to include for this set of arguments.</p> <code>None</code> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def add_server_arguments(\n    self, prefix: str = \"\", include_database: bool = False, help: str | None = None\n) -&gt; None:\n    \"\"\"Adds the usual set of arguments needed to connect to a server, i.e. `--host`, `--port`, `--user`\n    and `--password` (optional).\n\n    Note that the parser will assume this is a MySQL server.\n\n    Args:\n        prefix: Prefix to add the each argument, e.g. if prefix is `src_`, the arguments will be\n            `--src_host`, etc.\n        include_database: Include `--database` argument.\n        help: Description message to include for this set of arguments.\n\n    \"\"\"\n    group = self.add_argument_group(f\"{prefix}server connection arguments\", description=help)\n    group.add_argument(\n        f\"--{prefix}host\", required=True, metavar=\"HOST\", default=argparse.SUPPRESS, help=\"host name\"\n    )\n    group.add_argument(\n        f\"--{prefix}port\",\n        required=True,\n        type=int,\n        metavar=\"PORT\",\n        default=argparse.SUPPRESS,\n        help=\"port number\",\n    )\n    group.add_argument(\n        f\"--{prefix}user\", required=True, metavar=\"USER\", default=argparse.SUPPRESS, help=\"user name\"\n    )\n    group.add_argument(f\"--{prefix}password\", metavar=\"PWD\", help=\"host password\")\n    if include_database:\n        group.add_argument(\n            f\"--{prefix}database\",\n            required=True,\n            metavar=\"NAME\",\n            default=argparse.SUPPRESS,\n            help=\"database name\",\n        )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.ArgumentParser.parse_args","title":"<code>parse_args(*args, **kwargs)</code>","text":"<p>Extends the parent function by adding a new URL argument for every server group added.</p> <p>The type of this new argument will be <code>sqlalchemy.engine.URL</code>. It also logs all the parsed arguments for debugging purposes when logging arguments have been added.</p> Source code in <code>ensembl/utils/argparse.py</code> <pre><code>def parse_args(self, *args: Any, **kwargs: Any) -&gt; argparse.Namespace:  # type: ignore[override]\n    \"\"\"Extends the parent function by adding a new URL argument for every server group added.\n\n    The type of this new argument will be `sqlalchemy.engine.URL`. It also logs all the parsed\n    arguments for debugging purposes when logging arguments have been added.\n\n    \"\"\"\n    arguments = super().parse_args(*args, **kwargs)\n    # Build and add an sqlalchemy.engine.URL object for every server group added\n    pattern = re.compile(r\"([\\w-]*)host$\")\n    server_prefixes = [x.group(1) for x in map(pattern.match, vars(arguments)) if x]\n    for prefix in server_prefixes:\n        # Raise an error rather than overwriting when the URL argument is already present\n        if f\"{prefix}url\" in arguments:\n            self.error(f\"argument '{prefix}url' is already present\")\n        try:\n            server_url = URL.create(\n                \"mysql\",\n                getattr(arguments, f\"{prefix}user\"),\n                getattr(arguments, f\"{prefix}password\"),\n                getattr(arguments, f\"{prefix}host\"),\n                getattr(arguments, f\"{prefix}port\"),\n                getattr(arguments, f\"{prefix}database\", None),\n            )\n        except AttributeError:\n            # Not a database server host argument\n            continue\n        setattr(arguments, f\"{prefix}url\", server_url)\n    return arguments\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection","title":"<code>SeqCollection</code>","text":"<p>Represent a collection of seq_regions metadata.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>class SeqCollection:\n    \"\"\"Represent a collection of seq_regions metadata.\"\"\"\n\n    mock: bool\n    seqs: dict\n\n    def __init__(self, mock: bool = False) -&gt; None:\n        self.seqs = {}\n        self.mock = mock\n\n    def from_gbff(self, gbff_path: Path) -&gt; None:\n        \"\"\"Store seq_regions extracted from a GBFF file.\n\n        If a seq_region with the same ID exists in the collection, it will be replaced.\n        \"\"\"\n        with open_gz_file(gbff_path) as gbff_file:\n            for record in SeqIO.parse(gbff_file, \"genbank\"):\n                record_data = GBFFRecord(record)\n                new_seq: SeqRegionDict = self.make_seqregion_from_gbff(record_data)\n                name = record.id\n                merged_seq = self._merge(new_seq, self.seqs.get(name, {}))\n                self.seqs[name] = merged_seq\n\n    def _merge(self, source: SeqRegionDict, destination: SeqRegionDict) -&gt; SeqRegionDict:\n        \"\"\"Merge a source dict in a destination dict (only add values or append to lists).\"\"\"\n        if not destination:\n            return source\n        for key, value in source.items():\n            if isinstance(value, list):\n                destination[key] += value\n            else:\n                destination[key] = value\n\n        return destination\n\n    @staticmethod\n    def make_seqregion_from_gbff(record_data: GBFFRecord) -&gt; SeqRegionDict:\n        \"\"\"Returns a seq_region dict extracted from a GBFF record.\"\"\"\n        seqr: SeqRegionDict = {\"length\": len(record_data.record.seq)}  # type: ignore[arg-type]\n\n        if record_data.is_circular():\n            seqr[\"circular\"] = True\n\n        # Is there a genetic code defined?\n        codon_table = record_data.get_codon_table()\n        if codon_table is not None:\n            seqr[\"codon_table\"] = codon_table\n\n        # Is it an organelle?\n        location = record_data.get_organelle()\n        if location is not None:\n            seqr[\"location\"] = location\n\n        # Is there a comment stating the Genbank record this is based on?\n        genbank_id = record_data.get_genbank_id()\n        if genbank_id is not None:\n            seqr[\"synonyms\"] = [{\"source\": \"INSDC\", \"name\": genbank_id}]\n\n        return seqr\n\n    def from_report(self, report_path: Path, is_refseq: bool = False) -&gt; None:\n        \"\"\"Store seq_regions extracted from an INSDC assembly report file.\n\n        If a seq_region with the same id exists in the collection, it will be replaced.\n\n        Args:\n            report_path: Path to the sequence regions report file.\n            is_refseq: True if the source of the report is RefSeq, false if INSDC.\n\n        \"\"\"\n        report = ReportRecord(report_path)\n        for seq_data in report.reader:\n            new_seq = self.make_seq_region_from_report(seq_data, is_refseq)\n            name = new_seq[\"name\"]\n            merged_seq = self._merge(new_seq, self.seqs.get(name, {}))\n            self.seqs[name] = merged_seq\n\n    @staticmethod\n    def make_seq_region_from_report(\n        seq_data: dict[str, Any],\n        is_refseq: bool,\n        synonym_map: Mapping[str, str] = SYNONYM_MAP,\n        molecule_location: Mapping[str, str] = MOLECULE_LOCATION,\n    ) -&gt; SeqRegionDict:\n        \"\"\"Returns a sequence region from the information provided.\n\n        An empty sequence region will be returned if no accession information is found.\n\n        Args:\n            data: Dict from the report representing one line, where the key is the column name.\n            is_refseq: True if the source is RefSeq, false if INSDC.\n            synonym_map: Map of INSDC report column names to sequence region field names.\n            molecule_location: Map of sequence type to SO location.\n\n        Raises:\n            UnknownMetadata: If the sequence role or location is not recognised.\n\n        \"\"\"\n        seq_region = {}\n\n        # Set accession as the sequence region name\n        src = \"RefSeq\" if is_refseq else \"GenBank\"\n        accession_id = seq_data.get(f\"{src}-Accn\", \"\")\n        if not accession_id or (accession_id == \"na\"):\n            logging.warning(f'No {src} accession ID found for {seq_data[\"Sequence-Name\"]}')\n            return {}\n        seq_region[\"name\"] = accession_id\n\n        # Add synonyms\n        synonyms = []\n        for field, source in synonym_map.items():\n            if (field in seq_data) and (seq_data[field].casefold() != \"na\"):\n                synonym = {\"source\": source, \"name\": seq_data[field]}\n                synonyms.append(synonym)\n        synonyms.sort(key=lambda x: x[\"source\"])\n        seq_region[\"synonyms\"] = synonyms\n\n        # Add sequence length\n        field = \"Sequence-Length\"\n        if (field in seq_data) and (seq_data[field].casefold() != \"na\"):\n            seq_region[\"length\"] = int(seq_data[field])\n\n        # Add coordinate system and location\n        seq_role = seq_data[\"Sequence-Role\"]\n        # Scaffold?\n        if seq_role in (\"unplaced-scaffold\", \"unlocalized-scaffold\"):\n            seq_region[\"coord_system_level\"] = \"scaffold\"\n        # Chromosome? Check location\n        elif seq_role == \"assembled-molecule\":\n            seq_region[\"coord_system_level\"] = \"chromosome\"\n            location = seq_data[\"Assigned-Molecule-Location/Type\"].lower()\n            # Get location metadata\n            try:\n                seq_region[\"location\"] = molecule_location[location]\n            except KeyError as exc:\n                raise UnknownMetadata(f\"Unrecognized sequence location: {location}\") from exc\n        else:\n            raise UnknownMetadata(f\"Unrecognized sequence role: {seq_role}\")\n\n        return seq_region\n\n    def remove(self, to_exclude: list[str]) -&gt; None:\n        \"\"\"Remove seq_regions based on a provided list of accessions.\"\"\"\n        for seq_name in to_exclude:\n            if seq_name in self.seqs:\n                del self.seqs[seq_name]\n            else:\n                logging.info(f\"Cannot exclude seq not found: {seq_name}\")\n\n    def add_translation_table(self, location_codon: Mapping[str, int] = LOCATION_CODON) -&gt; None:\n        \"\"\"Adds the translation codon table to each sequence region (when missing) based on its location.\n\n        Args:\n            location_codon: Map of known codon tables for known locations.\n\n        \"\"\"\n        for seqr in self.seqs.values():\n            if \"codon_table\" in seqr:\n                continue\n            if seqr.get(\"location\", \"\") in location_codon:\n                seqr[\"codon_table\"] = location_codon[seqr[\"location\"]]\n\n    def add_mitochondrial_codon_table(self, taxon_id: int) -&gt; None:\n        \"\"\"Adds the mitochondrial codon table to each sequence region (when missing) based on the taxon ID.\n\n        If no mitochondrial genetic code can be found for the given taxon ID nothing will be changed.\n\n        Args:\n            taxon_id: The species taxon ID.\n\n        \"\"\"\n        if self.mock:\n            logging.info(\"Skip mitochondrial codon table: mock\")\n            return\n        if not taxon_id:\n            logging.info(\"Skip mitochondrial codon table: no taxon_id to use\")\n            return\n\n        url = f\"https://www.ebi.ac.uk/ena/taxonomy/rest/tax-id/{str(taxon_id)}\"\n        response = requests.get(url, headers={\"Content-Type\": \"application/json\"}, timeout=60)\n        response.raise_for_status()\n        # In case we have been redirected, check for HTML opening tag\n        if response.text.startswith(\"&lt;\"):\n            raise ValueError(f\"Response from {url} is not JSON\")\n        decoded = response.json()\n        genetic_code = int(decoded.get(\"mitochondrialGeneticCode\", 0))\n        if genetic_code == 0:\n            logging.warning(f\"No mitochondria genetic code found for taxon {taxon_id}\")\n            return\n\n        for seqr in self.seqs.values():\n            if (\"codon_table\" not in seqr) and (seqr.get(\"location\", \"\") == \"mitochondrial_chromosome\"):\n                seqr[\"codon_table\"] = genetic_code\n\n    def to_list(self) -&gt; list[SeqRegionDict]:\n        \"\"\"Returns the sequences as a simple list of `SeqRegionDict` objects.\"\"\"\n        return list(self.seqs.values())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.mock","title":"<code>mock = mock</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.seqs","title":"<code>seqs = {}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.add_mitochondrial_codon_table","title":"<code>add_mitochondrial_codon_table(taxon_id)</code>","text":"<p>Adds the mitochondrial codon table to each sequence region (when missing) based on the taxon ID.</p> <p>If no mitochondrial genetic code can be found for the given taxon ID nothing will be changed.</p> <p>Parameters:</p> Name Type Description Default <code>taxon_id</code> <code>int</code> <p>The species taxon ID.</p> required Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def add_mitochondrial_codon_table(self, taxon_id: int) -&gt; None:\n    \"\"\"Adds the mitochondrial codon table to each sequence region (when missing) based on the taxon ID.\n\n    If no mitochondrial genetic code can be found for the given taxon ID nothing will be changed.\n\n    Args:\n        taxon_id: The species taxon ID.\n\n    \"\"\"\n    if self.mock:\n        logging.info(\"Skip mitochondrial codon table: mock\")\n        return\n    if not taxon_id:\n        logging.info(\"Skip mitochondrial codon table: no taxon_id to use\")\n        return\n\n    url = f\"https://www.ebi.ac.uk/ena/taxonomy/rest/tax-id/{str(taxon_id)}\"\n    response = requests.get(url, headers={\"Content-Type\": \"application/json\"}, timeout=60)\n    response.raise_for_status()\n    # In case we have been redirected, check for HTML opening tag\n    if response.text.startswith(\"&lt;\"):\n        raise ValueError(f\"Response from {url} is not JSON\")\n    decoded = response.json()\n    genetic_code = int(decoded.get(\"mitochondrialGeneticCode\", 0))\n    if genetic_code == 0:\n        logging.warning(f\"No mitochondria genetic code found for taxon {taxon_id}\")\n        return\n\n    for seqr in self.seqs.values():\n        if (\"codon_table\" not in seqr) and (seqr.get(\"location\", \"\") == \"mitochondrial_chromosome\"):\n            seqr[\"codon_table\"] = genetic_code\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.add_translation_table","title":"<code>add_translation_table(location_codon=LOCATION_CODON)</code>","text":"<p>Adds the translation codon table to each sequence region (when missing) based on its location.</p> <p>Parameters:</p> Name Type Description Default <code>location_codon</code> <code>Mapping[str, int]</code> <p>Map of known codon tables for known locations.</p> <code>LOCATION_CODON</code> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def add_translation_table(self, location_codon: Mapping[str, int] = LOCATION_CODON) -&gt; None:\n    \"\"\"Adds the translation codon table to each sequence region (when missing) based on its location.\n\n    Args:\n        location_codon: Map of known codon tables for known locations.\n\n    \"\"\"\n    for seqr in self.seqs.values():\n        if \"codon_table\" in seqr:\n            continue\n        if seqr.get(\"location\", \"\") in location_codon:\n            seqr[\"codon_table\"] = location_codon[seqr[\"location\"]]\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.from_gbff","title":"<code>from_gbff(gbff_path)</code>","text":"<p>Store seq_regions extracted from a GBFF file.</p> <p>If a seq_region with the same ID exists in the collection, it will be replaced.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def from_gbff(self, gbff_path: Path) -&gt; None:\n    \"\"\"Store seq_regions extracted from a GBFF file.\n\n    If a seq_region with the same ID exists in the collection, it will be replaced.\n    \"\"\"\n    with open_gz_file(gbff_path) as gbff_file:\n        for record in SeqIO.parse(gbff_file, \"genbank\"):\n            record_data = GBFFRecord(record)\n            new_seq: SeqRegionDict = self.make_seqregion_from_gbff(record_data)\n            name = record.id\n            merged_seq = self._merge(new_seq, self.seqs.get(name, {}))\n            self.seqs[name] = merged_seq\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.from_report","title":"<code>from_report(report_path, is_refseq=False)</code>","text":"<p>Store seq_regions extracted from an INSDC assembly report file.</p> <p>If a seq_region with the same id exists in the collection, it will be replaced.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>Path</code> <p>Path to the sequence regions report file.</p> required <code>is_refseq</code> <code>bool</code> <p>True if the source of the report is RefSeq, false if INSDC.</p> <code>False</code> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def from_report(self, report_path: Path, is_refseq: bool = False) -&gt; None:\n    \"\"\"Store seq_regions extracted from an INSDC assembly report file.\n\n    If a seq_region with the same id exists in the collection, it will be replaced.\n\n    Args:\n        report_path: Path to the sequence regions report file.\n        is_refseq: True if the source of the report is RefSeq, false if INSDC.\n\n    \"\"\"\n    report = ReportRecord(report_path)\n    for seq_data in report.reader:\n        new_seq = self.make_seq_region_from_report(seq_data, is_refseq)\n        name = new_seq[\"name\"]\n        merged_seq = self._merge(new_seq, self.seqs.get(name, {}))\n        self.seqs[name] = merged_seq\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.make_seq_region_from_report","title":"<code>make_seq_region_from_report(seq_data, is_refseq, synonym_map=SYNONYM_MAP, molecule_location=MOLECULE_LOCATION)</code>  <code>staticmethod</code>","text":"<p>Returns a sequence region from the information provided.</p> <p>An empty sequence region will be returned if no accession information is found.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Dict from the report representing one line, where the key is the column name.</p> required <code>is_refseq</code> <code>bool</code> <p>True if the source is RefSeq, false if INSDC.</p> required <code>synonym_map</code> <code>Mapping[str, str]</code> <p>Map of INSDC report column names to sequence region field names.</p> <code>SYNONYM_MAP</code> <code>molecule_location</code> <code>Mapping[str, str]</code> <p>Map of sequence type to SO location.</p> <code>MOLECULE_LOCATION</code> <p>Raises:</p> Type Description <code>UnknownMetadata</code> <p>If the sequence role or location is not recognised.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>@staticmethod\ndef make_seq_region_from_report(\n    seq_data: dict[str, Any],\n    is_refseq: bool,\n    synonym_map: Mapping[str, str] = SYNONYM_MAP,\n    molecule_location: Mapping[str, str] = MOLECULE_LOCATION,\n) -&gt; SeqRegionDict:\n    \"\"\"Returns a sequence region from the information provided.\n\n    An empty sequence region will be returned if no accession information is found.\n\n    Args:\n        data: Dict from the report representing one line, where the key is the column name.\n        is_refseq: True if the source is RefSeq, false if INSDC.\n        synonym_map: Map of INSDC report column names to sequence region field names.\n        molecule_location: Map of sequence type to SO location.\n\n    Raises:\n        UnknownMetadata: If the sequence role or location is not recognised.\n\n    \"\"\"\n    seq_region = {}\n\n    # Set accession as the sequence region name\n    src = \"RefSeq\" if is_refseq else \"GenBank\"\n    accession_id = seq_data.get(f\"{src}-Accn\", \"\")\n    if not accession_id or (accession_id == \"na\"):\n        logging.warning(f'No {src} accession ID found for {seq_data[\"Sequence-Name\"]}')\n        return {}\n    seq_region[\"name\"] = accession_id\n\n    # Add synonyms\n    synonyms = []\n    for field, source in synonym_map.items():\n        if (field in seq_data) and (seq_data[field].casefold() != \"na\"):\n            synonym = {\"source\": source, \"name\": seq_data[field]}\n            synonyms.append(synonym)\n    synonyms.sort(key=lambda x: x[\"source\"])\n    seq_region[\"synonyms\"] = synonyms\n\n    # Add sequence length\n    field = \"Sequence-Length\"\n    if (field in seq_data) and (seq_data[field].casefold() != \"na\"):\n        seq_region[\"length\"] = int(seq_data[field])\n\n    # Add coordinate system and location\n    seq_role = seq_data[\"Sequence-Role\"]\n    # Scaffold?\n    if seq_role in (\"unplaced-scaffold\", \"unlocalized-scaffold\"):\n        seq_region[\"coord_system_level\"] = \"scaffold\"\n    # Chromosome? Check location\n    elif seq_role == \"assembled-molecule\":\n        seq_region[\"coord_system_level\"] = \"chromosome\"\n        location = seq_data[\"Assigned-Molecule-Location/Type\"].lower()\n        # Get location metadata\n        try:\n            seq_region[\"location\"] = molecule_location[location]\n        except KeyError as exc:\n            raise UnknownMetadata(f\"Unrecognized sequence location: {location}\") from exc\n    else:\n        raise UnknownMetadata(f\"Unrecognized sequence role: {seq_role}\")\n\n    return seq_region\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.make_seqregion_from_gbff","title":"<code>make_seqregion_from_gbff(record_data)</code>  <code>staticmethod</code>","text":"<p>Returns a seq_region dict extracted from a GBFF record.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>@staticmethod\ndef make_seqregion_from_gbff(record_data: GBFFRecord) -&gt; SeqRegionDict:\n    \"\"\"Returns a seq_region dict extracted from a GBFF record.\"\"\"\n    seqr: SeqRegionDict = {\"length\": len(record_data.record.seq)}  # type: ignore[arg-type]\n\n    if record_data.is_circular():\n        seqr[\"circular\"] = True\n\n    # Is there a genetic code defined?\n    codon_table = record_data.get_codon_table()\n    if codon_table is not None:\n        seqr[\"codon_table\"] = codon_table\n\n    # Is it an organelle?\n    location = record_data.get_organelle()\n    if location is not None:\n        seqr[\"location\"] = location\n\n    # Is there a comment stating the Genbank record this is based on?\n    genbank_id = record_data.get_genbank_id()\n    if genbank_id is not None:\n        seqr[\"synonyms\"] = [{\"source\": \"INSDC\", \"name\": genbank_id}]\n\n    return seqr\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.remove","title":"<code>remove(to_exclude)</code>","text":"<p>Remove seq_regions based on a provided list of accessions.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def remove(self, to_exclude: list[str]) -&gt; None:\n    \"\"\"Remove seq_regions based on a provided list of accessions.\"\"\"\n    for seq_name in to_exclude:\n        if seq_name in self.seqs:\n            del self.seqs[seq_name]\n        else:\n            logging.info(f\"Cannot exclude seq not found: {seq_name}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.SeqCollection.to_list","title":"<code>to_list()</code>","text":"<p>Returns the sequences as a simple list of <code>SeqRegionDict</code> objects.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def to_list(self) -&gt; list[SeqRegionDict]:\n    \"\"\"Returns the sequences as a simple list of `SeqRegionDict` objects.\"\"\"\n    return list(self.seqs.values())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.add_attribs","title":"<code>add_attribs(seq_region, seq_region_attrib)</code>","text":"<p>Map seq_regions attribs to a specific name and type defined below.</p> <p>Parameters:</p> Name Type Description Default <code>seq_region</code> <code>dict</code> <p>A seq_region dict to modify.</p> required <code>seq_region_attrib</code> <code>dict</code> <p>The attribs for this seq_region.</p> required Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def add_attribs(seq_region: dict, seq_region_attrib: dict) -&gt; None:\n    \"\"\"Map seq_regions attribs to a specific name and type defined below.\n\n    Args:\n        seq_region: A seq_region dict to modify.\n        seq_region_attrib: The attribs for this seq_region.\n    \"\"\"\n    bool_attribs = {\n        \"circular_seq\": \"circular\",\n        \"non_ref\": \"non_ref\",\n    }\n    int_attribs = {\n        \"codon_table\": \"codon_table\",\n    }\n    string_attribs = {\n        \"BRC4_seq_region_name\": \"BRC4_seq_region_name\",\n        \"EBI_seq_region_name\": \"EBI_seq_region_name\",\n        \"coord_system_tag\": \"coord_system_level\",\n        \"sequence_location\": \"location\",\n    }\n\n    for name, key in bool_attribs.items():\n        # Make sure \"0\" means False, i.e. not added\n        value = int(seq_region_attrib.get(name, \"0\"))\n        if value:\n            seq_region[key] = bool(value)\n\n    for name, key in int_attribs.items():\n        value = seq_region_attrib.get(name, \"\")\n        if value:\n            seq_region[key] = int(value)\n\n    for name, key in string_attribs.items():\n        value = seq_region_attrib.get(name, \"\")\n        if value:\n            seq_region[key] = str(value)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.fetch_coord_systems","title":"<code>fetch_coord_systems(session)</code>","text":"<p>Retrieve the coord_system metadata from the current core.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session for the current core database.</p> required <p>Yields:</p> Type Description <code>CoordSystem</code> <p>All default coord_systems in the core database.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def fetch_coord_systems(session: Session) -&gt; Iterator[CoordSystem]:\n    \"\"\"Retrieve the coord_system metadata from the current core.\n\n    Args:\n        session: Session for the current core database.\n\n    Yields:\n        All default coord_systems in the core database.\n    \"\"\"\n    coord_system_select = select(CoordSystem).filter(CoordSystem.attrib.like(r\"%default_version%\"))\n    for row in session.execute(coord_system_select).unique().all():\n        coord: CoordSystem = row[0]\n        yield coord\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.get_json","title":"<code>get_json(src_path, **kwargs)</code>","text":"<p>Generic data JSON loader.</p> <p>Parameters:</p> Name Type Description Default <code>src_path</code> <code>StrPath</code> <p>Path to the JSON file to load.</p> required Source code in <code>src/python/ensembl/io/genomio/utils/json_utils.py</code> <pre><code>def get_json(src_path: StrPath, **kwargs: Any) -&gt; Any:\n    \"\"\"Generic data JSON loader.\n\n    Args:\n        src_path: Path to the JSON file to load.\n\n    \"\"\"\n    with Path(src_path).open(\"r\", encoding=\"utf-8\") as json_file:\n        return json.load(json_file, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.get_karyotype","title":"<code>get_karyotype(seq_region)</code>","text":"<p>Given a seq_region, extract the karyotype bands.</p> <p>Parameters:</p> Name Type Description Default <code>seq_region</code> <code>SeqRegion</code> <p>The seq_region from which the karyotype bands are extracted.</p> required <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of all karyotype bands as a dict with values 'start', 'end', 'name' 'stain', 'structure'.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def get_karyotype(seq_region: SeqRegion) -&gt; list[dict[str, str]]:\n    \"\"\"Given a seq_region, extract the karyotype bands.\n\n    Args:\n        seq_region: The seq_region from which the karyotype bands are extracted.\n\n    Returns:\n        List of all karyotype bands as a dict with values 'start', 'end', 'name' 'stain', 'structure'.\n    \"\"\"\n    bands = seq_region.karyotype\n    kars = []\n    if bands:\n        for band in bands:\n            kar = {\"start\": band.seq_region_start, \"end\": band.seq_region_end}\n            if band.band:\n                kar[\"name\"] = band.band\n            if band.stain:\n                kar[\"stain\"] = band.stain\n                structure = _KARYOTYPE_STRUCTURE.get(band.stain, \"\")\n                if structure:\n                    kar[\"structure\"] = structure\n            kars.append(kar)\n\n    kars = sorted(kars, key=lambda kar: kar.get(\"name\", \"\"))\n    return kars\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.get_seq_regions","title":"<code>get_seq_regions(session, external_db_map)</code>","text":"<p>Returns all the sequence regions from the current core database.</p> <p>Include synonyms, attribs and karyotypes. Only the top level sequences are exported.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session from the current core database.</p> required <code>external_db_map</code> <code>dict</code> <p>Mapping of external_db names for the synonyms.</p> required Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def get_seq_regions(session: Session, external_db_map: dict) -&gt; list[SeqRegion]:\n    \"\"\"Returns all the sequence regions from the current core database.\n\n    Include synonyms, attribs and karyotypes. Only the top level sequences are exported.\n\n    Args:\n        session: Session from the current core database.\n        external_db_map: Mapping of external_db names for the synonyms.\n\n    \"\"\"\n    seq_regions = []\n\n    for coord_system in fetch_coord_systems(session):\n        logging.debug(f\"Dump coord {coord_system.name}\")\n        for seqr in fetch_seq_regions(session, coord_system):\n            seq_region: dict[str, Any] = {}\n            seq_region = {\"name\": seqr.name, \"length\": seqr.length}\n            synonyms = get_synonyms(seqr, external_db_map)\n            if synonyms:\n                seq_region[\"synonyms\"] = synonyms\n\n            attribs = get_attribs_dict(seqr)\n            if not attribs or \"toplevel\" not in attribs:\n                # Skip seq_region without attribs or not toplevel\n                continue\n            add_attribs(seq_region, attribs)\n\n            karyotype = get_karyotype(seqr)\n            if karyotype:\n                seq_region[\"karyotype_bands\"] = karyotype\n\n            added_seq = get_added_sequence(seqr)\n            if added_seq:\n                seq_region[\"added_sequence\"] = added_seq\n\n            if \"coord_system_level\" not in seq_region:\n                seq_region[\"coord_system_level\"] = coord_system.name\n\n            seq_regions.append(seq_region)\n\n    seq_regions = sorted(seq_regions, key=lambda seqr: (seqr[\"coord_system_level\"], seqr[\"name\"]))\n    return seq_regions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.get_synonyms","title":"<code>get_synonyms(seq_region, external_db_map)</code>","text":"<p>Get all synonyms for a given seq_region. Use the mapping for synonym source names.</p> <p>Parameters:</p> Name Type Description Default <code>seq_region</code> <code>SeqRegion</code> <p>Seq_region from which the synonyms are extracted.</p> required <code>external_db_map</code> <code>dict[str, str]</code> <p>To map the synonym source names.</p> required <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of all synonyms as a dict with 'name' and 'source' keys.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def get_synonyms(seq_region: SeqRegion, external_db_map: dict[str, str]) -&gt; list[dict[str, str]]:\n    \"\"\"Get all synonyms for a given seq_region. Use the mapping for synonym source names.\n\n    Args:\n        seq_region: Seq_region from which the synonyms are extracted.\n        external_db_map: To map the synonym source names.\n\n    Returns:\n        List of all synonyms as a dict with 'name' and 'source' keys.\n    \"\"\"\n    synonyms = seq_region.seq_region_synonym\n    syns = []\n    if synonyms:\n        for syn in synonyms:\n            if syn.external_db:\n                source = syn.external_db.db_name\n                if source in external_db_map:\n                    source = external_db_map[source]\n                syn_obj = {\"name\": syn.synonym, \"source\": source}\n            else:\n                syn_obj = {\"name\": syn.synonym}\n            syns.append(syn_obj)\n\n    syns = sorted(syns, key=lambda syn: (syn[\"name\"], syn.get(\"source\", \"\")))\n    return syns\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.init_logging_with_args","title":"<code>init_logging_with_args(args)</code>","text":"<p>Processes the Namespace object provided to call <code>init_logging()</code> with the correct arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Namespace populated by an argument parser.</p> required Source code in <code>ensembl/utils/logging.py</code> <pre><code>def init_logging_with_args(args: argparse.Namespace) -&gt; None:\n    \"\"\"Processes the Namespace object provided to call `init_logging()` with the correct arguments.\n\n    Args:\n        args: Namespace populated by an argument parser.\n\n    \"\"\"\n    args_dict = vars(args)\n    log_args = {x: args_dict[x] for x in [\"log_level\", \"log_file\", \"log_file_level\"] if x in args_dict}\n    init_logging(**log_args)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.main","title":"<code>main()</code>","text":"<p>Module's entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/prepare.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module's entry-point.\"\"\"\n    parser = ArgumentParser(description=\"Construct a sequence region metadata file from INSDC files.\")\n    parser.add_argument_src_path(\"--genome_file\", required=True, help=\"Genome metadata JSON file\")\n    parser.add_argument_src_path(\n        \"--report_file\", required=True, help=\"INSDC/RefSeq sequences report file to parse\"\n    )\n    parser.add_argument_src_path(\"--gbff_file\", help=\"INSDC/RefSeq GBFF file to parse\")\n    parser.add_argument_dst_path(\n        \"--dst_file\", default=\"seq_region.json\", help=\"Output JSON file for the processed sequence regions\"\n    )\n    parser.add_argument(\n        \"--to_exclude\", nargs=\"*\", metavar=\"SEQ_REGION_NAME\", help=\"Sequence region names to exclude\"\n    )\n    parser.add_argument(\"--mock_run\", action=\"store_true\", help=\"Do not call external APIs\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    prepare_seq_region_metadata(\n        genome_file=args.genome_file,\n        report_file=args.report_file,\n        dst_file=args.dst_file,\n        gbff_file=args.gbff_file,\n        to_exclude=args.to_exclude,\n        mock_run=args.mock_run,\n    )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.prepare_seq_region_metadata","title":"<code>prepare_seq_region_metadata(genome_file, report_file, dst_file, *, gbff_file=None, to_exclude=None, mock_run=False)</code>","text":"<p>Prepares the sequence region metadata found in the INSDC/RefSeq report and GBFF files.</p> <p>The sequence region information is loaded from both sources and combined. Elements are added/excluded as requested, and the final sequence region metadata is dumped in a JSON file that follows the schema defined in \"src/python/ensembl/io/genomio/data/schemas/seq_region.json\".</p> <p>Parameters:</p> Name Type Description Default <code>genome_file</code> <code>StrPath</code> <p>Genome metadata JSON file path.</p> required <code>report_file</code> <code>StrPath</code> <p>INSDC/RefSeq sequences report file path to parse.</p> required <code>gbff_file</code> <code>StrPath | None</code> <p>INSDC/RefSeq GBFF file path to parse.</p> <code>None</code> <code>dst_file</code> <code>StrPath</code> <p>JSON file output for the processed sequence regions JSON.</p> required <code>to_exclude</code> <code>list[str] | None</code> <p>Sequence region names to exclude.</p> <code>None</code> <code>mock_run</code> <code>bool</code> <p>Do not call external taxonomy service.</p> <code>False</code> Source code in <code>src/python/ensembl/io/genomio/seq_region/prepare.py</code> <pre><code>def prepare_seq_region_metadata(\n    genome_file: StrPath,\n    report_file: StrPath,\n    dst_file: StrPath,\n    *,\n    gbff_file: StrPath | None = None,\n    to_exclude: list[str] | None = None,\n    mock_run: bool = False,\n) -&gt; None:\n    \"\"\"Prepares the sequence region metadata found in the INSDC/RefSeq report and GBFF files.\n\n    The sequence region information is loaded from both sources and combined. Elements are added/excluded\n    as requested, and the final sequence region metadata is dumped in a JSON file that follows the schema\n    defined in \"src/python/ensembl/io/genomio/data/schemas/seq_region.json\".\n\n    Args:\n        genome_file: Genome metadata JSON file path.\n        report_file: INSDC/RefSeq sequences report file path to parse.\n        gbff_file: INSDC/RefSeq GBFF file path to parse.\n        dst_file: JSON file output for the processed sequence regions JSON.\n        to_exclude: Sequence region names to exclude.\n        mock_run: Do not call external taxonomy service.\n\n    \"\"\"\n    genome_data = get_json(genome_file)\n    dst_file = Path(dst_file)\n    is_refseq = genome_data[\"assembly\"][\"accession\"].startswith(\"GCF_\")\n\n    seqs = SeqCollection(mock=mock_run)\n    seqs.from_report(Path(report_file), is_refseq)\n    if gbff_file:\n        seqs.from_gbff(Path(gbff_file))\n\n    # Exclude seq_regions from a list\n    if to_exclude:\n        seqs.remove(to_exclude)\n\n    # Add translation and mitochondrial codon tables\n    seqs.add_translation_table()\n    seqs.add_mitochondrial_codon_table(genome_data[\"species\"][\"taxonomy_id\"])\n\n    # Print out the file\n    print_json(dst_file, seqs.to_list())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/#ensembl.io.genomio.seq_region.print_json","title":"<code>print_json(dst_path, data, **kwargs)</code>","text":"<p>Generic data JSON dumper to a file, with keys sorted and pretty-printed with indent 4 by default.</p> <p>Parameters:</p> Name Type Description Default <code>dst_path</code> <code>StrPath</code> <p>Path to the JSON file to create.</p> required <code>data</code> <code>Any</code> <p>Any data to store into the file.</p> required Source code in <code>src/python/ensembl/io/genomio/utils/json_utils.py</code> <pre><code>def print_json(dst_path: StrPath, data: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Generic data JSON dumper to a file, with keys sorted and pretty-printed with indent 4 by default.\n\n    Args:\n        dst_path: Path to the JSON file to create.\n        data: Any data to store into the file.\n\n    \"\"\"\n    kwargs.setdefault(\"sort_keys\", True)\n    kwargs.setdefault(\"indent\", 4)\n    with Path(dst_path).open(\"w\", encoding=\"utf-8\") as json_file:\n        json_file.write(json.dumps(data, **kwargs))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/","title":"collection","text":""},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection","title":"<code>ensembl.io.genomio.seq_region.collection</code>","text":"<p>SeqCollection as a collection of seq_regions metadata.</p>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqRegionDict","title":"<code>SeqRegionDict = dict[str, Any]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection","title":"<code>SeqCollection</code>","text":"<p>Represent a collection of seq_regions metadata.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>class SeqCollection:\n    \"\"\"Represent a collection of seq_regions metadata.\"\"\"\n\n    mock: bool\n    seqs: dict\n\n    def __init__(self, mock: bool = False) -&gt; None:\n        self.seqs = {}\n        self.mock = mock\n\n    def from_gbff(self, gbff_path: Path) -&gt; None:\n        \"\"\"Store seq_regions extracted from a GBFF file.\n\n        If a seq_region with the same ID exists in the collection, it will be replaced.\n        \"\"\"\n        with open_gz_file(gbff_path) as gbff_file:\n            for record in SeqIO.parse(gbff_file, \"genbank\"):\n                record_data = GBFFRecord(record)\n                new_seq: SeqRegionDict = self.make_seqregion_from_gbff(record_data)\n                name = record.id\n                merged_seq = self._merge(new_seq, self.seqs.get(name, {}))\n                self.seqs[name] = merged_seq\n\n    def _merge(self, source: SeqRegionDict, destination: SeqRegionDict) -&gt; SeqRegionDict:\n        \"\"\"Merge a source dict in a destination dict (only add values or append to lists).\"\"\"\n        if not destination:\n            return source\n        for key, value in source.items():\n            if isinstance(value, list):\n                destination[key] += value\n            else:\n                destination[key] = value\n\n        return destination\n\n    @staticmethod\n    def make_seqregion_from_gbff(record_data: GBFFRecord) -&gt; SeqRegionDict:\n        \"\"\"Returns a seq_region dict extracted from a GBFF record.\"\"\"\n        seqr: SeqRegionDict = {\"length\": len(record_data.record.seq)}  # type: ignore[arg-type]\n\n        if record_data.is_circular():\n            seqr[\"circular\"] = True\n\n        # Is there a genetic code defined?\n        codon_table = record_data.get_codon_table()\n        if codon_table is not None:\n            seqr[\"codon_table\"] = codon_table\n\n        # Is it an organelle?\n        location = record_data.get_organelle()\n        if location is not None:\n            seqr[\"location\"] = location\n\n        # Is there a comment stating the Genbank record this is based on?\n        genbank_id = record_data.get_genbank_id()\n        if genbank_id is not None:\n            seqr[\"synonyms\"] = [{\"source\": \"INSDC\", \"name\": genbank_id}]\n\n        return seqr\n\n    def from_report(self, report_path: Path, is_refseq: bool = False) -&gt; None:\n        \"\"\"Store seq_regions extracted from an INSDC assembly report file.\n\n        If a seq_region with the same id exists in the collection, it will be replaced.\n\n        Args:\n            report_path: Path to the sequence regions report file.\n            is_refseq: True if the source of the report is RefSeq, false if INSDC.\n\n        \"\"\"\n        report = ReportRecord(report_path)\n        for seq_data in report.reader:\n            new_seq = self.make_seq_region_from_report(seq_data, is_refseq)\n            name = new_seq[\"name\"]\n            merged_seq = self._merge(new_seq, self.seqs.get(name, {}))\n            self.seqs[name] = merged_seq\n\n    @staticmethod\n    def make_seq_region_from_report(\n        seq_data: dict[str, Any],\n        is_refseq: bool,\n        synonym_map: Mapping[str, str] = SYNONYM_MAP,\n        molecule_location: Mapping[str, str] = MOLECULE_LOCATION,\n    ) -&gt; SeqRegionDict:\n        \"\"\"Returns a sequence region from the information provided.\n\n        An empty sequence region will be returned if no accession information is found.\n\n        Args:\n            data: Dict from the report representing one line, where the key is the column name.\n            is_refseq: True if the source is RefSeq, false if INSDC.\n            synonym_map: Map of INSDC report column names to sequence region field names.\n            molecule_location: Map of sequence type to SO location.\n\n        Raises:\n            UnknownMetadata: If the sequence role or location is not recognised.\n\n        \"\"\"\n        seq_region = {}\n\n        # Set accession as the sequence region name\n        src = \"RefSeq\" if is_refseq else \"GenBank\"\n        accession_id = seq_data.get(f\"{src}-Accn\", \"\")\n        if not accession_id or (accession_id == \"na\"):\n            logging.warning(f'No {src} accession ID found for {seq_data[\"Sequence-Name\"]}')\n            return {}\n        seq_region[\"name\"] = accession_id\n\n        # Add synonyms\n        synonyms = []\n        for field, source in synonym_map.items():\n            if (field in seq_data) and (seq_data[field].casefold() != \"na\"):\n                synonym = {\"source\": source, \"name\": seq_data[field]}\n                synonyms.append(synonym)\n        synonyms.sort(key=lambda x: x[\"source\"])\n        seq_region[\"synonyms\"] = synonyms\n\n        # Add sequence length\n        field = \"Sequence-Length\"\n        if (field in seq_data) and (seq_data[field].casefold() != \"na\"):\n            seq_region[\"length\"] = int(seq_data[field])\n\n        # Add coordinate system and location\n        seq_role = seq_data[\"Sequence-Role\"]\n        # Scaffold?\n        if seq_role in (\"unplaced-scaffold\", \"unlocalized-scaffold\"):\n            seq_region[\"coord_system_level\"] = \"scaffold\"\n        # Chromosome? Check location\n        elif seq_role == \"assembled-molecule\":\n            seq_region[\"coord_system_level\"] = \"chromosome\"\n            location = seq_data[\"Assigned-Molecule-Location/Type\"].lower()\n            # Get location metadata\n            try:\n                seq_region[\"location\"] = molecule_location[location]\n            except KeyError as exc:\n                raise UnknownMetadata(f\"Unrecognized sequence location: {location}\") from exc\n        else:\n            raise UnknownMetadata(f\"Unrecognized sequence role: {seq_role}\")\n\n        return seq_region\n\n    def remove(self, to_exclude: list[str]) -&gt; None:\n        \"\"\"Remove seq_regions based on a provided list of accessions.\"\"\"\n        for seq_name in to_exclude:\n            if seq_name in self.seqs:\n                del self.seqs[seq_name]\n            else:\n                logging.info(f\"Cannot exclude seq not found: {seq_name}\")\n\n    def add_translation_table(self, location_codon: Mapping[str, int] = LOCATION_CODON) -&gt; None:\n        \"\"\"Adds the translation codon table to each sequence region (when missing) based on its location.\n\n        Args:\n            location_codon: Map of known codon tables for known locations.\n\n        \"\"\"\n        for seqr in self.seqs.values():\n            if \"codon_table\" in seqr:\n                continue\n            if seqr.get(\"location\", \"\") in location_codon:\n                seqr[\"codon_table\"] = location_codon[seqr[\"location\"]]\n\n    def add_mitochondrial_codon_table(self, taxon_id: int) -&gt; None:\n        \"\"\"Adds the mitochondrial codon table to each sequence region (when missing) based on the taxon ID.\n\n        If no mitochondrial genetic code can be found for the given taxon ID nothing will be changed.\n\n        Args:\n            taxon_id: The species taxon ID.\n\n        \"\"\"\n        if self.mock:\n            logging.info(\"Skip mitochondrial codon table: mock\")\n            return\n        if not taxon_id:\n            logging.info(\"Skip mitochondrial codon table: no taxon_id to use\")\n            return\n\n        url = f\"https://www.ebi.ac.uk/ena/taxonomy/rest/tax-id/{str(taxon_id)}\"\n        response = requests.get(url, headers={\"Content-Type\": \"application/json\"}, timeout=60)\n        response.raise_for_status()\n        # In case we have been redirected, check for HTML opening tag\n        if response.text.startswith(\"&lt;\"):\n            raise ValueError(f\"Response from {url} is not JSON\")\n        decoded = response.json()\n        genetic_code = int(decoded.get(\"mitochondrialGeneticCode\", 0))\n        if genetic_code == 0:\n            logging.warning(f\"No mitochondria genetic code found for taxon {taxon_id}\")\n            return\n\n        for seqr in self.seqs.values():\n            if (\"codon_table\" not in seqr) and (seqr.get(\"location\", \"\") == \"mitochondrial_chromosome\"):\n                seqr[\"codon_table\"] = genetic_code\n\n    def to_list(self) -&gt; list[SeqRegionDict]:\n        \"\"\"Returns the sequences as a simple list of `SeqRegionDict` objects.\"\"\"\n        return list(self.seqs.values())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.mock","title":"<code>mock = mock</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.seqs","title":"<code>seqs = {}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.add_mitochondrial_codon_table","title":"<code>add_mitochondrial_codon_table(taxon_id)</code>","text":"<p>Adds the mitochondrial codon table to each sequence region (when missing) based on the taxon ID.</p> <p>If no mitochondrial genetic code can be found for the given taxon ID nothing will be changed.</p> <p>Parameters:</p> Name Type Description Default <code>taxon_id</code> <code>int</code> <p>The species taxon ID.</p> required Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def add_mitochondrial_codon_table(self, taxon_id: int) -&gt; None:\n    \"\"\"Adds the mitochondrial codon table to each sequence region (when missing) based on the taxon ID.\n\n    If no mitochondrial genetic code can be found for the given taxon ID nothing will be changed.\n\n    Args:\n        taxon_id: The species taxon ID.\n\n    \"\"\"\n    if self.mock:\n        logging.info(\"Skip mitochondrial codon table: mock\")\n        return\n    if not taxon_id:\n        logging.info(\"Skip mitochondrial codon table: no taxon_id to use\")\n        return\n\n    url = f\"https://www.ebi.ac.uk/ena/taxonomy/rest/tax-id/{str(taxon_id)}\"\n    response = requests.get(url, headers={\"Content-Type\": \"application/json\"}, timeout=60)\n    response.raise_for_status()\n    # In case we have been redirected, check for HTML opening tag\n    if response.text.startswith(\"&lt;\"):\n        raise ValueError(f\"Response from {url} is not JSON\")\n    decoded = response.json()\n    genetic_code = int(decoded.get(\"mitochondrialGeneticCode\", 0))\n    if genetic_code == 0:\n        logging.warning(f\"No mitochondria genetic code found for taxon {taxon_id}\")\n        return\n\n    for seqr in self.seqs.values():\n        if (\"codon_table\" not in seqr) and (seqr.get(\"location\", \"\") == \"mitochondrial_chromosome\"):\n            seqr[\"codon_table\"] = genetic_code\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.add_translation_table","title":"<code>add_translation_table(location_codon=LOCATION_CODON)</code>","text":"<p>Adds the translation codon table to each sequence region (when missing) based on its location.</p> <p>Parameters:</p> Name Type Description Default <code>location_codon</code> <code>Mapping[str, int]</code> <p>Map of known codon tables for known locations.</p> <code>LOCATION_CODON</code> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def add_translation_table(self, location_codon: Mapping[str, int] = LOCATION_CODON) -&gt; None:\n    \"\"\"Adds the translation codon table to each sequence region (when missing) based on its location.\n\n    Args:\n        location_codon: Map of known codon tables for known locations.\n\n    \"\"\"\n    for seqr in self.seqs.values():\n        if \"codon_table\" in seqr:\n            continue\n        if seqr.get(\"location\", \"\") in location_codon:\n            seqr[\"codon_table\"] = location_codon[seqr[\"location\"]]\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.from_gbff","title":"<code>from_gbff(gbff_path)</code>","text":"<p>Store seq_regions extracted from a GBFF file.</p> <p>If a seq_region with the same ID exists in the collection, it will be replaced.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def from_gbff(self, gbff_path: Path) -&gt; None:\n    \"\"\"Store seq_regions extracted from a GBFF file.\n\n    If a seq_region with the same ID exists in the collection, it will be replaced.\n    \"\"\"\n    with open_gz_file(gbff_path) as gbff_file:\n        for record in SeqIO.parse(gbff_file, \"genbank\"):\n            record_data = GBFFRecord(record)\n            new_seq: SeqRegionDict = self.make_seqregion_from_gbff(record_data)\n            name = record.id\n            merged_seq = self._merge(new_seq, self.seqs.get(name, {}))\n            self.seqs[name] = merged_seq\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.from_report","title":"<code>from_report(report_path, is_refseq=False)</code>","text":"<p>Store seq_regions extracted from an INSDC assembly report file.</p> <p>If a seq_region with the same id exists in the collection, it will be replaced.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>Path</code> <p>Path to the sequence regions report file.</p> required <code>is_refseq</code> <code>bool</code> <p>True if the source of the report is RefSeq, false if INSDC.</p> <code>False</code> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def from_report(self, report_path: Path, is_refseq: bool = False) -&gt; None:\n    \"\"\"Store seq_regions extracted from an INSDC assembly report file.\n\n    If a seq_region with the same id exists in the collection, it will be replaced.\n\n    Args:\n        report_path: Path to the sequence regions report file.\n        is_refseq: True if the source of the report is RefSeq, false if INSDC.\n\n    \"\"\"\n    report = ReportRecord(report_path)\n    for seq_data in report.reader:\n        new_seq = self.make_seq_region_from_report(seq_data, is_refseq)\n        name = new_seq[\"name\"]\n        merged_seq = self._merge(new_seq, self.seqs.get(name, {}))\n        self.seqs[name] = merged_seq\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.make_seq_region_from_report","title":"<code>make_seq_region_from_report(seq_data, is_refseq, synonym_map=SYNONYM_MAP, molecule_location=MOLECULE_LOCATION)</code>  <code>staticmethod</code>","text":"<p>Returns a sequence region from the information provided.</p> <p>An empty sequence region will be returned if no accession information is found.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Dict from the report representing one line, where the key is the column name.</p> required <code>is_refseq</code> <code>bool</code> <p>True if the source is RefSeq, false if INSDC.</p> required <code>synonym_map</code> <code>Mapping[str, str]</code> <p>Map of INSDC report column names to sequence region field names.</p> <code>SYNONYM_MAP</code> <code>molecule_location</code> <code>Mapping[str, str]</code> <p>Map of sequence type to SO location.</p> <code>MOLECULE_LOCATION</code> <p>Raises:</p> Type Description <code>UnknownMetadata</code> <p>If the sequence role or location is not recognised.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>@staticmethod\ndef make_seq_region_from_report(\n    seq_data: dict[str, Any],\n    is_refseq: bool,\n    synonym_map: Mapping[str, str] = SYNONYM_MAP,\n    molecule_location: Mapping[str, str] = MOLECULE_LOCATION,\n) -&gt; SeqRegionDict:\n    \"\"\"Returns a sequence region from the information provided.\n\n    An empty sequence region will be returned if no accession information is found.\n\n    Args:\n        data: Dict from the report representing one line, where the key is the column name.\n        is_refseq: True if the source is RefSeq, false if INSDC.\n        synonym_map: Map of INSDC report column names to sequence region field names.\n        molecule_location: Map of sequence type to SO location.\n\n    Raises:\n        UnknownMetadata: If the sequence role or location is not recognised.\n\n    \"\"\"\n    seq_region = {}\n\n    # Set accession as the sequence region name\n    src = \"RefSeq\" if is_refseq else \"GenBank\"\n    accession_id = seq_data.get(f\"{src}-Accn\", \"\")\n    if not accession_id or (accession_id == \"na\"):\n        logging.warning(f'No {src} accession ID found for {seq_data[\"Sequence-Name\"]}')\n        return {}\n    seq_region[\"name\"] = accession_id\n\n    # Add synonyms\n    synonyms = []\n    for field, source in synonym_map.items():\n        if (field in seq_data) and (seq_data[field].casefold() != \"na\"):\n            synonym = {\"source\": source, \"name\": seq_data[field]}\n            synonyms.append(synonym)\n    synonyms.sort(key=lambda x: x[\"source\"])\n    seq_region[\"synonyms\"] = synonyms\n\n    # Add sequence length\n    field = \"Sequence-Length\"\n    if (field in seq_data) and (seq_data[field].casefold() != \"na\"):\n        seq_region[\"length\"] = int(seq_data[field])\n\n    # Add coordinate system and location\n    seq_role = seq_data[\"Sequence-Role\"]\n    # Scaffold?\n    if seq_role in (\"unplaced-scaffold\", \"unlocalized-scaffold\"):\n        seq_region[\"coord_system_level\"] = \"scaffold\"\n    # Chromosome? Check location\n    elif seq_role == \"assembled-molecule\":\n        seq_region[\"coord_system_level\"] = \"chromosome\"\n        location = seq_data[\"Assigned-Molecule-Location/Type\"].lower()\n        # Get location metadata\n        try:\n            seq_region[\"location\"] = molecule_location[location]\n        except KeyError as exc:\n            raise UnknownMetadata(f\"Unrecognized sequence location: {location}\") from exc\n    else:\n        raise UnknownMetadata(f\"Unrecognized sequence role: {seq_role}\")\n\n    return seq_region\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.make_seqregion_from_gbff","title":"<code>make_seqregion_from_gbff(record_data)</code>  <code>staticmethod</code>","text":"<p>Returns a seq_region dict extracted from a GBFF record.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>@staticmethod\ndef make_seqregion_from_gbff(record_data: GBFFRecord) -&gt; SeqRegionDict:\n    \"\"\"Returns a seq_region dict extracted from a GBFF record.\"\"\"\n    seqr: SeqRegionDict = {\"length\": len(record_data.record.seq)}  # type: ignore[arg-type]\n\n    if record_data.is_circular():\n        seqr[\"circular\"] = True\n\n    # Is there a genetic code defined?\n    codon_table = record_data.get_codon_table()\n    if codon_table is not None:\n        seqr[\"codon_table\"] = codon_table\n\n    # Is it an organelle?\n    location = record_data.get_organelle()\n    if location is not None:\n        seqr[\"location\"] = location\n\n    # Is there a comment stating the Genbank record this is based on?\n    genbank_id = record_data.get_genbank_id()\n    if genbank_id is not None:\n        seqr[\"synonyms\"] = [{\"source\": \"INSDC\", \"name\": genbank_id}]\n\n    return seqr\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.remove","title":"<code>remove(to_exclude)</code>","text":"<p>Remove seq_regions based on a provided list of accessions.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def remove(self, to_exclude: list[str]) -&gt; None:\n    \"\"\"Remove seq_regions based on a provided list of accessions.\"\"\"\n    for seq_name in to_exclude:\n        if seq_name in self.seqs:\n            del self.seqs[seq_name]\n        else:\n            logging.info(f\"Cannot exclude seq not found: {seq_name}\")\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/collection/#ensembl.io.genomio.seq_region.collection.SeqCollection.to_list","title":"<code>to_list()</code>","text":"<p>Returns the sequences as a simple list of <code>SeqRegionDict</code> objects.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/collection.py</code> <pre><code>def to_list(self) -&gt; list[SeqRegionDict]:\n    \"\"\"Returns the sequences as a simple list of `SeqRegionDict` objects.\"\"\"\n    return list(self.seqs.values())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/","title":"dump","text":""},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump","title":"<code>ensembl.io.genomio.seq_region.dump</code>","text":"<p>Fetch all the sequence regions from a core database and print them in JSON format.</p>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.add_attribs","title":"<code>add_attribs(seq_region, seq_region_attrib)</code>","text":"<p>Map seq_regions attribs to a specific name and type defined below.</p> <p>Parameters:</p> Name Type Description Default <code>seq_region</code> <code>dict</code> <p>A seq_region dict to modify.</p> required <code>seq_region_attrib</code> <code>dict</code> <p>The attribs for this seq_region.</p> required Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def add_attribs(seq_region: dict, seq_region_attrib: dict) -&gt; None:\n    \"\"\"Map seq_regions attribs to a specific name and type defined below.\n\n    Args:\n        seq_region: A seq_region dict to modify.\n        seq_region_attrib: The attribs for this seq_region.\n    \"\"\"\n    bool_attribs = {\n        \"circular_seq\": \"circular\",\n        \"non_ref\": \"non_ref\",\n    }\n    int_attribs = {\n        \"codon_table\": \"codon_table\",\n    }\n    string_attribs = {\n        \"BRC4_seq_region_name\": \"BRC4_seq_region_name\",\n        \"EBI_seq_region_name\": \"EBI_seq_region_name\",\n        \"coord_system_tag\": \"coord_system_level\",\n        \"sequence_location\": \"location\",\n    }\n\n    for name, key in bool_attribs.items():\n        # Make sure \"0\" means False, i.e. not added\n        value = int(seq_region_attrib.get(name, \"0\"))\n        if value:\n            seq_region[key] = bool(value)\n\n    for name, key in int_attribs.items():\n        value = seq_region_attrib.get(name, \"\")\n        if value:\n            seq_region[key] = int(value)\n\n    for name, key in string_attribs.items():\n        value = seq_region_attrib.get(name, \"\")\n        if value:\n            seq_region[key] = str(value)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.fetch_coord_systems","title":"<code>fetch_coord_systems(session)</code>","text":"<p>Retrieve the coord_system metadata from the current core.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session for the current core database.</p> required <p>Yields:</p> Type Description <code>CoordSystem</code> <p>All default coord_systems in the core database.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def fetch_coord_systems(session: Session) -&gt; Iterator[CoordSystem]:\n    \"\"\"Retrieve the coord_system metadata from the current core.\n\n    Args:\n        session: Session for the current core database.\n\n    Yields:\n        All default coord_systems in the core database.\n    \"\"\"\n    coord_system_select = select(CoordSystem).filter(CoordSystem.attrib.like(r\"%default_version%\"))\n    for row in session.execute(coord_system_select).unique().all():\n        coord: CoordSystem = row[0]\n        yield coord\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.fetch_seq_regions","title":"<code>fetch_seq_regions(session, coord_system)</code>","text":"<p>Retrieve the seq_region metadata for a given coord_system, with accessory tables cached.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session for the current core database.</p> required <code>coord_system</code> <code>CoordSystem</code> <p>Coord_system to get seq regions.</p> required <p>Yields:</p> Type Description <code>SeqRegion</code> <p>All seq_regions for the coord_system.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def fetch_seq_regions(session: Session, coord_system: CoordSystem) -&gt; Iterator[SeqRegion]:\n    \"\"\"Retrieve the seq_region metadata for a given coord_system, with accessory tables cached.\n\n    Args:\n        session: Session for the current core database.\n        coord_system: Coord_system to get seq regions.\n\n    Yields:\n        All seq_regions for the coord_system.\n    \"\"\"\n    seq_region_select = (\n        select(SeqRegion)\n        .where(SeqRegion.coord_system_id == coord_system.coord_system_id)\n        .options(\n            joinedload(SeqRegion.seq_region_synonym).joinedload(SeqRegionSynonym.external_db),\n            joinedload(SeqRegion.seq_region_attrib).joinedload(SeqRegionAttrib.attrib_type),\n            joinedload(SeqRegion.karyotype),\n        )\n    )\n    for row in session.execute(seq_region_select).unique().all():\n        seq_region: SeqRegion = row[0]\n        yield seq_region\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.get_added_sequence","title":"<code>get_added_sequence(seq_region)</code>","text":"<p>Extracts added sequence information of the given sequence region.</p> <p>Parameters:</p> Name Type Description Default <code>seq_region</code> <code>SeqRegion</code> <p>Sequence region.</p> required <p>Returns:</p> Type Description <code>dict[str, str | dict[str, str]]</code> <p>Accession as well as assembly and annotation provider information of the added sequence.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def get_added_sequence(seq_region: SeqRegion) -&gt; dict[str, str | dict[str, str]]:\n    \"\"\"Extracts added sequence information of the given sequence region.\n\n    Args:\n        seq_region: Sequence region.\n\n    Returns:\n        Accession as well as assembly and annotation provider information of the added sequence.\n    \"\"\"\n    attribs = get_attribs_dict(seq_region)\n    accession = attribs.get(\"added_seq_accession\")\n    if accession is None:\n        return {}\n\n    added_sequence = {\n        \"accession\": accession,\n    }\n\n    # Assembly provider\n    assembly_provider = {\n        \"name\": attribs.get(\"added_seq_asm_pr_nam\"),\n        \"url\": attribs.get(\"added_seq_asm_pr_url\"),\n    }\n    if assembly_provider[\"name\"] and assembly_provider[\"url\"]:\n        added_sequence[\"assembly_provider\"] = assembly_provider\n\n    # annotation provider\n    annotation_provider = {\n        \"name\": attribs.get(\"added_seq_ann_pr_nam\"),\n        \"url\": attribs.get(\"added_seq_ann_pr_url\"),\n    }\n    if annotation_provider[\"name\"] and annotation_provider[\"url\"]:\n        added_sequence[\"annotation_provider\"] = annotation_provider\n\n    return added_sequence\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.get_attribs_dict","title":"<code>get_attribs_dict(seq_region)</code>","text":"<p>Returns a dict of attrib code-value for all the attributes of the given sequence region.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def get_attribs_dict(seq_region: SeqRegion) -&gt; dict[str, Any]:\n    \"\"\"Returns a dict of attrib code-value for all the attributes of the given sequence region.\"\"\"\n    return {attrib.attrib_type.code: attrib.value for attrib in seq_region.seq_region_attrib}\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.get_karyotype","title":"<code>get_karyotype(seq_region)</code>","text":"<p>Given a seq_region, extract the karyotype bands.</p> <p>Parameters:</p> Name Type Description Default <code>seq_region</code> <code>SeqRegion</code> <p>The seq_region from which the karyotype bands are extracted.</p> required <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of all karyotype bands as a dict with values 'start', 'end', 'name' 'stain', 'structure'.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def get_karyotype(seq_region: SeqRegion) -&gt; list[dict[str, str]]:\n    \"\"\"Given a seq_region, extract the karyotype bands.\n\n    Args:\n        seq_region: The seq_region from which the karyotype bands are extracted.\n\n    Returns:\n        List of all karyotype bands as a dict with values 'start', 'end', 'name' 'stain', 'structure'.\n    \"\"\"\n    bands = seq_region.karyotype\n    kars = []\n    if bands:\n        for band in bands:\n            kar = {\"start\": band.seq_region_start, \"end\": band.seq_region_end}\n            if band.band:\n                kar[\"name\"] = band.band\n            if band.stain:\n                kar[\"stain\"] = band.stain\n                structure = _KARYOTYPE_STRUCTURE.get(band.stain, \"\")\n                if structure:\n                    kar[\"structure\"] = structure\n            kars.append(kar)\n\n    kars = sorted(kars, key=lambda kar: kar.get(\"name\", \"\"))\n    return kars\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.get_seq_regions","title":"<code>get_seq_regions(session, external_db_map)</code>","text":"<p>Returns all the sequence regions from the current core database.</p> <p>Include synonyms, attribs and karyotypes. Only the top level sequences are exported.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session</code> <p>Session from the current core database.</p> required <code>external_db_map</code> <code>dict</code> <p>Mapping of external_db names for the synonyms.</p> required Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def get_seq_regions(session: Session, external_db_map: dict) -&gt; list[SeqRegion]:\n    \"\"\"Returns all the sequence regions from the current core database.\n\n    Include synonyms, attribs and karyotypes. Only the top level sequences are exported.\n\n    Args:\n        session: Session from the current core database.\n        external_db_map: Mapping of external_db names for the synonyms.\n\n    \"\"\"\n    seq_regions = []\n\n    for coord_system in fetch_coord_systems(session):\n        logging.debug(f\"Dump coord {coord_system.name}\")\n        for seqr in fetch_seq_regions(session, coord_system):\n            seq_region: dict[str, Any] = {}\n            seq_region = {\"name\": seqr.name, \"length\": seqr.length}\n            synonyms = get_synonyms(seqr, external_db_map)\n            if synonyms:\n                seq_region[\"synonyms\"] = synonyms\n\n            attribs = get_attribs_dict(seqr)\n            if not attribs or \"toplevel\" not in attribs:\n                # Skip seq_region without attribs or not toplevel\n                continue\n            add_attribs(seq_region, attribs)\n\n            karyotype = get_karyotype(seqr)\n            if karyotype:\n                seq_region[\"karyotype_bands\"] = karyotype\n\n            added_seq = get_added_sequence(seqr)\n            if added_seq:\n                seq_region[\"added_sequence\"] = added_seq\n\n            if \"coord_system_level\" not in seq_region:\n                seq_region[\"coord_system_level\"] = coord_system.name\n\n            seq_regions.append(seq_region)\n\n    seq_regions = sorted(seq_regions, key=lambda seqr: (seqr[\"coord_system_level\"], seqr[\"name\"]))\n    return seq_regions\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.get_synonyms","title":"<code>get_synonyms(seq_region, external_db_map)</code>","text":"<p>Get all synonyms for a given seq_region. Use the mapping for synonym source names.</p> <p>Parameters:</p> Name Type Description Default <code>seq_region</code> <code>SeqRegion</code> <p>Seq_region from which the synonyms are extracted.</p> required <code>external_db_map</code> <code>dict[str, str]</code> <p>To map the synonym source names.</p> required <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of all synonyms as a dict with 'name' and 'source' keys.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def get_synonyms(seq_region: SeqRegion, external_db_map: dict[str, str]) -&gt; list[dict[str, str]]:\n    \"\"\"Get all synonyms for a given seq_region. Use the mapping for synonym source names.\n\n    Args:\n        seq_region: Seq_region from which the synonyms are extracted.\n        external_db_map: To map the synonym source names.\n\n    Returns:\n        List of all synonyms as a dict with 'name' and 'source' keys.\n    \"\"\"\n    synonyms = seq_region.seq_region_synonym\n    syns = []\n    if synonyms:\n        for syn in synonyms:\n            if syn.external_db:\n                source = syn.external_db.db_name\n                if source in external_db_map:\n                    source = external_db_map[source]\n                syn_obj = {\"name\": syn.synonym, \"source\": source}\n            else:\n                syn_obj = {\"name\": syn.synonym}\n            syns.append(syn_obj)\n\n    syns = sorted(syns, key=lambda syn: (syn[\"name\"], syn.get(\"source\", \"\")))\n    return syns\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/dump/#ensembl.io.genomio.seq_region.dump.main","title":"<code>main()</code>","text":"<p>Main script entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/dump.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main script entry-point.\"\"\"\n    parser = ArgumentParser(\n        description=\"Fetch all the sequence regions from a core database and print them in JSON format.\"\n    )\n    parser.add_server_arguments(include_database=True)\n    parser.add_argument_src_path(\n        \"--external_db_map\", default=DEFAULT_EXTERNAL_DB_MAP.resolve(), help=\"File with external_db mapping\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments(add_log_file=True)\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    dbc = DBConnectionLite(args.url)\n\n    external_map_path = Path(args.external_db_map)\n    external_map = get_external_db_map(external_map_path)\n\n    with dbc.session_scope() as session:\n        seq_regions = get_seq_regions(session, external_map)\n\n    print(json.dumps(seq_regions, indent=2, sort_keys=True))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/exceptions/","title":"exceptions","text":""},{"location":"reference/ensembl/io/genomio/seq_region/exceptions/#ensembl.io.genomio.seq_region.exceptions","title":"<code>ensembl.io.genomio.seq_region.exceptions</code>","text":"<p>Exceptions for sequence regions parsers.</p>"},{"location":"reference/ensembl/io/genomio/seq_region/exceptions/#ensembl.io.genomio.seq_region.exceptions.UnknownMetadata","title":"<code>UnknownMetadata</code>","text":"<p>               Bases: <code>Exception</code></p> <p>If a metadata is not supported or recognized.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/exceptions.py</code> <pre><code>class UnknownMetadata(Exception):\n    \"\"\"If a metadata is not supported or recognized.\"\"\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/gbff/","title":"gbff","text":""},{"location":"reference/ensembl/io/genomio/seq_region/gbff/#ensembl.io.genomio.seq_region.gbff","title":"<code>ensembl.io.genomio.seq_region.gbff</code>","text":"<p>A <code>SeqRecord</code> wrapper.</p>"},{"location":"reference/ensembl/io/genomio/seq_region/gbff/#ensembl.io.genomio.seq_region.gbff.GBFFRecord","title":"<code>GBFFRecord</code>  <code>dataclass</code>","text":"<p>Wrapper around a <code>SeqRecord</code> object to extract specific data.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/gbff.py</code> <pre><code>@dataclass\nclass GBFFRecord:\n    \"\"\"Wrapper around a `SeqRecord` object to extract specific data.\"\"\"\n\n    record: SeqRecord\n\n    def get_genbank_id(self) -&gt; str | None:\n        \"\"\"Returns the GenBank accession from a given sequence record (if present).\n\n        Only useful for RefSeq sequence records, where the GenBank accession is stored in a comment.\n\n        Args:\n            record: Sequence record.\n\n        \"\"\"\n        comment = str(self.record.annotations.get(\"comment\", \"\"))\n        if not comment:\n            return None\n        comment = re.sub(r\"[ \\n\\r]+\", \" \", comment)\n        match = re.search(r\"The reference sequence was derived from ([^\\.]+)\\.\", comment)\n        if not match:\n            return None\n        return match.group(1)\n\n    def get_codon_table(self) -&gt; int | None:\n        \"\"\"Returns the codon table number from a given a GenBank sequence record (if present).\"\"\"\n        for feat in self.record.features:\n            if \"transl_table\" in feat.qualifiers:\n                return int(feat.qualifiers[\"transl_table\"][0])\n        return None\n\n    def get_organelle(self, molecule_location: Mapping[str, str] = MOLECULE_LOCATION) -&gt; str | None:\n        \"\"\"Returns the organelle location from the given GenBank record (if present).\n\n        Args:\n            record: GenBank sequence record.\n            molecule_location: Map of sequence type to SO location.\n\n        Raises:\n            UnknownMetadata: If the location is not part of the controlled vocabulary.\n\n        \"\"\"\n        location = None\n        for feat in self.record.features:\n            if \"organelle\" not in feat.qualifiers:\n                continue\n            organelle = str(feat.qualifiers[\"organelle\"][0])\n            # Remove plastid prefix\n            with_prefix = re.match(r\"^(plastid|mitochondrion):(.+)$\", organelle)\n            if with_prefix:\n                organelle = with_prefix[2]\n            # Get controlled name\n            try:\n                location = molecule_location[organelle]\n            except KeyError as exc:\n                raise UnknownMetadata(f\"Unrecognized sequence location: {organelle}\") from exc\n            break\n        return location\n\n    def is_circular(self) -&gt; bool:\n        \"\"\"Returns True if the record says that the sequence is circular, False otherwise.\"\"\"\n        return self.record.annotations.get(\"topology\", \"\") == \"circular\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/gbff/#ensembl.io.genomio.seq_region.gbff.GBFFRecord.record","title":"<code>record</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/gbff/#ensembl.io.genomio.seq_region.gbff.GBFFRecord.get_codon_table","title":"<code>get_codon_table()</code>","text":"<p>Returns the codon table number from a given a GenBank sequence record (if present).</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/gbff.py</code> <pre><code>def get_codon_table(self) -&gt; int | None:\n    \"\"\"Returns the codon table number from a given a GenBank sequence record (if present).\"\"\"\n    for feat in self.record.features:\n        if \"transl_table\" in feat.qualifiers:\n            return int(feat.qualifiers[\"transl_table\"][0])\n    return None\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/gbff/#ensembl.io.genomio.seq_region.gbff.GBFFRecord.get_genbank_id","title":"<code>get_genbank_id()</code>","text":"<p>Returns the GenBank accession from a given sequence record (if present).</p> <p>Only useful for RefSeq sequence records, where the GenBank accession is stored in a comment.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <p>Sequence record.</p> required Source code in <code>src/python/ensembl/io/genomio/seq_region/gbff.py</code> <pre><code>def get_genbank_id(self) -&gt; str | None:\n    \"\"\"Returns the GenBank accession from a given sequence record (if present).\n\n    Only useful for RefSeq sequence records, where the GenBank accession is stored in a comment.\n\n    Args:\n        record: Sequence record.\n\n    \"\"\"\n    comment = str(self.record.annotations.get(\"comment\", \"\"))\n    if not comment:\n        return None\n    comment = re.sub(r\"[ \\n\\r]+\", \" \", comment)\n    match = re.search(r\"The reference sequence was derived from ([^\\.]+)\\.\", comment)\n    if not match:\n        return None\n    return match.group(1)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/gbff/#ensembl.io.genomio.seq_region.gbff.GBFFRecord.get_organelle","title":"<code>get_organelle(molecule_location=MOLECULE_LOCATION)</code>","text":"<p>Returns the organelle location from the given GenBank record (if present).</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <p>GenBank sequence record.</p> required <code>molecule_location</code> <code>Mapping[str, str]</code> <p>Map of sequence type to SO location.</p> <code>MOLECULE_LOCATION</code> <p>Raises:</p> Type Description <code>UnknownMetadata</code> <p>If the location is not part of the controlled vocabulary.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/gbff.py</code> <pre><code>def get_organelle(self, molecule_location: Mapping[str, str] = MOLECULE_LOCATION) -&gt; str | None:\n    \"\"\"Returns the organelle location from the given GenBank record (if present).\n\n    Args:\n        record: GenBank sequence record.\n        molecule_location: Map of sequence type to SO location.\n\n    Raises:\n        UnknownMetadata: If the location is not part of the controlled vocabulary.\n\n    \"\"\"\n    location = None\n    for feat in self.record.features:\n        if \"organelle\" not in feat.qualifiers:\n            continue\n        organelle = str(feat.qualifiers[\"organelle\"][0])\n        # Remove plastid prefix\n        with_prefix = re.match(r\"^(plastid|mitochondrion):(.+)$\", organelle)\n        if with_prefix:\n            organelle = with_prefix[2]\n        # Get controlled name\n        try:\n            location = molecule_location[organelle]\n        except KeyError as exc:\n            raise UnknownMetadata(f\"Unrecognized sequence location: {organelle}\") from exc\n        break\n    return location\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/gbff/#ensembl.io.genomio.seq_region.gbff.GBFFRecord.is_circular","title":"<code>is_circular()</code>","text":"<p>Returns True if the record says that the sequence is circular, False otherwise.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/gbff.py</code> <pre><code>def is_circular(self) -&gt; bool:\n    \"\"\"Returns True if the record says that the sequence is circular, False otherwise.\"\"\"\n    return self.record.annotations.get(\"topology\", \"\") == \"circular\"\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/mappings/","title":"mappings","text":""},{"location":"reference/ensembl/io/genomio/seq_region/mappings/#ensembl.io.genomio.seq_region.mappings","title":"<code>ensembl.io.genomio.seq_region.mappings</code>","text":"<p>Seq region mappings.</p>"},{"location":"reference/ensembl/io/genomio/seq_region/mappings/#ensembl.io.genomio.seq_region.mappings.LOCATION_CODON","title":"<code>LOCATION_CODON = MappingProxyType({'apicoplast_chromosome': 4})</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/mappings/#ensembl.io.genomio.seq_region.mappings.MOLECULE_LOCATION","title":"<code>MOLECULE_LOCATION = MappingProxyType({'apicoplast': 'apicoplast_chromosome', 'chromosome': 'nuclear_chromosome', 'kinetoplast': 'kinetoplast_chromosome', 'linkage group': 'linkage_group', 'mitochondrion': 'mitochondrial_chromosome', 'plasmid': 'plasmid'})</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/mappings/#ensembl.io.genomio.seq_region.mappings.SYNONYM_MAP","title":"<code>SYNONYM_MAP = MappingProxyType({'Assigned-Molecule': 'INSDC', 'GenBank-Accn': 'GenBank', 'RefSeq-Accn': 'RefSeq', 'Sequence-Name': 'INSDC_submitted_name'})</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/prepare/","title":"prepare","text":""},{"location":"reference/ensembl/io/genomio/seq_region/prepare/#ensembl.io.genomio.seq_region.prepare","title":"<code>ensembl.io.genomio.seq_region.prepare</code>","text":"<p>Construct a seq_region metadata file from INSDC files.</p>"},{"location":"reference/ensembl/io/genomio/seq_region/prepare/#ensembl.io.genomio.seq_region.prepare.main","title":"<code>main()</code>","text":"<p>Module's entry-point.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/prepare.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module's entry-point.\"\"\"\n    parser = ArgumentParser(description=\"Construct a sequence region metadata file from INSDC files.\")\n    parser.add_argument_src_path(\"--genome_file\", required=True, help=\"Genome metadata JSON file\")\n    parser.add_argument_src_path(\n        \"--report_file\", required=True, help=\"INSDC/RefSeq sequences report file to parse\"\n    )\n    parser.add_argument_src_path(\"--gbff_file\", help=\"INSDC/RefSeq GBFF file to parse\")\n    parser.add_argument_dst_path(\n        \"--dst_file\", default=\"seq_region.json\", help=\"Output JSON file for the processed sequence regions\"\n    )\n    parser.add_argument(\n        \"--to_exclude\", nargs=\"*\", metavar=\"SEQ_REGION_NAME\", help=\"Sequence region names to exclude\"\n    )\n    parser.add_argument(\"--mock_run\", action=\"store_true\", help=\"Do not call external APIs\")\n    parser.add_argument(\"--version\", action=\"version\", version=ensembl.io.genomio.__version__)\n    parser.add_log_arguments()\n    args = parser.parse_args()\n    init_logging_with_args(args)\n\n    prepare_seq_region_metadata(\n        genome_file=args.genome_file,\n        report_file=args.report_file,\n        dst_file=args.dst_file,\n        gbff_file=args.gbff_file,\n        to_exclude=args.to_exclude,\n        mock_run=args.mock_run,\n    )\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/prepare/#ensembl.io.genomio.seq_region.prepare.prepare_seq_region_metadata","title":"<code>prepare_seq_region_metadata(genome_file, report_file, dst_file, *, gbff_file=None, to_exclude=None, mock_run=False)</code>","text":"<p>Prepares the sequence region metadata found in the INSDC/RefSeq report and GBFF files.</p> <p>The sequence region information is loaded from both sources and combined. Elements are added/excluded as requested, and the final sequence region metadata is dumped in a JSON file that follows the schema defined in \"src/python/ensembl/io/genomio/data/schemas/seq_region.json\".</p> <p>Parameters:</p> Name Type Description Default <code>genome_file</code> <code>StrPath</code> <p>Genome metadata JSON file path.</p> required <code>report_file</code> <code>StrPath</code> <p>INSDC/RefSeq sequences report file path to parse.</p> required <code>gbff_file</code> <code>StrPath | None</code> <p>INSDC/RefSeq GBFF file path to parse.</p> <code>None</code> <code>dst_file</code> <code>StrPath</code> <p>JSON file output for the processed sequence regions JSON.</p> required <code>to_exclude</code> <code>list[str] | None</code> <p>Sequence region names to exclude.</p> <code>None</code> <code>mock_run</code> <code>bool</code> <p>Do not call external taxonomy service.</p> <code>False</code> Source code in <code>src/python/ensembl/io/genomio/seq_region/prepare.py</code> <pre><code>def prepare_seq_region_metadata(\n    genome_file: StrPath,\n    report_file: StrPath,\n    dst_file: StrPath,\n    *,\n    gbff_file: StrPath | None = None,\n    to_exclude: list[str] | None = None,\n    mock_run: bool = False,\n) -&gt; None:\n    \"\"\"Prepares the sequence region metadata found in the INSDC/RefSeq report and GBFF files.\n\n    The sequence region information is loaded from both sources and combined. Elements are added/excluded\n    as requested, and the final sequence region metadata is dumped in a JSON file that follows the schema\n    defined in \"src/python/ensembl/io/genomio/data/schemas/seq_region.json\".\n\n    Args:\n        genome_file: Genome metadata JSON file path.\n        report_file: INSDC/RefSeq sequences report file path to parse.\n        gbff_file: INSDC/RefSeq GBFF file path to parse.\n        dst_file: JSON file output for the processed sequence regions JSON.\n        to_exclude: Sequence region names to exclude.\n        mock_run: Do not call external taxonomy service.\n\n    \"\"\"\n    genome_data = get_json(genome_file)\n    dst_file = Path(dst_file)\n    is_refseq = genome_data[\"assembly\"][\"accession\"].startswith(\"GCF_\")\n\n    seqs = SeqCollection(mock=mock_run)\n    seqs.from_report(Path(report_file), is_refseq)\n    if gbff_file:\n        seqs.from_gbff(Path(gbff_file))\n\n    # Exclude seq_regions from a list\n    if to_exclude:\n        seqs.remove(to_exclude)\n\n    # Add translation and mitochondrial codon tables\n    seqs.add_translation_table()\n    seqs.add_mitochondrial_codon_table(genome_data[\"species\"][\"taxonomy_id\"])\n\n    # Print out the file\n    print_json(dst_file, seqs.to_list())\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/report/","title":"report","text":""},{"location":"reference/ensembl/io/genomio/seq_region/report/#ensembl.io.genomio.seq_region.report","title":"<code>ensembl.io.genomio.seq_region.report</code>","text":"<p>Object for an INSDC assembly report to expose its data and metadata easily.</p>"},{"location":"reference/ensembl/io/genomio/seq_region/report/#ensembl.io.genomio.seq_region.report.ReportRecord","title":"<code>ReportRecord</code>","text":"<p>Represent an assembly report file. Exposes 2 things: - Metadata as a dict from the comments. - A DictReader that yields all the seq_region lines of the report as dicts.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/report.py</code> <pre><code>class ReportRecord:\n    \"\"\"Represent an assembly report file. Exposes 2 things:\n    - Metadata as a dict from the comments.\n    - A DictReader that yields all the seq_region lines of the report as dicts.\n    \"\"\"\n\n    def __init__(self, report_path: Path) -&gt; None:\n        report_csv, metadata = self.report_to_csv(report_path)\n        self.metadata = metadata\n        self.reader = csv.DictReader(report_csv.splitlines(), delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n\n    @staticmethod\n    def report_to_csv(report_path: PathLike) -&gt; Tuple[str, dict]:\n        \"\"\"Returns an assembly report as a CSV string.\n\n        Args:\n            report_path: Path to a seq_region file from INSDC/RefSeq.\n\n        Returns:\n            The data as a string in CSV format, and the head metadata as a dictionary.\n\n        \"\"\"\n        with open_gz_file(report_path) as report:\n            data = \"\"\n            metadata = {}\n            header_line = \"\"\n            for line in report:\n                if line.startswith(\"#\"):\n                    # Get metadata values if possible\n                    match = re.search(\"# (.+?): (.+?)$\", line)\n                    if match:\n                        metadata[match.group(1)] = match.group(2)\n                    header_line = line\n                else:\n                    data += line\n\n            if not header_line:\n                raise ValueError(\"Missing header in report\")\n            data = header_line[2:].strip() + \"\\n\" + data\n\n            return data, metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/seq_region/report/#ensembl.io.genomio.seq_region.report.ReportRecord.metadata","title":"<code>metadata = metadata</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/report/#ensembl.io.genomio.seq_region.report.ReportRecord.reader","title":"<code>reader = csv.DictReader(report_csv.splitlines(), delimiter='\\t', quoting=(csv.QUOTE_NONE))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/io/genomio/seq_region/report/#ensembl.io.genomio.seq_region.report.ReportRecord.report_to_csv","title":"<code>report_to_csv(report_path)</code>  <code>staticmethod</code>","text":"<p>Returns an assembly report as a CSV string.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>PathLike</code> <p>Path to a seq_region file from INSDC/RefSeq.</p> required <p>Returns:</p> Type Description <code>Tuple[str, dict]</code> <p>The data as a string in CSV format, and the head metadata as a dictionary.</p> Source code in <code>src/python/ensembl/io/genomio/seq_region/report.py</code> <pre><code>@staticmethod\ndef report_to_csv(report_path: PathLike) -&gt; Tuple[str, dict]:\n    \"\"\"Returns an assembly report as a CSV string.\n\n    Args:\n        report_path: Path to a seq_region file from INSDC/RefSeq.\n\n    Returns:\n        The data as a string in CSV format, and the head metadata as a dictionary.\n\n    \"\"\"\n    with open_gz_file(report_path) as report:\n        data = \"\"\n        metadata = {}\n        header_line = \"\"\n        for line in report:\n            if line.startswith(\"#\"):\n                # Get metadata values if possible\n                match = re.search(\"# (.+?): (.+?)$\", line)\n                if match:\n                    metadata[match.group(1)] = match.group(2)\n                header_line = line\n            else:\n                data += line\n\n        if not header_line:\n            raise ValueError(\"Missing header in report\")\n        data = header_line[2:].strip() + \"\\n\" + data\n\n        return data, metadata\n</code></pre>"},{"location":"reference/ensembl/io/genomio/utils/","title":"utils","text":""},{"location":"reference/ensembl/io/genomio/utils/#ensembl.io.genomio.utils","title":"<code>ensembl.io.genomio.utils</code>","text":"<p>Utils module.</p>"},{"location":"reference/ensembl/io/genomio/utils/#ensembl.io.genomio.utils.get_json","title":"<code>get_json(src_path, **kwargs)</code>","text":"<p>Generic data JSON loader.</p> <p>Parameters:</p> Name Type Description Default <code>src_path</code> <code>StrPath</code> <p>Path to the JSON file to load.</p> required Source code in <code>src/python/ensembl/io/genomio/utils/json_utils.py</code> <pre><code>def get_json(src_path: StrPath, **kwargs: Any) -&gt; Any:\n    \"\"\"Generic data JSON loader.\n\n    Args:\n        src_path: Path to the JSON file to load.\n\n    \"\"\"\n    with Path(src_path).open(\"r\", encoding=\"utf-8\") as json_file:\n        return json.load(json_file, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/utils/#ensembl.io.genomio.utils.print_json","title":"<code>print_json(dst_path, data, **kwargs)</code>","text":"<p>Generic data JSON dumper to a file, with keys sorted and pretty-printed with indent 4 by default.</p> <p>Parameters:</p> Name Type Description Default <code>dst_path</code> <code>StrPath</code> <p>Path to the JSON file to create.</p> required <code>data</code> <code>Any</code> <p>Any data to store into the file.</p> required Source code in <code>src/python/ensembl/io/genomio/utils/json_utils.py</code> <pre><code>def print_json(dst_path: StrPath, data: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Generic data JSON dumper to a file, with keys sorted and pretty-printed with indent 4 by default.\n\n    Args:\n        dst_path: Path to the JSON file to create.\n        data: Any data to store into the file.\n\n    \"\"\"\n    kwargs.setdefault(\"sort_keys\", True)\n    kwargs.setdefault(\"indent\", 4)\n    with Path(dst_path).open(\"w\", encoding=\"utf-8\") as json_file:\n        json_file.write(json.dumps(data, **kwargs))\n</code></pre>"},{"location":"reference/ensembl/io/genomio/utils/json_utils/","title":"json_utils","text":""},{"location":"reference/ensembl/io/genomio/utils/json_utils/#ensembl.io.genomio.utils.json_utils","title":"<code>ensembl.io.genomio.utils.json_utils</code>","text":"<p>Utils to deal with JSON files.</p>"},{"location":"reference/ensembl/io/genomio/utils/json_utils/#ensembl.io.genomio.utils.json_utils.get_json","title":"<code>get_json(src_path, **kwargs)</code>","text":"<p>Generic data JSON loader.</p> <p>Parameters:</p> Name Type Description Default <code>src_path</code> <code>StrPath</code> <p>Path to the JSON file to load.</p> required Source code in <code>src/python/ensembl/io/genomio/utils/json_utils.py</code> <pre><code>def get_json(src_path: StrPath, **kwargs: Any) -&gt; Any:\n    \"\"\"Generic data JSON loader.\n\n    Args:\n        src_path: Path to the JSON file to load.\n\n    \"\"\"\n    with Path(src_path).open(\"r\", encoding=\"utf-8\") as json_file:\n        return json.load(json_file, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/io/genomio/utils/json_utils/#ensembl.io.genomio.utils.json_utils.print_json","title":"<code>print_json(dst_path, data, **kwargs)</code>","text":"<p>Generic data JSON dumper to a file, with keys sorted and pretty-printed with indent 4 by default.</p> <p>Parameters:</p> Name Type Description Default <code>dst_path</code> <code>StrPath</code> <p>Path to the JSON file to create.</p> required <code>data</code> <code>Any</code> <p>Any data to store into the file.</p> required Source code in <code>src/python/ensembl/io/genomio/utils/json_utils.py</code> <pre><code>def print_json(dst_path: StrPath, data: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Generic data JSON dumper to a file, with keys sorted and pretty-printed with indent 4 by default.\n\n    Args:\n        dst_path: Path to the JSON file to create.\n        data: Any data to store into the file.\n\n    \"\"\"\n    kwargs.setdefault(\"sort_keys\", True)\n    kwargs.setdefault(\"indent\", 4)\n    with Path(dst_path).open(\"w\", encoding=\"utf-8\") as json_file:\n        json_file.write(json.dumps(data, **kwargs))\n</code></pre>"}]}